Scopus
EXPORT DATE: 25 March 2024

@ARTICLE{Cassinadri2024,
	author = {Cassinadri, Guido},
	title = {ChatGPT and the Technology-Education Tension: Applying Contextual Virtue Epistemology to a Cognitive Artifact},
	year = {2024},
	journal = {Philosophy and Technology},
	volume = {37},
	number = {1},
	doi = {10.1007/s13347-024-00701-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183409431&doi=10.1007%2fs13347-024-00701-7&partnerID=40&md5=10ff1605e910f5fa43e4e52200797821},
	affiliations = {Scuola Superiore Sant’Anna, Piazza Martiri Della Libertà, 33, Pisa, 56127, Italy},
	abstract = {According to virtue epistemology, the main aim of education is the development of the cognitive character of students (Pritchard, 2014, 2016). Given the proliferation of technological tools such as ChatGPT and other LLMs for solving cognitive tasks, how should educational practices incorporate the use of such tools without undermining the cognitive character of students? Pritchard (2014, 2016) argues that it is possible to properly solve this ‘technology-education tension’ (TET) by combining the virtue epistemology framework with the theory of extended cognition (EXT) (Clark and Chalmers, 1998). He argues that EXT enables us to consider tools as constitutive parts of the students’ cognitive system, thus preserving their cognitive character from technologically induced cognitive diminishment. The first aim of this paper is to show that this solution is not sufficient to solve the TET. Second, I aim to offer a complementary and more encompassing framework of tool-use to address the TET. Then, I apply it to the educational uses of ChatGPT as the most notable example of LLM, although my arguments can be extended to other generative AI systems. To do so, in Sect. 1.1, I present Pritchard’s framework of cognitive character and virtue epistemology applied in education, to which I am committed in this treatment. In Sects. 2 and 3, I respectively illustrate Pritchard’s (2014) solution to the TET, and I highlight the general limitations of his proposal. Thus, in Sect. 4.1 I characterize ChatGPT as a computational cognitive artifact using Fasoli’s (Fasoli, 2017, 2018) taxonomy of cognitive artifacts. In Sect. 4.2, I introduce my proposal, which combines Pritchard’s account of virtue epistemology with Fasoli’s (2017, 2018) taxonomy of cognitive artifacts to address the TET. Finally, in Sect. 5.1, I present some epistemically virtuous uses of ChatGPT in educational contexts. To conclude, I argue in favor of a multidisciplinary approach for analyzing educational activities involving AI technologies such as ChatGPT. © 2024, The Author(s).},
	author_keywords = {AI; ChatGPT; Cognitive Artifacts; Cognitive Diminishment; Education; Extended Cognition; Generative AI; Virtue Epistemology},
	correspondence_address = {G. Cassinadri; Scuola Superiore Sant’Anna, Piazza Martiri Della Libertà, Pisa, 33, 56127, Italy; email: guido.cassinadri@santannapisa.it},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22105433},
	language = {English},
	abbrev_source_title = {Philos. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Dong20248,
	author = {Dong, Qifei and Chen, Xiangliang and Satyanarayanan, Mahadev},
	title = {Creating Edge AI from Cloud-based LLMs},
	year = {2024},
	journal = {HOTMOBILE 2024  - Proceedings of the 2024 25th International Workshop on Mobile Computing Systems and Applications},
	pages = {8 – 13},
	doi = {10.1145/3638550.3641126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187196987&doi=10.1145%2f3638550.3641126&partnerID=40&md5=df7a48dd3b5b759abbf1003a96e60dc1},
	affiliations = {Carnegie Mellon University, United States},
	abstract = {Cyber-human and cyber-physical systems have tight end-to-end latency bounds, typically on the order of a few tens of milliseconds. In contrast, cloud-based large-language models (LLMs) have end-to-end latencies that are two to three orders of magnitude larger. This paper shows how to bridge this large gap by using LLMs as offline compilers for creating task-specific code that avoids LLM accesses. We provide three case studies as proofs of concept, and discuss the challenges in generalizing this technique to broader uses. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Cloudlets; Drones; Edge Computing; Generative AI; Large Language Models; Machine Learning; Wearable Cognitive Assistance},
	keywords = {Computational linguistics; Edge computing; Embedded systems; Internet of things; Machine learning; Cloud-based; Cloudlet; Cognitive assistance; Edge computing; End to end latencies; Generative AI; Language model; Large language model; Machine-learning; Wearable cognitive assistance; Drones},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070497-0},
	language = {English},
	abbrev_source_title = {HOTMOBILE - Proc. Int. Workshop Mob. Comput. Syst. Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Abdullahi2024,
	author = {Abdullahi, Tassallah and Singh, Ritambhara and Eickhoff, Carsten},
	title = {Learning to Make Rare and Complex Diagnoses With Generative AI Assistance: Qualitative Study of Popular Large Language Models},
	year = {2024},
	journal = {JMIR Medical Education},
	volume = {10},
	number = {1},
	doi = {10.2196/51391},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186092843&doi=10.2196%2f51391&partnerID=40&md5=3073b268421dc28828f6922e8e112020},
	affiliations = {Department of Computer Science, Brown University, Providence, RI, United States; Center for Computational Molecular Biology, Brown University, Providence, RI, United States; School of Medicine, University of Tübingen, Tübingen, Germany},
	abstract = {Background: Patients with rare and complex diseases often experience delayed diagnoses and misdiagnoses because comprehensive knowledge about these diseases is limited to only a few medical experts. In this context, large language models (LLMs) have emerged as powerful knowledge aggregation tools with applications in clinical decision support and education domains. Objective: This study aims to explore the potential of 3 popular LLMs, namely Bard (Google LLC), ChatGPT-3.5 (OpenAI), and GPT-4 (OpenAI), in medical education to enhance the diagnosis of rare and complex diseases while investigating the impact of prompt engineering on their performance. Methods: We conducted experiments on publicly available complex and rare cases to achieve these objectives. We implemented various prompt strategies to evaluate the performance of these models using both open-ended and multiple-choice prompts. In addition, we used a majority voting strategy to leverage diverse reasoning paths within language models, aiming to enhance their reliability. Furthermore, we compared their performance with the performance of human respondents and MedAlpaca, a generative LLM specifically designed for medical tasks. Results: Notably, all LLMs outperformed the average human consensus and MedAlpaca, with a minimum margin of 5% and 13%, respectively, across all 30 cases from the diagnostic case challenge collection. On the frequently misdiagnosed cases category, Bard tied with MedAlpaca but surpassed the human average consensus by 14%, whereas GPT-4 and ChatGPT-3.5 outperformed MedAlpaca and the human respondents on the moderately often misdiagnosed cases category with minimum accuracy scores of 28% and 11%, respectively. The majority voting strategy, particularly with GPT-4, demonstrated the highest overall score across all cases from the diagnostic complex case collection, surpassing that of other LLMs. On the Medical Information Mart for Intensive Care-III data sets, Bard and GPT-4 achieved the highest diagnostic accuracy scores, with multiple-choice prompts scoring 93%, whereas ChatGPT-3.5 and MedAlpaca scored 73% and 47%, respectively. Furthermore, our results demonstrate that there is no one-size-fits-all prompting approach for improving the performance of LLMs and that a single strategy does not universally apply to all LLMs. Conclusions: Our findings shed light on the diagnostic capabilities of LLMs and the challenges associated with identifying an optimal prompting strategy that aligns with each language model's characteristics and specific task requirements. The significance of prompt engineering is highlighted, providing valuable insights for researchers and practitioners who use these language models for medical training. Furthermore, this study represents a crucial step toward understanding how LLMs can enhance diagnostic reasoning in rare and complex medical cases, paving the way for developing effective educational tools and accurate diagnostic aids to improve patient care and outcomes.  © Tassallah Abdullahi, Ritambhara Singh, Carsten Eickhoff.},
	author_keywords = {AI assistance; artificial intelligence; Bard; ChatGPT 3.5; clinical decision support; complex diagnosis; complex diseases; consistency; GPT-4; language model; MedAlpaca; medical education; medical training; natural language processing; prediction model; prompt engineering; rare diseases; reliability},
	correspondence_address = {C. Eickhoff; School of Medicine, University of Tübingen, Tübingen, Schaffhausenstr, 77, 72072, Germany; email: carsten.eickhoff@uni-tuebingen.de},
	publisher = {JMIR Publications Inc.},
	issn = {23693762},
	language = {English},
	abbrev_source_title = {JMIR Med. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access}
}

@ARTICLE{Yan20244747,
	author = {Yan, Ziming and Xu, Yan},
	title = {Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning},
	year = {2024},
	journal = {IEEE Transactions on Power Systems},
	volume = {39},
	number = {2},
	pages = {4747 – 4750},
	doi = {10.1109/TPWRS.2023.3338961},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179800752&doi=10.1109%2fTPWRS.2023.3338961&partnerID=40&md5=2e89286ed307a5f768aa0eccbc6395c8},
	affiliations = {Nanyang Technological University, School of Electrical and Electronic Engineering, 639798, Singapore},
	abstract = {Practical operations of a power system need to comply with Grid Codes, which are usually grounded in linguistic stipulations that may be hard to quantify in conventional optimal power flow (OPF) models. In the lights of recent breakthrough in large language models (LLM), this letter proposes an OPF model with linguistic stipulations and a solution method by integrating the generative pre-trained transformer (GPT) based LLM agent in the primal-dual deep reinforcement learning (DRL) training loop. For the first time, conventionally unquantifiable linguistic stipulations expressed in natural language can be directly modeled as the objectives and constraints in the OPF problem. The GPT-agent is used to interpret satisfactions of linguistic stipulations as rewards and constraints. The non-differentiable rewards obtained by GPT-agent are optimized through interactions with environments in the DRL process. Once sufficiently trained, the DRL agent can solve the OPF model in real-time. The proposed method is demonstrated on the IEEE 118-bus system.  © 1969-2012 IEEE.},
	author_keywords = {deep reinforcement learning; generative pre-trained transformer (GPT); large language models; Optimal power flow; qualitative objectives},
	keywords = {Acoustic generators; Deep learning; Electric load flow; Interactive computer systems; Linguistics; Real time systems; Code; Deep learning; Deep reinforcement learning; Generative pre-trained transformer; Language model; Large language model; Load flow; Optimal power flows; Qualitative objective; Real - Time system; Reinforcement learnings; Reinforcement learning},
	correspondence_address = {Y. Xu; Nanyang Technological University, School of Electrical and Electronic Engineering, 639798, Singapore; email: eeyanxu@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {08858950},
	coden = {ITPSE},
	language = {English},
	abbrev_source_title = {IEEE Trans Power Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Elyoseph2024,
	author = {Elyoseph, Zohar and Refoua, Elad and Asraf, Kfir and Lvovsky, Maya and Shimoni, Yoav and Hadar-Shoval, Dorit},
	title = {Capacity of Generative AI to Interpret Human Emotions From Visual and Textual Data: Pilot Evaluation Study},
	year = {2024},
	journal = {JMIR Mental Health},
	volume = {11},
	number = {1},
	doi = {10.2196/54369},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186111328&doi=10.2196%2f54369&partnerID=40&md5=909a728412153e28ad580a1d2a723abd},
	affiliations = {Department of Educational Psychology, The Center for Psychobiological Research, The Max Stern Yezreel Valley College, Emek Yezreel, Israel; Imperial College London, London, United Kingdom; Department of Psychology, Bar-Ilan University, Ramat Gan, Israel; Department of Psychology, The Max Stern Yezreel Valley College, Emek Yezreel, Israel; Boston Children’s Hospital, Boston, MA, United States},
	abstract = {Background: Mentalization, which is integral to human cognitive processes, pertains to the interpretation of one’s own and others’ mental states, including emotions, beliefs, and intentions. With the advent of artificial intelligence (AI) and the prominence of large language models in mental health applications, questions persist about their aptitude in emotional comprehension. The prior iteration of the large language model from OpenAI, ChatGPT-3.5, demonstrated an advanced capacity to interpret emotions from textual data, surpassing human benchmarks. Given the introduction of ChatGPT-4, with its enhanced visual processing capabilities, and considering Google Bard’s existing visual functionalities, a rigorous assessment of their proficiency in visual mentalizing is warranted. Objective: The aim of the research was to critically evaluate the capabilities of ChatGPT-4 and Google Bard with regard to their competence in discerning visual mentalizing indicators as contrasted with their textual-based mentalizing abilities. Methods: The Reading the Mind in the Eyes Test developed by Baron-Cohen and colleagues was used to assess the models’ proficiency in interpreting visual emotional indicators. Simultaneously, the Levels of Emotional Awareness Scale was used to evaluate the large language models’ aptitude in textual mentalizing. Collating data from both tests provided a holistic view of the mentalizing capabilities of ChatGPT-4 and Bard. Results: ChatGPT-4, displaying a pronounced ability in emotion recognition, secured scores of 26 and 27 in 2 distinct evaluations, significantly deviating from a random response paradigm (P<.001). These scores align with established benchmarks from the broader human demographic. Notably, ChatGPT-4 exhibited consistent responses, with no discernible biases pertaining to the sex of the model or the nature of the emotion. In contrast, Google Bard’s performance aligned with random response patterns, securing scores of 10 and 12 and rendering further detailed analysis redundant. In the domain of textual analysis, both ChatGPT and Bard surpassed established benchmarks from the general population, with their performances being remarkably congruent. Conclusions: ChatGPT-4 proved its efficacy in the domain of visual mentalizing, aligning closely with human performance standards. Although both models displayed commendable acumen in textual emotion interpretation, Bard’s capabilities in visual emotion interpretation necessitate further scrutiny and potential refinement. This study stresses the criticality of ethical AI development for emotional recognition, highlighting the need for inclusive data, collaboration with patients and mental health experts, and stringent governmental oversight to ensure transparency and protect patient privacy. © Zohar Elyoseph, Elad Refoua, Kfir Asraf, Maya Lvovsky, Yoav Shimoni, Dorit Hadar-Shoval.},
	author_keywords = {AI; algorithm; algorithms; artificial intelligence; ChatGPT; early detection; early warning; emotional awareness; emotional comprehension; emotional cue; emotional cues; empathy; large language model; large language models; LLM; LLMs; machine learning; mental disease; mental diseases; mental health; mental illness; mental illnesses; mentalization; mentalizing; practical model; practical models; predictive analytics; predictive model; predictive models; predictive system; Reading the Mind in the Eyes Test; RMET},
	keywords = {Article; Bard; benchmarking; ChatGPT; ChatGPT 4; controlled study; data interpretation; data validity; emotion; emotional awareness; facial expression; false discovery rate; female; generative artificial intelligence; human; information; linguistics; male; mentalization; pilot study; reliability; textual data; visual information},
	correspondence_address = {Z. Elyoseph; Imperial College London, London, Fulham Palace Road, W6 8RF, United Kingdom; email: zohar.j.a@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {23687959},
	language = {English},
	abbrev_source_title = {JMIR Ment. Heal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Luu2024,
	author = {Luu, Rachel K. and Buehler, Markus J.},
	title = {BioinspiredLLM: Conversational Large Language Model for the Mechanics of Biological and Bio-Inspired Materials},
	year = {2024},
	journal = {Advanced Science},
	volume = {11},
	number = {10},
	doi = {10.1002/advs.202306724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180443194&doi=10.1002%2fadvs.202306724&partnerID=40&md5=3c1f14b7571c7f547995d81baa7cefbf},
	affiliations = {Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Department of Materials Science and Engineering, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States; Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Avenue, Cambridge, 02139, MA, United States},
	abstract = {The study of biological materials and bio-inspired materials science is well established; however, surprisingly little knowledge is systematically translated to engineering solutions. To accelerate discovery and guide insights, an open-source autoregressive transformer large language model (LLM), BioinspiredLLM, is reported. The model is finetuned with a corpus of over a thousand peer-reviewed articles in the field of structural biological and bio-inspired materials and can be prompted to recall information, assist with research tasks, and function as an engine for creativity. The model has proven that it is able to accurately recall information about biological materials and is further strengthened with enhanced reasoning ability, as well as with Retrieval-Augmented Generation (RAG) to incorporate new data during generation that can also help to traceback sources, update the knowledge base, and connect knowledge domains. BioinspiredLLM also has shown to develop sound hypotheses regarding biological materials design and remarkably so for materials that have never been explicitly studied before. Lastly, the model shows impressive promise in collaborating with other generative artificial intelligence models in a workflow that can reshape the traditional materials design process. This collaborative generative artificial intelligence method can stimulate and enhance bio-inspired materials design workflows. Biological materials are at a critical intersection of multiple scientific fields and models like BioinspiredLLM help to connect knowledge domains. © 2023 The Authors. Advanced Science published by Wiley-VCH GmbH.},
	author_keywords = {bio-inspiration; biological materials; generative artificial intelligence; hierarchical structures; large language models; mechanical properties},
	keywords = {Artificial Intelligence; Biomimetic Materials; Engineering; Language; Biomechanics; Biomimetics; Computational linguistics; Degrees of freedom (mechanics); Knowledge based systems; Structural design; biomimetic material; Bio-inspiration; Bio-inspired materials; Engineering solutions; Generative artificial intelligence; Hierarchical structures; Knowledge domains; Language model; Large language model; Material science; Materials design; artificial intelligence; chemistry; engineering; language; Biological materials},
	correspondence_address = {M.J. Buehler; Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, Cambridge, 77 Massachusetts Avenue, 02139, United States; email: mbuehler@mit.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {21983844},
	pmid = {38145334},
	language = {English},
	abbrev_source_title = {Adv. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Patil2024343,
	author = {Patil, Megharani and Yadav, Hrishikesh and Gawali, Mahendra and Suryawanshi, Jaya and Patil, Jaikumar and Yeole, Anjali and Shetty, Prathik and Potlabattini, Jayesh},
	title = {A Novel Approach to Fake News Detection Using Generative AI},
	year = {2024},
	journal = {International Journal of Intelligent Systems and Applications in Engineering},
	volume = {12},
	number = {4s},
	pages = {343 – 354},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179672909&partnerID=40&md5=60f0ac0d87f03e107c090328338387c5},
	affiliations = {Thakur College of Engineering and Technology, Maharashtra, Mumbai, India; Sanjivani College of Engineering, Maharashtra, Pune, India; MVPS’s KBT COE, Maharashtra, Nashik, India; Shri Sant Gajanan Maharaja College of Engineering, Maharashtra, Shegaon, India; Vivekanand Education Society's Institute of Technology, Maharashtra, Mumbai, India},
	abstract = {Fake news has a significant impact on society, making the detection of such misinformation crucial. It undermines trust in reliable information sources, distorts public opinions, and can even influence political outcomes. Detecting fake news is important to ensure that users receive accurate and authentic information, maintain a trustworthy news ecosystem, and prevent the spread of misinformation. Directly classifying a fake news to be fake on some parameters is not possible. Here, the news article will be evaluated on the main three parameters, first is Text Analytics which includes identifying the exaggerated or propagandistic statements or the type of speech is been used in the article like acceptable, non acceptable, offensive, etc. and also through summarization, we get the context about the article, second is user behaviour through twitter analytics guides to understand the user reaction towards the article on the real time basis and at last, through indexing the authentic source in the index of Large Language Model build using LlamaIndex. This methodology integrated with the whatsapp bot showcased the better result to identify the fake news and ensure the user that the news is authentic or not. © 2024, Ismail Saritas. All rights reserved.},
	author_keywords = {Article summarization; Authentic sources; Detection; Fake news; Large Language Model (LLM); LlamaIndex; Misinformation; Reliable information; Text analytics; Twitter analytics; User behaviour; WhatsApp bot},
	correspondence_address = {M. Patil; Thakur College of Engineering and Technology, Mumbai, Maharashtra, India; email: megharani.patil@thakureducation.org},
	publisher = {Ismail Saritas},
	issn = {21476799},
	language = {English},
	abbrev_source_title = {Internat. J. Intel. Syst. Appl. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mira20242087,
	author = {Mira, Felipe Ahumada and Favier, Valentin and dos Santos Sobreira Nunes, Heloisa and de Castro, Joana Vaz and Carsuzaa, Florent and Meccariello, Giuseppe and Vicini, Claudio and De Vito, Andrea and Lechien, Jerome R. and Chiesa-Estomba, Carlos and Maniaci, Antonino and Iannella, Giannicola and Rojas, Eduardo Peña and Cornejo, Jenifer Barros and Cammaroto, Giovanni},
	title = {Chat GPT for the management of obstructive sleep apnea: do we have a polar star?},
	year = {2024},
	journal = {European Archives of Oto-Rhino-Laryngology},
	volume = {281},
	number = {4},
	pages = {2087 – 2093},
	doi = {10.1007/s00405-023-08270-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177061873&doi=10.1007%2fs00405-023-08270-9&partnerID=40&md5=eb132aa7922751162b207a40d194462b},
	affiliations = {ENT Department, Hospital of Linares, Linares, Chile; ENT Department, University Hospital of Montpellier, Montpellier, France; ENT and Sleep Medicine Department, Nucleus of Otolaryngology, Head and Neck Surgery and Sleep Medicine of São Paulo, São Paulo, Brazil; ENT Department, Armed Forces Hospital, Lisbon, Portugal; ENT Department, University Hospital of Poitiers, Poitiers, France; Head and Neck Department, ENT & Oral Surgery Unity, G.B. Morgagni, L. Pierantoni Hospital, Via Forlanini, Forlì, 47121, Italy; Division of Laryngology and Broncho-Esophagology, Department of Otolaryngology and Head and Neck Surgery, EpiCURA Hospital, UMONS Research Institute for Health Sciences and Technology, University of Mons, Mons, Belgium; Department of Otorhinolaryngology, Biodonostia Research Institute, Donostia University Hospital, Osakidetza, San Sebastian, 20014, Spain; Department of Medical and Surgical Sciences and Advanced Technologies “GF Ingrassia”, ENT Section, University of Catania, Piazza Università 2, Catania, 95100, Italy; Department of ‘Organi di Senso’, University “Sapienza”, Viale Dell’Università 33, Rome, 00185, Italy; Clínica Lircay, Talca, Chile; Hospital Clínico UC Christus, Santiago, Chile; Young Otolaryngologists-International Federations of Oto-Rhinolaryngological Societies (YO-IFOS), Paris, France},
	abstract = {Purpose: This study explores the potential of the Chat-Generative Pre-Trained Transformer (Chat-GPT), a Large Language Model (LLM), in assisting healthcare professionals in the diagnosis of obstructive sleep apnea (OSA). It aims to assess the agreement between Chat-GPT's responses and those of expert otolaryngologists, shedding light on the role of AI-generated content in medical decision-making. Methods: A prospective, cross-sectional study was conducted, involving 350 otolaryngologists from 25 countries who responded to a specialized OSA survey. Chat-GPT was tasked with providing answers to the same survey questions. Responses were assessed by both super-experts and statistically analyzed for agreement. Results: The study revealed that Chat-GPT and expert responses shared a common answer in over 75% of cases for individual questions. However, the overall consensus was achieved in only four questions. Super-expert assessments showed a moderate agreement level, with Chat-GPT scoring slightly lower than experts. Statistically, Chat-GPT's responses differed significantly from experts' opinions (p = 0.0009). Sub-analysis revealed areas of improvement for Chat-GPT, particularly in questions where super-experts rated its responses lower than expert consensus. Conclusions: Chat-GPT demonstrates potential as a valuable resource for OSA diagnosis, especially where access to specialists is limited. The study emphasizes the importance of AI-human collaboration, with Chat-GPT serving as a complementary tool rather than a replacement for medical professionals. This research contributes to the discourse in otolaryngology and encourages further exploration of AI-driven healthcare applications. While Chat-GPT exhibits a commendable level of consensus with expert responses, ongoing refinements in AI-based healthcare tools hold significant promise for the future of medicine, addressing the underdiagnosis and undertreatment of OSA and improving patient outcomes. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2023. corrected publication 2024.},
	author_keywords = {Chat-Gpt; Chatbot; OSA; Sleep apnea},
	keywords = {Alanine Transaminase; Clinical Decision-Making; Cross-Sectional Studies; Humans; Prospective Studies; Sleep Apnea, Obstructive; alanine aminotransferase; clinical decision making; cross-sectional study; human; prospective study; sleep apnea syndromes},
	correspondence_address = {G. Cammaroto; Head and Neck Department, ENT & Oral Surgery Unity, G.B. Morgagni, L. Pierantoni Hospital, Forlì, Via Forlanini, 47121, Italy; email: giovanni.cammaroto@hotmail.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09374477},
	coden = {EAOTE},
	pmid = {37980605},
	language = {English},
	abbrev_source_title = {Eur. Arch. Oto-Rhino-Laryngol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Raman2024,
	author = {Raman, Raghu and Calyam, Prasad and Achuthan, Krishnashree},
	title = {ChatGPT or Bard: Who is a better Certified Ethical Hacker?},
	year = {2024},
	journal = {Computers and Security},
	volume = {140},
	doi = {10.1016/j.cose.2024.103804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187237810&doi=10.1016%2fj.cose.2024.103804&partnerID=40&md5=1c6ee94bcb8445210d79c5f26522630d},
	affiliations = {Amrita School of Business, Amrita Vishwa Vidyapeetham, Kerala, Amritapuri, 690525, India; University of Missouri, Columbia, 65211, MO, United States; Center for Cybersecurity Systems and Networks, Amrita Vishwa Vidyapeetham, Kerala, Amritapuri, 690525, India},
	abstract = {In this study, we compare two leading Generative AI (GAI) tools, ChatGPT and Bard, specifically in Cybersecurity, using a robust set of standardized questions from a validated Certified Ethical Hacking (CEH) dataset. In the rapidly evolving domain of Generative AI (GAI) and large language models (LLM), a comparative analysis of tools becomes essential to measure their performance. We determine the Comprehensiveness, Clarity, and Conciseness of the AI-generated responses through a detailed questioning-based framework. The study revealed an overall accuracy rate of 80.8 % for ChatGPT and 82.6 % for Bard, indicating comparable capabilities and specific differences. Bard slightly outperformed ChatGPT in accuracy, while ChatGPT exhibited superiority in Comprehensiveness, Clarity, and Conciseness of responses. Introducing a confirmation query like “Are you sure?” increased accuracy for both generative AI tools, illustrating the potential of iterative query processing in enhancing GAI tools' effectiveness. The readability evaluation placed both tools at a college reading level, with Bard marginally more accessible. While evaluating certain questions, a distinct pattern emerged where Bard provided generic denials of assistance while ChatGPT referenced “ethics.” This discrepancy illustrates the contrasting philosophies of the developers of these tools, with Bard possibly following stricter guidelines, especially in sensitive topics like Cybersecurity. We explore the implications and identify key areas for future research that become increasingly relevant as GAI tools see broader adoption. © 2024 The Author(s)},
	author_keywords = {Cybersecurity generative ai; Ethical hacking; Policy; Readability; Similarity analysis; Social behavior},
	keywords = {Philosophical aspects; Social behavior; Comparative analyzes; Cyber security; Cybersecurity generative ai; Ethical hacking; Language model; Overall accuracies; Performance; Readability; Similarity analysis; Social behaviour; Personal computing},
	correspondence_address = {R. Raman; Amrita School of Business, Amrita Vishwa Vidyapeetham, Amritapuri, Kerala, 690525, India; email: raghu@amrita.edu},
	publisher = {Elsevier Ltd},
	issn = {01674048},
	coden = {CPSED},
	language = {English},
	abbrev_source_title = {Comput Secur},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Amirova2024,
	author = {Amirova, Aliya and Fteropoulli, Theodora and Ahmed, Nafiso and Cowie, Martin R. and Leibo, Joel Z.},
	title = {Framework-based qualitative analysis of free responses of Large Language Models: Algorithmic fidelity},
	year = {2024},
	journal = {PLoS ONE},
	volume = {19},
	number = {3 March},
	doi = {10.1371/journal.pone.0300024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187705186&doi=10.1371%2fjournal.pone.0300024&partnerID=40&md5=d01a80223a9a836897db65f7410668e7},
	affiliations = {Population Health Sciences, School of Life Course & Population Sciences, Faculty of Life Sciences & Medicine, King’s College London, London, United Kingdom; Medical School, University of Cyprus, Nicosia, Cyprus; Division of Psychiatry, University College London, London, United Kingdom; Royal Brompton Hospital, London, London, United Kingdom; School of Cardiovascular Medicine & Sciences, Faculty of Life Sciences & Medicine, King’s College London, London, United Kingdom; Google DeepMind, London, London, United Kingdom; Department of Informatics, Faculty of Natural, Mathematical & Engineering Sciences, King’s College London, London, United Kingdom},
	abstract = {Today, with the advent of Large-scale generative Language Models (LLMs) it is now possible to simulate free responses to interview questions such as those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial “silicon participants” generated by LLMs may be productively studied using qualitative analysis methods in such a way as to generate insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a validity concept capturing the degree to which LLM-generated outputs mirror human sub-populations’ beliefs and attitudes. By definition, high algorithmic fidelity suggests that latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews with “silicon participants” matching specific demographic characteristics one-for-one with a set of human participants. Using framework-based qualitative analysis, we showed the key themes obtained from both human and silicon participants were strikingly similar. However, when we analyzed the structure and tone of the interviews we found even more striking differences. We also found evidence of a hyper-accuracy distortion. We conclude that the LLM we tested (GPT-3.5) does not have sufficient algorithmic fidelity to expect in silico research on it to generalize to real human populations. However, rapid advances in artificial intelligence raise the possibility that algorithmic fidelity may improve in the future. Thus we stress the need to establish epistemic norms now around how to assess the validity of LLM-based qualitative research, especially concerning the need to ensure the representation of heterogeneous lived experiences. Copyright: © 2024 Amirova et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Artificial Intelligence; Caffeine; Communication; Humans; Language; Silicon; caffeine; silicon; artificial intelligence; human; interpersonal communication; language},
	correspondence_address = {A. Amirova; Population Health Sciences, School of Life Course & Population Sciences, Faculty of Life Sciences & Medicine, King’s College London, London, United Kingdom; email: aliya.1.amirova@kcl.ac.uk},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {38470890},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Pan20241,
	author = {Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
	title = {Unifying Large Language Models and Knowledge Graphs: A Roadmap},
	year = {2024},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	pages = {1–20},
	doi = {10.1109/TKDE.2024.3352100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182350576&doi=10.1109%2fTKDE.2024.3352100&partnerID=40&md5=96523fd500b93b54566f08f6d7695d1b},
	affiliations = {School of Information and Communication Technology and Institute for Integrated and Intelligent Systems (IIIS), Griffith University, Queensland, Australia; Department of Data Science and AI, Monash University, Melbourne, Australia; Nanyang Technological University, Singapore; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Key Laboratory of Knowledge Engineering with Big Data (the Ministry of Education of China), Hefei University of Technology, Hefei, China},
	abstract = {Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, <italic>1) KG-enhanced LLMs,</italic> which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; <italic>2) LLM-augmented KGs,</italic> that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and <italic>3) Synergized LLMs + KGs</italic>, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions. IEEE},
	author_keywords = {Bidirectional reasoning; Chatbots; Cognition; Decoding; generative pre-training; Knowledge graphs; knowledge graphs; large language models; natural language processing; Predictive models; roadmap; Task analysis; Training},
	keywords = {Computational linguistics; Graphic methods; Job analysis; Knowledge management; Natural language processing systems; Bidirectional reasoning; Chatbots; Cognition; Decoding; Generative pre-training; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Pre-training; Predictive models; Roadmap; Task analysis; Knowledge graph},
	publisher = {IEEE Computer Society},
	issn = {10414347},
	coden = {ITKEE},
	language = {English},
	abbrev_source_title = {IEEE Trans Knowl Data Eng},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Sindhwad2024,
	author = {Sindhwad, Parul V. and Ranka, Prateek and Muni, Siddhi and Kazi, Faruk},
	title = {VulnArmor: mitigating software vulnerabilities with code resolution and detection techniques},
	year = {2024},
	journal = {International Journal of Information Technology (Singapore)},
	doi = {10.1007/s41870-024-01775-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187927029&doi=10.1007%2fs41870-024-01775-4&partnerID=40&md5=137cd4daac6a13313dee904a895b4d9a},
	affiliations = {Department of Electrical Engineering, Veermata Jijabai Technological Institute, Mumbai, 400019, India; D.J. Sanghvi College of Engineering, Mumbai, India},
	abstract = {In today’s swiftly evolving digital environment, the security and dependability of software applications are crucial. In light of industries’ increasing reliance on software, identifying and mitigating vulnerabilities is essential for protecting data, systems, and user trust. With data-driven methodologies, there is increased interest in using Artificial Intelligence (AI) and Machine Learning (ML) for software assurance to construct trustworthy software systems. This research addresses the urgent need for an automated and comprehensive approach to code resolution and vulnerability detection, providing a robust solution to improve software security and reduce potential risks. Code resolution is implemented by fine-tuning Large Language Models (LLM) like Generative Pre-Trained Transformers (GPT)-2, Text-to-Text Transfer Transformers (T5), Bidirectional Encoder Representations from Transformers (BERT), and Large Language Model Meta AI (LLaMA). Secondly, vulnerable code detection plays a crucial role in evaluating the correctness of resolved code and identifying any remaining vulnerabilities. This essential step not only validates the efficacy of code resolution but also identifies areas where additional mitigation efforts are required. Utilizing Deep Learning (DL) models, the top performer of the study, Convolutional Neural Network (CNN), achieved a remarkable 93% accuracy rate, demonstrating its prowess in protecting software applications against potential attacks. © The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management 2024.},
	author_keywords = {Code resolution; Convolutional neural network (CNN); Large language models (LLMs); Software security; Vulnerability detection},
	correspondence_address = {P.V. Sindhwad; Department of Electrical Engineering, Veermata Jijabai Technological Institute, Mumbai, 400019, India; email: pvsindhwad_p21@el.vjti.ac.in},
	publisher = {Springer Science and Business Media B.V.},
	issn = {25112104},
	language = {English},
	abbrev_source_title = {Int. J. Inf. Technol.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus}
}

@ARTICLE{Zaki2024,
	author = {Zaki, Hossam A. and Aoun, Andrew and Munshi, Saminah and Abdel-Megid, Hazem and Nazario-Johnson, Lleayem and Ahn, Sun Ho},
	title = {The Application of Large Language Models for Radiologic Decision Making},
	year = {2024},
	journal = {Journal of the American College of Radiology},
	doi = {10.1016/j.jacr.2024.01.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186191231&doi=10.1016%2fj.jacr.2024.01.007&partnerID=40&md5=8dc76a90b95b36501956c6ab3ee83b8b},
	affiliations = {Department of Diagnostic Imaging, The Warren Alpert Medical School of Brown University/Rhode Island Hospital, Providence, Rhode Island, United States; Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Columbia, University Medical Center, New York, New York, United States; Professor of Diagnostic Imaging;, Interventional Radiology Integrated Residency Program Director, Medical Student Radiology Education Co-Director, Department of Diagnostic Imaging, The Warren Alpert Medical School of Brown University/Rhode Island Hospital, Providence, Rhode Island, United States},
	abstract = {Background and purpose: Large language models (LLMs) have seen explosive growth, but their potential role in medical applications remains underexplored. Our study investigates the capability of LLMs to predict the most appropriate imaging study for specific clinical presentations in various subspecialty areas in radiology. Methods and materials: Chat Generative Pretrained Transformer (ChatGPT), by OpenAI and Glass AI by Glass Health were tested on 1,075 clinical scenarios from 11 ACR expert panels to determine the most appropriate imaging study, benchmarked against the ACR Appropriateness Criteria. Two responses per clinical presentation were generated and averaged for the final clinical presentation score. Clinical presentation scores for each topic area were averaged as its final score. The average of the topic scores within a panel determined the final score of each panel. LLM responses were on a scale of 0 to 3. Partial scores were given for nonspecific answers. Pearson correlation coefficient (R-value) was calculated for each panel to determine a context-specific performance. Results: Glass AI scored significantly higher than ChatGPT (2.32 ± 0.67 versus 2.08 ± 0.74, P = .002). Both LLMs performed the best in the Polytrauma, Breast, and Vascular panels, and performed the worst in the Neurologic, Musculoskeletal, and Cardiac panels. Glass AI outperformed ChatGPT in 10 of 11 panels, except Obstetrics and Gynecology. Maximum agreement was in the Pediatrics, Neurologic, and Thoracic panels, and the most disagreement occurred in the Vascular, Breast, and Urologic panels. Conclusion: LLMs can be used to predict imaging studies, with Glass AI's superior performance indicating the benefits of extra medical-text training. This supports the potential of LLMs in radiologic decision making. © 2024 American College of Radiology},
	author_keywords = {Artificial intelligence; ChatGPT; clinical decision making},
	correspondence_address = {H.A. Zaki; Brown University Warren Alpert Medical School, Department of Diagnostic Imaging, Providence, 222 Richmond St, 02903, United States; email: hossam_zaki@brown.edu},
	publisher = {Elsevier B.V.},
	issn = {15461440},
	pmid = {38224925},
	language = {English},
	abbrev_source_title = {J. Am. Coll. Radiol.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus}
}

@ARTICLE{Ni2024,
	author = {Ni, Bo and Buehler, Markus J.},
	title = {MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge},
	year = {2024},
	journal = {Extreme Mechanics Letters},
	volume = {67},
	doi = {10.1016/j.eml.2024.102131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185307555&doi=10.1016%2fj.eml.2024.102131&partnerID=40&md5=8d8520113f0544792728b07b79d75fc5},
	affiliations = {Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, 02139, MA, United States; Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, 02139, MA, United States},
	abstract = {Solving mechanics problems using numerical methods requires comprehensive intelligent capability of retrieving relevant knowledge and theory, constructing and executing codes, analyzing the results, a task that has thus far mainly been reserved for humans. While emerging AI methods can provide effective approaches to solve end-to-end problems, for instance via the use of deep surrogate models or various data analytics strategies, they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights. By leveraging diverse capabilities of multiple dynamically interacting large language models (LLMs), we can overcome the limitations of conventional approaches and develop a new class of physics-inspired generative machine learning platform, here referred to as MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for elasticity problems, via autonomous collaborations. A two-agent team can effectively write, execute and self-correct code, in order to apply finite element methods to solve classical elasticity problems in various flavors (different boundary conditions, domain geometries, meshes, small/finite deformation and linear/hyper-elastic constitutive laws, and others). For more complex tasks, we construct a larger group of agents with enhanced division of labor among planning, formulating, coding, executing and criticizing the process and results. The agents mutually correct each other to improve the overall team-work performance in understanding, formulating and validating the solution. Our framework shows the potential of synergizing the intelligence of language models, the reliability of physics-based modeling, and the dynamic collaborations among diverse agents, opening novel avenues for automation of solving engineering problems. © 2024 Elsevier Ltd},
	author_keywords = {Elasticity; Finite element method; GPT-4; Hyper-elasticity; Large language model (LLM); Multi-agent modeling; Physics-inspired machine learning},
	keywords = {Autonomous agents; Computational linguistics; Computational methods; Data Analytics; Finite element method; Machine learning; Modeling languages; Numerical methods; Agent collaboration; Elasticity problems; GPT-4; Hyper-elasticity; Language model; Large language model; Machine-learning; Multi agent; Multi-Agent Model; Physic-inspired machine learning; Elasticity},
	correspondence_address = {M.J. Buehler; Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, Cambridge, 77 Massachusetts Ave, 02139, United States; email: mbuehler@MIT.EDU},
	publisher = {Elsevier Ltd},
	issn = {23524316},
	language = {English},
	abbrev_source_title = {Extrem. Mech. Lett.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Prather2023108,
	author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
	title = {The Robots are Here: Navigating the Generative AI Revolution in Computing Education},
	year = {2023},
	journal = {ITiCSE-WGR 2023 - Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
	pages = {108 – 159},
	doi = {10.1145/3623762.3633499},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177810142&doi=10.1145%2f3623762.3633499&partnerID=40&md5=34edcecea3a1c30c23c2148fce733934},
	affiliations = {Abilene Christian University, Abilene, TX, United States; University of Auckland, Auckland, New Zealand; University College Dublin, Dublin, Ireland; Princess Sumaya University for Technology, Amman, Jordan; University of Toronto, Toronto, Canada; Utrecht University, Utrecht, Netherlands; DIPF Leibniz Institute for Research and Information in Education, Frankfurt am Main, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Temple University, Philadelphia, PA, United States; University of Toronto Mississauga, Mississauga, Canada; University of Virginia, Charlottesville, VA, United States; Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving. There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms. © 2023 Copyright held by the owner/author(s).},
	author_keywords = {AI; artificial intelligence; ChatGPT; code generation; Codex; computer programming; Copilot; CS1; curriculum; Generative AI; GitHub; GPT; GPT-3; GPT-4; large language models; LLM; LLMs; novice programming; OpenAI; pedagogical practices; programming},
	keywords = {Benchmarking; Codes (symbols); Computational linguistics; Education computing; Ethical technology; Knowledge management; Robot programming; Students; ChatGPT; Codegeneration; Codex; Copilot; Generative artificial intelligence; Github; GPT; GPT-3; GPT-4; Language model; Large language model; Novice programming; Openai; Pedagogical practices; Programming; Curricula},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070405-5},
	language = {English},
	abbrev_source_title = {ITiCSE-WGR - Proc. Working Group Reports Innov. Technol. Comput. Scie. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Radwan2024,
	author = {Radwan, Ahmad and Amarneh, Mohannad and Alawneh, Hussam and Ashqar, Huthaifa I. and AlSobeh, Anas and Magableh, Aws Abed Al Raheem},
	title = {Predictive Analytics in Mental Health Leveraging LLM Embeddings and Machine Learning Models for Social Media Analysis},
	year = {2024},
	journal = {International Journal of Web Services Research},
	volume = {21},
	number = {1},
	doi = {10.4018/IJWSR.338222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185726145&doi=10.4018%2fIJWSR.338222&partnerID=40&md5=7fe6c4ee210802479e554f35396a299b},
	affiliations = {Arab American University, Palestine; Southern Illinois University, Carbondale, United States; Yarmouk University, Jordan & Prince Sultan University, Saudi Arabia},
	abstract = {The prevalence of stress-related disorders has increased significantly in recent years, necessitating scalable methods to identify affected individuals. This paper proposes a novel approach utilizing large language models (LLMs), with a focus on OpenAI’s generative pre-trained transformer (GPT-3) embeddings and machine learning (ML) algorithms to classify social media posts as indicative or not of stress disorders. The aim is to create a preliminary screening tool leveraging online textual data. GPT-3 embeddings transformed posts into vector representations capturing semantic meaning and linguistic nuances. Various models, including support vector machines, random forests, XGBoost, KNN, and neural networks, were trained on a dataset of >10,000 labeled social media posts. The top model, a support vector machine, achieved 83% accuracy in classifying posts displaying signs of stress. © 2024 IGI Global. All rights reserved.},
	author_keywords = {Design; Generative Pre-Trained Transformer (GPT-3); Large Language Models (LLM); Machine Learning (ML); Mental Health; Social Media Analysis; Stress Disorder Identification; System Analysis},
	keywords = {Computational linguistics; Embeddings; Forestry; Predictive analytics; Scalability; Semantics; Social networking (online); Embeddings; Generative pre-trained transformer (GPT-3); Language model; Large language model; Machine learning; Machine-learning; Mental health; Social media analysis; Stress disorder identification; Stress disorders; Support vector machines},
	publisher = {IGI Global},
	issn = {15457362},
	language = {English},
	abbrev_source_title = {Int. J. Web Serv. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Bronze Open Access}
}

@ARTICLE{Ding2024298,
	author = {Ding, Shiyao and Ito, Takayuki},
	title = {Self-agreement: A Framework for Fine-Tuning Language Models to Find Agreement Among Diverse Opinions},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14326 LNAI},
	pages = {298 – 309},
	doi = {10.1007/978-981-99-7022-3_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177449428&doi=10.1007%2f978-981-99-7022-3_26&partnerID=40&md5=d997fbb0776f9c0e0c54f27f54eb6140},
	affiliations = {Kyoto University, Kyoto-shi, Kyoto, 606-8501, Japan},
	abstract = {Finding an agreement among diverse opinions is a challenging topic in social intelligence. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a pre-trained LLM for discovering agreements among diverse opinions. Remarkably, a pre-trained LLM fine-tuned by our Self-Agreement framework achieves comparable performance to GPT-3 with only 1/25 of its parameters, showcasing its ability to identify agreement among various opinions without the need for human-annotated data. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2024.},
	author_keywords = {Consensus building; Large language models; Opinion summarization; Social intelligence},
	keywords = {Economic and social effects; Consensus buildings; Fine tuning; Human like; Language model; Large language model; Opinion summarization; Performance; Process yield; Social intelligence; Computational linguistics},
	correspondence_address = {S. Ding; Kyoto University, Kyoto, Kyoto-shi, 606-8501, Japan; email: ding@i.kyoto-u.ac.jp},
	editor = {Liu F. and Sadanandan A.A. and Pham D.N. and Mursanto P. and Lukose D.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981997021-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Verma202436,
	author = {Verma, Mudit and Bhambri, Siddhant and Kambhampati, Subbarao},
	title = {Theory of Mind abilities of Large Language Models in Human-Robot Interaction: An Illusion?},
	year = {2024},
	journal = {ACM/IEEE International Conference on Human-Robot Interaction},
	pages = {36 – 45},
	doi = {10.1145/3610978.3640767},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188097509&doi=10.1145%2f3610978.3640767&partnerID=40&md5=5af5e343939ab25365490a9ea41eb518},
	affiliations = {Arizona State University, School of Computing and Augmented Intelligence, Tempe, United States},
	abstract = {Large Language Models (LLMs) have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of LLMs especially on Theory of Mind (ToM) abilities in Large Language Models. While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences: Human Robot Interaction. In this work, we explore the task of Perceived Behavior Recognition, where a robot employs an LLM to assess the robot's generated behavior in a manner similar to human observer. We focus on four behavior types, namely - explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors. The LLMs goal is, therefore to be a human proxy to the agent, and to answer how a certain agent behavior would be perceived by the human in the loop, for example "Given a robot's behavior X, would the human observer find it explicable?". We conduct a human subject study to verify that the users are able to correctly answer such a question in the curated situations (robot setting and plan) across five domains. A first analysis of the belief test yields extremely positive results inflating ones expectations of LLMs possessing ToM abilities. We then propose and perform a suite of perturbation tests which breaks this illusion, i.e. Inconsistent Belief, Uninformative Context and Conviction Test. The high score of LLMs on vanilla prompts showcases its potential use in HRI settings, however to possess ToM demands invariance to trivial or irrelevant perturbations in the context which LLMs lack. We report our results on GPT-4 and GPT-3.5-turbo. © 2024 Copyright held by the owner/author(s)},
	author_keywords = {Large Language Models; Reasoning; Theory of Mind},
	publisher = {IEEE Computer Society},
	issn = {21672148},
	isbn = {979-840070323-2},
	language = {English},
	abbrev_source_title = {ACM/IEEE Int. Conf. Hum.-Rob. Interact.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Mao20241708,
	author = {Mao, Wendong and Wang, Meiqi and Xie, Xiaoru and Wu, Xiao and Wang, Zhongfeng},
	title = {Hardware Accelerator Design for Sparse DNN Inference and Training: A Tutorial},
	year = {2024},
	journal = {IEEE Transactions on Circuits and Systems II: Express Briefs},
	volume = {71},
	number = {3},
	pages = {1708 – 1714},
	doi = {10.1109/TCSII.2023.3344681},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181579371&doi=10.1109%2fTCSII.2023.3344681&partnerID=40&md5=a5b7aeacfcd0dc26355b56cc11ed2593},
	affiliations = {Sun Yat-sen University Shenzhen Campus, School of Integrated Circuits, Shenzhen, 518107, China; Nanjing University, School of Electronic Science and Engineering, Nanjing, 210008, China},
	abstract = {Deep neural networks (DNNs) are widely used in many fields, such as artificial intelligence generated content (AIGC) and robotics. To efficiently support these tasks, the model pruning technique is developed to compress the computational and memory-intensive DNNs. However, directly executing these sparse models on a common hardware accelerator can cause significant under-utilization, since invalid data resulting from the sparse patterns leads to unnecessary computations and irregular memory accesses. This brief analyzes the critical issues in accelerating sparse models, and provides an overview of typical hardware designs for various sparse DNNs, such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), generative adversarial networks (GANs), and Transformers. Following the overview, we give a practical guideline of designing efficient accelerators for sparse DNNs with qualitative metrics to evaluate hardware overhead under different cases. In addition, we highlight potential opportunities in terms of hardware/software/algorithm co-optimizations from the perspective of sparse DNN implementation, and provide insights into recent design trends for the efficient implementation of transformers with sparse attention, which facilitates large language model (LLM) deployments with high throughput and energy efficiency.  © 2004-2012 IEEE.},
	author_keywords = {CNN; deep learning; Hardware acceleration; sparsity; transformer; tutorial},
	keywords = {Computational efficiency; Convolution; Energy efficiency; Generative adversarial networks; Recurrent neural networks; Signal encoding; Computational modelling; Convolutional neural network; Deep learning; Encodings; Hardware acceleration; Hardware accelerators; Sparsity; Transformer; Tutorial; Deep neural networks},
	correspondence_address = {M. Wang; Sun Yat-sen University Shenzhen Campus, School of Integrated Circuits, Shenzhen, 518107, China; email: wangmq53@mail.sysu.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15497747},
	language = {English},
	abbrev_source_title = {IEEE Trans. Circuits Syst. Express Briefs},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Grinbaum2024,
	author = {Grinbaum, Alexei and Adomaitis, Laurynas},
	title = {Dual use concerns of generative AI and large language models},
	year = {2024},
	journal = {Journal of Responsible Innovation},
	volume = {11},
	number = {1},
	doi = {10.1080/23299460.2024.2304381},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184162687&doi=10.1080%2f23299460.2024.2304381&partnerID=40&md5=84cdeb84dd153dd86256e92b517b4a1d},
	affiliations = {CEA-Saclay/Larsim, Gif-sur-Yvette, France},
	abstract = {We suggest the implementation of the Dual Use Research of Concern (DURC) framework, originally designed for life sciences, to the domain of generative AI, with a specific focus on Large Language Models (LLMs). With its demonstrated advantages and drawbacks in biological research, we believe the DURC criteria can be effectively redefined for LLMs, potentially contributing to improved AI governance. Acknowledging the balance that must be struck when employing the DURC framework, we highlight its crucial political role in enhancing societal awareness of the impact of generative AI. As a final point, we offer a series of specific recommendations for applying the DURC approach to LLM research. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {AI ethics; Dual Use Research of Concern (DURC); generative AI; Large Language Models (LLMs)},
	correspondence_address = {A. Grinbaum; CEA-Saclay/Larsim, Gif-sur-Yvette, 91191, France; email: alexei.grinbaum@cea.fr},
	publisher = {Routledge},
	issn = {23299460},
	language = {English},
	abbrev_source_title = {J. Responsible Innov.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Valdez2024,
	author = {Valdez, Dustin and Bunnell, Arianna and Lim, Sian Y. and Sadowski, Peter and Shepherd, John A.},
	title = {Performance of Progressive Generations of GPT on an Exam Designed for Certifying Physicians as Certified Clinical Densitometrists},
	year = {2024},
	journal = {Journal of Clinical Densitometry},
	volume = {27},
	number = {2},
	doi = {10.1016/j.jocd.2024.101480},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187512252&doi=10.1016%2fj.jocd.2024.101480&partnerID=40&md5=8d7a66973051f65b1356d126e7fc0c22},
	affiliations = {University of Hawaii at Manoa, Honolulu, HI, United States; University of Hawaii Cancer Center, Honolulu, HI, United States; Hawai'i Pacific Health Medical Group, Hawai'i Pacific Health, Honolulu, HI, United States},
	abstract = {Background: Artificial intelligence (AI) large language models (LLMs) such as ChatGPT have demonstrated the ability to pass standardized exams. These models are not trained for a specific task, but instead trained to predict sequences of text from large corpora of documents sourced from the internet. It has been shown that even models trained on this general task can pass exams in a variety of domain-specific fields, including the United States Medical Licensing Examination. We asked if large language models would perform as well on a much narrower subdomain tests designed for medical specialists. Furthermore, we wanted to better understand how progressive generations of GPT (generative pre-trained transformer) models may be evolving in the completeness and sophistication of their responses even while generational training remains general. In this study, we evaluated the performance of two versions of GPT (GPT 3 and 4) on their ability to pass the certification exam given to physicians to work as osteoporosis specialists and become a certified clinical densitometrists. The CCD exam has a possible score range of 150 to 400. To pass, you need a score of 300. Methods: A 100-question multiple-choice practice exam was obtained from a 3rd party exam preparation website that mimics the accredited certification tests given by the ISCD (International Society for Clinical Densitometry). The exam was administered to two versions of GPT, the free version (GPT Playground) and ChatGPT+, which are based on GPT-3 and GPT-4, respectively (OpenAI, San Francisco, CA). The systems were prompted with the exam questions verbatim. If the response was purely textual and did not specify which of the multiple-choice answers to select, the authors matched the text to the closest answer. Each exam was graded and an estimated ISCD score was provided from the exam website. In addition, each response was evaluated by a rheumatologist CCD and ranked for accuracy using a 5-level scale. The two GPT versions were compared in terms of response accuracy and length. Results: The average response length was 11.6 ±19 words for GPT-3 and 50.0±43.6 words for GPT-4. GPT-3 answered 62 questions correctly resulting in a failing ISCD score of 289. However, GPT-4 answered 82 questions correctly with a passing score of 342. GPT-3 scored highest on the “Overview of Low Bone Mass and Osteoporosis” category (72 % correct) while GPT-4 scored well above 80 % accuracy on all categories except “Imaging Technology in Bone Health” (65 % correct). Regarding subjective accuracy, GPT-3 answered 23 questions with nonsensical or totally wrong responses while GPT-4 had no responses in that category. Conclusion: If this had been an actual certification exam, GPT-4 would now have a CCD suffix to its name even after being trained using general internet knowledge. Clearly, more goes into physician training than can be captured in this exam. However, GPT algorithms may prove to be valuable physician aids in the diagnoses and monitoring of osteoporosis and other diseases. © 2024 The International Society for Clinical Densitometry},
	author_keywords = {CCD; clinical densitometry; GPT; LLM},
	keywords = {Article; bone densitometry; bone mass; certification; ChatGPT; controlled study; cross-sectional study; examination; generative pretrained transformer; human; medical specialist; multiple choice test; osteoporosis; performance; prophylaxis; risk assessment},
	correspondence_address = {D. Valdez; University of Hawaii at Manoa, Honolulu, United States; email: dustinkv@hawaii.edu},
	publisher = {Elsevier Inc.},
	issn = {10946950},
	coden = {JCDTF},
	pmid = {38401238},
	language = {English},
	abbrev_source_title = {J. Clin. Densitometry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Green Open Access}
}

@ARTICLE{Savelka2024160,
	author = {Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Sakr, Majd},
	title = {From GPT-3 to GPT-4: On the Evolving Efficacy of LLMs to Answer Multiple-Choice Questions for Programming Classes in Higher Education},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2052},
	pages = {160 – 182},
	doi = {10.1007/978-3-031-53656-4_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186684747&doi=10.1007%2f978-3-031-53656-4_8&partnerID=40&md5=ff8a233c52a01e22db2c1c436152a6f3},
	affiliations = {School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {We explore the evolving efficacy of three generative pre-trained transformer (GPT) models in generating answers for multiple-choice questions (MCQ) from introductory and intermediate Python programming courses in higher education. We focus on the differences in capabilities of the models prior to the release of ChatGPT (Nov ’22), at the time of the release, and today (i.e., Aug ’23). Recent studies have established that the abilities of the OpenAI’s GPT models to handle assessments originally designed for humans keep increasing as the newer more capable models are released. However, the qualitative differences in the capabilities and limitations of these models to reason about and/or analyze programming MCQs have been under-explored. We evaluated three OpenAI’s GPT models on formative and summative MCQ assessments from three Python courses (530 questions) focusing on the qualitative differences in the evolving efficacy of the subsequent models. This study provides further evidence and insight into the trajectory of the current developments where there already exists a technology that can be utilized by students to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments. This study could be leveraged by educators and institutions to better understand the recent technological developments in order to adapt the design of programming assessments as well as to fuel the necessary discussions into how assessments in future programming classes should be updated. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Generative pre-trained transformers; GPT; Large language models; LLM; MCQ; Multiple-choice questions; Programming assessment; Python},
	keywords = {Education computing; Engineering education; High level languages; Students; Generative pre-trained transformer; Language model; Large language model; LLM; Multiple-choice questions; Programming assessment; Programming class; Transformer modeling; Python},
	correspondence_address = {J. Savelka; School of Computer Science, Carnegie Mellon University, Pittsburgh, United States; email: jsavelka@cs.cmu.edu},
	editor = {McLaren B.M. and Uhomoibhi J. and Jovanovic J. and Chounta I.-A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303153655-7},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Ma2024380,
	author = {Ma, Zhixin and Wu, Jiaxin and Ngo, Chong Wah},
	title = {Leveraging LLMs and Generative Models for Interactive Known-Item Video Search},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14557 LNCS},
	pages = {380 – 386},
	doi = {10.1007/978-3-031-53302-0_35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184830899&doi=10.1007%2f978-3-031-53302-0_35&partnerID=40&md5=e39daff74d746ee2c553e0220ccf8631},
	affiliations = {School of Computing and Information Systems, Singapore Management University, Singapore, Singapore; Department of Computer Science, City University of Hong Kong, Hong Kong},
	abstract = {While embedding techniques such as CLIP have considerably boosted search performance, user strategies in interactive video search still largely operate on a trial-and-error basis. Users are often required to manually adjust their queries and carefully inspect the search results, which greatly rely on the users’ capability and proficiency. Recent advancements in large language models (LLMs) and generative models offer promising avenues for enhancing interactivity in video retrieval and reducing the personal bias in query interpretation, particularly in the known-item search. Specifically, LLMs can expand and diversify the semantics of the queries while avoiding grammar mistakes or the language barrier. In addition, generative models have the ability to imagine or visualize the verbose query as images. We integrate these new LLM capabilities into our existing system and evaluate their effectiveness on V3C1 and V3C2 datasets. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Generative Model; Interactive Video Retrieval; Known-Item Search; Large Language Models},
	keywords = {Computational linguistics; Embedding technique; Generative model; Interactive video; Interactive video retrieval; Known item searches; Known items; Language model; Large language model; Video retrieval; Video search; Semantics},
	correspondence_address = {Z. Ma; School of Computing and Information Systems, Singapore Management University, Singapore, Singapore; email: zxma.2020@phdcs.smu.edu.sg},
	editor = {Rudinac S. and Worring M. and Liem C. and Hanjalic A. and Jónsson B.P. and Yamakata Y. and Liu B.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303153301-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Xia2024,
	author = {Xia, Liqiao and Li, Chengxi and Zhang, Canbin and Liu, Shimin and Zheng, Pai},
	title = {Leveraging error-assisted fine-tuning large language models for manufacturing excellence},
	year = {2024},
	journal = {Robotics and Computer-Integrated Manufacturing},
	volume = {88},
	doi = {10.1016/j.rcim.2024.102728},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183205050&doi=10.1016%2fj.rcim.2024.102728&partnerID=40&md5=b52cedd46d1036f83792200d7614a0c5},
	affiliations = {Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong; Key Laboratory of Ultra-precision Machining Technology, Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong},
	abstract = {The emergence of large language models (LLM), like GPT, is revolutionizing the field of information retrieval, finding applications across a wide range of domains. However, the intricate domain knowledge and the unique software paradigms inherent to the manufacturing sector have posed significant barriers to the effective utilization of LLM. To address this divide, an error-assisted fine-tuning approach is proposed to adapt LLM specifically for the manufacturing domain. Initially, the LLM is fine-tuned using a manufacturing-domain corpus, allowing it to learn and adapt to the nuances of the manufacturing field. Additionally, the injection of a labeled dataset into a pre-configured LLM enhances its ability to identify key elements within the domain. To ensure the generation of syntactically valid programs in domain-specific languages, and to accommodate environmental constraints, an error-assisted iterative prompting procedure is introduced, which facilitates the generation of reliable and expected code. Experimental results demonstrate the model's proficiency in accurately responding to manufacturing-related queries and its effectiveness in generating reliable code, where the accuracy of judgment querying can experience an improvement of approximately 4.1%. By expanding the applicability of LLM to the manufacturing industry, it is hoped that this research will pave the way for a broad array of new LLM-based applications within manufacturing. © 2024},
	author_keywords = {Generative AI; Industry 4.0; Knowledge management; Large language model; Smart manufacturing},
	keywords = {Computational linguistics; Domain Knowledge; Errors; Industrial research; Industry 4.0; Problem oriented languages; Domain knowledge; Fine tuning; Generative AI; Language model; Large language model; Manufacturing domains; Manufacturing excellence; Manufacturing sector; Smart manufacturing; Software paradigm; Knowledge management},
	correspondence_address = {P. Zheng; Department of Industrial and Systems Engineering, The Hong Kong Polytechnic University, Hong Kong; email: pai.zheng@polyu.edu.hk},
	publisher = {Elsevier Ltd},
	issn = {07365845},
	coden = {RCIME},
	language = {English},
	abbrev_source_title = {Rob Comput Integr Manuf},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Van Wyk2024,
	author = {Van Wyk, Micheal M.},
	title = {Is ChatGPT an opportunity or a threat? Preventive strategies employed by academics related to a GenAI-based LLM at a faculty of education},
	year = {2024},
	journal = {Journal of Applied Learning and Teaching},
	volume = {7},
	number = {1},
	doi = {10.37074/jalt.2024.7.1.15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187470827&doi=10.37074%2fjalt.2024.7.1.15&partnerID=40&md5=35a465d0c3280346e8b2f11a791bf8b0},
	affiliations = {University of South Africa, South Africa},
	abstract = {Within the past decade, enormous strides have been made related to the disruptive effect of AI in education, which has grown exponentially. Recent developments in GenAI conversational models have highlighted the need to investigate this phenomenon in different contexts. This prompted me to investigate academics’ views on ChatGPT as a GenAI-based conversation tool at a faculty of education. The conversation theory is foregrounding this research. An exploratory qualitative design study foregrounded the constructivist-interpretative perspective and a sample of eight participants was purposively selected. Semi-structured interviews were generated by Microsoft Teams (transcribed), recordings were downloaded, and themes were identified as guided by the thematic analysis process. Participants echoed sentiments of the usefulness of generative AI tools in promoting or advancing teaching and learning experiences. An awareness of the ethical considerations in using generative AI tools is important before adopting chatbots. To prevent the unethical behaviour of students, it is necessary to create and adopt measures to prevent academic dishonesty. Further research is needed to build on recent gains in academic awareness of GenAI tools for teaching and learning. © 2024. Micheal M Van Wyk.},
	author_keywords = {Academic dishonesty; artificial intelligence; constructivist-interpretative perspective; exploratory qualitative design; GenAI tools},
	correspondence_address = {M.M. Van Wyk; University of South Africa, South Africa; email: vwykmm@unisa.ac.za},
	publisher = {Kaplan Singapore},
	issn = {2591801X},
	language = {English},
	abbrev_source_title = {J. Appl. Learn. Teach.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Wolfer202443,
	author = {Wolfer, James},
	title = {A Qualitative Assessment of ChatGPT Generated Code in the Computer Science Curriculum},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {901 LNNS},
	pages = {43 – 53},
	doi = {10.1007/978-3-031-53022-7_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185711696&doi=10.1007%2f978-3-031-53022-7_5&partnerID=40&md5=0234595c70440ef0cb6ed075d6a4ef4b},
	affiliations = {Indiana University South Bend, South Bend, IN, United States},
	abstract = {The emergence of Large Language Models and their deployment in systems such as ChatGPT are poised to have a major impact on STEM education, particularly Computer Science. These generative large language models can produce program code as well as human language output. This has potentially serious implications for computer science programs and pedagogy. This work provides a qualitative assessment sample code generated by ChatGPT, as an example of an LLM explores implications for computing pedagogy.... © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {ChatGPT; computing education; computing pedagogy; engineering education; Large Language Models},
	keywords = {Computational linguistics; Education computing; ChatGPT; Code languages; Computer science curricula; Computing education; Computing pedagogy; Language model; Large language model; Program code; Qualitative assessments; STEM education; Engineering education},
	correspondence_address = {J. Wolfer; Indiana University South Bend, South Bend, United States; email: jwolfer@iusb.edu},
	editor = {Auer M.E. and Cukierman U.R. and Vendrell Vidal E. and Tovar Caro E.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303153021-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Fredheim2024,
	author = {Fredheim, Rolf and Pamment, James},
	title = {Assessing the risks and opportunities posed by AI-enhanced influence operations on social media},
	year = {2024},
	journal = {Place Branding and Public Diplomacy},
	doi = {10.1057/s41254-023-00322-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184437675&doi=10.1057%2fs41254-023-00322-5&partnerID=40&md5=6ea1c4f8e4507f686bcad1783a633191},
	affiliations = {Lund University Psychological Defence Research Institute, Helsingborg, 251 08, Sweden},
	abstract = {Large language models (LLMs) like GPT-4 have the potential to dramatically change the landscape of influence operations. They can generate persuasive, tailored content at scale, making campaigns using falsified content, such as disinformation and fake accounts, easier to produce. Advances in self-hosted open-source models have meant that adversaries can evade content moderation and security checks built into large commercial models such as those commercialised by Anthropic, Google, and OpenAI. New multi-lingual models make it easier than ever for foreign adversaries to pose as local actors. This article examines the heightened threats posed by synthetic media, as well as the potential that these tools hold for creating effective countermeasures. It begins with assessing the challenges posed by a toxic combination of automated bots, human-controlled troll accounts, and more targeted social engineering operations. However, the second part of the article assesses the potential for these same tools to improve detection. Promising countermeasures include running internal generative models to bolster training data for internal classifiers, detecting statistical anomalies, identifying output from common prompts, and building specialised classifiers optimised for specific monitoring needs. © The Author(s) 2024.},
	author_keywords = {AI; Digital diplomacy; Disinformation; Influence operations; LLM},
	correspondence_address = {J. Pamment; Lund University Psychological Defence Research Institute, Helsingborg, 251 08, Sweden; email: james.pamment@isk.lu.se},
	publisher = {Palgrave Macmillan},
	issn = {17518040},
	language = {English},
	abbrev_source_title = {Place Brand. Public Diplomacy},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Korinek20231281,
	author = {Korinek, Anton},
	title = {Generative AI for Economic Research: Use Cases and Implications for Economists†},
	year = {2023},
	journal = {Journal of Economic Literature},
	volume = {61},
	number = {4},
	pages = {1281 – 1317},
	doi = {10.1257/jel.20231736},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180358153&doi=10.1257%2fjel.20231736&partnerID=40&md5=20cb9125485be38953e814504080d1ed},
	affiliations = {University of Virginia, United States},
	abstract = {Generative artificial intelligence (AI) has the potential to revolutionize research. I analyze how large language models (LLMs) such as ChatGPT can assist economists by describing dozens of use cases in six areas: ideation and feedback, writing, background research, data analysis, coding, and mathematical derivations. I provide general instructions and demonstrate specific examples of how to take advantage of each of these, classifying the LLM capabilities from experimental to highly useful. I argue that economists can reap significant productivity gains by taking advantage of generative AI to automate micro-tasks. Moreover, these gains will grow as the performance of AI systems continues to improve. I also speculate on the longer-term implications of AI-powered cognitive automation for economic research. The online resources associated with this paper explain how to get started and will provide regular updates on the latest capabilities of generative AI in economics. © 2023 American Economic Association. All rights reserved.},
	correspondence_address = {A. Korinek; University of Virginia, United States; email: akorinek@virginia.edu},
	publisher = {American Economic Association},
	issn = {00220515},
	language = {English},
	abbrev_source_title = {J. Econ. Lit.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Blease2024,
	author = {Blease, Charlotte and Worthen, Abigail and Torous, John},
	title = {Psychiatrists’ experiences and opinions of generative artificial intelligence in mental healthcare: An online mixed methods survey},
	year = {2024},
	journal = {Psychiatry Research},
	volume = {333},
	doi = {10.1016/j.psychres.2024.115724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184764032&doi=10.1016%2fj.psychres.2024.115724&partnerID=40&md5=b24349aa59eaecc1af127264d01a91b5},
	affiliations = {Participatory eHeath and Health Data Research Group, Department of Women's and Children's Health, Uppsala University, Uppala, Sweden; Digital Psychiatry, Department of Psychiatry, Beth Israel Deaconess Medical Center, -Harvard Medical School, Boston, 02115, MA, United States; American Psychiatric Association, Washington, DC, United States},
	abstract = {Following the launch of ChatGPT in November 2022, interest in large language model (LLM)-powered chatbots has surged with increasing focus on the clinical potential of these tools. Missing from this discussion, however, are the perspectives of physicians. The current study aimed to explore psychiatrists’ experiences and opinions on this new generation of chatbots in mental health care. An online survey including both quantitative and qualitative responses was distributed to a non-probability sample of psychiatrists affiliated with the American Psychiatric Association. Findings revealed 44 % of psychiatrists had used OpenAI's ChatGPT-3.5 and 33 % had used GPT-4.0 “to assist with answering clinical questions.” Administrative tasks were cited as a major benefit of these tools: 70 % somewhat agreed/agreed “documentation will be/is more efficient”. Three in four psychiatrists (75 %) somewhat agreed/agreed “the majority of their patients will consult these tools before first seeing a doctor”. Nine in ten somewhat agreed/agreed that clinicians need more support/training in understanding these tools. Open-ended responses reflected these opinions but respondents also expressed divergent opinions on the value of generative AI in clinical practice, including its impact on the future of the profession. © 2024 The Author(s)},
	author_keywords = {Artificial intelligence; Chatbots; LLM; Psychiatry; Workforce},
	keywords = {Artificial Intelligence; Humans; Mental Health Services; Psychiatrists; Psychiatry; Surveys and Questionnaires; Article; artificial intelligence; ChatGPT; consultation; doctor patient relationship; experience; female; health survey; human; large language model; male; mental health care; online system; psychiatrist; qualitative analysis; quantitative analysis; artificial intelligence; mental health service; psychiatry; questionnaire},
	correspondence_address = {C. Blease; Participatory eHeath and Health Data Research Group, Department of Women's and Children's Health, Uppsala University, Uppala, Sweden; email: charlotte.blease@uu.se},
	publisher = {Elsevier Ireland Ltd},
	issn = {01651781},
	coden = {PSRSD},
	pmid = {38244285},
	language = {English},
	abbrev_source_title = {Psychiatry Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Cinquin2024,
	author = {Cinquin, Olivier},
	title = {ChIP-GPT: a managed large language model for robust data extraction from biomedical database records},
	year = {2024},
	journal = {Briefings in Bioinformatics},
	volume = {25},
	number = {2},
	doi = {10.1093/bib/bbad535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183984143&doi=10.1093%2fbib%2fbbad535&partnerID=40&md5=51ab509ddb2284c7ee6445415e8b968c},
	affiliations = {The Department of Developmental and Cell Biology, The University of California, Irvine, United States},
	abstract = {Increasing volumes of biomedical data are amassing in databases. Large-scale analyses of these data have wide-ranging applications in biology and medicine. Such analyses require tools to characterize and process entries at scale. However, existing tools, mainly centered on extracting predefined fields, often fail to comprehensively process database entries or correct evident errors—a task humans can easily perform. These tools also lack the ability to reason like domain experts, hindering their robustness and analytical depth. Recent advances with large language models (LLMs) provide a fundamentally new way to query databases. But while a tool such as ChatGPT is adept at answering questions about manually input records, challenges arise when scaling up this process. First, interactions with the LLM need to be automated. Second, limitations on input length may require a record pruning or summarization pre-processing step. Third, to behave reliably as desired, the LLM needs either well-designed, short, ‘few-shot’ examples, or fine-tuning based on a larger set of well-curated examples. Here, we report ChIP-GPT, based on fine-tuning of the generative pre-trained transformer (GPT) model Llama and on a program prompting the model iteratively and handling its generation of answer text. This model is designed to extract metadata from the Sequence Read Archive, emphasizing the identification of chromatin immunoprecipitation (ChIP) targets and cell lines. When trained with 100 examples, ChIP-GPT demonstrates 90–94% accuracy. Notably, it can seamlessly extract data from records with typos or absent field labels. Our proposed method is easily adaptable to customized questions and different databases. © The Author(s) 2024.},
	author_keywords = {biomedical databases; error-tolerant data mining; generative pre-trained transformer (GPT); large language model (LLM); natural language processing},
	keywords = {Cell Line; Chromatin Immunoprecipitation; Databases, Factual; Humans; Language; Medicine; cell line; chromatin immunoprecipitation; factual database; human; language; medicine},
	correspondence_address = {O. Cinquin; The Department of Developmental and Cell Biology, The University of California, Irvine, United States; email: olivier.cinquin@uci.edu},
	publisher = {Oxford University Press},
	issn = {14675463},
	pmid = {38314912},
	language = {English},
	abbrev_source_title = {Brief. Bioinform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Raman2024,
	author = {Raman, Raghu and Venugopalan, Murale and Kamal, Anju},
	title = {Evaluating human resources management literacy: A performance analysis of ChatGPT and bard},
	year = {2024},
	journal = {Heliyon},
	volume = {10},
	number = {5},
	doi = {10.1016/j.heliyon.2024.e27026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186971826&doi=10.1016%2fj.heliyon.2024.e27026&partnerID=40&md5=07da68c954c7b8d016bfe05e551ee85e},
	affiliations = {Amrita School of Business, Amrita Vishwa Vidyapeetham, Amritapuri, India},
	abstract = {This study presents a comprehensive analysis comparing the literacy levels of two Generative Artificial Intelligence (GAI) tools, ChatGPT and Bard, using a dataset of 134 questions from the Human Resources (HR) domain. The generated responses are evaluated for accuracy, relevance, and clarity. We find that ChatGPT outperforms Bard in overall accuracy (84.3% vs. 82.8%). This difference in performance suggests that ChatGPT could serve as a robotic advisor in transactional HR roles. In contrast, Bard may possess additional safeguards against misuse in the HR function, making it less capable of generating responses to certain types of questions. Statistical tests reveal that although the two systems differ in their mean accuracy, relevance, and clarity of the responses, the observed differences are not always statistically significant, implying that both tools may be more complementary than competitive. The Pearson correlation coefficients further support this by showing weak to non-existent relationships in performance metrics between the two tools. Confirmation queries don't improve ChatGPT or Bard's response accuracy. The study thus contributes to emerging research on the utility of GAI tools in Human Resources Management and suggests that involving certified HR professionals in the design phase could enhance underlying language model performance. © 2024 The Authors},
	author_keywords = {Ethics; Generative AI; Hiring; HR policy; Human resource management; LLM; Managerial decisions; Text mining},
	correspondence_address = {R. Raman; Amrita School of Business, Amritapuri, India; email: raghu@amrita.edu},
	publisher = {Elsevier Ltd},
	issn = {24058440},
	language = {English},
	abbrev_source_title = {Heliyon},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access}
}

@ARTICLE{Sauvola2024,
	author = {Sauvola, Jaakko and Tarkoma, Sasu and Klemettinen, Mika and Riekki, Jukka and Doermann, David},
	title = {Future of software development with generative AI},
	year = {2024},
	journal = {Automated Software Engineering},
	volume = {31},
	number = {1},
	doi = {10.1007/s10515-024-00426-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187214717&doi=10.1007%2fs10515-024-00426-z&partnerID=40&md5=8a2554ca83a09a6a21810b73b48b76c6},
	affiliations = {University of Oulu, Oulu, Finland; University of Helsinki, Helsinki, Finland; Business Finland, Helsinki, Finland; University at Buffalo, Buffalo, United States},
	abstract = {Generative AI is regarded as a major disruption to software development. Platforms, repositories, clouds, and the automation of tools and processes have been proven to improve productivity, cost, and quality. Generative AI, with its rapidly expanding capabilities, is a major step forward in this field. As a new key enabling technology, it can be used for many purposes, from creative dimensions to replacing repetitive and manual tasks. The number of opportunities increases with the capabilities of large-language models (LLMs). This has raised concerns about ethics, education, regulation, intellectual property, and even criminal activities. We analyzed the potential of generative AI and LLM technologies for future software development paths. We propose four primary scenarios, model trajectories for transitions between them, and reflect against relevant software development operations. The motivation for this research is clear: the software development industry needs new tools to understand the potential, limitations, and risks of generative AI, as well as guidelines for using it. © The Author(s) 2024.},
	author_keywords = {Generative AI; Real-time digital economy; Software development},
	keywords = {Creatives; Criminal activities; Digital economy; Enabling technologies; Ethics education; Generative AI; Language model; Modeling technology; Real- time; Real-time digital economy; Software design},
	correspondence_address = {J. Sauvola; University of Oulu, Oulu, Finland; email: jaakko.sauvola@oulu.fi},
	publisher = {Springer},
	issn = {09288910},
	coden = {ASOEE},
	language = {English},
	abbrev_source_title = {Autom Software Eng},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Yi2024,
	author = {Yi, Michael and Ceglinski, Kamil and Ashok, Pradeepkumar and Behounek, Michael and White, Spencer and Peroyea, Trey and Thetford, Taylor},
	title = {Applications of Large Language Models in Well Construction Planning and Real-Time Operation},
	year = {2024},
	journal = {SPE - International Association of Drilling Contractors Drilling Conference Proceedings},
	volume = {2024-March},
	doi = {10.2118/217700-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187229412&doi=10.2118%2f217700-MS&partnerID=40&md5=18b0f9fdf364058a6d6f9694cf0de994},
	affiliations = {Intellicess, Inc., Austin, TX, United States; APA Corp., Houston, TX, United States},
	abstract = {In today's well construction operations, a substantial volume of data is generated and stored across multiple databases. The primary objective being to use them as a guide for future well construction optimization. However, much of this data gets lost in computer storage, and appropriate information is difficult to find at the right time. This paper shows the results of deploying a generative pre-trained transformer (GPT) large language model on an operator's dataset to alleviate this problem. The process starts with gathering all relevant data into a common database. In this case, the dataset included sensor data, processed data, morning reports, end of well reports, after-action reviews of nonproductive times, bit forensics data and publicly available data from wells drilled by other operators. The files were pre-processed, and metadata was added appropriately to ensure appropriate indexing and training of the information. This data is then fed to the cloud platform on which the model is learnt. The model is then integrated into the data platform so that the end users can pose queries. The dataset consisted of more than 200 wells of the operator in a region that the operator is actively drilling. Data curation was a time-consuming task that had to be performed to ensure only quality and organized information was fed to the model. Documents containing well construction related subject matter were also used in the training to provide the end user assistance with core concepts. During the test stage, a multitude of questions were posed to the platform, including questions such as: What happened the last time there was a stuck pipe in this region? What is the best ROP that could be attained in the lateral section? Significant time savings were recorded due to the ease with which information could be retrieved. A big concern was the potential for wrongs answers being provided to the questions. To alleviate this concern, all answers were accompanied by references found in the database, to give the person reviewing the answers confidence in the answers. This paper introduces the benefits that large language models (LLMs) bring to both well planning and real-time operations. LLM offers the capability to be able to retrieve information extremely quickly and provide answers in a conversational format to user questions. This paper also provides recommendations to the industry and details some of the challenges to adopting LLMs.  Copyright © 2024, IADC/SPE International Drilling Conference and Exhibition.},
	keywords = {Computational linguistics; Digital storage; Infill drilling; Large datasets; Petroleum reservoir evaluation; Real time systems; Construction operations; Construction optimization; Construction planning; End-users; Language model; Planning time; Primary objective; Real-time operation; Sensors data; Well constructions; Database systems},
	publisher = {Society of Petroleum Engineers (SPE)},
	isbn = {978-195902510-8},
	language = {English},
	abbrev_source_title = {SPE - Int. Assoc. Drill. Contract. Drill. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Tavares2023,
	author = {Tavares, Célia and Oliveira, Luciana and Duarte, Pedro and da Silva, Manuel Moreira},
	title = {Artificial Intelligence: A Blessing or a Threat for Language Service Providers in Portugal},
	year = {2023},
	journal = {Informatics},
	volume = {10},
	number = {4},
	doi = {10.3390/informatics10040081},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180659093&doi=10.3390%2finformatics10040081&partnerID=40&md5=1bf0896fe4f9ba3feafe7cc3f7602f8e},
	affiliations = {CEOS.PP, ISCAP Polytechnic of Porto, Porto, 4465-004, Portugal},
	abstract = {According to a recent study by OpenAI, Open Research, and the University of Pennsylvania, large language models (LLMs) based on artificial intelligence (AI), such as generative pretrained transformers (GPTs), may have potential implications for the job market, specifically regarding occupations that demand writing or programming skills. This research points out that interpreters and translators are one of the main occupations with greater exposure to AI in the US job market (76.5%), in a trend that is expected to affect other regions of the globe. This article, following a mixed-methods survey-based research approach, provides insights into the awareness and knowledge about AI among Portuguese language service providers (LSPs), specifically regarding neural machine translation (NMT) and large language models (LLM), their actual use and usefulness, as well as their potential influence on work performance and the labour market. The results show that most professionals are unable to identify whether AI and/or automation technologies support the tools that are most used in the profession. The usefulness of AI is essentially low to moderate and the professionals who are less familiar with it and less knowledgeable also demonstrate a lack of trust in it. Two thirds of the sample estimate negative or very negative effects of AI in their profession, expressing the devaluation and replacement of experts, the reduction of income, and the reconfiguration of the career of translator to mere post-editors as major concerns. © 2023 by the authors.},
	author_keywords = {artificial intelligence; interpreters; language service providers; large language models; neural machine translation; translators},
	correspondence_address = {L. Oliveira; CEOS.PP, ISCAP Polytechnic of Porto, Porto, 4465-004, Portugal; email: lgo@eu.ipp.pt},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22279709},
	language = {English},
	abbrev_source_title = {Informatics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Jain202468,
	author = {Jain, Sachin and Subzwari, Syed Wasif Ali and Subzwari, Syed Aquib Ali},
	title = {Generative AI for Healthcare Engineering and Technology Challenges},
	year = {2024},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {697 AICT},
	pages = {68 – 80},
	doi = {10.1007/978-3-031-50188-3_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180629085&doi=10.1007%2f978-3-031-50188-3_7&partnerID=40&md5=49958939b4eef0e93fb164510fe8f5b6},
	affiliations = {Mumbai, India; Hyderabad, India},
	abstract = {Healthcare field engineers play a critical role in ensuring the smooth operation and maintenance of medical equipment. However, they face numerous challenges such as adhering to standard operating procedures (SOPs), managing inventory, maintaining equipment quality, and optimizing time allocation. This research paper proposes a novel approach that harnesses the power of generative artificial intelligence (AI) to overcome these challenges. In this study, generative AI algorithms are employed to develop an intelligent system that assists healthcare field engineers in following SOPs accurately while being always compliant. This is aimed to ensure consistent and efficient procedures, leading to improved equipment performance and patient safety. Additionally, the system integrates generative AI techniques to uphold equipment quality. It transforms lengthy equipment manuals into interactive Q&A systems, enabling engineers to focus on their tasks and access key information as needed. This enhances engineer productivity and indirectly contributes to the equipment’s working quality. While from a use case perspective, generative AI seems to effectively solve the problem of manually referring SOPs, compliance manuals and product catalogs. There would be technology challenges (especially around Artificial Intelligence) like data security, geo-political influences on data governance, dependency on specific technology platforms in addition to maintaining such systems over time effectively. In summary, this research introduces an innovative solution to address challenges faced by healthcare field engineers through the application of generative AI. By utilizing machine learning algorithms, the proposed system enhances adherence to standard operating procedures (SOPs), streamlines inventory management, improves equipment quality maintenance, and optimizes time management. The study’s outcomes contribute to the efficient implementation of SOP adherence and process guidelines, while also providing guidelines to tackle long-term challenges related to technology maintenance, ethical compliance of AI systems, mitigation of risks and data governance influenced by the dynamic geopolitical landscape. © 2024, IFIP International Federation for Information Processing.},
	author_keywords = {AI Bias; Artificial Intelligence; Compliance; Data Governance; Generative AI; Healthcare; LLM; Maintenance; NLP; Standard Procedures},
	keywords = {Engineers; Health care; Intelligent systems; Inventory control; Learning algorithms; Machine learning; Regulatory compliance; Artificial intelligence bias; Compliance; Data governances; Equipment quality; Field engineers; Generative artificial intelligence; Healthcare; LLM; Standard operating procedures; Standard procedures; Maintenance},
	correspondence_address = {S.W.A. Subzwari; Hyderabad, India; email: wasif.subzwari@gmail.com},
	editor = {Sharma S.K. and Metri B. and Dwivedi Y.K. and Lal B. and Elbanna A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303150187-6},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee2024238,
	author = {Lee, Jinhyung and Cho, Kyungjun and Lee, Chang Kwon and Lee, Yeonho and Park, Jae-Hyung and Oh, Su-Hyun and Ju, Yucheon and Jeong, Chunseok and Cho, Ho Sung and Lee, Jaeseung and Yun, Tae-Sik and Cho, Jin Hee and Oh, Sangmuk and Moon, Junil and Park, Young-Jun and Choi, Hong-Seok and Kim, In-Keun and Yang, Seung Min and Kim, Sun-Yeol and Jang, Jaemin and Kim, Jinwook and Lee, Seong-Hee and Jeon, Younghyun and Park, Juhyung and Kim, Tae-Kyun and Ka, Dongyoon and Oh, Sanghoon and Kim, Jinse and Jeon, Junyeol and Kim, Seonhong and Kim, Kyeong Tae and Kim, Taeho and Yang, Hyeonjin and Yang, Dongju and Lee, Minseop and Song, Heewoong and Jang, Dongwook and Shin, Junghyun and Kim, Hyunsik and Baek, Changki and Jeong, Hajun and Yoon, Jongchan and Lim, Seung-Kyun and Lee, Kyo Yun and Koo, Young Jun and Park, Myeong-Jae and Cho, Joohwan and Kim, Jonghwan},
	title = {13.4 A 48GB 16-High 1280GB/s HBM3E DRAM with All-Around Power TSV and a 6-Phase RDQS Scheme for TSV Area Optimization},
	year = {2024},
	journal = {Digest of Technical Papers - IEEE International Solid-State Circuits Conference},
	pages = {238 – 240},
	doi = {10.1109/ISSCC49657.2024.10454440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188102256&doi=10.1109%2fISSCC49657.2024.10454440&partnerID=40&md5=a37c229f6ed8e60b368a2f1c80b32c2c},
	affiliations = {SK Hynix Semiconductor, Icheon, South Korea},
	abstract = {With the emergence of large-language models (LLM) and generative AI, which require an enormous amount of model parameters, the required memory bandwidth and capacity for high-end systems is on an unprecedented increase. To meet this need, we present an extended version of the high-bandwidth memory-3 (HBM3 DRAM), HBM3E, which achieves a 1280GB/s bandwidth with a cube density of 48GB. New design schemes and features, such as all-around power-through-silicon via (TSV), a 6-phase read-data-strobe (RDQS) scheme, a byte-mapping swap scheme, and a voltage-drift compensator for write data strobe (WDQS), are implemented to achieve extended bandwidth and capacity with enhanced reliability. The overall architecture and specifications, such as bump map footprint, the number of channel and I/Os, and the operation voltage, are identical to the latest HBM3 [1, 2]; therefore, backward compatibility is provided, avoiding system modification.  © 2024 IEEE.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {01936530},
	isbn = {979-835030620-0},
	coden = {DTPCD},
	language = {English},
	abbrev_source_title = {Dig Tech Pap IEEE Int Solid State Circuits Conf},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Porcelli2024,
	author = {Porcelli, Lorenzo and Mastroianni, Michele and Ficco, Massimo and Palmieri, Francesco},
	title = {A User-Centered Privacy Policy Management System for Automatic Consent on Cookie Banners †},
	year = {2024},
	journal = {Computers},
	volume = {13},
	number = {2},
	doi = {10.3390/computers13020043},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187272878&doi=10.3390%2fcomputers13020043&partnerID=40&md5=8e9cf647e166eba352941c4cb99b97d5},
	affiliations = {Department of Computer Science, University of Salerno, Fisciano, 84084, Italy},
	abstract = {Despite growing concerns about privacy and an evolution in laws protecting users’ rights, there remains a gap between how industries manage data and how users can express their preferences. This imbalance often favors industries, forcing users to repeatedly define their privacy preferences each time they access a new website. This process contributes to the privacy paradox. We propose a user support tool named the User Privacy Preference Management System (UPPMS) that eliminates the need for users to handle intricate banners or deceptive patterns. We have set up a process to guide even a non-expert user in creating a standardized personal privacy policy, which is automatically applied to every visited website by interacting with cookie banners. The process of generating actions to apply the user’s policy leverages customized Large Language Models. Experiments demonstrate the feasibility of analyzing HTML code to understand and automatically interact with cookie banners, even implementing complex policies. Our proposal aims to address the privacy paradox related to cookie banners by reducing information overload and decision fatigue for users. It also simplifies user navigation by eliminating the need to repeatedly declare preferences in intricate cookie banners on every visited website, while protecting users from deceptive patterns. © 2024 by the authors.},
	author_keywords = {cookie banner; General Data Protection Regulation (EU GDPR); Generative Pre-trained Transformer (GPT); Large Language Model (LLM); Personal Information Management System (PIMS); privacy paradox; Transparency and Consent Framework (TCF); User Privacy Policy Management System (UPPMS)},
	correspondence_address = {L. Porcelli; Department of Computer Science, University of Salerno, Fisciano, 84084, Italy; email: lporcelli@unisa.it},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {2073431X},
	language = {English},
	abbrev_source_title = {Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access}
}

@ARTICLE{Griffiths202415,
	author = {Griffiths, Dai and Frías-Martínez, Enrique and Tlili, Ahmed and Burgos, Daniel},
	title = {A Cybernetic Perspective on Generative AI in Education: From Transmission to Coordination},
	year = {2024},
	journal = {International Journal of Interactive Multimedia and Artificial Intelligence},
	volume = {8},
	number = {5},
	pages = {15 – 24},
	doi = {10.9781/ijimai.2024.02.008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186890696&doi=10.9781%2fijimai.2024.02.008&partnerID=40&md5=38c90900c94fe3ee36d17489aba124f7},
	affiliations = {Research Institute for Innovation & Technology in Education (UNIR iTED), Universidad Internacional de La Rioja (UNIR), Spain; Smart Learning Institute(SLI), Beijing Normal University (BNU), China},
	abstract = {The recent sudden increase in the capabilities of Large Language Models (LLMs), and generative AI in general, has astonished education professionals and learners. In formulating a response to these developments, educational institutions are constrained by a lack of clarity concerning human-machine communication and its relationship to models of education. Ideas and models from the cybernetic tradition can help to fill this gap. Two paradigms are distinguished: (1) the transmission paradigm (combining the model of learning implied by the instruments and processes of formal education and the conduit model of communication), and (2) the coordination paradigm (combining the constructivist model of learning and the coordination model of communication). It is proposed that these paradigms have long coexisted in educational practice in a modus vivendi, which is disrupted by LLMs. If an LLM can pass an examination, then from within the transmission paradigm this can only understood as demonstrating that the LLM has indeed learned and understood the material being assessed. At the same time, we know that LLMs do not in fact have the capacity to learn and understand, but rather generate a simulacrum of intelligence. It is argued that this paradox prevents educational institutions from formulating a coherent response to generative AI systems. However, within the coordination paradigm the interactions of LLMs and education institutions can be more easily understood and can be situated in a conversational model of learning. These distinctions can help institutions, educational leaders, and teachers, to frame the complex and nuanced questions raised by GenAI, and to chart a course towards its effective use in education. More specifically, they indicate that to benefit fully from the capabilities of generative AI education institutions need to recognize the validity of the coordination paradigm and adapt their processes and instruments accordingly. © 2024, Universidad Internacional de la Rioja. All rights reserved.},
	author_keywords = {Cybernetics; Education; Generative AI; Human-Machine Communication; Large Language Model (LLM); Machine Learning},
	correspondence_address = {D. Griffiths; Research Institute for Innovation & Technology in Education (UNIR iTED), Universidad Internacional de La Rioja (UNIR), Spain; email: david.griffiths@unir.net},
	publisher = {Universidad Internacional de la Rioja},
	issn = {19891660},
	language = {English},
	abbrev_source_title = {Int. J. Interact. Multimed. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access}
}

@ARTICLE{Latif2024,
	author = {Latif, Ehsan and Zhai, Xiaoming},
	title = {Fine-tuning ChatGPT for automatic scoring},
	year = {2024},
	journal = {Computers and Education: Artificial Intelligence},
	volume = {6},
	doi = {10.1016/j.caeai.2024.100210},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184523347&doi=10.1016%2fj.caeai.2024.100210&partnerID=40&md5=b204de8b8aac19bd962b4ad8e8a0cf17},
	affiliations = {AI4STEM Education Center, University of Georgia, Athens, GA, United States},
	abstract = {This study highlights the potential of fine-tuned ChatGPT (GPT-3.5) for automatically scoring student written constructed responses using example assessment tasks in science education. The application of ChatGPT in research and academic fields has greatly enhanced productivity and efficiency. Recent studies on ChatGPT based on OpenAI's generative model GPT-3.5 proved its superiority in predicting the natural language with high accuracy and human-like responses. GPT-3.5 has been trained over enormous online language materials such as journals and Wikipedia; however, direct usage of pre-trained GPT-3.5 is insufficient for automatic scoring as students do not utilize the same language as journals or Wikipedia, and contextual information is required for accurate scoring. All of these imply that a fine-tuning of a domain-specific model using data for specific tasks can enhance model performance. In this study, we fine-tuned GPT-3.5 on six assessment tasks with a diverse dataset of middle-school and high-school student responses and expert scoring. The six tasks comprise two multi-label and four multi-class assessment tasks. We compare the performance of fine-tuned GPT-3.5 with the fine-tuned state-of-the-art Google's generated language model, BERT. The results show that in-domain training corpora constructed from science questions and responses for BERT achieved average accuracy = 0.838, SD = 0.069. GPT-3.5 shows a remarkable average increase (9.1%) in automatic scoring accuracy (mean = 9.15, SD = 0.042) for the six tasks, p =0.001 < 0.05. Specifically, for each of the two multi-label tasks (item 1 with 5 labels; item 2 with 10 labels), GPT-3.5 achieved significantly higher scoring accuracy than BERT across all the labels, with the second item achieving a 7.1% increase. The average scoring increase for the four multi-class items for GPT-3.5 was 10.6% compared to BERT. Our study confirmed the effectiveness of fine-tuned GPT-3.5 for automatic scoring of student responses on domain-specific data in education with high accuracy. We have released fine-tuned models for public use and community engagement. © 2024 The Author(s)},
	author_keywords = {Automatic scoring; BERT; Education; Finetune; GPT-3.5; Large language model (LLM)},
	keywords = {Computational linguistics; Education computing; Assessment tasks; Automatic scoring; BERT; Fine tuning; Finetune; GPT-3.5; High-accuracy; Language model; Large language model; Wikipedia; Students},
	correspondence_address = {X. Zhai; AI4STEM Education Center, University of Georgia, Athens, United States; email: xiaoming.zhai@uga.edu},
	publisher = {Elsevier B.V.},
	issn = {2666920X},
	language = {English},
	abbrev_source_title = {Comput. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Wang202429144,
	author = {Wang, Zhoumeng},
	title = {Empowering Few-Shot Recommender Systems With Large Language Models-Enhanced Representations},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {29144 – 29153},
	doi = {10.1109/ACCESS.2024.3368027},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186086298&doi=10.1109%2fACCESS.2024.3368027&partnerID=40&md5=435e762f3d416f7943382c7f872bf8c9},
	affiliations = {The Chinese University of Hong Kong Business School, Marketing Programme, Hong Kong},
	abstract = {Recommender systems utilizing explicit feedback have witnessed significant advancements and widespread applications over the past years. However, generating recommendations in few-shot scenarios remains a persistent challenge. Recently, large language models (LLMs) have emerged as a promising solution for addressing natural language processing (NLP) tasks, thereby offering novel insights into tackling the few-shot scenarios encountered by explicit feedback-based recommender systems. To bridge recommender systems and LLMs, we devise a prompting template that generates user and item representations based on explicit feedback. Subsequently, we integrate these LLM-processed representations into various recommendation models to evaluate their significance across diverse recommendation tasks. Our ablation experiments and case study analysis collectively demonstrate the effectiveness of LLMs in processing explicit feedback, highlighting that LLMs equipped with generative and logical reasoning capabilities can effectively serve as a component of recommender systems to enhance their performance in few-shot scenarios. Furthermore, the broad adaptability of LLMs augments the generalization potential of recommender models, despite certain inherent constraints. We anticipate that our study can inspire researchers to delve deeper into the multifaceted dimensions of LLMs' involvement in recommender systems and contribute to the advancement of the explicit feedback-based recommender systems field.  © 2013 IEEE.},
	author_keywords = {ChatGPT; Large language models; recommender systems; representations},
	keywords = {Computational linguistics; Job analysis; Natural language processing systems; Chatbots; ChatGPT; Explicit feedback; Feed-back based; Language model; Large language model; Natural languages; Predictive models; Representation; Task analysis; Recommender systems},
	correspondence_address = {Z. Wang; The Chinese University of Hong Kong Business School, Marketing Programme, Hong Kong; email: johnnywang@link.cuhk.edu.hk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Hou202429,
	author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
	title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {29 – 38},
	doi = {10.1145/3636243.3636247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182920352&doi=10.1145%2f3636243.3636247&partnerID=40&md5=5b4d36661131c060dca5f1a1c1c48fde},
	affiliations = {Temple University, Philadelphia, PA, United States},
	abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Bard; ChatGPT; computing education; Generative AI; GPT-4V; LLMs; Parsons Problems; visual programming problems},
	keywords = {Codes (symbols); Computational linguistics; Education computing; Risk assessment; Robot programming; Visual languages; Bard; ChatGPT; Computing education; Generative AI; GPT-4v; LLM; Parson problem; Programming problem; Visual programming; Visual programming problem; Character recognition},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071619-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Phillips2024,
	author = {Phillips, Jane and Robie, Chet},
	title = {Can a computer outfake a human?},
	year = {2024},
	journal = {Personality and Individual Differences},
	volume = {217},
	doi = {10.1016/j.paid.2023.112434},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173151802&doi=10.1016%2fj.paid.2023.112434&partnerID=40&md5=c4a55331c36c21a0c0f5db1bf01817dd},
	affiliations = {Wilfrid Laurier University, Lazaridis School of Business & Economics, 75 University Avenue West, Waterloo, N2L 3C7, ON, Canada},
	abstract = {Faking on personality tests continues to be a challenge in hiring practices, and with the increased accessibility to free, generative AI large language models (LLM), the difference between human and algorithmic responses is difficult to distinguish. Four LLMs–GPT-3.5, Jasper, Google Bard, and GPT-4 were prompted to provide ideal responses to personality measures, specific to a provided job description. Responses collected from the LLM's were compared to a previously collected student population sample who were also directed to respond in a ideal fashion to the same job description. Overall, score comparisons indicate the superior performance of GPT-4 on both the single stimulus and forced-choice personality assessments and reinforce the need to consider more advanced options in preventing faking on personality assessments. Additionally, results from this study indicate the need for future research, especially as generative AI improves and becomes more accessible to a range of candidates. © 2023},
	author_keywords = {Forced choice; Generative AI; Large language models; Personality; Single stimulus},
	correspondence_address = {J. Phillips; Wilfrid Laurier University, Lazaridis School of Business & Economics, Waterloo, 75 University Avenue West, N2L 3C7, Canada; email: phil2420@mylaurier.ca},
	publisher = {Elsevier Ltd},
	issn = {01918869},
	coden = {PEIDD},
	language = {English},
	abbrev_source_title = {Pers. Individ. Differ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hueso2023309,
	author = {Hueso, Miguel and Álvarez, Rafael and Marí, David and Ribas-Ripoll, Vicent and Lekadir, Karim and Vellido, Alfredo},
	title = {Is generative artificial intelligence the next step toward a personalized hemodialysis?},
	year = {2023},
	journal = {Revista de investigacion clinica; organo del Hospital de Enfermedades de la Nutricion},
	volume = {75},
	number = {6},
	pages = {309 – 317},
	doi = {10.24875/RIC.23000162},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181395946&doi=10.24875%2fRIC.23000162&partnerID=40&md5=0dd6118b264d6b6a33466ee4a0c7ca7f},
	affiliations = {Department of Nephrology, Hospital Universitari Bellvitge and Institut d'Investigació Biomèdica de Bellvitge-IDIBELL, Barcelona, Spain; BigData and Artificial Intelligence Group (BigSEN Working Group), Spanish Society of Nephrology (SENEFRO), Santander, Spain; Digital Health Unit, Eurecat - Centre Tecnològic de Catalunya, Barcelona, Spain; Artificial Intelligence in Medicine Lab (BCN-AIM), Department of Mathematics and Computer Science, University of Barcelona, Barcelona, Spain; Intelligent Data Science and Artificial Intelligence Research Center, Universitat Politècnica de Catalunya, Barcelona, Spain; Centro de Investigación Biomédica en Red (CIBER), Barcelona, Spain},
	abstract = {Artificial intelligence (AI) generative models driven by the integration of AI and natural language processing technologies, such as OpenAI's chatbot generative pre-trained transformer large language model (LLM), are receiving much public attention and have the potential to transform personalized medicine. Dialysis patients are highly dependent on technology and their treatment generates a challenging large volume of data that has to be analyzed for knowledge extraction. We argue that, by integrating the data acquired from hemodialysis treatments with the powerful conversational capabilities of LLMs, nephrologists could personalize treatments adapted to patients' lifestyles and preferences. We also argue that this new conversational AI integrated with a personalized patient-computer interface will enhance patients' engagement and self-care by providing them with a more personalized experience. However, generative AI models require continuous and accurate updates of data, and expert supervision and must address potential biases and limitations. Dialysis patients can also benefit from other new emerging technologies such as Digital Twins with which patients' care can also be addressed from a personalized medicine perspective. In this paper, we will revise LLMs potential strengths in terms of their contribution to personalized medicine, and, in particular, their potential impact, and limitations in nephrology. Nephrologists' collaboration with AI academia and companies, to develop algorithms and models that are more transparent, understandable, and trustworthy, will be crucial for the next generation of dialysis patients. The combination of technology, patient-specific data, and AI should contribute to create a more personalized and interactive dialysis process, improving patients' quality of life.},
	author_keywords = {Artificial intelligence; Large Language Models; Natural language processing; Personalized hemodialysis},
	keywords = {Algorithms; Artificial Intelligence; Humans; Quality of Life; Renal Dialysis; Software; algorithm; artificial intelligence; hemodialysis; human; quality of life; software},
	issn = {00348376},
	pmid = {37734067},
	language = {English},
	abbrev_source_title = {Rev Invest Clin},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{AlShaikh2024,
	author = {AlShaikh, Rana and Al-Malki, Norah and Almasre, Maida},
	title = {The implementation of the cognitive theory of multimedia learning in the design and evaluation of an AI educational video assistant utilizing large language models},
	year = {2024},
	journal = {Heliyon},
	volume = {10},
	number = {3},
	doi = {10.1016/j.heliyon.2024.e25361},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184014459&doi=10.1016%2fj.heliyon.2024.e25361&partnerID=40&md5=a8643a5a72390c2e1569ac3bd42ffe82},
	affiliations = {Faculty of Computing and Information Technology, Department of Information Systems, King Abdulaziz University, Rabigh, 21911, Saudi Arabia; Faculty of Arts and Humanities, Modern Languages and Literatures Department, King Abdulaziz University, Jeddah, Saudi Arabia; Faculty of Computing and Information Technology, Department of Information Technology, King Abdulaziz University, Jeddah, 21589, Saudi Arabia},
	abstract = {The integration of Artificial Intelligence (AI) holds immense potential for revolutionizing education; especially, in contexts where multimodal learning experiences are designed. This paper investigated the potential benefits of Generative Artificial Intelligence (AI) in education, concentrating on the design and evaluation of an AI Educational Video Assistant tailored for multimodal learning experiences. The tool, utilizing the principles of the Cognitive Theory of Multimedia Learning (CTML), comprises three modules: Transcription, Engagement, and Reinforcement, each focusing on distinct aspects of the learning process. It Integraties Automatic Speech Recognition (ASR) using OpenAI's Whisper and Google's Large Language Model (LLM) Bard. Our twofold objective includes both the development of this AI assistant tool and the assessment of its effect on improving the learning experiences. For the evaluation, a mixed methods approach was adopted, combining human evaluation by nine educational experts with automatic metrics. Participants provided their perceptions on the tool's effectiveness in terms of engagement, content organization, clarity, and usability. Additionally, automatic metrics including Content Distinctiveness and Readability scores were computed. The results from the human evaluation suggest positive impacts across all assessed domains. The automatic metrics further proved the tool's ability in content generation and readability. Collectively, these preliminary results highlight the tool's potential to revolutionize educational design and provide personalized and engaging learning experiences. © 2024 The Authors},
	author_keywords = {ASR; Cognitive theory of multimedia learning; Educational video; Google's bard; Large language models},
	correspondence_address = {R. AlShaikh; Faculty of Computing and Information Technology, Department of Information Systems, King Abdulaziz University, Rabigh, 21911, Saudi Arabia; email: raalshaikh@kau.edu.sa},
	publisher = {Elsevier Ltd},
	issn = {24058440},
	language = {English},
	abbrev_source_title = {Heliyon},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Sufi2024,
	author = {Sufi, Fahim},
	title = {Generative Pre-Trained Transformer (GPT) in Research: A Systematic Review on Data Augmentation},
	year = {2024},
	journal = {Information (Switzerland)},
	volume = {15},
	number = {2},
	doi = {10.3390/info15020099},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185721870&doi=10.3390%2finfo15020099&partnerID=40&md5=802ea936daefd542cce6581a00c08053},
	affiliations = {School of Public Health and Preventive Medicine, Monash University, 553 St. Kilda Rd., Melbourne, 3004, VIC, Australia},
	abstract = {GPT (Generative Pre-trained Transformer) represents advanced language models that have significantly reshaped the academic writing landscape. These sophisticated language models offer invaluable support throughout all phases of research work, facilitating idea generation, enhancing drafting processes, and overcoming challenges like writer’s block. Their capabilities extend beyond conventional applications, contributing to critical analysis, data augmentation, and research design, thereby elevating the efficiency and quality of scholarly endeavors. Strategically narrowing its focus, this review explores alternative dimensions of GPT and LLM applications, specifically data augmentation and the generation of synthetic data for research. Employing a meticulous examination of 412 scholarly works, it distills a selection of 77 contributions addressing three critical research questions: (1) GPT on Generating Research data, (2) GPT on Data Analysis, and (3) GPT on Research Design. The systematic literature review adeptly highlights the central focus on data augmentation, encapsulating 48 pertinent scholarly contributions, and extends to the proactive role of GPT in critical analysis of research data and shaping research design. Pioneering a comprehensive classification framework for “GPT’s use on Research Data”, the study classifies existing literature into six categories and 14 sub-categories, providing profound insights into the multifaceted applications of GPT in research data. This study meticulously compares 54 pieces of literature, evaluating research domains, methodologies, and advantages and disadvantages, providing scholars with profound insights crucial for the seamless integration of GPT across diverse phases of their scholarly pursuits. © 2024 by the author.},
	author_keywords = {data augmentation; feature extraction; GPT; GPT in research; LLM; synthetic data generation; systematic literature review},
	keywords = {Computational linguistics; Data augmentation; Features extraction; Generative pre-trained transformer; Generative pre-trained transformer in research; Language model; LLM; Research data; Research designs; Synthetic data generations; Systematic literature review; Quality control},
	correspondence_address = {F. Sufi; School of Public Health and Preventive Medicine, Monash University, Melbourne, 553 St. Kilda Rd., 3004, Australia; email: research@fahimsufi.com},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20782489},
	language = {English},
	abbrev_source_title = {Information},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access}
}

@ARTICLE{Liu2024464,
	author = {Liu, Zhengliang and Zhong, Aoxiao and Li, Yiwei and Yang, Longtao and Ju, Chao and Wu, Zihao and Ma, Chong and Shu, Peng and Chen, Cheng and Kim, Sekeun and Dai, Haixing and Zhao, Lin and Zhu, Dajiang and Liu, Jun and Liu, Wei and Shen, Dinggang and Li, Quanzheng and Liu, Tianming and Li, Xiang},
	title = {Tailoring Large Language Models to Radiology: A Preliminary Approach to LLM Adaptation for a Highly Specialized Domain},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14348 LNCS},
	pages = {464 – 473},
	doi = {10.1007/978-3-031-45673-2_46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176017806&doi=10.1007%2f978-3-031-45673-2_46&partnerID=40&md5=9ceede1fc434c3042b0f84b55e17bc4d},
	affiliations = {School of Computing, University of Georgia, Athens, United States; Department of Electrical Engineering, Harvard University, Cambridge, United States; School of Automation, Northwestern Polytechnical University, Xi’an, China; Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Massachusetts, United States; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, United States; Department of Radiation Oncology, Mayo Clinic, Phoenix, United States; School of Biomedical Engineering, ShanghaiTech University, Pudong, China; Shanghai United Imaging Intelligence Co., Ltd., Shanghai, China; Shanghai Clinical Research and Trial Center, Shanghai, China},
	abstract = {In this preliminary work, we present a domain fine-tuned LLM model for radiology, an experimental large language model adapted for radiology. This model, created through an exploratory application of instruction tuning on a comprehensive dataset of radiological information, demonstrates promising performance when compared with broader language models such as StableLM, Dolly, and LLaMA. This model exhibits initial versatility in applications related to radiological diagnosis, research, and communication. Our work contributes an early but encouraging step towards the evolution of clinical NLP by implementing a large language model that is local and domain-specific, conforming to stringent privacy norms like HIPAA. The hypothesis of creating customized, large-scale language models catering to distinct requirements of various medical specialties, presents a thought-provoking direction. The blending of conversational prowess and specific domain knowledge in these models kindles hope for future enhancements in healthcare AI. While it is still in its early stages, the potential of generative large language models is intriguing and worthy of further exploration. The demonstration code of our domain fine-tuned LLM model for radiology can be accessed at https://anonymous.4open.science/r/radiology-llm-demo-C3E2/. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Large Language Models; Natural Language Processing; Radiology},
	keywords = {Blending; Computational linguistics; Diagnosis; Domain Knowledge; Natural language processing systems; Domain specific; Language model; Language processing; Large language model; Large-scales; Natural language processing; Natural languages; Performance; Preliminary approach; Stringents; Radiology},
	correspondence_address = {X. Li; Department of Radiology, Massachusetts General Hospital and Harvard Medical School, Massachusetts, United States; email: xli60@mgh.harvard.edu},
	editor = {Cao X. and Ouyang X. and Xu X. and Rekik I. and Cui Z.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303145672-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bhattacharya2024,
	author = {Bhattacharya, Manojit and Pal, Soumen and Chatterjee, Srijan and Alshammari, Abdulrahman and Albekairi, Thamer H. and Jagga, Supriya and Ige Ohimain, Elijah and Zayed, Hatem and Byrareddy, Siddappa N. and Lee, Sang-Soo and Wen, Zhi-Hong and Agoramoorthy, Govindasamy and Bhattacharya, Prosun and Chakraborty, Chiranjib},
	title = {ChatGPT's scorecard after the performance in a series of tests conducted at the multi-country level: A pattern of responses of generative artificial intelligence or large language models},
	year = {2024},
	journal = {Current Research in Biotechnology},
	volume = {7},
	doi = {10.1016/j.crbiot.2024.100194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187948776&doi=10.1016%2fj.crbiot.2024.100194&partnerID=40&md5=fcf23669d14fe514cd9d58216f1a6fe6},
	affiliations = {Department of Zoology, Fakir Mohan University, Vyasa Vihar, Odisha, Balasore, 756020, India; School of Mechanical Engineering, Vellore Institute of Technology, Tamil Nadu, Vellore, 632014, India; Institute for Skeletal Aging & Orthopaedic Surgery, Hallym University-Chuncheon Sacred Heart Hospital, Gangwon-do, Chuncheon-si, 24252, South Korea; Department of Pharmacology and Toxicology, College of Pharmacy, King Saud University, Post Box 2455, Riyadh, 11451, Saudi Arabia; Division of Endocrinology, Brigham and Women's Hospital, Harvard Medical School, 25 Shattuck St, Boston, 02115, MA, United States; Microbiology Department, Niger Delta University, Wilberforce Island, Bayelsa State, Nigeria; Department of Biomedical Sciences, College of Health and Sciences, Qatar University, QU Health, Doha, Qatar; Department of Pharmacology and Experimental Neuroscience, University of Nebraska Medical Center, Omaha, 68198, NE, United States; Department of Marine Biotechnology and Resources, National Sun Yat-sen University, Kaohsiung, 80424, Taiwan; College of Pharmacy and Health Care, Tajen University, Pingtung, Yanpu, 907, Taiwan; Department of Sustainable Development, Environmental Science and Engineering, KTH Royal Institute of Technology, Teknikringen 10B, Stockholm, SE 10044, Sweden; Department of Biotechnology, School of Life Science and Biotechnology, Adamas University, West Bengal, Kolkata, 700126, India},
	abstract = {Recently, researchers have shown concern about the ChatGPT-derived answers. Here, we conducted a series of tests using ChatGPT by individual researcher at multi-country level to understand the pattern of its answer accuracy, reproducibility, answer length, plagiarism, and in-depth using two questionnaires (the first set with 15 MCQs and the second 15 KBQ). Among 15 MCQ-generated answers, 13 ± 70 were correct (Median : 82.5; Coefficient variance : 4.85), 3 ± 0.77 were incorrect (Median: 3, Coefficient variance: 25.81), and 1 to 10 were reproducible, and 11 to 15 were not. Among 15 KBQ, the length of each question (in words) is about 294.5 ± 97.60 (mean range varies from 138.7 to 438.09), and the mean similarity index (in words) is about 29.53 ± 11.40 (Coefficient variance: 38.62) for each question. The statistical models were also developed using analyzed parameters of answers. The study shows a pattern of ChatGPT-derive answers with correctness and incorrectness and urges for an error-free, next-generation LLM to avoid users’ misguidance. © 2024 The Author(s)},
	author_keywords = {Accuracy; Answer length; ChatGPT; Plagiarism; Reproducibility},
	keywords = {Article; artificial intelligence; ChatGPT; information processing; large language model; measurement accuracy; performance; plagiarism; reproducibility; statistical model; statistical parameters},
	publisher = {Elsevier B.V.},
	issn = {25902628},
	language = {English},
	abbrev_source_title = {Current Res. Biotechnol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access}
}

@ARTICLE{Wu202441,
	author = {Wu, Meng and Zhou, Xinyu and Ma, Gang and Lu, Zhangwei and Zhang, Liuxin and Zhang, Yu},
	title = {GIST: Transforming Overwhelming Information into Structured Knowledge with Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14474 LNAI},
	pages = {41 – 45},
	doi = {10.1007/978-981-99-9119-8_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185716688&doi=10.1007%2f978-981-99-9119-8_4&partnerID=40&md5=6e13c4e926ba0fe0ded6826232696048},
	affiliations = {Lenovo Research, Beijing, China},
	abstract = {This paper introduces GIST (Generative Information Synthesis Taskforce), a novel personal knowledge management system that utilizes large-scale online language models to analyze and organize the information, generating structured results, including summaries, key points, and questions and answers. The system also utilizes a multimodal information processing approach to enhance comprehension of the content. As the user’s knowledge base grows, GIST becomes a personal knowledge database and provides the necessary information at the right moment. GIST can be accessed on any device, serving as the brain and soul of the user’s devices, and empowering them to effectively manage their personal knowledge. Our demo video is at https://youtu.be/ImtduHMQKFQ. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Multimodal Information Processing with LLM; Personal Knowledge Database; Structured Knowledge},
	keywords = {Computational linguistics; Knowledge management; Information synthesis; Knowledge database; Knowledge management system; Language model; Multi-modal information; Multimodal information processing with LLM; Personal knowledge database; Personal knowledge management; Structured knowledge; Task force; Knowledge based systems},
	correspondence_address = {Y. Zhang; Lenovo Research, Beijing, China; email: Zhangyu29@lenovo.com},
	editor = {Fang L. and Pei J. and Zhai G. and Wang R.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981999118-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Sikand2024,
	author = {Sikand, Samarth and Phokela, Kanchanjot Kaur and Sharma, Vibhu Saujanya and Singi, Kapil and Kaulgud, Vikrant and Tung, Teresa and Sharma, Pragya and Burden, Adam P.},
	title = {How much SPACE do metrics have in GenAI assisted software development?},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3641399.3641419},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186759643&doi=10.1145%2f3641399.3641419&partnerID=40&md5=2528f4581a8e8f0c8c8934dc2199c84f},
	affiliations = {Accenture Labs, India; Accenture, United States},
	abstract = {Large Language Models (LLMs) are revolutionizing the way a developer creates software by replacing code with natural language prompts as primary drivers. While many initial assessments of such LLMs suggest that it helps with developer productivity, other research studies have also pointed out areas in the Software Development Life Cycle(SDLC) and developer experience where such tools fail miserably. Currently, there exist many studies dedicated to evaluation of LLM-based AI-assisted software tools but there lacks a standardization of studies and metrics which may prove to be a hindrance to adoption of metrics and reproducible studies. The primary objective of this survey is to assess the recent user studies and surveys, aimed at evaluating different aspects of developer’s experience of using code-based LLMs, and highlight any existing gaps among them. We have leveraged the SPACE framework to enumerate and categorise metrics from studies conducting some form of controlled user experiments. In Generative AI assisted SDLC, the developer’s experience should encompass the ability to perform the in-hand task efficiently and effectively, with minimal friction using these LLM tools. Our exploration has led to some critical insights regarding complete absence of user studies in Collaborative aspects of teams, bias towards certain LLM models & metrics and lack of diversity in metrics within productivity dimensions. We also propose some recommendations to the research community which will help bring some conformity in the evaluation of such LLMs. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Developer Productivity; Generative AI; Metrics; SDLC; Software},
	keywords = {Codes (symbols); Software design; Developer productivity; Generative AI; Initial assessment; Language model; Metric; Natural languages; Research studies; Software; Software development life-cycle; User study; Life cycle},
	editor = {Charkrabarti S.K. and Komondoor R. and Medicherla R.K. and Rastogi A. and Ghosh S.},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071767-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Saibene20241835,
	author = {Saibene, Alberto Maria and Allevi, Fabiana and Calvo-Henriquez, Christian and Maniaci, Antonino and Mayo-Yáñez, Miguel and Paderno, Alberto and Vaira, Luigi Angelo and Felisati, Giovanni and Craig, John R.},
	title = {Reliability of large language models in managing odontogenic sinusitis clinical scenarios: a preliminary multidisciplinary evaluation},
	year = {2024},
	journal = {European Archives of Oto-Rhino-Laryngology},
	volume = {281},
	number = {4},
	pages = {1835 – 1841},
	doi = {10.1007/s00405-023-08372-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181759067&doi=10.1007%2fs00405-023-08372-4&partnerID=40&md5=495c72818b6fededf59fb4ff4009c947},
	affiliations = {Otolaryngology Unit, Santi Paolo E Carlo Hospital, Department of Health Sciences, Università Degli Studi Di Milano, Milan, Italy; Maxillofacial Surgery Unit, Santi Paolo E Carlo Hospital, Department of Health Sciences, Università Degli Studi Di Milano, Milan, Italy; Service of Otolaryngology, Rhinology Unit, Hospital Complex at the University of Santiago de Compostela, Santiago de Compostela, A Coruña, Spain; Department of Medical, Surgical Sciences and Advanced Technologies G.F. Ingrassia, University of Catania, Catania, Italy; Otorhinolaryngology, Head and Neck Surgery Department, Complexo Hospitalario Universitario A Coruña (CHUAC), Galicia, A Coruña, Spain; Department of Otorhinolaryngology, Head and Neck Surgery, University of Brescia, Brescia, Italy; Maxillofacial Surgery Operative Unit, Department of Medicine, Surgery and Pharmacy, University of Sassari, Sassari, Italy; Biomedical Science PhD School, Biomedical Science Department, University of Sassari, Sassari, Italy; Department of Otolaryngology-Head and Neck Surgery, Henry Ford Health, Detroit, MI, United States},
	abstract = {Purpose: This study aimed to evaluate the utility of large language model (LLM) artificial intelligence tools, Chat Generative Pre-Trained Transformer (ChatGPT) versions 3.5 and 4, in managing complex otolaryngological clinical scenarios, specifically for the multidisciplinary management of odontogenic sinusitis (ODS). Methods: A prospective, structured multidisciplinary specialist evaluation was conducted using five ad hoc designed ODS-related clinical scenarios. LLM responses to these scenarios were critically reviewed by a multidisciplinary panel of eight specialist evaluators (2 ODS experts, 2 rhinologists, 2 general otolaryngologists, and 2 maxillofacial surgeons). Based on the level of disagreement from panel members, a Total Disagreement Score (TDS) was calculated for each LLM response, and TDS comparisons were made between ChatGPT3.5 and ChatGPT4, as well as between different evaluators. Results: While disagreement to some degree was demonstrated in 73/80 evaluator reviews of LLMs’ responses, TDSs were significantly lower for ChatGPT4 compared to ChatGPT3.5. Highest TDSs were found in the case of complicated ODS with orbital abscess, presumably due to increased case complexity with dental, rhinologic, and orbital factors affecting diagnostic and therapeutic options. There were no statistically significant differences in TDSs between evaluators’ specialties, though ODS experts and maxillofacial surgeons tended to assign higher TDSs. Conclusions: LLMs like ChatGPT, especially newer versions, showed potential for complimenting evidence-based clinical decision-making, but substantial disagreement was still demonstrated between LLMs and clinical specialists across most case examples, suggesting they are not yet optimal in aiding clinical management decisions. Future studies will be important to analyze LLMs’ performance as they evolve over time. © The Author(s) 2024.},
	author_keywords = {Artificial intelligence; Chronic rhinosinusitis; Computer-assisted diagnosis; Dental implant; Maxillary sinusitis; Oroantral fistula},
	keywords = {Artificial Intelligence; Humans; Language; Prospective Studies; Reproducibility of Results; Sinusitis; Article; artificial intelligence; ChatGPT; clinical assessment; clinical decision making; evidence based practice; head and neck surgery; human; large language model; maxillary sinus; multidisciplinary team; odontogenic sinusitis; otolaryngologist; preliminary communication; program evaluation; prospective study; reliability; scoring system; sinusitis; total disagreement score; language; reproducibility},
	correspondence_address = {A.M. Saibene; Otolaryngology Unit, Santi Paolo E Carlo Hospital, Department of Health Sciences, Università Degli Studi Di Milano, Milan, Italy; email: alberto.saibene@unimi.it},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09374477},
	coden = {EAOTE},
	pmid = {38189967},
	language = {English},
	abbrev_source_title = {Eur. Arch. Oto-Rhino-Laryngol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Freiman2024,
	author = {Freiman, Ori},
	title = {AI-Testimony, Conversational AIs and Our Anthropocentric Theory of Testimony},
	year = {2024},
	journal = {Social Epistemology},
	doi = {10.1080/02691728.2024.2316622},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187129442&doi=10.1080%2f02691728.2024.2316622&partnerID=40&md5=40e52cd3852fd865055ad20a41637961},
	affiliations = {Digital Society Lab, McMaster University, Hamilton, Canada; Digital Policy Hub, The Centre for International Governance Innovation, Waterloo, Canada},
	abstract = {The ability to interact in a natural language profoundly changes devices’ interfaces and potential applications of speaking technologies. Concurrently, this phenomenon challenges our mainstream theories of knowledge, such as how to analyze linguistic outputs of devices under existing anthropocentric theoretical assumptions. In section 1, I present the topic of machines that speak, connecting between Descartes and Generative AI. In section 2, I argue that accepted testimonial theories of knowledge and justification commonly reject the possibility that a speaking technological artifact can give testimony. In section 3, I identify three assumptions underlying the view that rejects conversational AIs–AI-based technologies that converse, as testifiers: conversational AIs (1) lack intentions, (2) cannot be normatively assessed, and (3) cannot constitute an object in trust relations, while humans can. In section 4, I propose the concept ‘AI-testimony’ for analyzing outputs of conversational AIs, suggesting three conditions for technologies to deliver AI-testimony: (1) content is propositional, (2) generated and delivered with no other human directly involved, (3) the output is perceived as phenomenologically similar to that of a human. I conclude that this concept overcomes the limitations of the anthropocentric concept of testimony, opening future directions of research without associating conversational AIs with human-like agency. © 2024 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {artificial intelligence; conversational AIs; LLM; Testimony},
	correspondence_address = {O. Freiman; Digital Society Lab, McMaster University, Hamilton, L.R. Wilson Hall, 1280 Main Street West, L8S 4L8, Canada; email: freimano@mcmaster.ca},
	publisher = {Routledge},
	issn = {02691728},
	language = {English},
	abbrev_source_title = {Soc. Epistem.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus}
}

@ARTICLE{Gay2024140,
	author = {Gay, Gregory},
	title = {Improving the Readability of Generated Tests Using GPT-4 and ChatGPT Code Interpreter},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14415 LNCS},
	pages = {140 – 146},
	doi = {10.1007/978-3-031-48796-5_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180541014&doi=10.1007%2f978-3-031-48796-5_11&partnerID=40&md5=3718f5529191943a892fcc889a50cf01},
	affiliations = {Chalmers and University of Gothenburg, Gothenburg, Sweden},
	abstract = {A major challenge in automated test generation is the readability of generated tests. Emerging large language models (LLMs) excel at language analysis and transformation tasks. We propose that improving test readability is such a task and explore the capabilities of the GPT-4 LLM in improving readability of tests generated by the Pynguin search-based generation framework. Our initial results are promising. However, there are remaining research and technical challenges. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Automated Test Generation; Generative AI; Large Language Models; Readability; Search-Based Test Generation},
	keywords = {Artificial intelligence; Automated test generations; Code interpreter; Excel; Generative AI; Language model; Large language model; Readability; Search-based; Search-based test generation; Test generations; Computational linguistics},
	correspondence_address = {G. Gay; Chalmers and University of Gothenburg, Gothenburg, Sweden; email: greg@greggay.com},
	editor = {Arcaini P. and Yue T. and Fredericks E.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303148795-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Takano2023872,
	author = {Takano, Yasuomi and Tsurube, Taketo and Ueno, Haruki and Komatsugawa, Hiroshi},
	title = {A Proposal and Evaluation of Learning Advising using a Generative AI},
	year = {2023},
	journal = {31st International Conference on Computers in Education, ICCE 2023 - Proceedings},
	volume = {2},
	pages = {872 – 874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181775931&partnerID=40&md5=065666fd70f830033e4ed09ba92c6c89},
	affiliations = {Graduate School of Science and Engineering, Chitose Institute of Science and Technology, Japan; Faculty of Science and Technology, Chitose Institute of Science and Technology, Japan},
	abstract = {In this paper, we propose and evaluate a method in which learner's learning history and information about goal setting and reflection are provided as prompts to Large Language Models (LLM) that enables automated learning advice generated. The proposed approach allows us to generate advice messages that are relevant to the learner's learning properties, using learners' own sentences for reflections and goal settings. The generated advice is evaluated from the point of view whether it is similar to the actual teacher's one. © 2023 Asia-Pacific Society for Computers in Education.},
	author_keywords = {Autonomous Learning; Flipped Classroom; Generative AI; GPT; LLM},
	keywords = {Automated learning; Autonomous learning; Flipped classroom; Generative AI; Goal-setting; GPT; Language model; Large language model; Property; Teachers'; Learning systems},
	correspondence_address = {Y. Takano; Graduate School of Science and Engineering, Chitose Institute of Science and Technology, Japan; email: takano210@kklab.spub.chitose.ac.jp},
	editor = {Shih J.-L. and Kashihara A. and Chen W. and Chen W. and Ogata H. and Baker R. and Chang B. and Dianati S. and Madathil J. and Yousef A.M.F. and Yang Y. and Zarzour H.},
	publisher = {Asia-Pacific Society for Computers in Education},
	isbn = {978-626968902-6},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Educ., ICCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ghimire2024,
	author = {Ghimire, Prashnna and Kim, Kyungki and Acharya, Manoj},
	title = {Opportunities and Challenges of Generative AI in Construction Industry: Focusing on Adoption of Text-Based Models},
	year = {2024},
	journal = {Buildings},
	volume = {14},
	number = {1},
	doi = {10.3390/buildings14010220},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183190607&doi=10.3390%2fbuildings14010220&partnerID=40&md5=a49449ac5ef5ab9e64204c1b63066c7d},
	affiliations = {Durham School of Architectural Engineering & Construction, University of Nebraska-Lincoln, Lincoln, 68588, NE, United States; SRI International, Menlo Park, 94025, CA, United States},
	abstract = {In the last decade, despite rapid advancements in artificial intelligence (AI) transforming many industry practices, construction largely lags in adoption. Recently, the emergence and rapid adoption of advanced large language models (LLMs) like OpenAI’s GPT, Google’s PaLM, and Meta’s Llama have shown great potential and sparked considerable global interest. However, the current surge lacks a study investigating the opportunities and challenges of implementing Generative AI (GenAI) in the construction sector, creating a critical knowledge gap for researchers and practitioners. This underlines the necessity to explore the prospects and complexities of GenAI integration. Bridging this gap is fundamental to optimizing GenAI’s early stage adoption within the construction sector. Given GenAI’s unprecedented capabilities to generate human-like content based on learning from existing content, we reflect on two guiding questions: What will the future bring for GenAI in the construction industry? What are the potential opportunities and challenges in implementing GenAI in the construction industry? This study delves into reflected perception in literature, analyzes the industry perception using programming-based word cloud and frequency analysis, and integrates authors’ opinions to answer these questions. This paper recommends a conceptual GenAI implementation framework, provides practical recommendations, summarizes future research questions, and builds foundational literature to foster subsequent research expansion in GenAI within the construction and its allied architecture and engineering domains. © 2024 by the authors.},
	author_keywords = {AEC; construction; fine-tuning; generative AI; GPT; implementation framework; Llama; LLM; PaLM},
	keywords = {AEC; Construction sectors; Fine tuning; Generative artificial intelligence; GPT; Implementation framework; Language model; Large language model; Llama; PaLM; Construction industry},
	correspondence_address = {P. Ghimire; Durham School of Architectural Engineering & Construction, University of Nebraska-Lincoln, Lincoln, 68588, United States; email: pghimire3@huskers.unl.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20755309},
	language = {English},
	abbrev_source_title = {Buildings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Thukral2023281,
	author = {Thukral, Vaikunth and Latvala, Lawrence and Swenson, Mark and Horn, Jeff},
	title = {Customer journey optimisation using large language models: Best practices and pitfalls in generative AI},
	year = {2023},
	journal = {Applied Marketing Analytics},
	volume = {9},
	number = {3},
	pages = {281 – 292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180174793&partnerID=40&md5=808ee0dba596cf6fd6057ac225c57d52},
	affiliations = {Teradata, 17095 Via Del Campo, Rancho Bernardo, 92127, CA, United States},
	abstract = {Today’s business environment is moving faster than ever, and the expressive and adaptive capabilities of generative AI (GenAI) and large language models (LLMs) are redefining the enterprise rails of tomorrow. Given the abundance of industry hype, investor expectations and leadership pressure, the initial impulse is to ‘get in the game’. But how does one implement initiatives that drive business outcomes within ethical parameters while avoiding technical pitfalls? Marketers need practical guidance to navigate through these changes. In this paper, the authors examine multiple considerations for deployment of GenAI in marketing and customer experience. How does the marketer decide on which initiatives and opportunities to begin with? Which use cases will drive value as the organisation adapts to deploying these new capabilities? Once a marketer has identified the opportunities to capitalise on through GenAI, how is the capability deployed? There are a variety of approaches that can be considered given the level of organisational capability with AI and resource levels to be applied. As with any cutting-edge capability, there are potential missteps that must be avoided to ensure success. This paper provides some insight based on practical experiences to date that cover ethical, technical and process concerns. The paper presents thoughtful approaches to the deployment of LLMs and GenAI that can result in concrete ROI and reduced risk even in this early stage of adoption. With this information, marketers can be prepared to confidently begin their journey using GenAI to transform their customer experience and drive enterprise value for their organisations. © 2023, Henry Stewart Publications. All rights reserved.},
	author_keywords = {AI; customer experience; CX; GenAI; generative AI; large language models; LLM; marketing},
	publisher = {Henry Stewart Publications},
	issn = {20547544},
	language = {English},
	abbrev_source_title = {Appl. Mark. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Amacher2024,
	author = {Amacher, Simon A. and Arpagaus, Armon and Sahmer, Christian and Becker, Christoph and Gross, Sebastian and Urben, Tabita and Tisljar, Kai and Sutter, Raoul and Marsch, Stephan and Hunziker, Sabina},
	title = {Prediction of outcomes after cardiac arrest by a generative artificial intelligence model},
	year = {2024},
	journal = {Resuscitation Plus},
	volume = {18},
	doi = {10.1016/j.resplu.2024.100587},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185776038&doi=10.1016%2fj.resplu.2024.100587&partnerID=40&md5=58804d340d66801934476b764dc70722},
	affiliations = {Intensive Care Medicine, Department of Acute Medical Care, University Hospital Basel, Basel, Switzerland; Medical Communication and Psychosomatic Medicine, University Hospital Basel, Basel, Switzerland; Emergency Medicine, Department of Acute Medical Care, University Hospital Basel, Basel, Switzerland; Medical Faculty, University of Basel, Basel, Switzerland; Division of Neurophysiology, Department of Neurology, University Hospital Basel, Basel, Switzerland; Post-Intensive Care Clinic, University Hospital Basel, Basel, Switzerland},
	abstract = {Aims: To investigate the prognostic accuracy of a non-medical generative artificial intelligence model (Chat Generative Pre-Trained Transformer 4 - ChatGPT-4) as a novel aspect in predicting death and poor neurological outcome at hospital discharge based on real-life data from cardiac arrest patients. Methods: This prospective cohort study investigates the prognostic performance of ChatGPT-4 to predict outcomes at hospital discharge of adult cardiac arrest patients admitted to intensive care at a large Swiss tertiary academic medical center (COMMUNICATE/PROPHETIC cohort study). We prompted ChatGPT-4 with sixteen prognostic parameters derived from established post-cardiac arrest scores for each patient. We compared the prognostic performance of ChatGPT-4 regarding the area under the curve (AUC), sensitivity, specificity, positive and negative predictive values, and likelihood ratios of three cardiac arrest scores (Out-of-Hospital Cardiac Arrest [OHCA], Cardiac Arrest Hospital Prognosis [CAHP], and PROgnostication using LOGistic regression model for Unselected adult cardiac arrest patients in the Early stages [PROLOGUE score]) for in-hospital mortality and poor neurological outcome. Results: Mortality at hospital discharge was 43% (n = 309/713), 54% of patients (n = 387/713) had a poor neurological outcome. ChatGPT-4 showed good discrimination regarding in-hospital mortality with an AUC of 0.85, similar to the OHCA, CAHP, and PROLOGUE (AUCs of 0.82, 0.83, and 0.84, respectively) scores. For poor neurological outcome, ChatGPT-4 showed a similar prediction to the post-cardiac arrest scores (AUC 0.83). Conclusions: ChatGPT-4 showed a similar performance in predicting mortality and poor neurological outcome compared to validated post-cardiac arrest scores. However, more research is needed regarding illogical answers for potential incorporation of an LLM in the multimodal outcome prognostication after cardiac arrest. © 2024 The Author(s)},
	author_keywords = {Artificial intelligence; Cardiac arrest; Cardiopulmonary resuscitation; Mortality prediction; Neurological outcome},
	correspondence_address = {S. Hunziker; University Hospital Basel, Basel, Petersgraben 4, CH - 4031, Switzerland; email: sabina.hunziker@usb.ch},
	publisher = {Elsevier B.V.},
	issn = {26665204},
	language = {English},
	abbrev_source_title = {Resusc. Plus},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Ahmed2024,
	author = {Ahmed, Wasil and Saturno, Michael and Rajjoub, Rami and Duey, Akiro H. and Zaidat, Bashar and Hoang, Timothy and Restrepo Mejia, Mateo and Gallate, Zachary S. and Shrestha, Nancy and Tang, Justin and Zapolsky, Ivan and Kim, Jun S. and Cho, Samuel K.},
	title = {ChatGPT versus NASS clinical guidelines for degenerative spondylolisthesis: a comparative analysis},
	year = {2024},
	journal = {European Spine Journal},
	doi = {10.1007/s00586-024-08198-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187872385&doi=10.1007%2fs00586-024-08198-6&partnerID=40&md5=57a464234e1877a631c929d091fa978f},
	affiliations = {Icahn School of Medicine at Mount Sinai, New York, NY, United States; Chicago Medical School at Rosalind Franklin University, North Chicago, IL, United States; Department of Orthopedics, Icahn School of Medicine at Mount Sinai, One Gustave L. Levy Place, New York, 10029, NY, United States},
	abstract = {Background context: Clinical guidelines, developed in concordance with the literature, are often used to guide surgeons’ clinical decision making. Recent advancements of large language models and artificial intelligence (AI) in the medical field come with exciting potential. OpenAI’s generative AI model, known as ChatGPT, can quickly synthesize information and generate responses grounded in medical literature, which may prove to be a useful tool in clinical decision-making for spine care. The current literature has yet to investigate the ability of ChatGPT to assist clinical decision making with regard to degenerative spondylolisthesis. Purpose: The study aimed to compare ChatGPT’s concordance with the recommendations set forth by The North American Spine Society (NASS) Clinical Guideline for the Diagnosis and Treatment of Degenerative Spondylolisthesis and assess ChatGPT’s accuracy within the context of the most recent literature. Methods: ChatGPT-3.5 and 4.0 was prompted with questions from the NASS Clinical Guideline for the Diagnosis and Treatment of Degenerative Spondylolisthesis and graded its recommendations as “concordant” or “nonconcordant” relative to those put forth by NASS. A response was considered “concordant” when ChatGPT generated a recommendation that accurately reproduced all major points made in the NASS recommendation. Any responses with a grading of “nonconcordant” were further stratified into two subcategories: “Insufficient” or “Over-conclusive,” to provide further insight into grading rationale. Responses between GPT-3.5 and 4.0 were compared using Chi-squared tests. Results: ChatGPT-3.5 answered 13 of NASS’s 28 total clinical questions in concordance with NASS’s guidelines (46.4%). Categorical breakdown is as follows: Definitions and Natural History (1/1, 100%), Diagnosis and Imaging (1/4, 25%), Outcome Measures for Medical Intervention and Surgical Treatment (0/1, 0%), Medical and Interventional Treatment (4/6, 66.7%), Surgical Treatment (7/14, 50%), and Value of Spine Care (0/2, 0%). When NASS indicated there was sufficient evidence to offer a clear recommendation, ChatGPT-3.5 generated a concordant response 66.7% of the time (6/9). However, ChatGPT-3.5’s concordance dropped to 36.8% when asked clinical questions that NASS did not provide a clear recommendation on (7/19). A further breakdown of ChatGPT-3.5’s nonconcordance with the guidelines revealed that a vast majority of its inaccurate recommendations were due to them being “over-conclusive” (12/15, 80%), rather than “insufficient” (3/15, 20%). ChatGPT-4.0 answered 19 (67.9%) of the 28 total questions in concordance with NASS guidelines (P = 0.177). When NASS indicated there was sufficient evidence to offer a clear recommendation, ChatGPT-4.0 generated a concordant response 66.7% of the time (6/9). ChatGPT-4.0’s concordance held up at 68.4% when asked clinical questions that NASS did not provide a clear recommendation on (13/19, P = 0.104). Conclusions: This study sheds light on the duality of LLM applications within clinical settings: one of accuracy and utility in some contexts versus inaccuracy and risk in others. ChatGPT was concordant for most clinical questions NASS offered recommendations for. However, for questions NASS did not offer best practices, ChatGPT generated answers that were either too general or inconsistent with the literature, and even fabricated data/citations. Thus, clinicians should exercise extreme caution when attempting to consult ChatGPT for clinical recommendations, taking care to ensure its reliability within the context of recent literature. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	author_keywords = {Artificial intelligence; Clinical guidelines; Degenerative spondylolisthesis; Large language models; Spine},
	correspondence_address = {S.K. Cho; Department of Orthopedics, Icahn School of Medicine at Mount Sinai, New York, One Gustave L. Levy Place, 10029, United States; email: Samuel.Cho@mountsinai.org},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09406719},
	coden = {ESJOE},
	language = {English},
	abbrev_source_title = {Eur. Spine J.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus}
}

@ARTICLE{Suárez202446,
	author = {Suárez, Ana and Jiménez, Jaime and Llorente de Pedro, María and Andreu-Vázquez, Cristina and Díaz-Flores García, Víctor and Gómez Sánchez, Margarita and Freire, Yolanda},
	title = {Beyond the Scalpel: Assessing ChatGPT's potential as an auxiliary intelligent virtual assistant in oral surgery},
	year = {2024},
	journal = {Computational and Structural Biotechnology Journal},
	volume = {24},
	pages = {46 – 52},
	doi = {10.1016/j.csbj.2023.11.058},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179123620&doi=10.1016%2fj.csbj.2023.11.058&partnerID=40&md5=86cd61eacbc28df4c7d780cf29547aeb},
	affiliations = {Department of Pre-Clinic Dentistry, Faculty of Biomedical and Health Sciences, Universidad Europea de Madrid, Calle Tajo s/n, Villaviciosa de Odón, Madrid, 28670, Spain; Department of Clinic Dentistry, Faculty of Biomedical and Health Sciences, Universidad Europea de Madrid, Calle Tajo s/n, Villaviciosa de Odón, Madrid, 28670, Spain; Department of Veterinary Medicine, Faculty of Biomedical and Health Sciences, Universidad Europea de Madrid, Calle Tajo s/n, Villaviciosa de Odón, Madrid, 28670, Spain},
	abstract = {AI has revolutionized the way we interact with technology. Noteworthy advances in AI algorithms and large language models (LLM) have led to the development of natural generative language (NGL) systems such as ChatGPT. Although these LLM can simulate human conversations and generate content in real time, they face challenges related to the topicality and accuracy of the information they generate. This study aimed to assess whether ChatGPT-4 could provide accurate and reliable answers to general dentists in the field of oral surgery, and thus explore its potential as an intelligent virtual assistant in clinical decision making in oral surgery. Thirty questions related to oral surgery were posed to ChatGPT4, each question repeated 30 times. Subsequently, a total of 900 responses were obtained. Two surgeons graded the answers according to the guidelines of the Spanish Society of Oral Surgery, using a three-point Likert scale (correct, partially correct/incomplete, and incorrect). Disagreements were arbitrated by an experienced oral surgeon, who provided the final grade Accuracy was found to be 71.7%, and consistency of the experts' grading across iterations, ranged from moderate to almost perfect. ChatGPT-4, with its potential capabilities, will inevitably be integrated into dental disciplines, including oral surgery. In the future, it could be considered as an auxiliary intelligent virtual assistant, though it would never replace oral surgery experts. Proper training and verified information by experts will remain vital to the implementation of the technology. More comprehensive research is needed to ensure the safe and successful application of AI in oral surgery. © 2023 The Authors},
	author_keywords = {Artificial Intelligence; Chatbot; ChatGPT; Dentistry; Large language models; Natural generative language; Open AI; Oral surgery},
	keywords = {Computational linguistics; Decision making; Dentistry; Grading; AI algorithms; Chatbots; ChatGPT; Language model; Large language model; Natural generative language; Open AI; Oral surgery; Real- time; Virtual assistants; algorithm; Article; ChatGPT; clinical decision making; data availability; dentist; disruptive technology; human; medical practice; open ended questionnaire; oral surgery; practice guideline; Surgery},
	correspondence_address = {V. Díaz-Flores García; Department of Pre-Clinic Dentistry, School of Biomedical Sciences, Universidad Europea de Madrid, Madrid, Calle Tajo s/n, Villaviciosa de Odón, 28670, Spain; email: victor.diaz-flores@universidadeuropea.es},
	publisher = {Elsevier B.V.},
	issn = {20010370},
	language = {English},
	abbrev_source_title = {Comput. Struct. Biotechnol. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Silverman2024,
	author = {Silverman, Anna L. and Sushil, Madhumita and Bhasuran, Balu and Ludwig, Dana and Buchanan, James and Racz, Rebecca and Parakala, Mahalakshmi and El-Kamary, Samer and Ahima, Ohenewaa and Belov, Artur and Choi, Lauren and Billings, Monisha and Li, Yan and Habal, Nadia and Liu, Qi and Tiwari, Jawahar and Butte, Atul J. and Rudrapatna, Vivek A.},
	title = {Algorithmic Identification of Treatment-Emergent Adverse Events From Clinical Notes Using Large Language Models: A Pilot Study in Inflammatory Bowel Disease},
	year = {2024},
	journal = {Clinical Pharmacology and Therapeutics},
	doi = {10.1002/cpt.3226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187178037&doi=10.1002%2fcpt.3226&partnerID=40&md5=33c33a196e3063242fb655ee9eea6328},
	affiliations = {Division of Gastroenterology and Hepatology, Department of Medicine, Mayo Clinic, Phoenix, AZ, United States; Department of Medicine, University of California, San Diego, La Jolla, CA, United States; Bakar Computational Health Sciences Institute, San Francisco, CA, United States; United States Food and Drug Administration, Silver Spring, MD, United States; Department of Public Health, University of California, Berkeley, Berkeley, CA, United States; Center for Data-Driven Insights and Innovation, University of California Health, Oakland, CA, United States; Division of Gastroenterology and Hepatology, Department of Medicine, University of California, San Francisco, San Francisco, CA, United States},
	abstract = {Outpatient clinical notes are a rich source of information regarding drug safety. However, data in these notes are currently underutilized for pharmacovigilance due to methodological limitations in text mining. Large language models (LLMs) like Bidirectional Encoder Representations from Transformers (BERT) have shown progress in a range of natural language processing tasks but have not yet been evaluated on adverse event (AE) detection. We adapted a new clinical LLM, University of California – San Francisco (UCSF)-BERT, to identify serious AEs (SAEs) occurring after treatment with a non-steroid immunosuppressant for inflammatory bowel disease (IBD). We compared this model to other language models that have previously been applied to AE detection. We annotated 928 outpatient IBD notes corresponding to 928 individual patients with IBD for all SAE-associated hospitalizations occurring after treatment with a non-steroid immunosuppressant. These notes contained 703 SAEs in total, the most common of which was failure of intended efficacy. Out of eight candidate models, UCSF-BERT achieved the highest numerical performance on identifying drug-SAE pairs from this corpus (accuracy 88–92%, macro F1 61–68%), with 5–10% greater accuracy than previously published models. UCSF-BERT was significantly superior at identifying hospitalization events emergent to medication use (P < 0.01). LLMs like UCSF-BERT achieve numerically superior accuracy on the challenging task of SAE detection from clinical notes compared with prior methods. Future work is needed to adapt this methodology to improve model performance and evaluation using multicenter data and newer architectures like Generative pre-trained transformer (GPT). Our findings support the potential value of using large language models to enhance pharmacovigilance. © 2024 The Authors. Clinical Pharmacology & Therapeutics © 2024 American Society for Clinical Pharmacology and Therapeutics.},
	correspondence_address = {V.A. Rudrapatna; Bakar Computational Health Sciences Institute, San Francisco, United States; email: vivek.rudrapatna@ucsf.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {00099236},
	coden = {CLPTA},
	language = {English},
	abbrev_source_title = {Clin. Pharmacol. Ther.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {All Open Access, Green Open Access}
}

@ARTICLE{Zaretsky2024E240357,
	author = {Zaretsky, Jonah and Min Kim, Jeong and Baskharoun, Samuel and Zhao, Yunan and Austrian, Jonathan and Aphinyanaphongs, Yindalon and Gupta, Ravi and Blecker, Saul B. and Feldman, Jonah},
	title = {Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format},
	year = {2024},
	journal = {JAMA Network Open},
	pages = {E240357},
	doi = {10.1001/jamanetworkopen.2024.0357},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187472990&doi=10.1001%2fjamanetworkopen.2024.0357&partnerID=40&md5=f69bdc78efc778e78319f1f817bc41fb},
	affiliations = {Division of Hospital Medicine, Department of Medicine, NYU (New York University) Langone Health, New York, NY, United States; Department of Medicine, NYU Long Island School of Medicine, Mineola, United States; Department of Population Health, NYU Langone Health, New York, United States; Department of Health Informatics, NYU Langone Medical Center Information Technology, New York, United States; Predictive Analytics Unit, NYU Langone Health, New York, United States; Department of Internal Medicine, Long Island Community Hospital, NYU Langone Health, New York, United States},
	abstract = {IMPORTANCE By law, patients have immediate access to discharge notes in their medical records. Technical language and abbreviations make notes difficult to read and understand for a typical patient. Large language models (LLMs [eg, GPT-4]) have the potential to transform these notes into patient-friendly language and format. OBJECTIVE To determine whether an LLM can transform discharge summaries into a format that is more readable and understandable. DESIGN, SETTING, AND PARTICIPANTS This cross-sectional study evaluated a sample of the discharge summaries of adult patients discharged from the General Internal Medicine service at NYU (New York University) Langone Health from June 1 to 30, 2023. Patients discharged as deceased were excluded. All discharge summaries were processed by the LLM between July 26 and August 5, 2023. INTERVENTIONS A secure Health Insurance Portability and Accountability Act–compliant platform, Microsoft Azure OpenAI, was used to transform these discharge summaries into a patient-friendly format between July 26 and August 5, 2023. MAIN OUTCOMES AND MEASURES Outcomes included readability as measured by Flesch-Kincaid Grade Level and understandability using Patient Education Materials Assessment Tool (PEMAT) scores. Readability and understandability of the original discharge summaries were compared with the transformed, patient-friendly discharge summaries created through the LLM. As balancing metrics, accuracy and completeness of the patient-friendly version were measured. RESULTS Discharge summaries of 50 patients (31 female [62.0%] and 19 male [38.0%]) were included. The median patient age was 65.5 (IQR, 59.0-77.5) years. Mean (SD) Flesch-Kincaid Grade Level was significantly lower in the patient-friendly discharge summaries (6.2 [0.5] vs 11.0 [1.5]; P < .001). PEMAT understandability scores were significantly higher for patient-friendly discharge summaries (81% vs 13%; P < .001). Two physicians reviewed each patient-friendly discharge summary for accuracy on a 6-point scale, with 54 of 100 reviews (54.0%) giving the best possible rating of 6. Summaries were rated entirely complete in 56 reviews (56.0%). Eighteen reviews noted safety concerns, mostly involving omissions, but also several inaccurate statements (termed hallucinations). CONCLUSIONS AND RELEVANCE The findings of this cross-sectional study of 50 discharge summaries suggest that LLMs can be used to translate discharge summaries into patient-friendly language and formats that are significantly more readable and understandable than discharge summaries as they appear in electronic health records. However, implementation will require improvements in accuracy, completeness, and safety. Given the safety concerns, initial implementation will require physician review. © 2024 American Medical Association. All rights reserved.},
	keywords = {Adult; Aged; Artificial Intelligence; Cross-Sectional Studies; Electronic Health Records; Female; Humans; Inpatients; Language; Male; Middle Aged; Patient Discharge; United States; adult; aged; artificial intelligence; cross-sectional study; electronic health record; female; hospital discharge; hospital patient; human; language; male; middle aged; United States},
	correspondence_address = {J. Zaretsky; NYU Langone Health, New York, 550 First Ave, 10016, United States; email: jonah.zaretsky@nyulangone.org},
	publisher = {American Medical Association},
	issn = {25743805},
	pmid = {38466307},
	language = {English},
	abbrev_source_title = {JAMA Netw. Open},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Camara2024,
	author = {Camara, Vanessa and Mendonca-Neto, Rayol and Silva, Andre and Cordovil, Luiz},
	title = {A Large Language Model approach to SQL-To-Text Generation},
	year = {2024},
	journal = {Digest of Technical Papers - IEEE International Conference on Consumer Electronics},
	doi = {10.1109/ICCE59016.2024.10444148},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186995974&doi=10.1109%2fICCE59016.2024.10444148&partnerID=40&md5=8e46dc02ccbb8a4180ed5b31a8ff8b53},
	affiliations = {Sidia Science and Technology Institute, Av. Darcy Vargas, 654, AM, Manaus, 69055-035, Brazil},
	abstract = {Generating relevant explanations given an structured code representation, such as SQL, is a challenging task. Tackling the SQL-To-Text, more specifically the SQL-explanation problem, benefits both non-Technical and technical users. Automatic explanations written in human language can facilitate the understanding of the query's logical structure and it also helps developers to better document and learn SQL code. The approaches for this niche are diverse. Some of them involve sequence-To-sequence models and others utilize graph-To-sequence models to generate explanations. However, considering the latest advances in Large Language Models (LLMs) and the relatively little attention in SQL-To-Text problem, we investigate a new generative approach based on LLMs to infer the logical structure about the query, including columns, tables and relations. We categorize our research on SQL-explanation as a subtask of SQL-To-Text to differ from the translation of SQL code into natural language questions. Experiments were conducted with the open-source Falcon LLM and compared with T5 LLM and Graph2Seq models. The results show that Falcon outperforms previous models achieving 70% of accuracy with human evaluation on Spider dataset and it achieves competitive 75% accuracy with human evaluation on WikiSQL dataset.  © 2024 IEEE.},
	author_keywords = {Deep Learning; Large Language Models; Natural Language Processing; Pre-Trained Models; SQL-To-Text},
	correspondence_address = {V. Camara; Sidia Science and Technology Institute, Manaus, Av. Darcy Vargas, 654, AM, 69055-035, Brazil; email: vanessa.camara@sidia.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {0747668X},
	isbn = {979-835032413-6},
	coden = {DTPEE},
	language = {English},
	abbrev_source_title = {Dig Tech Pap IEEE Int Conf Consum Electron},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Roest2024144,
	author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
	title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {144 – 153},
	doi = {10.1145/3636243.3636259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182947216&doi=10.1145%2f3636243.3636259&partnerID=40&md5=80ee53cbe83496c6b6f61f280c41c773},
	affiliations = {Utrecht University, Utrecht, Netherlands},
	abstract = {Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student's code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {automated feedback; Generative AI; Large Language Models; learning programming; Next-step hints},
	keywords = {Computational linguistics; Education computing; Automated feedback; Expert assessment; Generative AI; Introductory programming; Language model; Large language model; Learning programming; Next-step hint; Programming education; Programming exercise; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071619-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Luke2024,
	author = {Luke, W. A. Nathasha V. and Seow Chong, Lee and Ban, Kenneth H. and Wong, Amanda H. and Zhi Xiong, Chen and Shuh Shing, Lee and Taneja, Reshma and Samarasekera, Dujeepa D. and Yap, Celestial T.},
	title = {Is ChatGPT ‘ready’ to be a learning tool for medical undergraduates and will it perform equally in different subjects? Comparative study of ChatGPT performance in tutorial and case-based learning questions in physiology and biochemistry},
	year = {2024},
	journal = {Medical Teacher},
	doi = {10.1080/0142159X.2024.2308779},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184173668&doi=10.1080%2f0142159X.2024.2308779&partnerID=40&md5=023e43909445eb6d55a6feff36acdb49},
	affiliations = {Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore; Department of Biochemistry, Yong Loo Lin School of Medicine, National University of Singapore, Singapore; Centre for Medical Education, Yong Loo Lin School of Medicine, National University of Singapore, Singapore},
	abstract = {Purpose: Generative AI will become an integral part of education in future. The potential of this technology in different disciplines should be identified to promote effective adoption. This study evaluated the performance of ChatGPT in tutorial and case-based learning questions in physiology and biochemistry for medical undergraduates. Our study mainly focused on the performance of GPT-3.5 version while a subgroup was comparatively assessed on GPT-3.5 and GPT-4 performances. Materials and methods: Answers were generated in GPT-3.5 for 44 modified essay questions (MEQs) in physiology and 43 MEQs in biochemistry. Each answer was graded by two independent examiners. Subsequently, a subset of 15 questions from each subject were selected to represent different score categories of the GPT-3.5 answers; responses were generated in GPT-4, and graded. Results: The mean score for physiology answers was 74.7 (SD 25.96). GPT-3.5 demonstrated a statistically significant (p = .009) superior performance in lower-order questions of Bloom’s taxonomy in comparison to higher-order questions. Deficiencies in the application of physiological principles in clinical context were noted as a drawback. Scores in biochemistry were relatively lower with a mean score of 59.3 (SD 26.9) for GPT-3.5. There was no statistically significant difference in the scores for higher and lower-order questions of Bloom’s taxonomy. The deficiencies highlighted were lack of in-depth explanations and precision. The subset of questions where the GPT-4 and GPT-3.5 were compared demonstrated a better overall performance in GPT-4 responses in both subjects. This difference between the GPT-3.5 and GPT-4 performance was statistically significant in biochemistry but not in physiology. Conclusions: The differences in performance across the two versions, GPT-3.5 and GPT-4 across the disciplines are noteworthy. Educators and students should understand the strengths and limitations of this technology in different fields to effectively integrate this technology into teaching and learning. © 2024 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {ChatGPT; GPT-3.5; GPT-4 generative AI (artificial intelligence); LLM (large language model); physiology biochemistry},
	correspondence_address = {W.A.N.V. Luke; Department of Physiology, Yong Loo Lin School of Medicine, National University of Singapore, Singapore; email: nathasha@nus.edu.sg; C.T. Yap; National University of Singapore, 2 Medical Drive, MD 9, 117593, Singapore; email: phsyapc@nus.edu.sg},
	publisher = {Taylor and Francis Ltd.},
	issn = {0142159X},
	coden = {MEDTD},
	language = {English},
	abbrev_source_title = {Med. Teach.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lan20241,
	author = {Lan, Yu-Ju and Chen, Nian-Shing},
	title = {Teachers’ agency in the era of LLM and generative AI: Designing pedagogical AI agents},
	year = {2024},
	journal = {Educational Technology and Society},
	volume = {27},
	number = {1},
	pages = {1 – 18},
	doi = {10.30191/ETS.202401_27(1).PP01},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185172942&doi=10.30191%2fETS.202401_27%281%29.PP01&partnerID=40&md5=1325b42fc4794a33e5a805fd0900ee78},
	affiliations = {National Taiwan Normal University, Taiwan; Institute for Research Excellence in Learning Sciences, Program of Learning Sciences, National Taiwan Normal University, Taiwan},
	abstract = {The purpose of this study is to explore the existing problems associated with using generative AI in education and to propose a potential solution for addressing those issues through the design of pedagogical AI agents. The existing problems are examined from two different perspectives: those of teachers and students. The proposed solutions for designing pedagogical AI agents are systematically presented, including main concepts, design considerations, functions, procedures, and structure/templates. An example of how to apply the proposed solution in designing a pedagogical AI agent is provided, illustrating its application in teaching order words (or sequencing words). Finally, the paper concludes with a discussion of potential topics for further research. © (2024), (International Forum of Educational Technology and Society). All Rights Reserved.},
	author_keywords = {Generative artificial intelligence (GAI); Instructional design; Pedagogical AI agent; Personalized learning},
	correspondence_address = {N.-S. Chen; Institute for Research Excellence in Learning Sciences, Program of Learning Sciences, National Taiwan Normal University, Taiwan; email: nianshing@gmail.com},
	publisher = {International Forum of Educational Technology and Society,National Taiwan Normal University},
	issn = {11763647},
	language = {English},
	abbrev_source_title = {Educational Technology and Society},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Divito2024320,
	author = {Divito, Christopher B. and Katchikian, Bryan M. and Gruenwald, Jenna E. and Burgoon, Jennifer M.},
	title = {The tools of the future are the challenges of today: The use of ChatGPT in problem-based learning medical education},
	year = {2024},
	journal = {Medical Teacher},
	volume = {46},
	number = {3},
	pages = {320 – 322},
	doi = {10.1080/0142159X.2023.2290997},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180844679&doi=10.1080%2f0142159X.2023.2290997&partnerID=40&md5=7acc46162d743a27db29f3f058f78901},
	affiliations = {College of Medicine, Lake Erie College of Osteopathic Medicine at Seton Hill, Greensburg, PA, United States},
	abstract = {What is the educational challenge? Incorporation of large language model (LLM) or generative artificial intelligence (AI) software poses a challenge to various areas of medical education, including problem-based learning (PBL). LLMs, such as ChatGPT, have incredible potential to transform educational systems and enhance student learning outcomes when used responsibly. What are the proposed solutions? ChatGPT can provide several ways to support students and assist facilitators with course responsibilities. Here we address factors of implementation and describe how ChatGPT can be responsibly utilized to support key elements of PBL. How was the solution implemented? Providing reasonable access is an essential element of novel software implementation. Additionally, training for both faculty and staff is vital to foster responsible usage, provide base-line proficiency, and guide users to critically evaluate the quality of output. What lessons were learned that are relevant to a wider audience? The use of LLMs or other generative AI is dramatically rising in the world. Appropriate and conscientious incorporation of AI into educational programs can foster responsible use and potentially enhance student learning. What are the next steps? Assessment of learning outcomes, student self-efficacy, group dynamics, and stakeholder feedback are required to measure the effects of ChatGPT in the PBL curriculum. Additionally, software programs competitive with ChatGPT are currently under development and will also need to be investigated for their potential role in education. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {ChatGPT; generative artificial intelligence (AI); large language models (LLM); medical education; problem-based learning (PBL)},
	keywords = {Artificial Intelligence; Curriculum; Education, Medical; Humans; Learning; Problem-Based Learning; artificial intelligence; curriculum; human; learning; medical education; problem based learning},
	correspondence_address = {J.M. Burgoon; College of Medicine, Lake Erie College of Osteopathic Medicine at Seton Hill, Greensburg, 20 Seton Hill Drive, 15601, United States; email: jburgoon@lecom.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {0142159X},
	coden = {MEDTD},
	pmid = {38149617},
	language = {English},
	abbrev_source_title = {Med. Teach.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Herrmann-Werner2024,
	author = {Herrmann-Werner, Anne and Festl-Wietek, Teresa and Holderried, Friederike and Herschbach, Lea and Griewatz, Jan and Masters, Ken and Zipfel, Stephan and Mahling, Moritz},
	title = {Assessing ChatGPT's Mastery of Bloom's Taxonomy Using Psychosomatic Medicine Exam Questions: Mixed-Methods Study},
	year = {2024},
	journal = {Journal of Medical Internet Research},
	volume = {26},
	number = {1},
	doi = {10.2196/52113},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183224105&doi=10.2196%2f52113&partnerID=40&md5=0bb89fbd1ef18bc48868aaf4422563f3},
	affiliations = {Tübingen Institute for Medical Education, Faculty of Medicine, University of Tübingen, Tübingen, Germany; Department of Psychosomatic Medicine and Psychotherapy, University Hospital Tübingen, Tübingen, Germany; University Department of Anesthesiology and Intensive Care Medicine, University Hospital Tübingen, Tübingen, Germany; Medical Education and Informatics Department, College of Medicine and Health Sciences, Sultan Qaboos University, Muscat, Oman; Department of Diabetology, Endocrinology, Nephrology, Section of Nephrology and Hypertension, University Hospital Tübingen, Tübingen, Germany; Tübingen Institute for Medical Education, Faculty of Medicine, University of Tübingen, Elfriede-Aulhorn-Strasse 10, Tübingen, 72076, Germany},
	abstract = {Background: Large language models such as GPT-4 (Generative Pre-trained Transformer 4) are being increasingly used in medicine and medical education. However, these models are prone to “hallucinations” (ie, outputs that seem convincing while being factually incorrect). It is currently unknown how these errors by large language models relate to the different cognitive levels defined in Bloom's taxonomy. Objective: This study aims to explore how GPT-4 performs in terms of Bloom's taxonomy using psychosomatic medicine exam questions. Methods: We used a large data set of psychosomatic medicine multiple-choice questions (N=307) with real-world results derived from medical school exams. GPT-4 answered the multiple-choice questions using 2 distinct prompt versions: detailed and short. The answers were analyzed using a quantitative approach and a qualitative approach. Focusing on incorrectly answered questions, we categorized reasoning errors according to the hierarchical framework of Bloom's taxonomy. Results: GPT-4's performance in answering exam questions yielded a high success rate: 93% (284/307) for the detailed prompt and 91% (278/307) for the short prompt. Questions answered correctly by GPT-4 had a statistically significant higher difficulty than questions answered incorrectly (P = .002 for the detailed prompt and P < .001 for the short prompt). Independent of the prompt, GPT-4's lowest exam performance was 78.9% (15/19), thereby always surpassing the “pass” threshold. Our qualitative analysis of incorrect answers, based on Bloom's taxonomy, showed that errors were primarily in the “remember” (29/68) and “understand” (23/68) cognitive levels; specific issues arose in recalling details, understanding conceptual relationships, and adhering to standardized guidelines. Conclusions: GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic medicine multiple-choice exam questions, aligning with previous findings. When evaluated through Bloom's taxonomy, our data revealed that GPT-4 occasionally ignored specific facts (remember), provided illogical reasoning (understand), or failed to apply concepts to a new situation (apply). These errors, which were confidently presented, could be attributed to inherent model biases and the tendency to generate outputs that maximize likelihood. © 2024 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {answer; artificial intelligence; assessment; Bloom's taxonomy; ChatGPT; classification; error; exam; examination; generative; Generative Pre-trained Transformer 4; GPT-4; language model; learning outcome; LLM; MCQ; medical education; medical exam; multiple-choice question; natural language processing; NLP; psychosomatic; question; response; taxonomy},
	keywords = {Aminosalicylic Acid; Education, Medical; Humans; Medicine; Psychosomatic Medicine; Research Design; aminosalicylic acid; Article; ChatGPT; error; human; medical education; medical student; multiple choice test; psychosomatics; qualitative analysis; quantitative analysis; reasoning; taxonomy; medical education; medicine; methodology},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {38261378},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Truhn2024310,
	author = {Truhn, Daniel and Loeffler, Chiara ML and Müller-Franzes, Gustav and Nebelung, Sven and Hewitt, Katherine J and Brandner, Sebastian and Bressem, Keno K and Foersch, Sebastian and Kather, Jakob Nikolas},
	title = {Extracting structured information from unstructured histopathology reports using generative pre-trained transformer 4 (GPT-4)},
	year = {2024},
	journal = {Journal of Pathology},
	volume = {262},
	number = {3},
	pages = {310 – 319},
	doi = {10.1002/path.6232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179672280&doi=10.1002%2fpath.6232&partnerID=40&md5=447111885af14c201add58273c42b10b},
	affiliations = {Department of Diagnostic and Interventional Radiology, University Hospital RWTH Aachen, Aachen, Germany; Else Kroener Fresenius Center for Digital Health, Technical University Dresden, Dresden, Germany; Department of Medicine I, University Hospital Dresden, Dresden, Germany; Department of Medicine III, University Hospital RWTH Aachen, Aachen, Germany; Department of Neurosurgery, University Hospital Erlangen, Erlangen, Germany; Department of Radiology, Charité – Universitätsmedizin Berlin, corporate member of Freie Universität Berlin and Humboldt-Universität zu Berlin, Berlin, Germany; Institute of Pathology, University Medical Center Mainz, Mainz, Germany; Medical Oncology, National Center for Tumor Diseases (NCT), University Hospital Heidelberg, Heidelberg, Germany; Pathology and Data Analytics, Leeds Institute of Medical Research at St James's, University of Leeds, Leeds, United Kingdom},
	abstract = {Deep learning applied to whole-slide histopathology images (WSIs) has the potential to enhance precision oncology and alleviate the workload of experts. However, developing these models necessitates large amounts of data with ground truth labels, which can be both time-consuming and expensive to obtain. Pathology reports are typically unstructured or poorly structured texts, and efforts to implement structured reporting templates have been unsuccessful, as these efforts lead to perceived extra workload. In this study, we hypothesised that large language models (LLMs), such as the generative pre-trained transformer 4 (GPT-4), can extract structured data from unstructured plain language reports using a zero-shot approach without requiring any re-training. We tested this hypothesis by utilising GPT-4 to extract information from histopathological reports, focusing on two extensive sets of pathology reports for colorectal cancer and glioblastoma. We found a high concordance between LLM-generated structured data and human-generated structured data. Consequently, LLMs could potentially be employed routinely to extract ground truth data for machine learning from unstructured pathology reports in the future. © 2023 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of The Pathological Society of Great Britain and Ireland. © 2023 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of The Pathological Society of Great Britain and Ireland.},
	author_keywords = {artificial intelligence; large language models; named entity recognition; natural language processing; pathology report; text mining},
	keywords = {Glioblastoma; Humans; Machine Learning; Precision Medicine; United Kingdom; Article; artificial intelligence; cohort analysis; colorectal cancer; data accuracy; data extraction; deep learning; generative pretrained transformer; glioblastoma; histopathology; human; hypothesis; information center; large language model; large scale production; medical information; natural language processing; neuropathology; proof of concept; glioblastoma; machine learning; personalized medicine; United Kingdom},
	correspondence_address = {J.N. Kather; Else Kroener Fresenius Center for Digital Health, Technical University Dresden, Dresden, Fetscherstrasse 74, 01307, Germany; email: jakob-nikolas.kather@alumni.dkfz.de},
	publisher = {John Wiley and Sons Ltd},
	issn = {00223417},
	coden = {JPTLA},
	pmid = {38098169},
	language = {English},
	abbrev_source_title = {J. Pathol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Fang2024,
	author = {Fang, Xiao and Che, Shangkun and Mao, Minjia and Zhang, Hongzhe and Zhao, Ming and Zhao, Xiaohang},
	title = {Bias of AI-generated content: an examination of news produced by large language models},
	year = {2024},
	journal = {Scientific Reports},
	volume = {14},
	number = {1},
	doi = {10.1038/s41598-024-55686-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186548795&doi=10.1038%2fs41598-024-55686-2&partnerID=40&md5=6c76041b707163dc68aa9679c98be1bb},
	affiliations = {University of Delaware, Newark, United States; Tsinghua University, Beijing, China; Chinese University of Hong Kong, Shenzhen, China; Shanghai University of Finance and Economics, Shanghai, China},
	abstract = {Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts. © The Author(s) 2024.},
	author_keywords = {AI-generated content (AIGC); Bias; ChatGPT; Gender bias; Generative AI; Large language model (LLM); Prompt; Racial bias},
	keywords = {Animals; Aortic Valve Insufficiency; Bias; Camelids, New World; Female; Humans; Language; Male; Sexism; animal; aortic regurgitation; female; human; language; male; New World camelid; sexism; statistical bias},
	correspondence_address = {X. Fang; University of Delaware, Newark, United States; email: xfang@udel.edu; S. Che; Tsinghua University, Beijing, China; email: csk19@mails.tsinghua.edu.cn},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {38433238},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Andrew2024,
	author = {Andrew, Albert},
	title = {Potential applications and implications of large language models in primary care},
	year = {2024},
	journal = {Family Medicine and Community Health},
	volume = {12},
	number = {Suppl 1},
	doi = {10.1136/fmch-2023-002602},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183695151&doi=10.1136%2ffmch-2023-002602&partnerID=40&md5=3e484de141b0059468f9139733427c68},
	affiliations = {The University of Auckland School of Medicine, Auckland, New Zealand},
	abstract = {The recent release of highly advanced generative artificial intelligence (AI) chatbots, including ChatGPT and Bard, which are powered by large language models (LLMs), has attracted growing mainstream interest over its diverse applications in clinical practice, including in health and healthcare. The potential applications of LLM-based programmes in the medical field range from assisting medical practitioners in improving their clinical decision-making and streamlining administrative paperwork to empowering patients to take charge of their own health. However, despite the broad range of benefits, the use of such AI tools also comes with several limitations and ethical concerns that warrant further consideration, encompassing issues related to privacy, data bias, and the accuracy and reliability of information generated by AI. The focus of prior research has primarily centred on the broad applications of LLMs in medicine. To the author’s knowledge, this is, the first article that consolidates current and pertinent literature on LLMs to examine its potential in primary care. The objectives of this paper are not only to summarise the potential benefits, risks and challenges of using LLMs in primary care, but also to offer insights into considerations that primary care clinicians should take into account when deciding to adopt and integrate such technologies into their clinical practice. © Author(s)},
	keywords = {Artificial Intelligence; Clinical Decision-Making; Humans; Language; Primary Health Care; Reproducibility of Results; accuracy; Article; artificial intelligence; clinical decision making; clinical practice; clinician; disease surveillance; history; human; information security; language model; management; misinformation; primary medical care; privacy; reliability; software; artificial intelligence; clinical decision making; language; primary health care; reproducibility},
	correspondence_address = {A. Andrew; The University of Auckland School of Medicine, Auckland, New Zealand; email: albertandrew@hotmail.co.nz},
	publisher = {BMJ Publishing Group},
	issn = {23056983},
	pmid = {38290759},
	language = {English},
	abbrev_source_title = {Fam. Med. Community Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Rando2024164,
	author = {Rando, Javier and Perez-Cruz, Fernando and Hitaj, Briland},
	title = {PassGPT: Password Modeling and (Guided) Generation with Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14347 LNCS},
	pages = {164 – 183},
	doi = {10.1007/978-3-031-51482-1_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182587448&doi=10.1007%2f978-3-031-51482-1_9&partnerID=40&md5=0652cc962b5ac2eb901d8b6ed13e625e},
	affiliations = {ETH Zürich, Andreasstrasse 5, Zürich, 8092, Switzerland; Swiss Data Science Center, Andreasstrasse 5, Zürich, 8092, Switzerland; SRI International, New York, 10165, NY, United States},
	abstract = {Large language models (LLMs) successfully model natural language from vast amounts of text without the need for explicit supervision. In this paper, we investigate the efficacy of LLMs in modeling passwords. We present PassGPT, an LLM trained on password leaks for password generation. PassGPT outperforms existing methods based on generative adversarial networks (GAN) by guessing twice as many previously unseen passwords. Furthermore, we introduce the concept of guided password generation, where we leverage PassGPT sampling procedure to generate passwords matching arbitrary constraints, a feat lacking in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the entropy and probability distribution that PassGPT defines over passwords and discuss their use in enhancing existing password strength estimators. © 2024, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Generative AI; LLMs; Password Guessing},
	keywords = {Authentication; Computational linguistics; Modeling languages; Probability distributions; 'current; Arbitrary constraints; Generative AI; Language model; Large language model; Matchings; Natural languages; Network-based strategy; Password guessing; Sampling procedures; Generative adversarial networks},
	correspondence_address = {J. Rando; ETH Zürich, Zürich, Andreasstrasse 5, 8092, Switzerland; email: jrando@ethz.ch},
	editor = {Tsudik G. and Conti M. and Liang K. and Smaragdakis G.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303151481-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Meça202458,
	author = {Meça, Alba and Shkëlzeni, Nirvana},
	title = {Academic Integrity in the Face of Generative Language Models},
	year = {2024},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {538 LNICST},
	pages = {58 – 70},
	doi = {10.1007/978-3-031-50215-6_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180747804&doi=10.1007%2f978-3-031-50215-6_5&partnerID=40&md5=f773c563d3e3509b4ab97b34989bfdc4},
	affiliations = {Universita degli Studi di Padova, Padova, Italy; Aleksandër Xhuvani University, Elbasan, Albania},
	abstract = {The increasing sophistication of generative language models and their widespread accessibility to the general public has been a cause of growing concern in academia in recent years. While these AI technologies have the potential to greatly enhance the learning experience and facilitate research, they also pose a significant threat to academic integrity. This paper investigates the impact of using tools like chatGPT and other large language models (LLM) in higher education, discussing their potential benefits while focusing more on assessing the risks, including the possibility of plagiarism, cheating, and other types of academic misconduct. It explores how these technologies may be used to undermine established scholarly principles and practices, as well as the challenges of identifying and combating academic dishonesty. Some measures universities and academics may employ in order to mitigate such risks are proposed, and several strategies and tools for detecting AI-generated content are discussed, along with their limitations. © 2024, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
	author_keywords = {Artificial Intelligence; Content Generation; Higher Education; Large language models; Plagiarism},
	keywords = {Intellectual property; Risk assessment; Academic integrity; AI Technologies; Content generation; General publics; High educations; Language model; Large language model; Learning experiences; Plagiarism; Potential benefits; Computational linguistics},
	correspondence_address = {A. Meça; Universita degli Studi di Padova, Padova, Italy; email: alba.meca@studenti.unipd.it},
	editor = {Miraz M.H. and Southall G. and Ali M. and Ware A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18678211},
	isbn = {978-303150214-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Reason2024205,
	author = {Reason, Tim and Benbow, Emma and Langham, Julia and Gimblett, Andy and Klijn, Sven L. and Malcolm, Bill},
	title = {Artificial Intelligence to Automate Network Meta-Analyses: Four Case Studies to Evaluate the Potential Application of Large Language Models},
	year = {2024},
	journal = {PharmacoEconomics - Open},
	volume = {8},
	number = {2},
	pages = {205 – 220},
	doi = {10.1007/s41669-024-00476-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184504830&doi=10.1007%2fs41669-024-00476-9&partnerID=40&md5=8b7cafa342e897474aea83848f9db401},
	affiliations = {Estima Scientific, Mediaworks, 191 Wood Lane, London, W12 7FP, United Kingdom; Bristol Myers Squibb, Princeton, NJ, United States; Bristol Myers Squibb, Uxbridge, United Kingdom},
	abstract = {Background: The emergence of artificial intelligence, capable of human-level performance on some tasks, presents an opportunity to revolutionise development of systematic reviews and network meta-analyses (NMAs). In this pilot study, we aim to assess use of a large-language model (LLM, Generative Pre-trained Transformer 4 [GPT-4]) to automatically extract data from publications, write an R script to conduct an NMA and interpret the results. Methods: We considered four case studies involving binary and time-to-event outcomes in two disease areas, for which an NMA had previously been conducted manually. For each case study, a Python script was developed that communicated with the LLM via application programming interface (API) calls. The LLM was prompted to extract relevant data from publications, to create an R script to be used to run the NMA and then to produce a small report describing the analysis. Results: The LLM had a > 99% success rate of accurately extracting data across 20 runs for each case study and could generate R scripts that could be run end-to-end without human input. It also produced good quality reports describing the disease area, analysis conducted, results obtained and a correct interpretation of the results. Conclusions: This study provides a promising indication of the feasibility of using current generation LLMs to automate data extraction, code generation and NMA result interpretation, which could result in significant time savings and reduce human error. This is provided that routine technical checks are performed, as recommend for human-conducted analyses. Whilst not currently 100% consistent, LLMs are likely to improve with time. © The Author(s) 2024.},
	correspondence_address = {T. Reason; Estima Scientific, Mediaworks, London, 191 Wood Lane, W12 7FP, United Kingdom; email: tim.reason@estima-sci.com},
	publisher = {Adis},
	issn = {25094262},
	language = {English},
	abbrev_source_title = {PharmacoEcon. Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Singer2024438,
	author = {Singer, Maxwell B. and Fu, Julia J. and Chow, Jessica and Teng, Christopher C.},
	title = {Development and Evaluation of Aeyeconsult: A Novel Ophthalmology Chatbot Leveraging Verified Textbook Knowledge and GPT-4},
	year = {2024},
	journal = {Journal of Surgical Education},
	volume = {81},
	number = {3},
	pages = {438 – 443},
	doi = {10.1016/j.jsurg.2023.11.019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180609426&doi=10.1016%2fj.jsurg.2023.11.019&partnerID=40&md5=29f55af080729cac3415802aa7f6cd24},
	affiliations = {Department of Ophthalmology and Visual Science, Yale School of Medicine, New Haven, Connecticut, United States; Yale School of Medicine, New Haven, Connecticut, United States},
	abstract = {Objective: There has been much excitement on the use of large language models (LLMs) such as ChatGPT in ophthalmology. However, LLMs are limited in that they are trained on unverified information and do not cite their sources. This paper highlights a new methodology to create a generative AI chatbot to answer eye care related questions which uses only verified ophthalmology textbooks as data and cites its sources. Setting: Yale School of Medicine Department of Ophthalmology and Visual Science. Design/Methods: Aeyeconsult, an ophthalmology chatbot, was developed using GPT-4 (the LLM used to power the publicly available chatbot ChatGPT-4), LangChain, and Pinecone. Ophthalmology textbooks were processed into embeddings and stored in Pinecone. User queries were similarly converted, compared to stored embeddings, and GPT-4 generated responses. The interface was adapted from public code. Both Aeyeconsult and ChatGPT-4 were tested on the same 260 questions from OphthoQuestions.com, with the first response from Aeyeconsult and ChatGPT-4 recorded as the answer. Results: Aeyeconsult outperformed ChatGPT-4 on the OKAP dataset, with 83.4% correct answers compared to 69.2% (p = 0.0118). Aeyeconsult also had fewer instances of no answer and multiple answers. Both systems performed best in General Medicine, with Aeyeconsult achieving 96.2% accuracy. Aeyeconsult's weakest performance was in Clinical Optics at 68.1%, but it still outperformed ChatGPT-4 in this category (45.5%). Conclusion: LLMs may be useful in answering ophthalmology questions but their trustworthiness and accuracy is limited due to training on unverified internet data and lack of source citation. We used a new methodology, using verified ophthalmology textbooks as source material and providing citations, to mitigate these issues, resulting in a chatbot more accurate than ChatGPT-4 in answering OKAPs style questions. © 2023 Association of Program Directors in Surgery},
	author_keywords = {artificial intelligence; chatbot; ChatGPT; large language models; OKAPs; Systems-Based Practice},
	keywords = {Internet; Ophthalmology; Schools; Software; Article; book; ChatGPT; evaluation study; human; knowledge; language; model; ophthalmology; performance; self evaluation; Internet; school; software},
	correspondence_address = {M.B. Singer; Department of Ophthalmology and Visual Science, Yale School of Medicine, New Haven, 40 Temple Street, 06510, United States; email: maxwell.singer@yale.edu},
	publisher = {Elsevier Inc.},
	issn = {19317204},
	pmid = {38135548},
	language = {English},
	abbrev_source_title = {J. Surg. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Patel2024,
	author = {Patel, Urjitkumar and Yeh, Fang-Chun and Gondhalekar, Chinmay},
	title = {CANAL - Cyber Activity News Alerting Language Model : Empirical Approach vs. Expensive LLMs},
	year = {2024},
	journal = {2024 IEEE 3rd International Conference on AI in Cybersecurity, ICAIC 2024},
	doi = {10.1109/ICAIC60265.2024.10433839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186526416&doi=10.1109%2fICAIC60265.2024.10433839&partnerID=40&md5=828c549b33dd6b79986f0914a16ddaca},
	affiliations = {S&p Global, Ratings Data Science, New York, United States},
	abstract = {In today's digital landscape, where cyber attacks have become the norm, the detection of cyber attacks and threats is critically imperative across diverse domains. Our research presents a new empirical framework for cyber threat modeling, adept at parsing and categorizing cyber-related information from news articles, enhancing real-time vigilance for market stakeholders. At the core of this framework is a fine-tuned BERT model, which we call CANAL - Cyber Activity News Alerting Language Model, tailored for cyber categorization using a novel silver labeling approach powered by Random Forest. We benchmark CANAL against larger, costlier LLMs, including GPT-4, LLaMA, and Zephyr, highlighting their zero to few-shot learning in cyber news classification. CANAL demonstrates superior performance by outperforming all other LLM counterparts in both accuracy and cost-effectiveness. Furthermore, we introduce the Cyber Signal Discovery module, a strategic component designed to efficiently detect emerging cyber signals from news articles. Collectively, CANAL and Cyber Signal Discovery module equip our framework to provide a robust and cost-effective solution for businesses that require agile responses to cyber intelligence. © 2024 IEEE.},
	author_keywords = {BERT; Cyber News Alerts; Cyber Risk Modeling; Cyber Signal Discovery; Empirical Cost Analysis; Generative AI (Gen AI); Large Language Models (LLM); Machine Learning; Natural Language Processing (NLP)},
	keywords = {Computational linguistics; Computer crime; Cost benefit analysis; Crime; Learning algorithms; Learning systems; Natural language processing systems; Network security; Risk assessment; BERT; Cost analysis; Cybe news alert; Cybe risk modeling; Cybe signal discovery; Empirical cost analyse; Generative AI; Language model; Language processing; Large language model; Machine-learning; Natural language processing; Natural languages; News alerts; Risk modeling; Cost effectiveness},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038185-6},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. AI Cybersecur., ICAIC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Maree2024551,
	author = {Maree, Mohammed and Al-Qasem, Rabee and Tantour, Banan},
	title = {Transforming legal text interactions: leveraging natural language processing and large language models for legal support in Palestinian cooperatives},
	year = {2024},
	journal = {International Journal of Information Technology (Singapore)},
	volume = {16},
	number = {1},
	pages = {551 – 558},
	doi = {10.1007/s41870-023-01584-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174855000&doi=10.1007%2fs41870-023-01584-1&partnerID=40&md5=b618a9062c9193891fcdfc70581f5c3a},
	affiliations = {Faculty of Information Technology, Department of Information Technology, Arab American University, Jenin, Palestine; Cooperative Work Agency, Ramallah, Palestine},
	abstract = {In recent years, there has been a remarkable transformation in our interaction with legal texts due to the widespread utilization and adoption of natural language processing technology. This technology has advanced the analysis and enhanced the understanding of complex legal terminology and contexts. Moreover, the emergence of recent generative large language models (LLMs), particularly ChatGPT, has also introduced a revolutionary contribution to the way legal texts can be processed and comprehended. This paper focuses on the development of a cooperative legal question-answering LLM-based chatbot. Our work involves formulating a set of legal questions pertaining to Palestinian cooperatives and their associated regulations. We compare the auto-generated answers provided by the chatbot with correspondences prepared by a legal expert.To assess the chatbot’s performance, we evaluate its responses to 50 queries generated by the legal expert and compare them to their relevance judgments. The results indicate that the chatbot achieved an impressive overall accuracy rate of 82% in answering the queries, with an F1 score equivalent to 79%. © 2023, The Author(s), under exclusive licence to Bharati Vidyapeeth's Institute of Computer Applications and Management.},
	author_keywords = {Artificial intelligence; Chatbots; Large language models; Legal text; Natural languae processing; Question answering},
	correspondence_address = {M. Maree; Faculty of Information Technology, Department of Information Technology, Arab American University, Jenin, Palestine; email: mohammed.maree@aaup.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {25112104},
	language = {English},
	abbrev_source_title = {Int. J. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{MacNeil202411,
	author = {MacNeil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
	title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {11 – 18},
	doi = {10.1145/3636243.3636245},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182946993&doi=10.1145%2f3636243.3636245&partnerID=40&md5=eb7f4fea87ef58406b3d56051bde73c8},
	affiliations = {Temple University, Philadelphia, PA, United States; University of Auckland, Auckland, New Zealand; Aalto University, Espoo, Finland},
	abstract = {Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior - in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {bug detection; computing education; generative AI; large language models; programming errors},
	keywords = {Computational linguistics; Computer circuits; Education computing; Error detection; Syntactics; Bug detection; Comparatives studies; Computing education; Generative AI; Language model; Large language model; Logic errors; Novice programmer; Performance; Programming errors; Students},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071619-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Agarwal2024,
	author = {Agarwal, Shivali and Chimalakonda, Sridhar and Krishnan, Saravanan and Kanvar, Vini and Shah, Samveg},
	title = {Legacy Software Modernization: A Journey From Non-AI to Generative AI Approaches},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3641399.3641434},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186766261&doi=10.1145%2f3641399.3641434&partnerID=40&md5=67f0620fda481dde9b4322b9faa8693b},
	affiliations = {IBM Research, Bengaluru, India; Indian Institute of Technology, Tirupati, India; IBM Research, Delhi, India},
	abstract = {Dealing with ageing software is a reality of the industry, and even open source software systems. This is a great opportunity for the software engineering researchers to apply the traditional techniques of program analysis to solve problems of refactoring and modernization. The generative AI advancements have opened up a whole new world of possibilities for software engineering tasks such as code generation, code translation, bug fixing among others. Industry is keen on exploring scalable solutions for refactoring, automated testing and now automatic code generation. In this tutorial, we aim to (i) provide a background and overview of legacy software modernization and its importance amidst the emergence of AI-Assisted software and Generative AI (ii) discuss the challenges being faced by industry due to monolithic legacy code and systems (iii) introduce architectural and technological paradigms to modernize this legacy or ageing software (iv) highlight the research and engineering problems that remain to be solved in this space discussing the opportunities for the software engineering research community. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Code LLMs; Legacy Software Modernization; Program Analysis; Refactoring},
	keywords = {Automatic programming; Automation; Codes (symbols); Legacy systems; Modernization; Open source software; Software testing; Code LLM; Codegeneration; Engineering tasks; Legacy software; Legacy software modernization; Open source software systems; Program analysis; Refactorings; Software modernization; Traditional techniques; Open systems},
	editor = {Charkrabarti S.K. and Komondoor R. and Medicherla R.K. and Rastogi A. and Ghosh S.},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071767-3},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Gray2023157,
	author = {Gray, Morgan and Savelka, Jaromir and Oliver, Wesley and Ashley, Kevin},
	title = {Can GPT Alleviate the Burden of Annotation?},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {379},
	pages = {157 – 166},
	doi = {10.3233/FAIA230961},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181174743&doi=10.3233%2fFAIA230961&partnerID=40&md5=f47ec5b47c52b7b74553efde8dc239b5},
	affiliations = {Intelligent Systems Program, University of Pittsburgh, United States; School of Law, University of Pittsburgh, United States; School of Computer Science, Carnegie Mellon University, United States; School of Law, Duquesne University, United States},
	abstract = {Manual annotation is just as burdensome as it is necessary for some legal text analytic tasks. Given the promising performance of Generative Pretrained Transformers (GPT) on a number of different tasks in the legal domain, it is natural to ask if it can help with text annotation. Here we report a series of experiments using GPT-4 and GPT 3.5 as a pre-annotation tool to determine whether a sentence in a legal opinion describes a legal factor. These GPT models assign labels that human annotators subsequently confirm or reject. To assess the utility of pre-annotating sentences at scale, we examine the agreement among gold-standard annotations, GPT's pre-annotations, and law students' annotations. The agreements among these groups support that using GPT-4 as a pre-annotation tool is a useful starting point for large-scale annotation of factors.  © 2023 The Authors.},
	author_keywords = {Annotation; Generative LLMs; GPT-4; Interrater Agreement},
	keywords = {Annotation; Annotation tool; Generative LLM; Generative pretrained transformer-4; Inter-rater agreements; Legal domains; Legal texts; Manual annotation; Performance; Text analytics},
	correspondence_address = {M. Gray; Learning Research and Development Center, Pittsburgh, 3420 Forbes Ave, 15260, United States; email: mag454@pitt.edu},
	editor = {Sileno G. and Spanakis J. and van Dijck G.},
	publisher = {IOS Press BV},
	issn = {09226389},
	isbn = {978-164368472-7},
	language = {English},
	abbrev_source_title = {Front. Artif. Intell. Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Sai202431078,
	author = {Sai, Siva and Gaur, Aanchal and Sai, Revant and Chamola, Vinay and Guizani, Mohsen and Rodrigues, Joel J. P. C.},
	title = {Generative AI for Transformative Healthcare: A Comprehensive Study of Emerging Models, Applications, Case Studies, and Limitations},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {31078 – 31106},
	doi = {10.1109/ACCESS.2024.3367715},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186096742&doi=10.1109%2fACCESS.2024.3367715&partnerID=40&md5=9b8cb3434eebce4c892bcaddee80569b},
	affiliations = {Birla Institute of Technology and Science (BITS), Pilani Campus, Department of Electrical and Electronics Engineering and Appcair, Rajasthan, Pilani, 333031, India; Maharaja Agrasen Institute of Technology, Department of Electrical and Communication Engineering, New Delhi, Delhi, 110086, India; Birla Institute of Technology and Science (BITS), Pilani Campus, Department of Computer Science and Information Systems, Rajasthan, Pilani, 333031, India; Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI), Department of Machine Learning, Abu Dhabi, United Arab Emirates; Lusófona University, Department of Computer Engineering and Information Systems, Lisbon, 1749-024, Portugal},
	abstract = {Generative artificial intelligence (GAI) can be broadly described as an artificial intelligence system capable of generating images, text, and other media types with human prompts. GAI models like ChatGPT, DALL-E, and Bard have recently caught the attention of industry and academia equally. GAI applications span various industries like art, gaming, fashion, and healthcare. In healthcare, GAI shows promise in medical research, diagnosis, treatment, and patient care and is already making strides in real-world deployments. There has yet to be any detailed study concerning the applications and scope of GAI in healthcare. Addressing this research gap, we explore several applications, real-world scenarios, and limitations of GAI in healthcare. We examine how GAI models like ChatGPT and DALL-E can be leveraged to aid in the applications of medical imaging, drug discovery, personalized patient treatment, medical simulation and training, clinical trial optimization, mental health support, healthcare operations and research, medical chatbots, human movement simulation, and a few more applications. Along with applications, we cover four real-world healthcare scenarios that employ GAI: visual snow syndrome diagnosis, molecular drug optimization, medical education, and dentistry. We also provide an elaborate discussion on seven healthcare-customized LLMs like Med-PaLM, BioGPT, DeepHealth, etc.,Since GAI is still evolving, it poses challenges like the lack of professional expertise in decision making, risk of patient data privacy, issues in integrating with existing healthcare systems, and the problem of data bias which are elaborated on in this work along with several other challenges. We also put forward multiple directions for future research in GAI for healthcare.  © 2013 IEEE.},
	author_keywords = {applications; ChatGPT; Generative AI; healthcare; LLMs},
	keywords = {Clinical research; Data privacy; Decision making; Generative adversarial networks; Hospital data processing; Medical education; Medical imaging; Patient treatment; Chatbots; ChatGPT; Drug; Generative AI; Healthcare; LLM; Medical diagnostic imaging; Medical services; Solid modelling; Diagnosis},
	correspondence_address = {V. Chamola; Birla Institute of Technology and Science (BITS), Pilani Campus, Department of Electrical and Electronics Engineering and Appcair, Pilani, Rajasthan, 333031, India; email: vinay.chamola@pilani.bits-pilani.ac.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Matz2024,
	author = {Matz, S.C. and Teeny, J.D. and Vaid, S.S. and Peters, H. and Harari, G.M. and Cerf, M.},
	title = {The potential of generative AI for personalized persuasion at scale},
	year = {2024},
	journal = {Scientific Reports},
	volume = {14},
	number = {1},
	doi = {10.1038/s41598-024-53755-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186219319&doi=10.1038%2fs41598-024-53755-0&partnerID=40&md5=13e82680ee10c83145141a1aa7bfe73f},
	affiliations = {Columbia Business School, NY, United States; Center for Advanced Technology and Human Performance, Columbia Business School, NY, United States; Kellogg School of Management, Evanston, United States; Negotiation, Organizations and Marketing Unit, Department of Communication, Harvard Business School, Stanford University, Stanford, United States; Department of Communication, Stanford University, Stanford, United States},
	abstract = {Matching the language or content of a message to the psychological profile of its recipient (known as “personalized persuasion”) is widely considered to be one of the most effective messaging strategies. We demonstrate that the rapid advances in large language models (LLMs), like ChatGPT, could accelerate this influence by making personalized persuasion scalable. Across four studies (consisting of seven sub-studies; total N = 1788), we show that personalized messages crafted by ChatGPT exhibit significantly more influence than non-personalized messages. This was true across different domains of persuasion (e.g., marketing of consumer products, political appeals for climate action), psychological profiles (e.g., personality traits, political ideology, moral foundations), and when only providing the LLM with a single, short prompt naming or describing the targeted psychological dimension. Thus, our findings are among the first to demonstrate the potential for LLMs to automate, and thereby scale, the use of personalized persuasion in ways that enhance its effectiveness and efficiency. We discuss the implications for researchers, practitioners, and the general public. © The Author(s) 2024.},
	keywords = {Climate; Language; Marketing; Morals; Persuasive Communication; article; ChatGPT; controlled study; generative artificial intelligence; human; large language model; marketing; morality; personality; persuasive communication},
	correspondence_address = {S.C. Matz; Columbia Business School, United States; email: sm4409@gsb.columbia.edu},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {38409168},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Maceda202319,
	author = {Maceda, Lany Laguna and Llovido, Jennifer Laraya and Artiaga, Miles Biago and Abisado, Mideth Balawiswis},
	title = {Classifying Sentiments on Social Media Texts: A GPT-4 Preliminary Study},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {19 – 24},
	doi = {10.1145/3639233.3639353},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187552216&doi=10.1145%2f3639233.3639353&partnerID=40&md5=8e8b42e665cc33a666e8f8068e1897ca},
	affiliations = {Bicol University, Legazpi City, Philippines; National University, Manila, Philippines},
	abstract = {In today's digital age, social media has become a hub for people to express their thoughts and feelings. Sentiment classification discerns public opinions and trends to understand their sentiments towards a certain topic. Often, achieving accurate sentiment classifications in large datasets necessitate the use of human-Annotated training data which can be costly and time-consuming. Large Language Models (LLMs) like the Generative Pre-Trained models by OpenAI have surged in popularity due to its capabilities in understanding the given tasks. In this preliminary study, we report the performance of the latest OpenAI GPT-4 using zero-and one-shot learning approaches on classifying sentiments when fed with social media dataset. Notably, the latter approach written in English which mimics the instructions designed for human annotators, achieved a substantial agreement (k = 0.77) with human annotations, displaying high accuracy, precision, and recall accordingly even without explicit training data. Meanwhile, the fine-Tuned mBERT resulted to lower evaluation scores than the GPT-4. Our findings provide foundational insights into the strengths and limitations of GPT-4 for sentiment classification in a social media dataset, setting the groundwork for broad future research in this field. © 2023 ACM.},
	author_keywords = {GPT-4; LLM Prompting; Sentiment Annotation; Social Media Data},
	keywords = {Classification (of information); Social networking (online); Zero-shot learning; Digital age; GPT-4; Language model; Large datasets; Large language model prompting; Public opinions; Sentiment annotation; Sentiment classification; Social media; Social media datum; Large datasets},
	correspondence_address = {L.L. Maceda; Bicol University, Legazpi City, Philippines; email: llmaceda@bicol-u.edu.ph},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070922-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024,
	author = {Yang, JaeWon and Ardavanis, Kyle S. and Slack, Katherine E. and Fernando, Navin D. and Della Valle, Craig J. and Hernandez, Nicholas M.},
	title = {Chat Generative Pretrained Transformer (ChatGPT) and Bard: Artificial Intelligence Does not yet Provide Clinically Supported Answers for Hip and Knee Osteoarthritis},
	year = {2024},
	journal = {Journal of Arthroplasty},
	doi = {10.1016/j.arth.2024.01.029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186240876&doi=10.1016%2fj.arth.2024.01.029&partnerID=40&md5=c5419fc37ebd7bfef5018392ac08f3bd},
	affiliations = {Department of Orthopaedic Surgery, University of Washington, Seattle, WA, United States; Department of Orthopaedic Surgery, Madigan Medical Center, Tacoma, Washington, United States; Elson S. Floyd College of Medicine, Washington State University, Spokane, WA, United States; Department of Orthopaedic Surgery, Rush University Medical Center, Chicago, Illinois, United States},
	abstract = {Background: Advancements in artificial intelligence (AI) have led to the creation of large language models (LLMs), such as Chat Generative Pretrained Transformer (ChatGPT) and Bard, that analyze online resources to synthesize responses to user queries. Despite their popularity, the accuracy of LLM responses to medical questions remains unknown. This study aimed to compare the responses of ChatGPT and Bard regarding treatments for hip and knee osteoarthritis with the American Academy of Orthopaedic Surgeons (AAOS) Evidence-Based Clinical Practice Guidelines (CPGs) recommendations. Methods: Both ChatGPT (Open AI) and Bard (Google) were queried regarding 20 treatments (10 for hip and 10 for knee osteoarthritis) from the AAOS CPGs. Responses were classified by 2 reviewers as being in “Concordance,” “Discordance,” or “No Concordance” with AAOS CPGs. A Cohen's Kappa coefficient was used to assess inter-rater reliability, and Chi-squared analyses were used to compare responses between LLMs. Results: Overall, ChatGPT and Bard provided responses that were concordant with the AAOS CPGs for 16 (80%) and 12 (60%) treatments, respectively. Notably, ChatGPT and Bard encouraged the use of non-recommended treatments in 30% and 60% of queries, respectively. There were no differences in performance when evaluating by joint or by recommended versus non-recommended treatments. Studies were referenced in 6 (30%) of the Bard responses and none (0%) of the ChatGPT responses. Of the 6 Bard responses, studies could only be identified for 1 (16.7%). Of the remaining, 2 (33.3%) responses cited studies in journals that did not exist, 2 (33.3%) cited studies that could not be found with the information given, and 1 (16.7%) provided links to unrelated studies. Conclusions: Both ChatGPT and Bard do not consistently provide responses that align with the AAOS CPGs. Consequently, physicians and patients should temper expectations on the guidance AI platforms can currently provide. © 2024 Elsevier Inc.},
	author_keywords = {artificial intelligence; bard; ChatGPT; large language models; machine learning},
	publisher = {Elsevier B.V.},
	issn = {08835403},
	coden = {JOARE},
	pmid = {38237878},
	language = {English},
	abbrev_source_title = {J. Arthroplasty},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus}
}

@ARTICLE{Zhang20241,
	author = {Zhang, Xinyu and Xu, Huiyu and Ba, Zhongjie and Wang, Zhibo and Hong, Yuan and Liu, Jian and Qin, Zhan and Ren, Kui},
	title = {PrivacyAsst: Safeguarding User Privacy in Tool-Using Large Language Model Agents},
	year = {2024},
	journal = {IEEE Transactions on Dependable and Secure Computing},
	pages = {1–16},
	doi = {10.1109/TDSC.2024.3372777},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187347404&doi=10.1109%2fTDSC.2024.3372777&partnerID=40&md5=62a0710b5bf24e25320c10bffc3f2aee},
	affiliations = {State Key Laboratory of Blockchain and Data Security, School of Cyber Science and Technology, College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; University of Connecticut, Stamford, CT, USA},
	abstract = {Swift advancements in large language model (LLM) technologies lead to widespread research and applications, particularly in integrating LLMs with auxiliary tools, known as tool-using LLM agents. However, amid user interactions, the transmission of private information to both LLMs and tools poses considerable privacy risks to users. In this paper, we delve into current privacy-preserving solutions for LLMs and outline three pivotal challenges for tool-using LLM agents: generalization to both open-source and closed-source LLMs and tools, compliance with privacy requirements, and applicability to unrestricted tasks. To tackle these challenges, we present PrivacyAsst, the first privacy-preserving framework tailored for tool-using LLM agents, encompassing two solutions for different application scenarios. First, we incorporate a homomorphic encryption scheme to ensure computational security guarantees for users as a safeguard against both open-source and closed-source LLMs and tools. Moreover, we propose a shuffling-based solution to broaden the framework&#x0027;s applicability to unrestricted tasks. This solution employs an attribute-based forgery generative model and an attribute shuffling mechanism to craft privacy-preserving requests, effectively concealing individual inputs. Additionally, we introduce an innovative privacy concept, <inline-formula><tex-math notation="LaTeX">$t$</tex-math></inline-formula>-closeness in image data, for privacy compliance within this solution. Finally, we implement PrivacyAsst, accompanied by two case studies, demonstrating its effectiveness in advancing privacy-preserving artificial intelligence. IEEE},
	author_keywords = {<inline-formula xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"> <tex-math notation="LaTeX">$ t$</tex-math> </inline-formula>-Closeness; Cryptography; Data models; Data privacy; Forgery; Homomorphic encryption; Image color analysis; Large language model (LLM); Privacy; Privacy; Task analysis; Tool-using LLM agent},
	keywords = {Computational linguistics; Privacy-preserving techniques; <inline-formula xmlns:ali="; > <tex-math notation="LaTeX">$ t$</tex-math> </inline-formula>-closeness; Forgery; Ho-momorphic encryptions; Homomorphic-encryptions; Image color analysis; Language model; Large language model; Model agents; Privacy; Task analysis; Tool-using large language model agent; Xmlns:mml="; Xmlns:xlink="; Xmlns:xsi="; Job analysis},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15455971},
	language = {English},
	abbrev_source_title = {IEEE Trans. Dependable Secure Comput.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus}
}

@ARTICLE{Drápal2023197,
	author = {Drápal, Jakub and Westermann, Hannes and Savelka, Jaromir},
	title = {Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {379},
	pages = {197 – 206},
	doi = {10.3233/FAIA230965},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181171915&doi=10.3233%2fFAIA230965&partnerID=40&md5=7ea0fb3bd1d1c15166656cd457530ed9},
	affiliations = {Institute of State and Law, Czech Academy of Sciences, Czech Republic; Institute of Criminal Law and Criminology, Leiden University, Netherlands; Cyberjustice Laboratory, Université de Montréal, Canada; School of Computer Science, Carnegie Mellon University, United States},
	abstract = {Thematic analysis and other variants of inductive coding are widely used qualitative analytic methods within empirical legal studies (ELS). We propose a novel framework facilitating effective collaboration of a legal expert with a large language model (LLM) for generating initial codes (phase 2 of thematic analysis), searching for themes (phase 3), and classifying the data in terms of the themes (to kick-start phase 4). We employed the framework for an analysis of a dataset (n = 785) of facts descriptions from criminal court opinions regarding thefts. The goal of the analysis was to discover classes of typical thefts. Our results show that the LLM, namely OpenAI's GPT-4, generated reasonable initial codes, and it was capable of improving the quality of the codes based on expert feedback. They also suggest that the model performed well in zero-shot classification of facts descriptions in terms of the themes. Finally, the themes autonomously discovered by the LLM appear to map fairly well to the themes arrived at by legal experts. These findings can be leveraged by legal researchers to guide their decisions in integrating LLMs into their thematic analyses, as well as other inductive coding projects.  © 2023 The Authors.},
	author_keywords = {criminal law; empirical legal studies; generative pre-trained transformers; GPT-4; large language models; Thematic analysis},
	keywords = {Crime; Zero-shot learning; Analytic method; Criminal laws; Empirical legal study; Fact descriptions; Generative pre-trained transformer; GPT-4; Language model; Large language model; Legal experts; Thematic analysis; Computational linguistics},
	correspondence_address = {J. Drápal; Institute of State and Law, Czech Academy of Sciences, Czech Republic; email: drapalja@prf.cuni.cz},
	editor = {Sileno G. and Spanakis J. and van Dijck G.},
	publisher = {IOS Press BV},
	issn = {09226389},
	isbn = {978-164368472-7},
	language = {English},
	abbrev_source_title = {Front. Artif. Intell. Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Doughty2024114,
	author = {Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd},
	title = {A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {114 – 123},
	doi = {10.1145/3636243.3636256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179252252&doi=10.1145%2f3636243.3636256&partnerID=40&md5=0e3226760ecd3f6bd81714a39663992d},
	affiliations = {Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models (LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Assessments; Automated Content Generation; Automatic Generation; GPT-4; Large Language Models; Learning Objectives; LLMs; LOs; MCQs; Multiple-choice Questions},
	keywords = {Computational linguistics; High level languages; Learning systems; Assessment; Automated content generation; Automatic Generation; GPT-4; Language model; Large language model; Learning objectives; Multiple-choice questions; Python},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071619-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Patil2024309,
	author = {Patil, Dinesh D. and Dhotre, Dhanraj R. and Gawande, Gopal S. and Mate, Dipali S. and Shelke, Mayura V. and Bhoye, Tejaswini S.},
	title = {Transformative Trends in Generative AI: Harnessing Large Language Models for Natural Language Understanding and Generation},
	year = {2024},
	journal = {International Journal of Intelligent Systems and Applications in Engineering},
	volume = {12},
	number = {4s},
	pages = {309 – 319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179684433&partnerID=40&md5=64e67bff69fc6c7fcd79f9e53267dcb5},
	affiliations = {Department of Computer Science and Engineering, Shri Sant Gadge Baba College of Engineering andTechnology, Bhusawal, India; Department of Computer Science and Engineering, School of Computing, MIT Art Design and Technology University, Loni, Pune, India; Deptt of E & TC Engg, Marathwada Mitra Mandal's College of Engineering, Karve Nagar, Pune, India; Computer Sci.&Engg, Pune, India; Faculty, AI & DS Department, AISSMS Institute of Information Technology, Pune, India; Computer engineering Department, Marathwada Mitra Mandal's College of Engineering, Karve Nagar, Pune, India},
	abstract = {The advent of Large Language Models (LLMs) has ushered in transformative trends in the field of Generative Artificial Intelligence (AI). These models, with billions of parameters, have demonstrated unparalleled capabilities in Natural Language Understanding (NLU) and Generation (NLG) tasks. This paper delves into the evolution of generative AI, emphasizing the pivotal role played by LLMs. We explore the mechanisms by which these models have revolutionized NLU and NLG through their capacity to process vast amounts of textual data and generate coherent and contextually relevant text. Additionally, we investigate the techniques and methodologies employed in harnessing the power of LLMs for various applications, ranging from chatbots and content generation to machine translation and sentiment analysis. Furthermore, we examine the challenges associated with LLM-based generative AI, such as ethical concerns, model bias, and the computational resources required for training and fine-tuning. Finally, we offer insights into the future directions of research in this domain, with a focus on optimizing LLMs for broader applications, mitigating their limitations, and ensuring their responsible deployment in real-world scenarios. This paper serves as a comprehensive overview of the current state of generative AI, shedding light on its potential to reshape the way we interact with and generate natural language content. © 2024, Ismail Saritas. All rights reserved.},
	author_keywords = {Content Generation Ethics; Data Privacy; Ethical Content Generation; Generative AI; Human-AI; Large Language Models (LLMs); Multimodal AI; Natural Language Generation (NLG); Natural Language Understanding (NLU)},
	publisher = {Ismail Saritas},
	issn = {21476799},
	language = {English},
	abbrev_source_title = {Internat. J. Intel. Syst. Appl. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu2024,
	author = {Liu, Zeyu and Liu, Yitong and Zhang, Zehao and Di, Lei and Wei, Feng and Wang, Yin},
	title = {Method for extracting power emergency plan information based on LLM Prompt Learning},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13080},
	doi = {10.1117/12.3025216},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187541793&doi=10.1117%2f12.3025216&partnerID=40&md5=b183b5ce7d5b9f97b1eba12f9b6471b3},
	affiliations = {State Grid Smart Grid Research Institute Co., Ltd, Beijing, China; State Grid Gansu Electric Power Company, Lanzhou, China},
	abstract = {The Large Language Model (LLM) as a representative of generative artificial intelligence, demonstrates strong capabilities in natural language comprehension, which was recently put into engineering applications in the field of power emergency. The author proposes a method of extracting information from power emergency plans by leveraging its emergent abilities and prompt learning techniques. By this method, custom-defined contents can be extracted from power emergency plans and linked to the corresponding personnel to generate executable task instructions. The results indicated that this method can accurately extract the custom-defined information from power emergency plans and applys to different LLMs. And the stronger the emergent abilities of the LLM, the more accurate the information extraction is. The method is proofed to effectively assist power emergency personnel in making decisions and expected to be used in various practical scenarios. © 2024 SPIE.},
	author_keywords = {information extraction; LLM; power emergency plan; prompt},
	keywords = {Information retrieval; Learning systems; Emergency plans; Engineering applications; Information extraction; Language comprehensions; Language model; Large language model; Natural languages; Power; Power emergency plan; Prompt; Personnel},
	correspondence_address = {Z. Liu; State Grid Smart Grid Research Institute Co., Ltd, Beijing, China; email: 393848552@qq.com},
	editor = {Ferreira M.F. and Nakarmi B.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151067478-3},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Guo2024,
	author = {Guo, Eddie and Gupta, Mehul and Deng, Jiawen and Park, Ye-Jean and Paget, Michael and Naugler, Christopher},
	title = {Automated Paper Screening for Clinical Reviews Using Large Language Models: Data Analysis Study},
	year = {2024},
	journal = {Journal of Medical Internet Research},
	volume = {26},
	number = {1},
	doi = {10.2196/48996},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182288843&doi=10.2196%2f48996&partnerID=40&md5=bcefbc7b4792530573f06a8868a90229},
	affiliations = {Cumming School of Medicine, University of Calgary, Calgary, AB, Canada; Temerty Faculty of Medicine, University of Toronto, Toronto, AB, Canada},
	abstract = {Background: The systematic review of clinical research papers is a labor-intensive and time-consuming process that often involves the screening of thousands of titles and abstracts. The accuracy and efficiency of this process are critical for the quality of the review and subsequent health care decisions. Traditional methods rely heavily on human reviewers, often requiring a significant investment of time and resources. Objective: This study aims to assess the performance of the OpenAI generative pretrained transformer (GPT) and GPT-4 application programming interfaces (APIs) in accurately and efficiently identifying relevant titles and abstracts from real-world clinical review data sets and comparing their performance against ground truth labeling by 2 independent human reviewers. Methods: We introduce a novel workflow using the Chat GPT and GPT-4 APIs for screening titles and abstracts in clinical reviews. A Python script was created to make calls to the API with the screening criteria in natural language and a corpus of title and abstract data sets filtered by a minimum of 2 human reviewers. We compared the performance of our model against human-reviewed papers across 6 review papers, screening over 24,000 titles and abstracts. Results: Our results show an accuracy of 0.91, a macro F1-score of 0.60, a sensitivity of excluded papers of 0.91, and a sensitivity of included papers of 0.76. The interrater variability between 2 independent human screeners was κ=0.46, and the prevalence and bias-adjusted κ between our proposed methods and the consensus-based human decisions was κ=0.96. On a randomly selected subset of papers, the GPT models demonstrated the ability to provide reasoning for their decisions and corrected their initial decisions upon being asked to explain their reasoning for incorrect classifications. Conclusions: Large language models have the potential to streamline the clinical review process, save valuable time and effort for researchers, and contribute to the overall quality of clinical reviews. By prioritizing the workflow and acting as an aid rather than a replacement for researchers and reviewers, models such as GPT-4 can enhance efficiency and lead to more accurate and reliable conclusions in medical research. © 2024 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {abstract screening; Chat GPT; classification; extract; extraction; free text; GPT; GPT-4; language model; large language models; LLM; natural language processing; NLP; nonopiod analgesia; review methodology; review methods; screening; systematic; systematic review; unstructured data},
	keywords = {Biomedical Research; Consensus; Data Analysis; Humans; Language; Problem Solving; Article; artificial intelligence; ChatGPT; consensus; data analysis; human; large language model; prevalence; sensitivity analysis; workflow; data analysis; language; medical research; problem solving},
	correspondence_address = {E. Guo; Cumming School of Medicine, University of Calgary, Calgary, 3330 University Dr NW, T2N 1N4, Canada; email: eddie.guo@ucalgary.ca},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {38214966},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kobza2023,
	author = {Kobza, Ondrej and Herel, David and Cuhel, Jan and Gargiani, Tommaso and Pichl, Jan and Marek, Petr and Konrad, Jakub and Sedivy, Jan},
	title = {Enhancements in BlenderBot 3: Expanding Beyond a Singular Model Governance and Boosting Generational Performance},
	year = {2023},
	journal = {Future Internet},
	volume = {15},
	number = {12},
	doi = {10.3390/fi15120384},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180165776&doi=10.3390%2ffi15120384&partnerID=40&md5=3e0d54d8add9e60508a75fd6ee2d6296},
	affiliations = {Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University, Prague, 156 00, Czech Republic},
	abstract = {This paper provides a pioneering examination and enhancement of generative chat models, with a specific focus on the BlenderBot 3 model. Through meticulous interaction with a diverse set of human participants, we dissected the fundamental components of these models, unveiling several deficiencies, including long-term memory and entity recognition. Leveraging these insights, we engineered refined, streamlined iterations, culminating in a chatbot that transcends the capabilities of all existing models. Our work follows Occam’s razor principle and proves that, for tasks with relatively low complexity, using large overparameterized models instead of smaller ones does not bring significant benefits but increases latency, which may result in a lowered overall user experience. In upholding our commitment to transparency and the progression of shared knowledge, we have made our improved model universally accessible through open-source distribution. © 2023 by the authors.},
	author_keywords = {BlenderBot; ChatBot; DeBERTa; LLM; Transformer},
	keywords = {Blenderbot; Chatbots; DeBERTa; Entity recognition; Fundamental component; LLM; Long term memory; Lower complexity; Performance; Transformer},
	correspondence_address = {J. Sedivy; Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University, Prague, 156 00, Czech Republic; email: jan.sedivy@cvut.cz},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {19995903},
	language = {English},
	abbrev_source_title = {Future Internet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Park2024,
	author = {Park, Ye-Jean and Pillai, Abhinav and Deng, Jiawen and Guo, Eddie and Gupta, Mehul and Paget, Mike and Naugler, Christopher},
	title = {Assessing the research landscape and clinical utility of large language models: a scoping review},
	year = {2024},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {24},
	number = {1},
	doi = {10.1186/s12911-024-02459-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187530678&doi=10.1186%2fs12911-024-02459-6&partnerID=40&md5=9b97b44693fe4f525e4f2743874bd31f},
	affiliations = {Temerty Faculty of Medicine, University of Toronto, 1 King’s College Cir, Toronto, M5S 1A8, ON, Canada; Cumming School of Medicine, University of Calgary, 3330 Hospital Dr NW, Calgary, T2N 4N1, AB, Canada},
	abstract = {Importance: Large language models (LLMs) like OpenAI’s ChatGPT are powerful generative systems that rapidly synthesize natural language responses. Research on LLMs has revealed their potential and pitfalls, especially in clinical settings. However, the evolving landscape of LLM research in medicine has left several gaps regarding their evaluation, application, and evidence base. Objective: This scoping review aims to (1) summarize current research evidence on the accuracy and efficacy of LLMs in medical applications, (2) discuss the ethical, legal, logistical, and socioeconomic implications of LLM use in clinical settings, (3) explore barriers and facilitators to LLM implementation in healthcare, (4) propose a standardized evaluation framework for assessing LLMs’ clinical utility, and (5) identify evidence gaps and propose future research directions for LLMs in clinical applications. Evidence review: We screened 4,036 records from MEDLINE, EMBASE, CINAHL, medRxiv, bioRxiv, and arXiv from January 2023 (inception of the search) to June 26, 2023 for English-language papers and analyzed findings from 55 worldwide studies. Quality of evidence was reported based on the Oxford Centre for Evidence-based Medicine recommendations. Findings: Our results demonstrate that LLMs show promise in compiling patient notes, assisting patients in navigating the healthcare system, and to some extent, supporting clinical decision-making when combined with human oversight. However, their utilization is limited by biases in training data that may harm patients, the generation of inaccurate but convincing information, and ethical, legal, socioeconomic, and privacy concerns. We also identified a lack of standardized methods for evaluating LLMs’ effectiveness and feasibility. Conclusions and relevance: This review thus highlights potential future directions and questions to address these limitations and to further explore LLMs’ potential in enhancing healthcare delivery. © The Author(s) 2024.},
	author_keywords = {ChatGPT; Clinical settings; Large language models; Natural language processing; Scoping review},
	keywords = {Clinical Decision-Making; Evidence-Based Medicine; Health Facilities; Humans; Language; MEDLINE; clinical decision making; evidence based medicine; health care facility; human; language; Medline},
	correspondence_address = {Y.-J. Park; Temerty Faculty of Medicine, University of Toronto, Toronto, 1 King’s College Cir, M5S 1A8, Canada; email: yejean.park@mail.utoronto.ca},
	publisher = {BioMed Central Ltd},
	issn = {14726947},
	pmid = {38475802},
	language = {English},
	abbrev_source_title = {BMC Med. Informatics Decis. Mak.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Gold Open Access}
}

@ARTICLE{Tan2024,
	author = {Tan, Yang and Zhang, Zhixing and Li, Mingchen and Pan, Fei and Duan, Hao and Huang, Zijie and Deng, Hua and Yu, Zhuohang and Yang, Chen and Shen, Guoyang and Qi, Peng and Yue, Chengyuan and Liu, Yuxian and Hong, Liang and Yu, Huiqun and Fan, Guisheng and Tang, Yun},
	title = {MedChatZH: A tuning LLM for traditional Chinese medicine consultations},
	year = {2024},
	journal = {Computers in Biology and Medicine},
	volume = {172},
	doi = {10.1016/j.compbiomed.2024.108290},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188030473&doi=10.1016%2fj.compbiomed.2024.108290&partnerID=40&md5=e297d6cdfcab4d753dbbb260e1589377},
	affiliations = {Department of Computer Science and Technology, East China University of Science and Technology, Shanghai, 200237, China; Shanghai Frontiers Science Center of Optogenetic Techniques for Cell Metabolism, Shanghai Key Laboratory of New Drug Design, School of Pharmacy, East China University of Science and Technology, Shanghai, 200237, China; Shanghai Artificial Intelligence Laboratory, Shanghai, 200240, China; Chongqing Artificial Intelligence Research Institute of Shanghai Jiao Tong University, 200240, China; The University of Sydney, Sydney, 2050, Australia; School of Physics and Astronomy & School of Pharmacy, Shanghai Jiao Tong University, Shanghai, 200240, China},
	abstract = {Generative Large Language Models (LLMs) have achieved significant success in various natural language processing tasks, including Question-Answering (QA) and dialogue systems. However, most models are trained on English data and lack strong generalization in providing answers in Chinese. This limitation is especially evident in specialized domains like traditional Chinese medical QA, where performance suffers due to the absence of fine-tuning and high-quality datasets. To address this, we introduce MedChatZH, a dialogue model optimized for Chinese medical QA based on transformer decoder with LLaMA architecture. Continued pre-training on a curated corpus of Chinese medical books is followed by fine-tuning with a carefully selected medical instruction dataset, resulting in MedChatZH outperforming several Chinese dialogue baselines on a real-world medical dialogue dataset. Our model, code, and dataset are publicly available on GitHub (https://github.com/tyang816/MedChatZH) to encourage further research in traditional Chinese medicine and LLMs. © 2024 Elsevier Ltd},
	author_keywords = {Dialogue model; Fine-tuning; Generative large language models (LLMs); Question-answering (QA); Traditional Chinese medical QA},
	keywords = {Computational linguistics; Medicine; Speech processing; Dialogue models; Fine tuning; Generative large language model; Language model; Medical question answering; Natural languages; Question Answering; Question-answering; Traditional chinese medical question-answering; Traditional Chinese Medicine; article; Chinese medicine; consultation; controlled study; human; large language model; llama; medical education; natural language processing; Natural language processing systems},
	correspondence_address = {Y. Tang; Shanghai Frontiers Science Center of Optogenetic Techniques for Cell Metabolism, Shanghai Key Laboratory of New Drug Design, School of Pharmacy, East China University of Science and Technology, Shanghai, 200237, China; email: ytang234@ecust.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {00104825},
	coden = {CBMDA},
	language = {English},
	abbrev_source_title = {Comput. Biol. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{De Renzis202425,
	author = {De Renzis, Simone and Dosso, Dennis and Testolin, Alberto},
	title = {Exploiting Large Language Models to Train Automatic Detectors of Sensitive Data},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3643},
	pages = {25 – 33},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186145176&partnerID=40&md5=65180f473767e150704feae6341f76f3},
	affiliations = {Department of Mathematics, University of Padova, Italy; Siav S.p.A., Italy; Department of General Psychology, University of Padova, Italy},
	abstract = {This paper describes a machine learning system designed to identify sensitive data within Italian text documents, aligning with the definitions and regulations outlined in the General Data Protection Regulation (GDPR). To overcome the lack of suitable training datasets, which would require the disclosure of sensitive data from real users, the proposed system exploits a Large Language Model (LLM) to generate synthetic documents that can be used to train supervised classifiers to detect the target sensitive data. We show that “artificial” sensitive data can be generated using both proprietary or open source LLMs, demonstrating that the proposed approach can be implemented either using external services or by relying on locally runnable models. We focus on the detection of six key domains of sensitive data, by training supervised classifiers based on the BERT Transformer architecture adapted to carry out text classification and Named-Entity Recognition (NER) tasks. We evaluate the performance of the system using fine-grained metrics, and show that the NER model can achieve a remarkable detection performance (over 90% F1 score), thus confirming the quality of the synthetic datasets generated with both proprietary and open source LLMs. The dataset we generated using the open source model is made publicly available for download. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT; Generative Artificial Intelligence; LLM; NER; Sensitive data detection},
	keywords = {Artificial intelligence; Character recognition; Classification (of information); Computational linguistics; Large datasets; Learning systems; Natural language processing systems; Text processing; BERT; Data-detection; Generative artificial intelligence; Language model; Large language model; Named entity recognition; Open-source; Sensitive data detection; Sensitive datas; Supervised classifiers; Sensitive data},
	editor = {Bernasconi E. and Mannocci A. and Poggi A. and Salatino A. and Silvello G.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Earley2023215,
	author = {Earley, Seth},
	title = {What executives need to know about knowledge management, large language models and generative AI},
	year = {2023},
	journal = {Applied Marketing Analytics},
	volume = {9},
	number = {3},
	pages = {215 – 229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180239029&partnerID=40&md5=cde96c9cf7b9458ab64549759f6d0580},
	affiliations = {CEO, Earley Information Science, United States; Earley Information Science, 63 Old East Street, Carlisle, 01741, MA, United States},
	abstract = {This paper discusses the opportunities and risks presented by large language models (LLMs), which power the popular and widely adopted Chat-GPT types of applications. The potential benefits include support for enhancing the customer journey and efficient management of an ever-increasing volume of information for employees. Risks include hallucinations (made up answers by generative AI that are not factually correct), exposure of corporate intellectual property (IP) to training models, lack of traceability and audit trails and misalignment with brand guidelines. The approach to handling risk described in this paper is retrieval-augmented generation (RAG), which references corporate knowledge and data sources in order to identify precise answers and retrieve exactly what users want. The paper also outlines the need for a knowledge architecture which enables enriched embeddings into vector databases which retain the context of intelligently componentised content. Using RAG requires knowledge hygiene and metadata models, and the paper discusses an experiment in which results were measured with and without the knowledge architecture. The improvement was significant: 53 per cent of questions were answered correctly without the model versus 83 per cent with the model. The use of RAG virtually eliminated hallucinations, secured corporate IP and provided traceability and an audit trail. © 2023, Henry Stewart Publications. All rights reserved.},
	author_keywords = {ChatGPT; generative AI; KM; knowledge architecture; knowledge management; knowledge models; large language models; LLM challenges; LLM solutions; LLMs; metadata models; RAG; retrieval augmented generation},
	correspondence_address = {S. Earley; CEO, Earley Information Science, United States; email: seth@earley.com},
	publisher = {Henry Stewart Publications},
	issn = {20547544},
	language = {English},
	abbrev_source_title = {Appl. Mark. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Isleem202427,
	author = {Isleem, Ula N. and Zaidat, Bashar and Ren, Renee and Geng, Eric A. and Burapachaisri, Aonnicha and Tang, Justin E. and Kim, Jun S. and Cho, Samuel K.},
	title = {Can generative artificial intelligence pass the orthopaedic board examination?},
	year = {2024},
	journal = {Journal of Orthopaedics},
	volume = {53},
	pages = {27 – 33},
	doi = {10.1016/j.jor.2023.10.026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186741251&doi=10.1016%2fj.jor.2023.10.026&partnerID=40&md5=94c55bb2cd4635cea87594225815d8ad},
	affiliations = {Department of Orthopaedic Surgery, Icahn School of Medicine at Mount Sinai, New York, NY, United States},
	abstract = {Background: Resident training programs in the US use the Orthopaedic In-Training Examination (OITE) developed by the American Academy of Orthopaedic Surgeons (AAOS) to assess the current knowledge of their residents and to identify the residents at risk of failing the Amerian Board of Orthopaedic Surgery (ABOS) examination. Optimal strategies for OITE preparation are constantly being explored. There may be a role for Large Language Models (LLMs) in orthopaedic resident education. ChatGPT, an LLM launched in late 2022 has demonstrated the ability to produce accurate, detailed answers, potentially enabling it to aid in medical education and clinical decision-making. The purpose of this study is to evaluate the performance of ChatGPT on Orthopaedic In-Training Examinations using Self-Assessment Exams from the AAOS database and approved literature as a proxy for the Orthopaedic Board Examination. Methods: 301 SAE questions from the AAOS database and associated AAOS literature were input into ChatGPT's interface in a question and multiple-choice format and the answers were then analyzed to determine which answer choice was selected. A new chat was used for every question. All answers were recorded, categorized, and compared to the answer given by the OITE and SAE exams, noting whether the answer was right or wrong. Results: Of the 301 questions asked, ChatGPT was able to correctly answer 183 (60.8%) of them. The subjects with the highest percentage of correct questions were basic science (81%), oncology (72.7%, shoulder and elbow (71.9%), and sports (71.4%). The questions were further subdivided into 3 groups: those about management, diagnosis, or knowledge recall. There were 86 management questions and 47 were correct (54.7%), 45 diagnosis questions with 32 correct (71.7%), and 168 knowledge recall questions with 102 correct (60.7%). Conclusions: ChatGPT has the potential to provide orthopedic educators and trainees with accurate clinical conclusions for the majority of board-style questions, although its reasoning should be carefully analyzed for accuracy and clinical validity. As such, its usefulness in a clinical educational context is currently limited but rapidly evolving. Clinical relevance: ChatGPT can access a multitude of medical data and may help provide accurate answers to clinical questions. © 2023 Professor P K Surendran Memorial Education Foundation},
	keywords = {accuracy; Article; board examination; ChatGPT; clinical decision making; data analysis; data base; examination; generative artificial intelligence; large language model; medical education; medical society; multiple choice test; orthopedics; professional competence; residency education; scientific literature; United States; validity},
	correspondence_address = {S.K. Cho; NY, 787 11th Avenue, 7th Fl, New York, 10019, United States; email: samuel.cho@mountsinai.org},
	publisher = {Reed Elsevier India Pvt. Ltd.},
	issn = {0972978X},
	language = {English},
	abbrev_source_title = {J. Orthop.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Insuasti2023,
	author = {Insuasti, Jesus and Roa, Felipe and Zapata-Jaramillo, Carlos Mario},
	title = {Computers’ Interpretations of Knowledge Representation Using Pre-Conceptual Schemas: An Approach Based on the BERT and Llama 2-Chat Models},
	year = {2023},
	journal = {Big Data and Cognitive Computing},
	volume = {7},
	number = {4},
	doi = {10.3390/bdcc7040182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180700331&doi=10.3390%2fbdcc7040182&partnerID=40&md5=080cbde132b1783b7bf6bcb375a73c3e},
	affiliations = {Systems Engineering Department, University of Nariño, Pasto, 520001, Colombia; Computer and Decision Science Department, Universidad Nacional de Colombia, Medellín, 050034, Colombia},
	abstract = {Pre-conceptual schemas are a straightforward way to represent knowledge using controlled language regardless of context. Despite the benefits of using pre-conceptual schemas by humans, they present challenges when interpreted by computers. We propose an approach to making computers able to interpret the basic pre-conceptual schemas made by humans. To do that, the construction of a linguistic corpus is required to work with large language models—LLM. The linguistic corpus was mainly fed using Master’s and doctoral theses from the digital repository of the University of Nariño to produce a training dataset for re-training the BERT model; in addition, we complement this by explaining the elicited sentences in triads from the pre-conceptual schemas using one of the cutting-edge large language models in natural language processing: Llama 2-Chat by Meta AI. The diverse topics covered in these theses allowed us to expand the spectrum of linguistic use in the BERT model and empower the generative capabilities using the fine-tuned Llama 2-Chat model and the proposed solution. As a result, the first version of a computational solution was built to consume the language models based on BERT and Llama 2-Chat and thus automatically interpret pre-conceptual schemas by computers via natural language processing, adding, at the same time, generative capabilities. The validation of the computational solution was performed in two phases: the first one for detecting sentences and interacting with pre-conceptual schemas with students in the Formal Languages and Automata Theory course—the seventh semester of the systems engineering undergraduate program at the University of Nariño’s Tumaco campus. The second phase was for exploring the generative capabilities based on pre-conceptual schemas; this second phase was performed with students in the Object-oriented Design course—the second semester of the systems engineering undergraduate program at the University of Nariño’s Tumaco campus. This validation yielded favorable results in implementing natural language processing using the BERT and Llama 2-Chat models. In this way, some bases were laid for future developments related to this research topic. © 2023 by the authors.},
	author_keywords = {computational linguistics; language models; linguistic corpus; pre-conceptual schema},
	keywords = {Computational linguistics; Curricula; Formal languages; Large dataset; Modeling languages; Natural language processing systems; Students; Computational solutions; Conceptual schemas; Engineering undergraduates; Language model; Language processing; Linguistic corpus; Natural languages; Pre-conceptual schema; Second phase; Undergraduate projects; Knowledge representation},
	correspondence_address = {J. Insuasti; Systems Engineering Department, University of Nariño, Pasto, 520001, Colombia; email: insuasti@udenar.edu.co},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {25042289},
	language = {English},
	abbrev_source_title = {Big Data Cogn. Computing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Khraisha2024,
	author = {Khraisha, Qusai and Put, Sophie and Kappenberg, Johanna and Warraitch, Azza and Hadfield, Kristin},
	title = {Can large language models replace humans in systematic reviews? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages},
	year = {2024},
	journal = {Research Synthesis Methods},
	doi = {10.1002/jrsm.1715},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188242800&doi=10.1002%2fjrsm.1715&partnerID=40&md5=8c4d6d91df6838927513bd92be6a0175},
	affiliations = {Trinity Centre for Global Health, Trinity College Dublin, Dublin, Ireland; School of Psychology, Trinity College Dublin, Dublin, Ireland; Department of Education, York University, York, United Kingdom},
	abstract = {Systematic reviews are vital for guiding practice, research and policy, although they are often slow and labour-intensive. Large language models (LLMs) could speed up and automate systematic reviews, but their performance in such tasks has yet to be comprehensively evaluated against humans, and no study has tested Generative Pre-Trained Transformer (GPT)-4, the biggest LLM so far. This pre-registered study uses a “human-out-of-the-loop” approach to evaluate GPT-4's capability in title/abstract screening, full-text review and data extraction across various literature types and languages. Although GPT-4 had accuracy on par with human performance in some tasks, results were skewed by chance agreement and dataset imbalance. Adjusting for these caused performance scores to drop across all stages: for data extraction, performance was moderate, and for screening, it ranged from none in highly balanced literature datasets (~1:1) to moderate in those datasets where the ratio of inclusion to exclusion in studies was imbalanced (~1:3). When screening full-text literature using highly reliable prompts, GPT-4's performance was more robust, reaching “human-like” levels. Although our findings indicate that, currently, substantial caution should be exercised if LLMs are being used to conduct systematic reviews, they also offer preliminary evidence that, for certain review tasks delivered under specific conditions, LLMs can rival human performance. © 2024 The Authors. Research Synthesis Methods published by John Wiley & Sons Ltd.},
	author_keywords = {artificial intelligence (AI); GPT; large language models (LLMs); machine learning; natural language processing (NLP); systematic reviews},
	correspondence_address = {Q. Khraisha; Trinity Centre for Global Health and School of Psychology, Trinity College Dublin, Dublin, Ireland; email: khraishq@tcd.ie},
	publisher = {John Wiley and Sons Ltd},
	issn = {17592887},
	language = {English},
	abbrev_source_title = {Res. Synth. Methods},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Acher2024139,
	author = {Acher, Mathieu},
	title = {A Demonstration of End-User Code Customization Using Generative AI},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {139 – 145},
	doi = {10.1145/3634713.3634732},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184283402&doi=10.1145%2f3634713.3634732&partnerID=40&md5=396cbf656c0c98693fa8eaf1d94e19fb},
	affiliations = {Univ Rennes, Cnrs, Irisa, Iuf, France},
	abstract = {Producing a variant of code is highly challenging, particularly for individuals unfamiliar with programming. This demonstration introduces a novel use of generative AI to aid end-users in customizing code. We first describe how generative AI can be used to customize code through prompts and instructions, and further demonstrate its potential in building end-user tools for configuring code. We showcase how to transform an undocumented, technical, low-level TikZ into a user-friendly, configurable, Web-based customization tool written in Python, HTML, CSS, and JavaScript and itself configurable. We discuss how generative AI can support this transformation process and traditional variability engineering tasks, such as identification and implementation of features, synthesis of a template code generator, and development of end-user configurators. We believe it is a first step towards democratizing variability programming, opening a path for end-users to adapt code to their needs.  © 2024 ACM.},
	author_keywords = {code synthesis; customization; end-user programming; generative AI; generator; LLM; software product lines; variability},
	keywords = {User interfaces; Code synthesis; Customisation; End-user programming; End-users; Generative AI; Generator; LLM; Software Product Line; User codes; Variability; High level languages},
	correspondence_address = {M. Acher; Univ Rennes, Cnrs, Irisa, Iuf, France; email: mathieu.acher@irisa.fr},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070877-0},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ali20231353,
	author = {Ali, Rohaid and Tang, Oliver Y. and Connolly, Ian D. and Zadnik Sullivan, Patricia L. and Shin, John H. and Fridley, Jared S. and Asaad, Wael F. and Cielo, Deus and Oyelese, Adetokunbo A. and Doberstein, Curtis E. and Gokaslan, Ziya L. and Telfeian, Albert E.},
	title = {Performance of ChatGPT and GPT-4 on Neurosurgery Written Board Examinations},
	year = {2023},
	journal = {Neurosurgery},
	volume = {93},
	number = {6},
	pages = {1353 – 1365},
	doi = {10.1227/neu.0000000000002632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181011502&doi=10.1227%2fneu.0000000000002632&partnerID=40&md5=358894928c54c0e375f62848d39d577e},
	affiliations = {Department of Neurosurgery, The Warren Alpert Medical School of Brown University, Providence, RI, United States; Department of Neurosurgery, Massachusetts General Hospital, Boston, MA, United States; Department of Neuroscience, Norman Prince Neurosciences Institute, Rhode Island Hospital, Providence, RI, United States; Department of Neuroscience, Brown University, Providence, RI, United States; Department of Neuroscience, Carney Institute for Brain Science, Brown University, Providence, RI, United States},
	abstract = {BACKGROUND AND OBJECTIVES: Interest surrounding generative large language models (LLMs) has rapidly grown. Although ChatGPT (GPT-3.5), a general LLM, has shown near-passing performance on medical student board examinations, the performance of ChatGPT or its successor GPT-4 on specialized examinations and the factors affecting accuracy remain unclear. This study aims to assess the performance of ChatGPT and GPT-4 on a 500-question mock neurosurgical written board examination. METHODS: The Self-Assessment Neurosurgery Examinations (SANS) American Board of Neurological Surgery Self-Assessment Examination 1 was used to evaluate ChatGPT and GPT-4. Questionswere in single best answer, multiple-choice format. Χ2, Fisher exact, and univariable logistic regression testswere used to assess performance differences in relation to question characteristics. RESULTS: ChatGPT (GPT-3.5) and GPT-4 achieved scores of 73.4%(95%CI: 69.3%-77.2%) and 83.4%(95% CI: 79.8%-86.5%), respectively, relative to the user average of 72.8% (95% CI: 68.6%-76.6%). Both LLMs exceeded last year’s passing threshold of 69%. Although scores between ChatGPT and question bank users were equivalent (P = .963), GPT-4 outperformed both (both P < .001). GPT-4 answered every question answered correctly by ChatGPT and 37.6% (50/133) of remaining incorrect questions correctly. Among 12 question categories, GPT-4 significantly outperformed users in each but performed comparably with ChatGPT in 3 (functional, other general, and spine) and outperformed both users and ChatGPT for tumor questions. Increased word count (odds ratio = 0.89 of answering a question correctly per +10 words) and higher-order problem-solving (odds ratio = 0.40, P = .009) were associated with lower accuracy for ChatGPT, but not for GPT-4 (both P > .005). Multimodal input was not available at the time of this study; hence, on questions with image content, ChatGPT and GPT-4 answered 49.5% and 56.8% of questions correctly based on contextual context clues alone. CONCLUSION: LLMs achieved passing scores on a mock 500-question neurosurgical written board examination, with GPT-4 significantly outperforming ChatGPT. © Congress of Neurological Surgeons 2023. All rights reserved.},
	author_keywords = {Artificial intelligence; ChatGPT; GPT-4; Large language models; Medical education; Neurosurgery; Residency education; Surgical education},
	keywords = {Humans; Neurosurgery; Neurosurgical Procedures; Odds Ratio; Self-Assessment; Spine; accuracy; adult; American Board of Neurological Surgery; Article; artificial intelligence; cafe au lait spot; ChatGPT; child; clinical article; clinical assessment; clinical evaluation; gpt 4; human; large language model; Lisch nodule; male; medical education; medical examination; medical society; medical student; mock exam; multiple choice test; neoplasm; neurosurgery; nociceptive stimulation; performance; problem solving; question bank user; residency education; school child; scoliosis; self assessment neurosurgery examinations; surgical training; test score; written board examination; x-ray computed tomography; odds ratio; self evaluation; spine},
	correspondence_address = {R. Ali; Department of Neurosurgery, Rhode Island Hospital, LPG Neurosurgery, Providence, 593 Eddy St, APC6, 02903, United States; email: RAli@lifespan.org},
	publisher = {Wolters Kluwer Medknow Publications},
	issn = {0148396X},
	coden = {NRSRD},
	pmid = {37581444},
	language = {English},
	abbrev_source_title = {Neurosurgery},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access}
}

@ARTICLE{Zack2024e12,
	author = {Zack, Travis and Lehman, Eric and Suzgun, Mirac and Rodriguez, Jorge A and Celi, Leo Anthony and Gichoya, Judy and Jurafsky, Dan and Szolovits, Peter and Bates, David W and Abdulnour, Raja-Elie E and Butte, Atul J and Alsentzer, Emily},
	title = {Assessing the potential of GPT-4 to perpetuate racial and gender biases in health care: a model evaluation study},
	year = {2024},
	journal = {The Lancet Digital Health},
	volume = {6},
	number = {1},
	pages = {e12 – e22},
	doi = {10.1016/S2589-7500(23)00225-X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180347404&doi=10.1016%2fS2589-7500%2823%2900225-X&partnerID=40&md5=512470e0e5e6932e9c95e349c4287dd9},
	affiliations = {Bakar Computational Health Sciences Institute, University of California San Francisco, San Francisco, CA, United States; Helen Diller Family Comprehensive Cancer Center, University of California San Francisco, San Francisco, CA, United States; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States; Laboratory for Computational Physiology, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Computer Science, Stanford University, Stanford, CA, United States; Stanford Law School, Stanford University, Stanford, CA, United States; Department of Linguistics, Stanford University, Stanford, CA, United States; Division of General Internal Medicine, Brigham and Women's Hospital, Boston, MA, United States; Division of Pulmonary and Critical Care Medicine, Brigham and Women's Hospital, Boston, MA, United States; Division of Pulmonary, Critical Care and Sleep Medicine, Beth Israel Deaconess Medical Center, Boston, MA, United States; Department of Biostatistics, Harvard T H Chan School of Public Health, Boston, MA, United States; Department of Health Policy and Management, Harvard T H Chan School of Public Health, Boston, MA, United States; Department of Radiology, Emory University, Atlanta, GA, United States; Harvard Medical School, Boston, MA, United States; Center for Data-Driven Insights and Innovation, University of California, Office of the President, Oakland, CA, United States},
	abstract = {Background: Large language models (LLMs) such as GPT-4 hold great promise as transformative tools in health care, ranging from automating administrative tasks to augmenting clinical decision making. However, these models also pose a danger of perpetuating biases and delivering incorrect medical diagnoses, which can have a direct, harmful impact on medical care. We aimed to assess whether GPT-4 encodes racial and gender biases that impact its use in health care. Methods: Using the Azure OpenAI application interface, this model evaluation study tested whether GPT-4 encodes racial and gender biases and examined the impact of such biases on four potential applications of LLMs in the clinical domain—namely, medical education, diagnostic reasoning, clinical plan generation, and subjective patient assessment. We conducted experiments with prompts designed to resemble typical use of GPT-4 within clinical and medical education applications. We used clinical vignettes from NEJM Healer and from published research on implicit bias in health care. GPT-4 estimates of the demographic distribution of medical conditions were compared with true US prevalence estimates. Differential diagnosis and treatment planning were evaluated across demographic groups using standard statistical tests for significance between groups. Findings: We found that GPT-4 did not appropriately model the demographic diversity of medical conditions, consistently producing clinical vignettes that stereotype demographic presentations. The differential diagnoses created by GPT-4 for standardised clinical vignettes were more likely to include diagnoses that stereotype certain races, ethnicities, and genders. Assessment and plans created by the model showed significant association between demographic attributes and recommendations for more expensive procedures as well as differences in patient perception. Interpretation: Our findings highlight the urgent need for comprehensive and transparent bias assessments of LLM tools such as GPT-4 for intended use cases before they are integrated into clinical care. We discuss the potential sources of these biases and potential mitigation strategies before clinical implementation. Funding: Priscilla Chan and Mark Zuckerberg. © 2024 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license},
	keywords = {Clinical Decision-Making; Delivery of Health Care; Diagnosis, Differential; Education, Medical; Female; Health Facilities; Humans; Male; Clinical research; Decision making; Encoding (symbols); Health care; Medical education; Population statistics; Administrative tasks; Application interfaces; Clinical decision making; Differential diagnosis; Evaluation study; Gender bias; Language model; Medical conditions; Model evaluation; Racial bias; angiography; Article; Asian; Black person; Caucasian; Chlamydia infection; clinical article; controlled study; demography; diagnostic reasoning; differential diagnosis; exercise test; female; gender bias; generative pretrained transformer; health care; Hispanic; human; Human immunodeficiency virus infection; male; medical education; mononucleosis; patient assessment; patient attitude; patient referral; pharyngitis; prevalence; racism; streptococcal pharyngitis; syphilis; treatment planning; United States; viral pharyngitis; clinical decision making; health care delivery; health care facility; medical education; Diagnosis},
	correspondence_address = {E. Alsentzer; Division of General Internal Medicine, Brigham and Women's Hospital, Boston, 02115, United States; email: ealsentzer@bwh.harvard.edu},
	publisher = {Elsevier Ltd},
	issn = {25897500},
	pmid = {38123252},
	language = {English},
	abbrev_source_title = {Lancet Digit. Heal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Reason2024191,
	author = {Reason, Tim and Rawlinson, William and Langham, Julia and Gimblett, Andy and Malcolm, Bill and Klijn, Sven},
	title = {Artificial Intelligence to Automate Health Economic Modelling: A Case Study to Evaluate the Potential Application of Large Language Models},
	year = {2024},
	journal = {PharmacoEconomics - Open},
	volume = {8},
	number = {2},
	pages = {191 – 203},
	doi = {10.1007/s41669-024-00477-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184504375&doi=10.1007%2fs41669-024-00477-8&partnerID=40&md5=5e4ff3548612ba55082c436621b4a513},
	affiliations = {Estima Scientific, Mediaworks, 191 Wood Ln, London, W12 7FP, United Kingdom; Bristol Myers Squibb, Uxbridge, United Kingdom; Bristol Myers Squibb, Princeton, NJ, United States},
	abstract = {Background: Current generation large language models (LLMs) such as Generative Pre-Trained Transformer 4 (GPT-4) have achieved human-level performance on many tasks including the generation of computer code based on textual input. This study aimed to assess whether GPT-4 could be used to automatically programme two published health economic analyses. Methods: The two analyses were partitioned survival models evaluating interventions in non-small cell lung cancer (NSCLC) and renal cell carcinoma (RCC). We developed prompts which instructed GPT-4 to programme the NSCLC and RCC models in R, and which provided descriptions of each model’s methods, assumptions and parameter values. The results of the generated scripts were compared to the published values from the original, human-programmed models. The models were replicated 15 times to capture variability in GPT-4’s output. Results: GPT-4 fully replicated the NSCLC model with high accuracy: 100% (15/15) of the artificial intelligence (AI)-generated NSCLC models were error-free or contained a single minor error, and 93% (14/15) were completely error-free. GPT-4 closely replicated the RCC model, although human intervention was required to simplify an element of the model design (one of the model’s fifteen input calculations) because it used too many sequential steps to be implemented in a single prompt. With this simplification, 87% (13/15) of the AI-generated RCC models were error-free or contained a single minor error, and 60% (9/15) were completely error-free. Error-free model scripts replicated the published incremental cost-effectiveness ratios to within 1%. Conclusion: This study provides a promising indication that GPT-4 can have practical applications in the automation of health economic model construction. Potential benefits include accelerated model development timelines and reduced costs of development. Further research is necessary to explore the generalisability of LLM-based automation across a larger sample of models. © The Author(s) 2024.},
	correspondence_address = {T. Reason; Estima Scientific, London, Mediaworks, 191 Wood Ln, W12 7FP, United Kingdom; email: tim.reason@estima-sci.com},
	publisher = {Adis},
	issn = {25094262},
	language = {English},
	abbrev_source_title = {PharmacoEcon. Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}@CONFERENCE{Savelka2023447,
	author = {Savelka, Jaromir},
	title = {Unlocking Practical Applications in Legal Domain: Evaluation of GPT for Zero-Shot Semantic Annotation of Legal Texts},
	year = {2023},
	journal = {19th International Conference on Artificial Intelligence and Law, ICAIL 2023 - Proceedings of the Conference},
	pages = {447 – 451},
	doi = {10.1145/3594536.3595161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177829432&doi=10.1145%2f3594536.3595161&partnerID=40&md5=f79b552235236cc2501f5d4099610665},
	affiliations = {Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {We evaluated the capability of a state-of-the-art generative pre-trained transformer (GPT) model to perform semantic annotation of short text snippets (one to few sentences) coming from legal documents of various types. Discussions of potential uses (e.g., document drafting, summarization) of this emerging technology in legal domain have intensified, but to date there has not been a rigorous analysis of these large language models’ (LLM) capacity in sentence-level semantic annotation of legal texts in zero-shot learning settings. Yet, this particular type of use could unlock many practical applications (e.g., in contract review) and research opportunities (e.g., in empirical legal studies). We fill the gap with this study. We examined if and how successfully the model can semantically annotate small batches of short text snippets (10–50) based exclusively on concise definitions of the semantic types. We found that the GPT model performs surprisingly well in zero-shot settings on diverse types of documents (F1 = .73 on a task involving court opinions, .86 for contracts, and .54 for statutes and regulations). These findings can be leveraged by legal scholars and practicing lawyers alike to guide their decisions in integrating LLMs in wide range of workflows involving semantic annotation of legal texts. © ICAIL 2023. All rights reserved.},
	author_keywords = {adjudicatory decisions; contracts; generative pre-trained transformers; GPT; regulatory provisions; Semantic legal annotation; statutory; transfer learning; zero-shot},
	keywords = {Laws and legislation; Learning systems; Zero-shot learning; Adjudicatory decision; Generative pre-trained transformer; Legal texts; Regulatory provision; Semantic annotations; Semantic legal annotation; Statutory; Transfer learning; Zero-shot; Semantics},
	correspondence_address = {J. Savelka; Carnegie Mellon University, Pittsburgh, United States; email: jsavelka@cs.cmu.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070197-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Artif. Intel. Law, ICAIL - Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Askari20235311,
	author = {Askari, Arian and Aliannejadi, Mohammad and Kanoulas, Evangelos and Verberne, Suzan},
	title = {A Test Collection of Synthetic Documents for Training Rankers: ChatGPT vs. Human Experts},
	year = {2023},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5311 – 5315},
	doi = {10.1145/3583780.3615111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178122401&doi=10.1145%2f3583780.3615111&partnerID=40&md5=4756a7a5b86c9ccfb2b1dc774a4af98b},
	affiliations = {Leiden University, Netherlands; University of Amsterdam, Netherlands},
	abstract = {We investigate the usefulness of generative large language models (LLMs) in generating training data for cross-encoder re-rankers in a novel direction: generating synthetic documents instead of synthetic queries. We introduce a new dataset, ChatGPT-RetrievalQA, and compare the effectiveness of strong models fine-tuned on both LLM-generated and human-generated data. We build ChatGPT-RetrievalQA based on an existing dataset, the human ChatGPT comparison corpus (HC3), consisting of multiple public question collections featuring both human- and ChatGPT-generated responses. We fine-tune a range of cross-encoder re-rankers on either human-generated or ChatGPT-generated data. Our evaluation on MS MARCO DEV, TREC DL'19, and TREC DL'20 demonstrates that cross-encoder re-ranking models trained on LLM-generated responses are significantly more effective for out-of-domain re-ranking than those trained on human responses. For in-domain re-ranking, however, the human-trained re-rankers outperform the LLM-trained re-rankers. Our novel findings suggest that generative LLMs have high potential in generating training data for neural retrieval models and can be used to augment training data, especially in domains with less labeled data. ChatGPT-RetrievalQA presents various opportunities for analyzing and improving rankers with both human- and LLM-generated data. Our data, code, and model checkpoints are publicly available. © 2023 Copyright held by the owner/author(s).},
	author_keywords = {Cross-encoder re-rankers; Document Generation; Large language models},
	keywords = {Information retrieval; Natural language processing systems; Signal encoding; Cross-encoder re-ranker; Document generation; Human expert; Human response; Language model; Large language model; Ranking model; Re-ranking; Test Collection; Training data; Computational linguistics},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070124-5},
	language = {English},
	abbrev_source_title = {Int Conf Inf Knowledge Manage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Savelka202378,
	author = {Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd},
	title = {Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
	year = {2023},
	journal = {ICER 2023 - Proceedings of the 2023 ACM Conference on International Computing Education Research V.1},
	pages = {78 – 92},
	doi = {10.1145/3568813.3600142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169462375&doi=10.1145%2f3568813.3600142&partnerID=40&md5=a22f2eaaae3e1c62d039bc28390d525a},
	affiliations = {Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {This paper studies recent developments in large language models' (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class' assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4's handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments. © 2023 Owner/Author.},
	author_keywords = {AI code generation; AlphaCode; ChatGPT; Codex; coding exercises; generative pre-trained transformers; GitHub Copilot; GPT; introductory and intermediate programming; MCQ; Multiple-choice question answering; programming knowledge assessment; Python course},
	keywords = {Computational linguistics; Curricula; Education computing; Engineering education; High level languages; AI code generation; Alphacode; ChatGPT; Codegeneration; Codex; Coding exercise; Generative pre-trained transformer; Github copilot; GPT; Introductory and intermediate programming; Knowledge assessment; MCQ; Multiple-choice question answering; Multiple-choice questions; Programming knowledge; Programming knowledge assessment; Python course; Question Answering; Python},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039976-0},
	language = {English},
	abbrev_source_title = {ICER - Proc. ACM Conf. Int. Comput. Educ. Res. V.1},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kumar20235251,
	author = {Kumar, Prathyusha Senthil},
	title = {Practical Lessons Learned From Detecting, Preventing and Mitigating Harmful Experiences on Facebook},
	year = {2023},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5251 – 5252},
	doi = {10.1145/3583780.3615511},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178087037&doi=10.1145%2f3583780.3615511&partnerID=40&md5=174ca4e8c6d3c13d5695c59c3ce57d97},
	affiliations = {Meta Platforms Inc, Menlo Park, CA, United States},
	abstract = {Social media's explosive growth brings with it a variety of societal risks ranging from severely harmful issues such as dangerous organizations and child sexual exploitation to moderately harmful content like displays of aggression, borderline nudity to benign or distasteful contents like gross videos and baity content. In recent times, the multitude and magnitude of these harms is being further exacerbated with the advent of generative AI [5]. Meta is committed to ensuring that Facebook is a place where people feel empowered to communicate and we take our role seriously in keeping abuse off the platform [7]. In this talk, I will describe practical challenges and lessons learned from tackling bad experiences for users on Facebook, particularly in the subjective, borderline and low quality spectrum of harms using state of the art, scalable machine learning approaches to content understanding, user behavior understanding and personalized ranking. © 2023 Copyright held by the owner/author(s).},
	author_keywords = {content classification; content understanding; detecting abuse; generative AI; integrity; LLM safety; ML; personalization; ranking; trust and safety; user behavior modeling},
	keywords = {Social networking (online); User profile; Content classification; Content understanding; Detecting abuse; Generative AI; Integrity; LLM safety; ML; Personalizations; Ranking; Trust and safety; User behavior modeling; Behavioral research},
	correspondence_address = {P.S. Kumar; Meta Platforms Inc, Menlo Park, United States; email: prathyushas@meta.com},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070124-5},
	language = {English},
	abbrev_source_title = {Int Conf Inf Knowledge Manage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2023,
	author = {Li, Zhiyu and Chen, Yanfang and Zhang, Xuan and Liang, Xun},
	title = {BookGPT: A General Framework for Book Recommendation Empowered by Large Language Model},
	year = {2023},
	journal = {Electronics (Switzerland)},
	volume = {12},
	number = {22},
	doi = {10.3390/electronics12224654},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178119230&doi=10.3390%2felectronics12224654&partnerID=40&md5=ce6cb9d3d90fd607e7f6a0f3b17a172e},
	affiliations = {Institute for Advanced Algorithms Research, Shanghai, 200232, China; Libraries, Renmin University of China, Beijng, 100872, China; School of Information, Renmin University of China, Beijng, 100872, China},
	abstract = {With the continuous development and change exhibited by large language model (LLM) technology, represented by generative pretrained transformers (GPTs), many classic scenarios in various fields have re-emerged with new opportunities. This paper takes ChatGPT as the modeling object, incorporates LLM technology into the typical book resource understanding and recommendation scenario for the first time, and puts it into practice. By building a ChatGPT-like book recommendation system (BookGPT) framework based on ChatGPT, this paper attempts to apply ChatGPT to recommendation modeling for three typical tasks: book rating recommendation, user rating recommendation, and the book summary recommendation; it also explores the feasibility of LLM technology in book recommendation scenarios. At the same time, based on different evaluation schemes for book recommendation tasks and the existing classic recommendation models, this paper discusses the advantages and disadvantages of the BookGPT in book recommendation scenarios and analyzes the opportunities and improvement directions for subsequent LLMs in these scenarios. The experimental research shows the following: (1) The BookGPT can achieve good recommendation results in existing classic book recommendation tasks. Especially in cases containing less information about the target object to be recommended, such as zero-shot or one-shot learning tasks, the performance of the BookGPT is close to or even better than that of the current classic book recommendation algorithms, and this method has great potential for improvement. (2) In text generation tasks such as book summary recommendation, the recommendation effect of the BookGPT model is better than that of the manual editing process of Douban Reading, and it can even perform personalized interpretable content recommendations based on readers’ attribute and identity information, making it more persuasive than interpretable one-size-fits-all recommendation models. Finally, we have open-sourced the relevant datasets and experimental codes, hoping that the exploratory program proposed in this paper can inspire the development of more LLMs to expand their applications and theoretical research prospects in the field of book recommendation and general recommendation tasks. © 2023 by the authors.},
	author_keywords = {book recommendation; general recommendation; large language model},
	correspondence_address = {Y. Chen; Libraries, Renmin University of China, Beijng, 100872, China; email: cyf@ruc.edu.cn},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Esplugas2023819,
	author = {Esplugas, Mireia},
	title = {The use of artificial intelligence (AI) to enhance academic communication, education and research: a balanced approach},
	year = {2023},
	journal = {Journal of Hand Surgery: European Volume},
	volume = {48},
	number = {8},
	pages = {819 – 822},
	doi = {10.1177/17531934231185746},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164530406&doi=10.1177%2f17531934231185746&partnerID=40&md5=86fb875c7b2174c64c435417dc3534fd},
	affiliations = {Kaplan Hand Institute Barcelona, Avinguda Reina Elisenda 17, Barcelona, 08034, Spain},
	abstract = {Much has been written about the concerns surrounding artificial intelligence (AI). This article looks positively at how AI can enhance communication and academic skills, including teaching and research. The article explains what AI, Generative Pre-trained Transformer (GPT), and chat-GPT are and highlights a few AI-based tools that are currently in use to improve communication and academic skills. It also mentions potential AI problems, such as a lack of personalization, societal biases, and privacy concerns. The future lies in the training of hand surgeons to master the skill of precise communication and academia using AI tools. © The Author(s) 2023.},
	author_keywords = {AI-related tools; Artificial intelligence (AI); Large language model (LLM) academics; research; risks},
	keywords = {Artificial Intelligence; Communication; Educational Status; Humans; Surgeons; Writing; article; artificial intelligence; education; human; human experiment; language; privacy; skill; surgeon; teaching; educational status; interpersonal communication; surgeon; writing},
	correspondence_address = {M. Esplugas; Kaplan Hand Institute Barcelona, Barcelona, Avinguda Reina Elisenda 17, 08034, Spain; email: mireiaesplugas@institut-kaplan.com},
	publisher = {SAGE Publications Ltd},
	issn = {17531934},
	pmid = {37417005},
	language = {English},
	abbrev_source_title = {J. Hand Surg. Eur. Vol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Godoy2023136,
	author = {Godoy, William and Valero-Lara, Pedro and Teranishi, Keita and Balaprakash, Prasanna and Vetter, Jeffrey},
	title = {Evaluation of OpenAI Codex for HPC Parallel Programming Models Kernel Generation},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {136 – 144},
	doi = {10.1145/3605731.3605886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172435472&doi=10.1145%2f3605731.3605886&partnerID=40&md5=761a142c8cdf23365415b05d7686cc8d},
	affiliations = {Oak Ridge National Laboratory, Oak Ridge, TN, United States},
	abstract = {We evaluate AI-assisted generative capabilities on fundamental numerical kernels in high-performance computing (HPC), including AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG. We test the generated kernel codes for a variety of language-supported programming models, including (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). We use the GitHub Copilot capabilities powered by the GPT-based OpenAI Codex available in Visual Studio Code as of April 2023 to generate a vast amount of implementations given simple <kernel> + <programming model> + <optional hints> prompt variants. To quantify and compare the results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. Results suggest that the OpenAI Codex outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general-purpose Python can benefit from adding code keywords, while Julia prompts perform acceptably well for its mature programming models (e.g., Threads and CUDA.jl). We expect for these benchmarks to provide a point of reference for each programming model's community. Overall, understanding the convergence of large language models, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human-computer interactions.  © 2023 ACM.},
	author_keywords = {generative AI; GitHub Copilot; GPT; high-performance computing; HPC; large language models; LLM; numerical kernels; OpenAI Codex; programming models},
	keywords = {Application programming interfaces (API); C++ (programming language); Computational linguistics; FORTRAN (programming language); Human computer interaction; Modeling languages; Parallel programming; Visual languages; Generative AI; Github copilot; GPT; High-performance computing; Language model; Large language model; LLM; Numerical kernel; Openai codex; Performance computing; Programming models; Python},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070843-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Mishra202315178,
	author = {Mishra, Mayank and Kumar, Prince and Bhat, Riyaz and Murthy, Rudra V. and Contractor, Danish and Tamilselvam, Srikanth},
	title = {Prompting with Pseudo-Code Instructions},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {15178 – 15197},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184805509&partnerID=40&md5=67d5035d793418aebc2e2cf3d8da589b},
	affiliations = {IBM Research AI, United States},
	abstract = {Prompting with natural language instructions has recently emerged as a popular method of harnessing the capabilities of large language models (LLM). Given the inherent ambiguity present in natural language, it is intuitive to consider the possible advantages of prompting with less ambiguous prompt styles, like pseudo-code. In this paper, we explore if prompting via pseudo-code instructions helps improve the performance of pre-trained language models. We manually create a dataset1 of pseudo-code prompts for 132 different tasks spanning classification, QA, and generative language tasks, sourced from the Super-NaturalInstructions dataset (Wang et al., 2022b). Using these prompts along with their counterparts in natural language, we study their performance on two LLM families - BLOOM (Scao et al., 2023), CodeGen (Nijkamp et al., 2023). Our experiments show that using pseudo-code instructions leads to better results, with an average increase (absolute) of 7-16 points in F1 scores for classification tasks and an improvement (relative) of 12-38% in aggregate ROUGE-L scores across all tasks. We include detailed ablation studies which indicate that code comments, docstrings, and the structural clues encoded in pseudo-code all contribute towards the improvement in performance. To the best of our knowledge, our work is the first to demonstrate how pseudo-code prompts can be helpful in improving the performance of pre-trained LMs. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Classification tasks; Docstrings; F1 scores; Language model; Natural languages; Performance; Pseudo codes; Classification (of information)},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Antaki2023,
	author = {Antaki, Fares and Touma, Samir and Milad, Daniel and El-Khoury, Jonathan and Duval, Renaud},
	title = {Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of Its Successes and Shortcomings},
	year = {2023},
	journal = {Ophthalmology Science},
	volume = {3},
	number = {4},
	doi = {10.1016/j.xops.2023.100324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163557911&doi=10.1016%2fj.xops.2023.100324&partnerID=40&md5=35b88d52174cc6588e212cc6387648c9},
	affiliations = {Department of Ophthalmology, Université de Montréal, Montréal, QC, Canada; Centre Universitaire d'Ophtalmologie (CUO), Hôpital Maisonneuve-Rosemont, CIUSSS de l'Est-de-l’Île-de-Montréal, Montréal, QC, Canada; Department of Ophthalmology, Centre Hospitalier de l'Université de Montréal (CHUM), Montréal, QC, Canada; The CHUM School of Artificial Intelligence in Healthcare (SAIH), Centre Hospitalier de l'Université de Montréal (CHUM), Montréal, QC, Canada},
	abstract = {Purpose: Foundation models are a novel type of artificial intelligence algorithms, in which models are pretrained at scale on unannotated data and fine-tuned for a myriad of downstream tasks, such as generating text. This study assessed the accuracy of ChatGPT, a large language model (LLM), in the ophthalmology question-answering space. Design: Evaluation of diagnostic test or technology. Participants: ChatGPT is a publicly available LLM. Methods: We tested 2 versions of ChatGPT (January 9 “legacy” and ChatGPT Plus) on 2 popular multiple choice question banks commonly used to prepare for the high-stakes Ophthalmic Knowledge Assessment Program (OKAP) examination. We generated two 260-question simulated exams from the Basic and Clinical Science Course (BCSC) Self-Assessment Program and the OphthoQuestions online question bank. We carried out logistic regression to determine the effect of the examination section, cognitive level, and difficulty index on answer accuracy. We also performed a post hoc analysis using Tukey's test to decide if there were meaningful differences between the tested subspecialties. Main Outcome Measures: We reported the accuracy of ChatGPT for each examination section in percentage correct by comparing ChatGPT's outputs with the answer key provided by the question banks. We presented logistic regression results with a likelihood ratio (LR) chi-square. We considered differences between examination sections statistically significant at a P value of < 0.05. Results: The legacy model achieved 55.8% accuracy on the BCSC set and 42.7% on the OphthoQuestions set. With ChatGPT Plus, accuracy increased to 59.4% ± 0.6% and 49.2% ± 1.0%, respectively. Accuracy improved with easier questions when controlling for the examination section and cognitive level. Logistic regression analysis of the legacy model showed that the examination section (LR, 27.57; P = 0.006) followed by question difficulty (LR, 24.05; P < 0.001) were most predictive of ChatGPT's answer accuracy. Although the legacy model performed best in general medicine and worst in neuro-ophthalmology (P < 0.001) and ocular pathology (P = 0.029), similar post hoc findings were not seen with ChatGPT Plus, suggesting more consistent results across examination sections. Conclusion: ChatGPT has encouraging performance on a simulated OKAP examination. Specializing LLMs through domain-specific pretraining may be necessary to improve their performance in ophthalmic subspecialties. Financial Disclosure(s): Proprietary or commercial disclosure may be found after the references. © 2023 American Academy of Ophthalmology},
	author_keywords = {Artificial intelligence; ChatGPT; Generative Pretrained Transformer; Medical education; Ophthalmology},
	keywords = {accreditation; Article; artificial intelligence; cognition; eye disease; general practice; logistic regression analysis; measurement accuracy; measurement repeatability; neuroophthalmology; ophthalmology; post hoc analysis},
	correspondence_address = {R. Duval; Montréal, 5415 Boulevard de l'Assomption, H1T 2M4, Canada; email: renaud.duval@gmail.com},
	publisher = {Elsevier Inc.},
	issn = {26669145},
	language = {English},
	abbrev_source_title = {Ophthalmol. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 68; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ma2023,
	author = {Ma, Yumeng and Ren, Jiahao},
	title = {ProactiveAgent: Personalized Context-Aware Reminder System},
	year = {2023},
	journal = {UIST 2023 Adjunct - Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
	doi = {10.1145/3586182.3625115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178275865&doi=10.1145%2f3586182.3625115&partnerID=40&md5=f0bd1c1ec7db1af62479a6f62570dcdf},
	affiliations = {Department of Computer Science, Brown University, Providence, RI, United States},
	abstract = {We introduce ProactiveAgent, a proactive application that harnesses the capabilities of large language models (LLMs) and personal agents to provide context-aware, personalized reminders and suggestions. By assimilating real-time environmental data, user histories, and verbal interactions, the system discerns user intent and offers tailored recommendations. The application captures visual activity and spoken interactions, integrating them into short and long-term memory storage for context-rich decision support. We propose scenarios where ProactiveAgent could be valuable: suggesting snack options depending on the time, offering culinary options based on dietary preferences, and even guiding users in their daily tasks. In envisioned use cases, ProactiveAgent could potentially track user attributes during their shopping experience, such as time spent on items and other cues, leading towards insightful product recommendations. Our work represents a potential advancement in the realm of personalized assistance, merging LLM strengths with personal agent technologies to enhance user decision-making in dynamic real-world scenarios. © 2023 Owner/Author.},
	author_keywords = {generative AI; Human-AI interaction; large language models},
	keywords = {Artificial intelligence; Computational linguistics; Decision support systems; Digital storage; Context-Aware; Generative AI; Human-AI interaction; Language model; Large language model; Model agents; Personal Agent; Proactive applications; Real- time; Reminder systems; Decision making},
	correspondence_address = {Y. Ma; Department of Computer Science, Brown University, Providence, United States; email: yumeng_ma1@brown.edu; J. Ren; Department of Computer Science, Brown University, Providence, United States; email: jiahao_ren@brown.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070096-5},
	language = {English},
	abbrev_source_title = {UIST Adjun. - Adjun. Proc. Annu. ACM Symp. User Interface Softw. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Trichopoulos2023,
	author = {Trichopoulos, Georgios},
	title = {Large Language Models for Cultural Heritage},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3609987.3610018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174493260&doi=10.1145%2f3609987.3610018&partnerID=40&md5=f80f0ece5a6bf6a90cf097101f280443},
	affiliations = {Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece},
	abstract = {This research explores the potential applications of Generative Pre-Trained Transformer (GPT) by OpenAI, a Large Language Model (LLM), in the realm of cultural heritage. It investigates GPT's role as a digital storytelling machine that can be trained and guided to act as a museum guide and a recommender system for cultural spaces. LLM's advanced language understanding capabilities make it an interactive guide, providing personalized and information to visitors about artworks and historical contexts. As a recommender system, GPT can offer tailored suggestions based on user preferences and past interactions, enhancing the visitor experience and encouraging exploration. It is a system extremely capable in handling language and with that power, it can act as a digital storytelling machine, creating immersive narratives that bring exhibits to life by weaving historical information with imaginative elements. The paper presents experiment results and evaluations, highlighting GPT's potential to revolutionize visitor engagement in cultural spaces. However, ethical considerations and challenges associated with large language models in cultural contexts are also addressed, emphasizing the need for thoughtful implementation and ongoing evaluation to ensure inclusivity and accuracy while preserving cultural integrity. © 2023 Owner/Author.},
	author_keywords = {artificial intelligence; cultural heritage; digital storytelling; emergent storytelling; generative pre-Trained transformers; museum; smart glasses; ubiquitous systems},
	keywords = {Computational linguistics; Museums; User interfaces; Cultural heritages; Digital storytelling; Emergent storytelling; Generative pre-trained transformer; Language model; Language understanding; Museum guide; Smart glass; Ubiquitous systems; User's preferences; Recommender systems},
	correspondence_address = {G. Trichopoulos; Department of Cultural Technology and Communication, University of the Aegean, Mytilene, Greece; email: gtricho@aegean.gr},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070888-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Huang2023325,
	author = {Huang, Ziheng and Quan, Kexin and Chan, Joel and MacNeil, Stephen},
	title = {CausalMapper: Challenging designers to think in systems with Causal Maps and Large Language Model},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {325 – 329},
	doi = {10.1145/3591196.3596818},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164038861&doi=10.1145%2f3591196.3596818&partnerID=40&md5=6f4939bf5b4b1873c2073072a2e0846e},
	affiliations = {University of California, La Jolla, San Diego, CA, United States; University of Maryland, College Park, MD, United States; Temple University, Philadelphia, PA, United States},
	abstract = {Professional designers often construct and explore conceptual representations (e.g.: design spaces) to help them reason about complex design situations and consider potential design pitfalls. However, it is often challenging, even for professional designers, to exhaustively consider the many pitfalls that might result from design activity. We present CausalMapper, a mixed-initiative system, that leverages a large language model (LLM) and a causal map representation to teach design students how to reason about the relationships between problems and solutions. Where creativity support tools often focus on ideating creative solutions, our mixed-initiative approach focuses on ideating ecosystems of solutions that holistically address a set of related problems. By leveraging the generative creativity of LLMs, designers are inspired to consider solutions and potential consequences that emerge when solutions are adopted. At the same time, leveraging the designers' domain knowledge to account for and correct the biases inherent in LLMs. Through a case study, we demonstrate the functionality of this mixed-initiative system. The goal of this demo is to present a creativity support tool that is intended to teach design students to think more systematically by generating ideas that challenge their thinking rather just augmenting their creative potential.  © 2023 Owner/Author.},
	author_keywords = {creativity support tools; design space; large language models},
	keywords = {Computational linguistics; Domain Knowledge; Students; Causal Maps; Complex designs; Creativity support; Creativity support tool; Design spaces; Language model; Large language model; Mixed-initiative systems; Professional designers; Support tool; Knowledge management},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038376-9},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Giudici202342,
	author = {Giudici, Mathyas and Abbo, Giulio Antonio and Belotti, Ottavia and Braccini, Alessio and Dubini, Francesco and Izzo, Riccardo Andrea and Crovari, Pietro and Garzotto, Franca},
	title = {Assessing LLMs Responses in the Field of Domestic Sustainability: An Exploratory Study},
	year = {2023},
	journal = {Proceedings - 2023 3rd International Conference on Digital Data Processing, DDP 2023},
	pages = {42 – 48},
	doi = {10.1109/DDP60485.2023.00019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186140844&doi=10.1109%2fDDP60485.2023.00019&partnerID=40&md5=8a26a04a011ada2087160bf8565e0146},
	affiliations = {Politecnico di Milano, Milan, Italy; Ghent University - Imec, IDLab-AIRO, Ghent, Belgium},
	abstract = {In the next years, we must challenge climate change, and the urgency of adopting a more sustainable lifestyle has increased. Conversational Agents, such as Smart home Personal Assistants, have shown promise in fostering sustainable behaviors in domestic environments. However, traditional conversations with rule-based approaches in such agents face challenges in addressing users' questions in complex domains like sustainability. Large Language Models (LLMs) are a promising tool to overcome these limitations of their capability to answer open-domain questions. The final objective of this work is to compare the generative capabilities of four large language models in ecological sustainability to determine the most suitable LLM to be embedded into home assistants and create a hybrid model of conversational agent for environmental sustainability. We performed two evaluations. In the former, we constructed a set of trustable sources on the topic and analyzed the extent to which the themes covered in the text generated by the models appeared in it. The results do not show a statistical difference between the outputs of the candidate models, while qualitative analysis determined that ChatGPT, at the moment, is the optimal solution. In the second evaluation, we tested the responses generated by ChatGPT on a corpus of 167 questions from a sample of 75 people. Responses evaluation was performed by a team of experts (N=5) on fluency, coherency, consistency, accuracy, and reasoning. The results suggest that ChatGPT for generic questions on sustainability is quite reliable.  © 2023 IEEE.},
	author_keywords = {Conversational Agent; LLM; Rule-based CA; Sustainability},
	keywords = {Automation; Climate change; Computational linguistics; Intelligent buildings; Conversational agents; Exploratory studies; Language model; Large language model; Model response; Personal assistants; Rule based; Rule-based CA; Smart homes; Sustainable behaviours; Sustainable development},
	editor = {Ariwa E. and Ariwa E. and Fong S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032901-8},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Digit. Data Process., DDP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Šigut202335,
	author = {Šigut, Petr and Foltýnek, Tomáš},
	title = {Can We Detect ChatGPT-generated Texts in Czech and Slovak Languages?},
	year = {2023},
	journal = {Recent Advances in Slavonic Natural Language Processing},
	pages = {35 – 43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187230508&partnerID=40&md5=9ff246d832d0933ec0ef0ba23239ca81},
	affiliations = {Faculty of Informatics, Masaryk University, Brno, Czech Republic},
	abstract = {The wide availability of generative AI exacerbates existing threats to society. It would not be easy even for linguists to tell whether the text we are reading was generated by a Large Language Model (LLM) or written by a human.[1]. Researchers have started developing tools that detect AI-generated content [2]. This paper tested how two of these tools, Compilatio [3] and GPT-2 Output Detector [4], performed with Czech, Slovak and English texts. There was only one tool somewhat capable of detecting AI-generated texts: Compilatio. Other tools were designed to work only with English texts. Hence, we also tested whether automatically translating the Czech and Slovak texts to English before uploading them to the detectors would have given any promising results. Ultimately, we showed that the texts generated by ChatGPT4 were less detectable than the texts generated by ChatGPT3.5. © Tribun EU 2023.},
	author_keywords = {AI-detection; ChatGPT; Czech; Slovak},
	keywords = {AI detection; ChatGPT; Czech; Czech language; Language model; Slovak; Slovak languages},
	editor = {Horak A. and Masaryk University, Faculty of Informatics, Department of Information Technologies, Botanicka 68a, Brno and Rychly P. and Masaryk University, Faculty of Informatics, Department of Information Technologies, Botanicka 68a, Brno and Rambousek A. and Masaryk University, Faculty of Informatics, Department of Information Technologies, Botanicka 68a, Brno},
	publisher = {Tribun EU s. r. o.},
	issn = {23364289},
	isbn = {978-802631793-7},
	language = {English},
	abbrev_source_title = {Recent Adv. Slavon. Nat. Lang. Process.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Sathe2023633,
	author = {Sathe, Neha and Deodhe, Vaibhav and Sharma, Yash and Shinde, Anand},
	title = {A Comprehensive Review of AI in Healthcare: Exploring Neural Networks in Medical Imaging, LLM-Based Interactive Response Systems, NLP-Based EHR Systems, Ethics, and Beyond},
	year = {2023},
	journal = {Proceedings - 2023 International Conference on Advanced Computing and Communication Technologies, ICACCTech 2023},
	pages = {633 – 640},
	doi = {10.1109/ICACCTech61146.2023.00108},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187220373&doi=10.1109%2fICACCTech61146.2023.00108&partnerID=40&md5=81d5e0a662e0a1ac3661690142c031be},
	affiliations = {School of Computer Engineering & Technology, Mit World Peace University, Pune, India},
	abstract = {The AI-based technologies used in healthcare systems have witnessed significant growth and innovation, as this growth is attributed to innovations in AI and rise in data collection in the healthcare sector. This survey paper provides a comprehensive overview of the diverse technological advancements reshaping the healthcare landscape. The reviewed topics include Medical Image Interpretation using Deep Learning, Generative AI-based Large Language Models (LLMs), Natural Language Processing for Healthcare Records to give a sense of what AI based systems look like in healthcare. For each of these topics, we've delved into their technical aspects and their applications. Through an overview of these cutting-edge technologies, this research aims to shed light on their current state, challenges, and potential implications for the future of health care. From enhancing diagnostics to improving patient care and accessibility, AI is poised to play pivotal roles in shaping the healthcare industry for years to come. Furthermore, this survey also delves into the ethical considerations surrounding these technologies.  © 2023 IEEE.},
	author_keywords = {AI; CNN; EHR; Healthcare; LLM; Medicine; ML},
	keywords = {Deep learning; Health care; Medical imaging; Natural language processing systems; Philosophical aspects; EHR; EHR systems; Healthcare; Healthcare systems; Interactive response systems; Language model; Large language model; ML; Model-based OPC; Neural-networks; Diagnosis},
	editor = {Mittal H.K. and Singla S.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835038088-0},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Adv. Comput. Commun. Technol., ICACCTech},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Morbidoni2023,
	author = {Morbidoni, Christian},
	title = {Poster: LLMs for online customer reviews analysis: Oracles or tools? Experiments with GPT 3.5},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3605390.3610810},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173655975&doi=10.1145%2f3605390.3610810&partnerID=40&md5=551aa2bfa2dd8ae0beaefae57cf0b13e},
	affiliations = {Università Degli Studi G. d'Annunzio, Pescara, Italy},
	abstract = {Generative Large Language Models, pre-trained on a huge amount of human authored text, are showing emergent capabilities in understanding and accomplishing a variety of NLP and text comprehension tasks. Recently, interest is growing in understanding to what extent LLMs can support humans, or even replace them, in accomplishing non trivial data analysis tasks. In this paper, we explore OpenAI's GPT capabilities in online customer review analysis, a multi-step analysis activity which typically involves both human knowledge and predictive data analysis techniques (e.g. topic extraction, aspect-based sentiment analysis). We explore different interaction modalities where the LLM covers all or part of the analysis process, and provide a preliminary evaluation against human annotation outcomes.  © 2023 Owner/Author.},
	author_keywords = {GPT; Large Language Models; NLP; Online customer reviews analysis; topic-level sentiment analysis; zero-shot},
	keywords = {Computational linguistics; Data handling; Sales; Zero-shot learning; Comprehension tasks; GPT; Language model; Large language model; Online customer review analyse; Online customer reviews; Sentiment analysis; Text comprehensions; Topic-level sentiment analyse; Zero-shot; Sentiment analysis},
	correspondence_address = {C. Morbidoni; Università Degli Studi G. d'Annunzio, Pescara, Italy; email: christian.morbidoni@gmail.com},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070806-0},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang202373,
	author = {Wang, Shuai and Scells, Harrisen and Koopman, Bevan and Potthast, Martin and Zuccon, Guido},
	title = {Generating Natural Language Queries for More Effective Systematic Review Screening Prioritisation},
	year = {2023},
	journal = {SIGIR-AP 2023 - Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
	pages = {73 – 83},
	doi = {10.1145/3624918.3625322},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180127416&doi=10.1145%2f3624918.3625322&partnerID=40&md5=e6e8370976e66a506bcc590e7d87448f},
	affiliations = {Eecs, The University of Queensland, Australia; Leipzig University, Germany; Leipzig University, ScaDS.AI, Germany; Csiro, The University of Queensland, Australia},
	abstract = {Screening prioritisation in medical systematic reviews aims to rank the set of documents retrieved by complex Boolean queries. Prioritising the most important documents ensures that subsequent review steps can be carried out more efficiently and effectively. The current state of the art uses the final title of the review as a query to rank the documents using BERT-based neural rankers. However, the final title is only formulated at the end of the review process, which makes this approach impractical as it relies on ex post facto information. At the time of screening, only a rough working title is available, with which the BERT-based ranker performs significantly worse than with the final title. In this paper, we explore alternative sources of queries for prioritising screening, such as the Boolean query used to retrieve the documents to be screened and queries generated by instruction-based generative large-scale language models such as ChatGPT and Alpaca. Our best approach is not only viable based on the information available at the time of screening, but also has similar effectiveness to the final title.  © 2023 ACM.},
	author_keywords = {LLM; Query variations; Screening prioritisation; Systematic review},
	keywords = {Natural language processing systems; 'current; Boolean queries; LLM; Natural language queries; Prioritization; Query variation; Review process; Screening prioritization; State of the art; Systematic Review; Diagnosis},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070408-6},
	language = {English},
	abbrev_source_title = {SIGIR-AP - Annu. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr. Asia Pac. Reg.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{French2023,
	author = {French, Fiona and Levi, David and Maczo, Csaba and Simonaityte, Aiste and Triantafyllidis, Stefanos and Varda, Gergo},
	title = {Creative Use of OpenAI in Education: Case Studies from Game Development},
	year = {2023},
	journal = {Multimodal Technologies and Interaction},
	volume = {7},
	number = {8},
	doi = {10.3390/mti7080081},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169072019&doi=10.3390%2fmti7080081&partnerID=40&md5=43b7dfea735ded9fc172468e7770a3cb},
	affiliations = {School of Computing and Digital Media, London Metropolitan University, London, N7 8DB, United Kingdom},
	abstract = {Educators and students have shown significant interest in the potential for generative artificial intelligence (AI) technologies to support student learning outcomes, for example, by offering personalized experiences, 24 h conversational assistance, text editing and help with problem-solving. We review contemporary perspectives on the value of AI as a tool in an educational context and describe our recent research with undergraduate students, discussing why and how we integrated OpenAI tools ChatGPT and Dall-E into the curriculum during the 2022–2023 academic year. A small cohort of games programming students in the School of Computing and Digital Media at London Metropolitan University was given a research and development assignment that explicitly required them to engage with OpenAI. They were tasked with evaluating OpenAI tools in the context of game development, demonstrating a working solution and reporting on their findings. We present five case studies that showcase some of the outputs from the students and we discuss their work. This mode of assessment was both productive and popular, mapping to students’ interests and helping to refine their skills in programming, problem-solving, critical reflection and exploratory design. © 2023 by the authors.},
	author_keywords = {artificial intelligence; ChatGPT; Dall-E; education; game design; game programming; interaction design; LLM; OpenAI; procedural generation},
	correspondence_address = {F. French; School of Computing and Digital Media, London Metropolitan University, London, N7 8DB, United Kingdom; email: f.french@londonmet.ac.uk},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {24144088},
	language = {English},
	abbrev_source_title = {Multimodal Tech. Inter.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Mooney202385,
	author = {Mooney, Peter and Cui, Wencong and Guan, Boyuan and Juhász, Levente},
	title = {Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam},
	year = {2023},
	journal = {GeoAI 2023 - Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
	pages = {85 – 94},
	doi = {10.1145/3615886.3627745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179098925&doi=10.1145%2f3615886.3627745&partnerID=40&md5=bb73d9923075997c1c12ae5e0f78ff07},
	affiliations = {Department of Computer Science, Maynooth University, Co. Kildare, Maynooth, Ireland; GIS Center, Florida International University, Miami, FL, United States},
	abstract = {This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3% (GPT-3.5) and 88.3% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.  © 2023 Owner/Author.},
	author_keywords = {ChatGPT; education; foundation model; Generative AI; geospatial; GIS; Large Language Models},
	keywords = {Computational linguistics; Grading; Information management; Information systems; Information use; ChatGPT; Foundation models; Generative AI; Geo-spatial; Human learning; Language model; Large language model; Model training; Performance; Spatial concepts; Geographic information systems},
	editor = {Newsam S. and Yang L. and Mai G. and Martins B. and Lunga D. and Gao S.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070348-5},
	language = {English},
	abbrev_source_title = {GeoAI - Proc. ACM SIGSPATIAL Int. Workshop AI Geogr. Knowl. Discov.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Hua20231281,
	author = {Hua, Wenyue and Li, Lei and Xu, Shuyuan and Chen, Li and Zhang, Yongfeng},
	title = {Tutorial on Large Language Models for Recommendation},
	year = {2023},
	journal = {Proceedings  of the 17th ACM Conference on Recommender Systems, RecSys 2023},
	pages = {1281 – 1283},
	doi = {10.1145/3604915.3609494},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174527192&doi=10.1145%2f3604915.3609494&partnerID=40&md5=85d7a85896b19c12295722e09c91a25a},
	affiliations = {Department of Computer Science, Rutgers University, United States; Department of Computer Science, Hong Kong Baptist University, Hong Kong},
	abstract = {Foundation Models such as Large Language Models (LLMs) have significantly advanced many research areas. In particular, LLMs offer significant advantages for recommender systems, making them valuable tools for personalized recommendations. For example, by formulating various recommendation tasks such as rating prediction, sequential recommendation, straightforward recommendation, and explanation generation into language instructions, LLMs make it possible to build universal recommendation engines that can handle different recommendation tasks. Additionally, LLMs have a remarkable capacity for understanding natural language, enabling them to comprehend user preferences, item descriptions, and contextual information to generate more accurate and relevant recommendations, leading to improved user satisfaction and engagement. This tutorial introduces Foundation Models such as LLMs for recommendation. We will introduce how recommender system advanced from shallow models to deep models and to large models, how LLMs enable generative recommendation in contrast to traditional discriminative recommendation, and how to build LLM-based recommender systems. We will cover multiple perspectives of LLM-based recommendation, including data preparation, model design, model pre-training, fine-tuning and prompting, multi-modality and multi-task learning, as well as trustworthy perspectives of LLM-based recommender systems such as fairness and transparency. © 2023 ACM.},
	author_keywords = {Foundation Models; Large Language Models; Recommendation},
	keywords = {Computational linguistics; User interfaces; Foundation models; Item descriptions; Language model; Large language model; Model-based OPC; Natural languages; Personalized recommendation; Recommendation; Research areas; User's preferences; Recommender systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070241-9},
	language = {English},
	abbrev_source_title = {Proc. ACM Conf. Recommen. Syst., RecSys},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Saikia2023881,
	author = {Saikia, Krishi Pallab and Mukherjee, Debdeep and Mahapatra, Saranik and Nandy, Prasun and Das, Rik},
	title = {Unveiling Deeper Petrochemical Insights: Navigating Contextual Question Answering with the Power of Semantic Search and LLM Fine-Tuning},
	year = {2023},
	journal = {Proceedings - 4th IEEE 2023 International Conference on Computing, Communication, and Intelligent Systems, ICCCIS 2023},
	pages = {881 – 886},
	doi = {10.1109/ICCCIS60361.2023.10425564},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186494632&doi=10.1109%2fICCCIS60361.2023.10425564&partnerID=40&md5=3b09bd9d48e03f10c274aa078f555835},
	affiliations = {Data and Analytics, PwC India, Kolkata, India},
	abstract = {In the dynamic and complex landscape of the petrochemical industry, competitiveness and efficiency are paramount. Extracting actionable insights from diverse data sources, such as video transcripts, business process data, and organizational information, has become increasingly vital with technological advancements. Video transcripts hold untapped potential, offering opportunities to enhance products and services. This study introduces a comprehensive approach by leveraging semantic search to retrieve targeted information from video transcripts, business process data, and organizational insights. Semantic search employs natural language understanding and vectorization techniques to extract contextual information, yielding precise results and eliminating the need for manual data sifting. Comparative analysis demonstrates the superiority of semantic search over fine-Tuned Large Language Models (LLMs) in relevance and response time. Semantic search consistently produces contextually relevant answers, owing to its vector-based semantic comprehension. Additionally, the response time of semantic search outperforms LLMs, enhancing user satisfaction. This research proposes the first of its kind semantic search-based approach for information retrieval in the petrochemical sector using a fusion of video transcript data with other data sources. By developing a domain-specific question answering system, the paper aims to enhance efficiency, accuracy, and decision-making. The integration of video transcripts, semantic search, and organizational data promises transformative implications for the petrochemical sector. This innovative approach holds the promise of streamlined operations, improved safety, and timely insights. The research contributes to bridging the gap in semantic search and bot-based Question Answer (QA) systems by integrating video transcript data with organizational and process data, enhancing information retrieval within the petrochemical sector. © 2023 IEEE.},
	author_keywords = {finetuning; generative artificial intelligence; large language model (LLM); petrochemical; semantic search},
	keywords = {Competition; Competitive intelligence; Computational linguistics; Data integration; Data mining; Decision making; Efficiency; Petrochemicals; Search engines; Semantic Web; Semantics; Business Process; Data-source; Finetuning; Generative artificial intelligence; Language model; Large language model; Organisational; Petrochemical sector; Process data; Semantic search; Information retrieval},
	editor = {Nand P. and Singh M. and Kaur M. and Jain V. and Gupta K.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030611-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Comput., Commun., Intell. Syst., ICCCIS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Agossah2023237,
	author = {Agossah, Alexandre and Krupa, Frédérique and Perreira Da Silva, Matthieu and Le Callet, Patrick},
	title = {LLM-Based Interaction for Content Generation: A Case Study on the Perception of Employees in an IT Department},
	year = {2023},
	journal = {IMX 2023 - Proceedings of the 2023 ACM International Conference on Interactive Media Experiences},
	pages = {237 – 241},
	doi = {10.1145/3573381.3603362},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174303277&doi=10.1145%2f3573381.3603362&partnerID=40&md5=b42f2e2feda9f3c56053a0c3c80da1ed},
	affiliations = {Nantes Université, Ecole Centrale Nantes, Cnrs, LS2N, Umr 60004, Nantes, F-44000, France; Digital Design Lab, L'École de Design Nantes Atlantique, Nantes, 44200, France; Groupe Sigma, La Chapelle-sur-Erdre, 44240, France},
	abstract = {In the past years, AI has seen many advances in the field of NLP. This has led to the emergence of LLMs, such as the now famous GPT-3.5, which revolutionise the way humans can access or generate content. Current studies on LLM-based generative tools are mainly interested in the performance of such tools in generating relevant content (code, text or image). However, ethical concerns related to the design and use of generative tools seem to be growing, impacting the public acceptability for specific tasks. This paper presents a questionnaire survey to identify the intention to use generative tools by employees of an IT company in the context of their work. This survey is based on empirical models measuring intention to use (TAM by Davis, 1989, and UTAUT2 by Venkatesh and al., 2008). Our results indicate a rather average acceptability of generative tools, although the more useful the tool is perceived to be, the higher the intention to use seems to be. Furthermore, our analyses suggest that the frequency of use of generative tools is likely to be a key factor in understanding how employees perceive these tools in the context of their work. Following on from this work, we plan to investigate the nature of the requests that may be made to these tools by specific audiences.  © 2023 Owner/Author.},
	author_keywords = {acceptability; computer-human interaction; large language models; professional context},
	keywords = {Human computer interaction; 'current; Acceptability; Case-studies; Computer Human Interaction; Generative tools; Intention to use; Language model; Large language model; Performance; Professional context; Personnel},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070028-6},
	language = {English},
	abbrev_source_title = {IMX - Proc. ACM Int. Conf. Interact. Media Exp.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Delsoz20233121,
	author = {Delsoz, Mohammad and Raja, Hina and Madadi, Yeganeh and Tang, Anthony A. and Wirostko, Barbara M. and Kahook, Malik Y. and Yousefi, Siamak},
	title = {The Use of ChatGPT to Assist in Diagnosing Glaucoma Based on Clinical Case Reports},
	year = {2023},
	journal = {Ophthalmology and Therapy},
	volume = {12},
	number = {6},
	pages = {3121 – 3132},
	doi = {10.1007/s40123-023-00805-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171271083&doi=10.1007%2fs40123-023-00805-x&partnerID=40&md5=2afb226d8498f09e582714d7ec1a37c1},
	affiliations = {Department of Ophthalmology, Hamilton Eye Institute, University of Tennessee Health Science Center, 930 Madison Ave., Suite 471, Memphis, 38163, TN, United States; John Moran Eye Center, University of Utah, Salt Lake City, UT, United States; Department of Ophthalmology, University of Colorado School of Medicine, Aurora, CO, United States; Department of Genetics, Genomics, and Informatics, University of Tennessee Health Science Center, Memphis, TN, United States},
	abstract = {Introduction: The purpose of this study was to evaluate the capabilities of large language models such as Chat Generative Pretrained Transformer (ChatGPT) to diagnose glaucoma based on specific clinical case descriptions with comparison to the performance of senior ophthalmology resident trainees. Methods: We selected 11 cases with primary and secondary glaucoma from a publicly accessible online database of case reports. A total of four cases had primary glaucoma including open-angle, juvenile, normal-tension, and angle-closure glaucoma, while seven cases had secondary glaucoma including pseudo-exfoliation, pigment dispersion glaucoma, glaucomatocyclitic crisis, aphakic, neovascular, aqueous misdirection, and inflammatory glaucoma. We input the text of each case detail into ChatGPT and asked for provisional and differential diagnoses. We then presented the details of 11 cases to three senior ophthalmology residents and recorded their provisional and differential diagnoses. We finally evaluated the responses based on the correct diagnoses and evaluated agreements. Results: The provisional diagnosis based on ChatGPT was correct in eight out of 11 (72.7%) cases and three ophthalmology residents were correct in six (54.5%), eight (72.7%), and eight (72.7%) cases, respectively. The agreement between ChatGPT and the first, second, and third ophthalmology residents were 9, 7, and 7, respectively. Conclusions: The accuracy of ChatGPT in diagnosing patients with primary and secondary glaucoma, using specific case examples, was similar or better than senior ophthalmology residents. With further development, ChatGPT may have the potential to be used in clinical care settings, such as primary care offices, for triaging and in eye care clinical practices to provide objective and quick diagnoses of patients with glaucoma. © 2023, The Author(s).},
	author_keywords = {Artificial intelligence (AI); ChatGPT; Differential diagnosis; Glaucoma; Large language models (LLM); Provisional diagnosis},
	keywords = {Article; artificial intelligence; ChatGPT; chemexfoliation; clinical practice; diagnostic accuracy; differential diagnosis; dispersion; eye care; glaucoma; human; intraocular pressure; malignant glaucoma; neovascular glaucoma; ophthalmology; patient triage; pigmentation; primary medical care; pseudoexfoliation; refraction error; resident; secondary glaucoma},
	correspondence_address = {S. Yousefi; Department of Ophthalmology, Hamilton Eye Institute, University of Tennessee Health Science Center, Memphis, 930 Madison Ave., Suite 471, 38163, United States; email: siamak.yousefi@uthsc.edu},
	publisher = {Adis},
	issn = {21938245},
	language = {English},
	abbrev_source_title = {Ophthalmol. Ther.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lee2023,
	author = {Lee, Minhyeok},
	title = {A Mathematical Investigation of Hallucination and Creativity in GPT Models},
	year = {2023},
	journal = {Mathematics},
	volume = {11},
	number = {10},
	doi = {10.3390/math11102320},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160403833&doi=10.3390%2fmath11102320&partnerID=40&md5=ab6ef55c3309916acf6252b671f191c4},
	affiliations = {School of Electrical and Electronics Engineering, Chung-Ang University, Seoul, 06974, South Korea},
	abstract = {In this paper, we present a comprehensive mathematical analysis of the hallucination phenomenon in generative pretrained transformer (GPT) models. We rigorously define and measure hallucination and creativity using concepts from probability theory and information theory. By introducing a parametric family of GPT models, we characterize the trade-off between hallucination and creativity and identify an optimal balance that maximizes model performance across various tasks. Our work offers a novel mathematical framework for understanding the origins and implications of hallucination in GPT models and paves the way for future research and development in the field of large language models (LLMs). © 2023 by the author.},
	author_keywords = {ChatGPT; creativity; generative pretrained transformers; GPT; hallucination; large language model; LLM},
	correspondence_address = {M. Lee; School of Electrical and Electronics Engineering, Chung-Ang University, Seoul, 06974, South Korea; email: mlee@cau.ac.kr},
	publisher = {MDPI},
	issn = {22277390},
	language = {English},
	abbrev_source_title = {Mathematics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@CONFERENCE{Fan202331,
	author = {Fan, Angela and Gokkaya, Beliz and Harman, Mark and Lyubarskiy, Mitya and Sengupta, Shubho and Yoo, Shin and Zhang, Jie M.},
	title = {Large Language Models for Software Engineering: Survey and Open Problems},
	year = {2023},
	journal = {Proceedings - 2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering, ICSE-FoSE 2023},
	pages = {31 – 53},
	doi = {10.1109/ICSE-FoSE59343.2023.00008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185604518&doi=10.1109%2fICSE-FoSE59343.2023.00008&partnerID=40&md5=8940cca3aaa53cdab79b08a8ef247214},
	affiliations = {Generative Ai Team, Meta Platforms Inc., New York, NY, United States; PyTorch Team, Meta Platforms Inc., Menlo Park, CA, United States; Instagram Product Foundation, Meta Platforms Inc., London, United Kingdom; Developer Infrastructure, Meta Platforms Inc., London, United Kingdom; Fair, Meta Platforms Inc., Menlo Park, CA, United States; School of Computing, Kaist, Daejeon, South Korea; King's College London, Department of Informatics, London, United Kingdom},
	abstract = {This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding, design, requirements, repair, refactoring, performance improvement, documentation and analytics. However, these very same emergent properties also pose significant technical challenges; we need techniques that can reliably weed out incorrect solutions, such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable, efficient and effective LLM-based SE. © 2023 IEEE.},
	author_keywords = {Automated Program Repair; Documentation generation; Generative AI; Genetic Improvement; Human-Computer Interaction; Large Language Models; Refactoring; Requirements engineering; Search Based Software Engineering (SBSE); Software Analytics; Software Engineering Education; Software Maintenance and Evolution; Software Processes; Software Testing},
	keywords = {Application programs; Computational linguistics; Engineering education; Human computer interaction; Repair; Automated program repair; Documentation generation; Generative AI; Genetic improvements; Language model; Large language model; Refactorings; Requirement engineering; Search based software engineering; Search-based; Software analytic; Software engineering education; Software maintenance and evolution; Software process; Software testings; Software testing},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032496-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Int. Conf. Softw. Eng.: Future Softw. Eng., ICSE-FoSE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {All Open Access, Green Open Access}
}

@ARTICLE{Brie2023,
	author = {Brie, Paul and Burny, Nicolas and Sluyters, Arthur and Vanderdonckt, Jean},
	title = {Evaluating a Large Language Model on Searching for GUI Layouts},
	year = {2023},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	volume = {7},
	number = {EICS},
	doi = {10.1145/3593230},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163743748&doi=10.1145%2f3593230&partnerID=40&md5=496c3f7b5c9bd7306311f27a59070a8b},
	affiliations = {TeleportHQ, Calea Motilor, 84, Cluj-Napoca, 400370, Romania; Université Catholique de Louvain, Louvain Research Institute in Management and Organizations, Place des Doyens, 1, Louvain-la-Neuve, 1348, Belgium},
	abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-Trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.  © 2023 ACM.},
	author_keywords = {generative pre-Training; gui design; gui layout; large language model; web pages},
	keywords = {Computational linguistics; Graphical user interfaces; Software engineering; Engineering tasks; Generative pre-training; GUI designs; Gui layout; Language model; Large language model; Pre-training; Research questions; Users' experiences; Web-page; Websites},
	publisher = {Association for Computing Machinery},
	issn = {25730142},
	language = {English},
	abbrev_source_title = {Proc. ACM Hum. Comput. Interact.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Chen2023310,
	author = {Chen, Huan-Yuan and Yu, Hong},
	title = {Intent-based Web Page Summarization with Structure-Aware Chunking and Generative Language Models},
	year = {2023},
	journal = {ACM Web Conference 2023 - Companion of the World Wide Web Conference, WWW 2023},
	pages = {310 – 313},
	doi = {10.1145/3543873.3587372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159623360&doi=10.1145%2f3543873.3587372&partnerID=40&md5=576bf19d23f6302e7781b6a4e65f361d},
	affiliations = {College of Information and Computer Sciences, University of Massachusetts Amherst, Amherst, MA, United States; School of Computer and Information Sciences, University of Massachusetts Lowell, Lowell, MA, United States},
	abstract = {This paper introduces a structure-aware method to segment web pages into chunks based on their web structures. We utilize large language models to select chunks correspond to a given intent and generate the abstractive summary. Experiments on a food pantry dataset developed for mitigating food insecurity show that the proposed framework is promising.  © 2023 Owner/Author.},
	author_keywords = {LLM Applications; Structure-Aware Chunking; Web for Good; Web Page Summarization},
	keywords = {Computational linguistics; Information retrieval; Food insecurity; Language model; LLM application; Structure-aware; Structure-aware chunking; Web for good; Web page summarization; Web structures; Web-page; Websites},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039416-1},
	language = {English},
	abbrev_source_title = {ACM Web Conf. - Companion World Wide Web Conf., WWW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Tan2023,
	author = {Tan, Ting Fang and Thirunavukarasu, Arun James and Campbell, J. Peter and Keane, Pearse A. and Pasquale, Louis R. and Abramoff, Michael D. and Kalpathy-Cramer, Jayashree and Lum, Flora and Kim, Judy E. and Baxter, Sally L. and Ting, Daniel Shu Wei},
	title = {Generative Artificial Intelligence Through ChatGPT and Other Large Language Models in Ophthalmology: Clinical Applications and Challenges},
	year = {2023},
	journal = {Ophthalmology Science},
	volume = {3},
	number = {4},
	doi = {10.1016/j.xops.2023.100394},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174553744&doi=10.1016%2fj.xops.2023.100394&partnerID=40&md5=1ddefce51280fef771f97d29304ddba0},
	affiliations = {Singapore Eye Research Institute, Singapore National Eye Centre, Singapore; University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom; Corpus Christi College, University of Cambridge, Cambridge, United Kingdom; Department of Ophthalmology, Casey Eye Institute, Oregon Health and Science University, Portland, Oregon, United States; Moorfields Eye Hospital, University of College London, London, United Kingdom; Department of Ophthalmology, Icahn School of Medicine at Mount Sinai, New York City, New York, United States; American Medical Association's Digital Medicine Payment Advisory Group (DMPAG) Artificial Intelligence Workgroup, American Medical Association, Chicago, Illinois, United States; Department of Ophthalmology, University of Iowa, Iowa City, IA, United States; Digital Diagnostics, Inc, Coralville, IA, United States; Department of Ophthalmology, University of Colorado Anschutz Medical Campus, Aurora, Colorado, United States; American Academy of Ophthalmology, San Francisco, California, United States; Department of Ophthalmology, Medical College of Wisconsin, Milwaukee, WI, United States; Division of Ophthalmology Informatics and Data Science, Viterbi Family Department of Ophthalmology and Shiley Eye Institute, La Jolla, California, United States; Health Department of Biomedical Informatics, University of California San Diego, La Jolla, California, United States; Byers Eye Institute, Stanford University, Stanford, California, United States},
	abstract = {The rapid progress of large language models (LLMs) driving generative artificial intelligence applications heralds the potential of opportunities in health care. We conducted a review up to April 2023 on Google Scholar, Embase, MEDLINE, and Scopus using the following terms: “large language models,” “generative artificial intelligence,” “ophthalmology,” “ChatGPT,” and “eye,” based on relevance to this review. From a clinical viewpoint specific to ophthalmologists, we explore from the different stakeholders’ perspectives—including patients, physicians, and policymakers—the potential LLM applications in education, research, and clinical domains specific to ophthalmology. We also highlight the foreseeable challenges of LLM implementation into clinical practice, including the concerns of accuracy, interpretability, perpetuating bias, and data security. As LLMs continue to mature, it is essential for stakeholders to jointly establish standards for best practices to safeguard patient safety. Financial Disclosure(s): Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article. © 2023 American Academy of Ophthalmology},
	author_keywords = {Artificial intelligence; Chatbots; ChatGPT; Large language models},
	keywords = {adult; article; artificial intelligence; ChatGPT; clinical practice; drug safety; education; Embase; human; information security; Medline; ophthalmologist; ophthalmology; patient safety; physician; Scopus; search engine},
	correspondence_address = {D.S.W. Ting; Duke-NUS Medical School, AI and Digital Innovation, Singapore Eye Research Institute, Singapore Eye Research Institute (SERI), The Academia, 20 College Road, Level 6 Discovery Tower, 169856, Singapore; email: daniel.ting@duke-nus.edu.sg},
	publisher = {Elsevier Inc.},
	issn = {26669145},
	language = {English},
	abbrev_source_title = {Ophthalmol. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tian20234198,
	author = {Tian, Yonglin and Li, Xuan and Zhang, Hui and Zhao, Chen and Li, Bai and Wang, Xiao and Wang, Xiao and Wang, Fei-Yue},
	title = {VistaGPT: Generative Parallel Transformers for Vehicles With Intelligent Systems for Transport Automation},
	year = {2023},
	journal = {IEEE Transactions on Intelligent Vehicles},
	volume = {8},
	number = {9},
	pages = {4198 – 4207},
	doi = {10.1109/TIV.2023.3307012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168704878&doi=10.1109%2fTIV.2023.3307012&partnerID=40&md5=2404bf092e67f27e9c05b847dfec8d2e},
	affiliations = {Chinese Academy of Sciences, State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Beijing, 100190, China; Peng Cheng Laboratory, Shenzhen, 518000, China; Beijing Jiaotong University, School of Computer and Information Technology, Beijing, 100044, China; Hunan University, State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body, College of Mechanical and Vehicle Engineering, Changsha, 410082, China; Purdue University, Department of Computer Science, West Lafayette, 47906, IN, United States; Anhui University, Hefei, 266114, China},
	abstract = {Diverse transport demands have resulted in the wide existence of heterogeneous vehicle automation systems. While these systems have demonstrated effectiveness, they also pose challenges in terms of the share of technological advancements among different organizations and lead to poor generalization ability of individual systems. This article proposes a Transformer-based unified framework, VistaGPT, to address these challenges. VistaGPT, composed of Modular Federations of Vehicular Transformers (M-FoV) and Automated Composing of Autonomous Driving Systems (AutoAuto), aims to overcome the information barriers due to system-level and module-level heterogeneity. M-FoV collects and organizes Transformer-based models in a modular fashion to facilitate system integration by providing diversity and versatility. AutoAuto utilizes large language models (LLMs) to automatically compose end-to-end autonomous driving systems with a 'Dividing and Recombining' strategy. Besides, we deploy Scenario Engineering systems to evaluate the composed systems and provide systematic feedback for the optimization of AutoAuto, and Federated intelligence to contribute to diverse training samples and applications. With its capacity, scalability, and diversity, VistaGPT provides a new paradigm of LLM-aided system development for transport automation, which promotes virtual-real interactive parallel driving and advances progress toward '6S' objectives.  © 2016 IEEE.},
	author_keywords = {end-to-end driving; federation of vehicular transformers; Generative parallel transformers; large-language models; scenario engineering; transport automation},
	keywords = {Computational linguistics; Intelligent systems; End to end; End-to-end driving; Federation of vehicular transformer; Generative parallel transformer; Language model; Large-language model; Modulars; Parallel transformers; Scenario engineering; Transport automation; Autonomous vehicles},
	correspondence_address = {X. Li; Peng Cheng Laboratory, Shenzhen, 518000, China; email: lix05@pcl.ac.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23798858},
	language = {English},
	abbrev_source_title = {IEEE Trans. Intell. Veh.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Shukla20232872,
	author = {Shukla, Neelesh K and Katikeri, Raghu and Raja, Msp and Sivam, Gowtham and Yadav, Shlok and Vaid, Amit and Prabhakararao, Shreenivas},
	title = {Generative AI Approach to Distributed Summarization of Financial Narratives},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {2872 – 2876},
	doi = {10.1109/BigData59044.2023.10386313},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184979173&doi=10.1109%2fBigData59044.2023.10386313&partnerID=40&md5=3aef93a75c87d2f8e717d2e9c5e77059},
	affiliations = {Artificial Intelligence Group State Street Corporation, Bengaluru, India; Artificial Intelligence Group State Street Corporation, Hyderabad, India},
	abstract = {This paper presents our submission to the Financial Narrative Summarization (FNS) task at the FNP-2023 workshop. The FNS task involves the generation of concise summaries, not exceeding 1000 words, for annual financial reports composed in English, Spanish, and Greek. In our prior work, presented in FNP-2022, we introduced DiMSum [1], a novel framework designed to automatically identify crucial narrative sections within financial reports and quantify their weighted contributions. The field of Generative AI and Large Language Models (LLMs) has recently witnessed significant advancements, prompting us to explore their utility in summarizing financial reports. Our investigation revealed that LLMs, when left to their own devices often struggle to effectively summarize complex financial documents, necessitating external guidance. In this study, we demonstrate how LLMs, when guided by the DiMSum framework, exhibit substantial improvements in the quality of financial report summarization. To the best of our knowledge, this research marks the first instance of applying LLMs to the FNS task, offering a novel approach to enhancing the summarization of financial reports.  © 2023 IEEE.},
	author_keywords = {Financial; Generative AI; LLM; Narrative; Prompt; Summary},
	correspondence_address = {N.K. Shukla; Artificial Intelligence Group State Street Corporation, Bengaluru, India; email: nshukla@statestreet.com},
	editor = {He J. and Palpanas T. and Hu X. and Cuzzocrea A. and Dou D. and Slezak D. and Wang W. and Gruca A. and Lin J.C.-W. and Agrawal R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032445-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Yong202345,
	author = {Yong, Qian and Wei, Jueqi and Zhang, Yiren and Zhang, Xilun and Wei, Chao and Chen, Simiao and Li, Yunhe and Ye, Cheng and Huang, Bing and Wang, Hao},
	title = {CGSMP: Controllable Generative Summarization via Multimodal Prompt},
	year = {2023},
	journal = {LGM3A 2023 -  Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications, Co-located with: MM 2023},
	pages = {45 – 50},
	doi = {10.1145/3607827.3616841},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180411267&doi=10.1145%2f3607827.3616841&partnerID=40&md5=fb1e0f18bb1e1acda3360b54cc393d5d},
	affiliations = {Shanghai Shizhuang Information Technology Co. Ltd., ShangHai, China; Wuhan University, ShenZhen, China},
	abstract = {Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of a large language model (LLM), this advancement has resulted in more fluent and coherent Natural Language Generation, which has contributed to improved development in downstream tasks such as abstractive summarization. Despite the recent progress in LLM, hallucination has become a serious problem in NLG. Hallucination happens when language models generate nonsensical or unfaithful text, which will lead to severe problems with reliability and effectiveness. In this paper, we propose a novel approach called Controllable Generative Summarization via Multimodal Prompt (CGSMP), which uses entities extracted from content and images as multimodal prompt control signals, thereby reducing hallucination issues. Specifically, the proposed CGSMP consists of three main modules: (1) an image prefix module that obtains image representations; (2) a prompt encoder module that fusion entities and images as multimodal prompts; and (3) a pre-Trained causal language model that fuses input and controllable prompt and serves as the backbone of the language model. Experimental results demonstrate that the proposed method significantly improves the quality of generated summaries compared to the state of the arts.  © 2023 ACM.},
	author_keywords = {controllable; hallucination; llm; multimodal; summarization},
	keywords = {Arts computing; Image representation; Natural language processing systems; Controllable; Down-stream; Fluents; Hallucination; Language model; Llm; Multi-modal; Natural language generation; Recent progress; Summarization; Computational linguistics},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070283-9},
	language = {English},
	abbrev_source_title = {LGM3A - Proc. Workshop Large Gener. Models Meet Multimodal Appl., Co-located: MM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kaarre20235190,
	author = {Kaarre, Janina and Feldt, Robert and Keeling, Laura E. and Dadoo, Sahil and Zsidai, Bálint and Hughes, Jonathan D. and Samuelsson, Kristian and Musahl, Volker},
	title = {Exploring the potential of ChatGPT as a supplementary tool for providing orthopaedic information},
	year = {2023},
	journal = {Knee Surgery, Sports Traumatology, Arthroscopy},
	volume = {31},
	number = {11},
	pages = {5190 – 5198},
	doi = {10.1007/s00167-023-07529-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167346281&doi=10.1007%2fs00167-023-07529-2&partnerID=40&md5=d9aeabe1ea6073e777fdd829be098049},
	affiliations = {Department of Orthopaedic Surgery, UPMC Freddie Fu Sports Medicine Center, University of Pittsburgh, Pittsburgh, United States; Department of Orthopaedics, Institute of Clinical Sciences, Sahlgrenska Academy, University of Gothenburg, Göteborgsvägen 31, Mölndal, 431 80, Sweden; Department of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, Sweden; Department of Orthopaedics, Sahlgrenska University Hospital, Mölndal, Sweden},
	abstract = {Purpose: To investigate the potential use of large language models (LLMs) in orthopaedics by presenting queries pertinent to anterior cruciate ligament (ACL) surgery to generative pre-trained transformer (ChatGPT, specifically using its GPT-4 model of March 14th 2023). Additionally, this study aimed to evaluate the depth of the LLM’s knowledge and investigate its adaptability to different user groups. It was hypothesized that the ChatGPT would be able to adapt to different target groups due to its strong language understanding and processing capabilities. Methods: ChatGPT was presented with 20 questions and response was requested for two distinct target audiences: patients and non-orthopaedic medical doctors. Two board-certified orthopaedic sports medicine surgeons and two expert orthopaedic sports medicine surgeons independently evaluated the responses generated by ChatGPT. Mean correctness, completeness, and adaptability to the target audiences (patients and non-orthopaedic medical doctors) were determined. A three-point response scale facilitated nuanced assessment. Results: ChatGPT exhibited fair accuracy, with average correctness scores of 1.69 and 1.66 (on a scale from 0, incorrect, 1, partially correct, to 2, correct) for patients and medical doctors, respectively. Three of the 20 questions (15.0%) were deemed incorrect by any of the four orthopaedic sports medicine surgeon assessors. Moreover, overall completeness was calculated to be 1.51 and 1.64 for patients and medical doctors, respectively, while overall adaptiveness was determined to be 1.75 and 1.73 for patients and doctors, respectively. Conclusion: Overall, ChatGPT was successful in generating correct responses in approximately 65% of the cases related to ACL surgery. The findings of this study imply that LLMs offer potential as a supplementary tool for acquiring orthopaedic knowledge. However, although ChatGPT can provide guidance and effectively adapt to diverse target audiences, it cannot supplant the expertise of orthopaedic sports medicine surgeons in diagnostic and treatment planning endeavours due to its limited understanding of orthopaedic domains and its potential for erroneous responses. Level of evidence: V. © 2023, The Author(s).},
	author_keywords = {ACL; Anterior cruciate ligament; Artificial intelligence; ChatGPT; Correctness; Large language models},
	keywords = {Anterior Cruciate Ligament; Humans; Language; Orthopedic Procedures; Orthopedic Surgeons; Orthopedics; adult; anterior cruciate ligament reconstruction; article; artificial intelligence; controlled study; female; human; language; major clinical study; male; physician; sports medicine; surgeon; treatment planning; anterior cruciate ligament; language; orthopedic surgeon; orthopedic surgery; orthopedics},
	correspondence_address = {J. Kaarre; Department of Orthopaedic Surgery, UPMC Freddie Fu Sports Medicine Center, University of Pittsburgh, Pittsburgh, United States; email: janina.kaarre@gu.se},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09422056},
	pmid = {37553552},
	language = {English},
	abbrev_source_title = {Knee Surg. Sports Traumatol. Arthroscopy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Han2023118,
	author = {Han, Yuzhang and Hou, Jing and Sun, Yi},
	title = {Research and Application of GPT-Based Large Language Models in Business and Economics: A Systematic Literature Review in Progress},
	year = {2023},
	journal = {2023 IEEE International Conference on Computing, ICOCO 2023},
	pages = {118 – 123},
	doi = {10.1109/ICOCO59262.2023.10397642},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184849676&doi=10.1109%2fICOCO59262.2023.10397642&partnerID=40&md5=00a33771b0b943f825eac57417d48c55},
	affiliations = {College of Business Administration, California State University San Marcos, San Marcos, United States; College of Science Technology, Engineering and Mathematics, California State University San Marcos, San Marcos, United States},
	abstract = {Represented by ChatGPT and GPT-4, Large Language Models (LLM) based on the Generative Pre-trained Transformer (GPT) have revolutionized the capability of Artificial Intelligence (AI) in natural language processing. In the fields of business and economics, large amounts of research and applications of GPT-based LLMs have been developed and published to automate tasks that mandate advanced human-machine interaction. Nevertheless, there has not been a systematic literature review on GPT-based LLMs in business and economics. To fill this gap, we present our in-progress literature review in this paper focusing on these two related fields. This paper analyzed 30 published research articles and delineated the trends in research, application, prompt engineering and ethical considerations. Our goal is to provide a research framework as well as an application guideline for the fast-growing audience of GPT and LLMs in business and economics. Results of the literature review indicate that many studies are: (1) engaged in creating new applications of GPT-LLM; (2) empirical-qualitative research based on evidenced-oriented data sources; (3) applying diverse methods of prompt engineering; (4) concerned about ethical challenges of GPT-based LLMs. © 2023 IEEE.},
	author_keywords = {business; ChatGPT; economics; Generative Pre-trained Transformer (GPT); Large Language Model (LLM); systematic literature review},
	keywords = {Economics; Ethical technology; Natural language processing systems; Business and economics; ChatGPT; Generative pre-trained transformer; Language model; Large language model; Literature reviews; Model-based OPC; Natural languages; Research and application; Systematic literature review; Computational linguistics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172813946-3},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Comput., ICOCO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Dencik202330,
	author = {Dencik, Jacob and Goehring, Brian and Marshall, Anthony},
	title = {Managing the emerging role of generative AI in next-generation business},
	year = {2023},
	journal = {Strategy and Leadership},
	volume = {51},
	number = {6},
	pages = {30 – 36},
	doi = {10.1108/SL-08-2023-0079},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168859765&doi=10.1108%2fSL-08-2023-0079&partnerID=40&md5=5c2c8563244389fa3db355a1b40efa55},
	affiliations = {IBM Institute for Business Value (IBV), Belgium; IBM IBV, Belgium},
	abstract = {Purpose: Since the release of ChatGPT by OpenAI in November 2022 – with its ability to create compelling, relevant content, new large language model (LLM) technology – business leaders, especially CEOs, are being pressured to accelerate new generative AI investments. IBM IBV surveyed executives to assess their progress and concerns and their adoption strategies. Design/methodology/approach: Adoption of generative AI is still in its very early stages. Most organizations are only beginning to figure out how and where to make use of it. In fact, as few as 6 percent of executives in new surveying conducted by the IBM Institute for Business Value say they are operating generative AI in their enterprise today. Findings: In contrast to many peoples’ expectations about AI, automating tasks is not the top priority for executives looking to tap generative AI to grow business value. Looking at benefits by function, research and innovation is the primary area where organizations see opportunities for generative AI. Practical implications: IBM IBV's recent survey of executives found that the key barriers to the effective deployment and use of generative AI are linked to security, privacy, ethics, regulations and economics – not access to the underlying technology itself. Originality/value: Organizations will have to evaluate where in their enterprise the potential gains and cost efficiencies outweigh the risks of possible errors or unintended consequences from the use of generative AI along with broader ethical considerations. Ecosystems expand generative AI opportunities to harness data, insights and technology capabilities from across partners and stakeholders while enabling control over the capabilities that are most central to an organization’s value proposition. © 2023, Emerald Publishing Limited.},
	author_keywords = {Ecosystems; Generative AI; Key barriers; Opportunities and risks; Standards},
	correspondence_address = {A. Marshall; IBM IBV, Belgium; email: anthony2@us.ibm.com},
	publisher = {Emerald Publishing},
	issn = {10878572},
	language = {English},
	abbrev_source_title = {Strategy Leadersh.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Guleria20231292,
	author = {Guleria, Ankita and Krishan, Kewal and Sharma, Vishal and Kanchan, Tanuj},
	title = {ChatGPT: ethical concerns and challenges in academics and research},
	year = {2023},
	journal = {Journal of Infection in Developing Countries},
	volume = {17},
	number = {9},
	pages = {1292 – 1299},
	doi = {10.3855/jidc.18738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174233915&doi=10.3855%2fjidc.18738&partnerID=40&md5=0f14c5ffe000c5e2808759c9ccaa9173},
	affiliations = {Department of Anthropology, Panjab University, Sector-14, Chandigarh, India; Institute of Forensic Science and Criminology, Panjab University, Sector-14, Chandigarh, India; Department of Forensic Medicine and Toxicology, All India Institute of Medical Sciences, Jodhpur, India},
	abstract = {Introduction: The emergence of artificial intelligence (AI) has presented several opportunities to ease human work. AI applications are available for almost every domain of life. A new technology, Chat Generative Pre-Trained Transformer (ChatGPT), was introduced by OpenAI in November 2022, and has become a topic of discussion across the world. ChatGPT-3 has brought many opportunities, as well as ethical and privacy considerations. ChatGPT is a large language model (LLM) which has been trained on the events that happened until 2021. The use of AI and its assisted technologies in scientific writing is against research and publication ethics. Therefore, policies and guidelines need to be developed over the use of such tools in scientific writing. The main objective of the present study was to highlight the use of AI and AI assisted technologies such as the ChatGPT and other chatbots in the scientific writing and in the research domain resulting in bias, spread of inaccurate information and plagiarism. Methodology: Experiments were designed to test the accuracy of ChatGPT when used in research and academic writing. Results: The information provided by ChatGPT was inaccurate and may have far-reaching implications in the field of medical science and engineering. Critical thinking should be encouraged among researchers to raise awareness about the associated privacy and ethical risks. Conclusions: Regulations for ethical and privacy concerns related to the use of ChatGPT in academics and research need to be developed. Copyright © 2023 Guleria et al.},
	author_keywords = {artificial intelligence; chatbot; ChatGPT; Open AI; privacy concerns; publication ethics},
	keywords = {Artificial Intelligence; Humans; Organizations; article; artificial intelligence; awareness; ChatGPT; critical thinking; ethics; human; human experiment; plagiarism; practice guideline; privacy; writing; organization},
	correspondence_address = {K. Krishan; Department of Anthropology, (UGC Centre of Advanced Study), Panjab University, Sector-14, Chandigarh, India; email: kewalkrishan@pu.ac.in},
	publisher = {Journal of Infection in Developing Countries},
	issn = {20366590},
	pmid = {37824352},
	language = {English},
	abbrev_source_title = {J. Infect. Dev. Ctries.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Li20231348,
	author = {Li, Lei and Zhang, Yongfeng and Chen, Li},
	title = {Prompt Distillation for Efficient LLM-based Recommendation},
	year = {2023},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {1348 – 1357},
	doi = {10.1145/3583780.3615017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172440036&doi=10.1145%2f3583780.3615017&partnerID=40&md5=31b86e0af2993eb7f89b0b928736a490},
	affiliations = {Hong Kong Baptist University, Hong Kong, Hong Kong; Rutgers University, New Brunswick, United States},
	abstract = {Large language models (LLM) have manifested unparalleled modeling capability on various tasks, e.g., multi-step reasoning, but the input to these models is mostly limited to plain text, which could be very long and contain noisy information. Long text could take long time to process, and thus may not be efficient enough for recommender systems that require immediate response. In LLM-based recommendation models, user and item IDs are usually filled in a template (i.e., discrete prompt) to allow the models to understand a given task, but the models usually need extensive fine-tuning to bridge the user/item IDs and the template words and to unleash the power of LLM for recommendation. To address the problems, we propose to distill the discrete prompt for a specific task to a set of continuous prompt vectors so as to bridge IDs and words and to reduce the inference time. We also design a training strategy with an attempt to improve the efficiency of training these models. Experimental results on three real-world datasets demonstrate the effectiveness of our PrOmpt Distillation (POD) approach on both sequential recommendation and top-N recommendation tasks. Although the training efficiency can be significantly improved, the improvement of inference efficiency is limited. This finding may inspire researchers in the community to further improve the inference efficiency of LLM-based recommendation models. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0124-5/23/10...$15.00.},
	author_keywords = {Explainable Recommendation; Generative Recommendation; Large Language Models; Prompt Distillation; Recommender Systems; Sequential Recommendation; Top-N Recommendation},
	keywords = {Computational linguistics; Distillation; Efficiency; Modeling languages; Explainable recommendation; Generative recommendation; Inference efficiency; Language model; Large language model; Model-based OPC; Modelling capabilities; Prompt distillation; Sequential recommendation; Top-N recommendation; Recommender systems},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070124-5},
	language = {English},
	abbrev_source_title = {Int Conf Inf Knowledge Manage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Angert2023,
	author = {Angert, Tyler and Suzara, Miroslav and Han, Jenny and Pondoc, Christopher and Subramonyam, Hariharan},
	title = {Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts},
	year = {2023},
	journal = {UIST 2023 - Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
	doi = {10.1145/3586183.3606719},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174000971&doi=10.1145%2f3586183.3606719&partnerID=40&md5=64181e21a86f07a40cbeae9c31e8e0df},
	affiliations = {Replit, Inc., San Francisco, United States; Stanford University, Stanford, United States},
	abstract = {Creative coding tasks are often exploratory in nature. When producing digital artwork, artists usually begin with a high-level semantic construct such as a "stained glass filter"and programmatically implement it by varying code parameters such as shape, color, lines, and opacity to produce visually appealing results. Based on interviews with artists, it can be effortful to translate semantic constructs to program syntax, and current programming tools don't lend well to rapid creative exploration. To address these challenges, we introduce Spellburst, a large language model (LLM) powered creative-coding environment. Spellburst provides (1) a node-based interface that allows artists to create generative art and explore variations through branching and merging operations, (2) expressive prompt-based interactions to engage in semantic programming, and (3) dynamic prompt-driven interfaces and direct code editing to seamlessly switch between semantic and syntactic exploration. Our evaluation with artists demonstrates Spellburst's potential to enhance creative coding practices and inform the design of computational creativity tools that bridge semantic and syntactic spaces.  © 2023 ACM.},
	author_keywords = {creative coding; exploratory programming; generative art; large language models; prompt engineering},
	keywords = {Computational linguistics; Syntactics; Creative coding; Creatives; Exploratory programming; Generative art; High level semantics; Language model; Large language model; Natural languages; Node-based; Prompt engineering; Semantics},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070132-0},
	language = {English},
	abbrev_source_title = {UIST - Proc. Annu. ACM Symp. User Interface Softw. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Petridis2023,
	author = {Petridis, Savvas and Terry, Michael and Cai, Carrie Jun},
	title = {PromptInfuser: Bringing User Interface Mock-ups to Life with Large Language Models},
	year = {2023},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3544549.3585628},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158096486&doi=10.1145%2f3544549.3585628&partnerID=40&md5=f6633a7d7e4890134681e799850b2550},
	affiliations = {Google Research, New York, NY, United States; Google Research, Cambridge, MA, United States; Google Research, Mountain View, CA, United States},
	abstract = {Large Language Models have enabled novices without machine learning (ML) experience to quickly prototype ML functionalities with prompt programming. This paper investigates incorporating prompt-based prototyping into designing functional user interface (UI) mock-ups. To understand how infusing LLM prompts into UI mock-ups might affect the prototyping process, we conduct a exploratory study with five designers, and find that this capability might significantly speed up creating functional prototypes, inform designers earlier on how their designs will integrate ML, and enable user studies with functional prototypes earlier. From these findings, we built PromptInfuser, a Figma plugin for authoring LLM-infused mock-ups. PromptInfuser introduces two novel LLM-interactions: input-output, which makes content interactive and dynamic, and frame-change, which directs users to different frames depending on their natural language input. From initial observations, we find that PromptInfuser has the potential to transform the design process by tightly integrating UI and AI prototyping in a single interface. © 2023 Owner/Author.},
	author_keywords = {Design; Generative AI; Large Language Models; Prototyping},
	keywords = {Computational linguistics; Design; Mockups; Exploratory studies; Functional Prototypes; Generative AI; Language model; Large language model; Learning experiences; Machine-learning; Prototype machine; Prototyping; Prototyping process; User interfaces},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039422-2},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2023374,
	author = {Li, Yinheng and Wang, Shaofei and Ding, Han and Chen, Hang},
	title = {Large Language Models in Finance: A Survey},
	year = {2023},
	journal = {ICAIF 2023 -  4th ACM International Conference on AI in Finance},
	pages = {374 – 382},
	doi = {10.1145/3604237.3626869},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179853539&doi=10.1145%2f3604237.3626869&partnerID=40&md5=ee2b728c8b9fe0013974da302d3afc8a},
	affiliations = {Columbia University, New York, NY, United States; New York University, New York, NY, United States},
	abstract = {Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI. © 2023 Owner/Author.},
	author_keywords = {Finance; Generative AI; Large Language Models; Natural Language Processing},
	keywords = {Computational linguistics; Deep learning; Natural language processing systems; Zero-shot learning; 'current; Domain specific; Fine tuning; Generative AI; Language model; Language processing; Large language model; Natural language processing; Natural languages; Performance; Investments},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070240-2},
	language = {English},
	abbrev_source_title = {ICAIF - ACM Int. Conf. AI Financ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tikayat Ray2023,
	author = {Tikayat Ray, Archana and Bhat, Anirudh Prabhakara and White, Ryan T. and Nguyen, Van Minh and Pinon Fischer, Olivia J. and Mavris, Dimitri N.},
	title = {Examining the Potential of Generative Language Models for Aviation Safety Analysis: Case Study and Insights Using the Aviation Safety Reporting System (ASRS)},
	year = {2023},
	journal = {Aerospace},
	volume = {10},
	number = {9},
	doi = {10.3390/aerospace10090770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172146359&doi=10.3390%2faerospace10090770&partnerID=40&md5=26f4d35cbdc8683c3552fe4d1a514ba4},
	affiliations = {Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, GA, United States; AI Fusion Technologies, Toronto, M5V 3Z5, ON, Canada; NEural TransmissionS Lab, Department of Mathematics and Systems Engineering, Florida Institute of Technology, Melbourne, 32901, FL, United States},
	abstract = {This research investigates the potential application of generative language models, especially ChatGPT, in aviation safety analysis as a means to enhance the efficiency of safety analyses and accelerate the time it takes to process incident reports. In particular, ChatGPT was leveraged to generate incident synopses from narratives, which were subsequently compared with ground-truth synopses from the Aviation Safety Reporting System (ASRS) dataset. The comparison was facilitated by using embeddings from Large Language Models (LLMs), with aeroBERT demonstrating the highest similarity due to its aerospace-specific fine-tuning. A positive correlation was observed between the synopsis length and its cosine similarity. In a subsequent phase, human factors issues involved in incidents, as identified by ChatGPT, were compared to human factors issues identified by safety analysts. The precision was found to be 0.61, with ChatGPT demonstrating a cautious approach toward attributing human factors issues. Finally, the model was utilized to execute an evaluation of accountability. As no dedicated ground-truth column existed for this task, a manual evaluation was conducted to compare the quality of outputs provided by ChatGPT to the ground truths provided by safety analysts. This study discusses the advantages and pitfalls of generative language models in the context of aviation safety analysis and proposes a human-in-the-loop system to ensure responsible and effective utilization of such models, leading to continuous improvement and fostering a collaborative approach in the aviation safety domain. © 2023 by the authors.},
	author_keywords = {aeroBERT; ASRS; aviation safety; Aviation Safety Reporting System; BERT; ChatGPT; generative language models; GPT-3.5; human factors; InstructGPT; large language models; LLM; NLP; prompt engineering},
	correspondence_address = {A. Tikayat Ray; Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, United States; email: archanatikayatray@gmail.com; O.J. Pinon Fischer; Aerospace Systems Design Laboratory, School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, 30332, United States; email: olivia.pinon@asdl.gatech.edu},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {22264310},
	language = {English},
	abbrev_source_title = {Aerosp.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Esiobu20233764,
	author = {Esiobu, David and Tan, Xiaoqing and Hosseini, Saghar and Ung, Megan and Zhang, Yuchen and Fernandes, Jude and Dwivedi-Yu, Jane and Presani, Eleonora and Williams, Adina and Smith, Eric Michael},
	title = {ROBBIE: Robust Bias Evaluation of Large Generative Language Models},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {3764 – 3814},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184812073&partnerID=40&md5=77f1379ac069a7708099eea35f2f98a0},
	affiliations = {Meta, United States},
	abstract = {As generative large language models (LLMs) grow more performant and prevalent, we must develop comprehensive enough tools to measure and improve their fairness. Different prompt-based datasets can be used to measure social bias across multiple text domains and demographic axes, meaning that testing LLMs on more datasets can potentially help us characterize their biases more fully, and better ensure equal and equitable treatment of marginalized demographic groups. In this work, our focus is two-fold: Benchmarking: a comparison of 6 different prompt-based bias and toxicity metrics across 12 demographic axes and 5 families of generative LLMs. Out of those 6 metrics, AdvPromptSet and HolisticBiasR are novel datasets proposed in the paper. The comparison of those benchmarks gives us insights about the bias and toxicity of the compared models. Therefore, we explore the frequency of demographic terms in common LLM pre-training corpora and how this may relate to model biases. Mitigation: we conduct a comprehensive study of how well 3 bias/toxicity mitigation techniques perform across our suite of measurements. ROBBIE aims to provide insights for practitioners while deploying a model, emphasizing the need to not only measure potential harms, but also understand how they arise by characterizing the data, mitigate harms once found, and balance any trade-offs. We open-source our analysis code in hopes of encouraging broader measurements of bias in future LLMs. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Economic and social effects; Open source software; Open systems; Toxicity; Demographic groups; Language model; Measurements of; Mitigation techniques; Model bias; Open-source; Potential harm; Pre-training; Trade off; Training corpus; Population statistics},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Shriram2023,
	author = {Shriram, Jaidev and Sreekala, Sanjayan},
	title = {ZINify: Transforming Research Papers into Engaging Zines with Large Language Models},
	year = {2023},
	journal = {UIST 2023 Adjunct - Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
	doi = {10.1145/3586182.3625118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178303594&doi=10.1145%2f3586182.3625118&partnerID=40&md5=e36c82bb36328112ed71da32960d09d3},
	affiliations = {University of California, San Diego, San Diego, CA, United States},
	abstract = {Research papers are a vital building block for scientific discussion. While these papers follow effective structures for the relevant community, they are unable to cater to novice readers and express otherwise creative ideas in creative mediums. To this end, we propose ZINify, the first approach to automatically transform research papers into engaging zines using large language models (LLM) and text-to-image generators. Following zine's long history of supporting independent, creative expression, we propose a technique that can work with authors to build more engaging, marketable, and unconventional content that is based on their research. We believe that our work will help make research more engaging and accessible to all while helping papers stand out in crowded online venues. © 2023 Owner/Author.},
	author_keywords = {Generative Art; Information Extraction; Large Language Models; Summarization; Text-to-Image Generation; Zines},
	keywords = {Computational linguistics; Creatives; Generative art; Image generations; Information extraction; Language model; Large language model; Research papers; Summarization; Text-to-image generation; Zines; Paper},
	correspondence_address = {J. Shriram; University of California, San Diego, San Diego, United States; email: jkariyatt@ucsd.edu; S. Sreekala; University of California, San Diego, San Diego, United States; email: sps223@ucsd.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070096-5},
	language = {English},
	abbrev_source_title = {UIST Adjun. - Adjun. Proc. Annu. ACM Symp. User Interface Softw. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tzachor2023941,
	author = {Tzachor, A. and Devare, M. and Richards, C. and Pypers, P. and Ghosh, A. and Koo, J. and Johal, S. and King, B.},
	title = {Large language models and agricultural extension services},
	year = {2023},
	journal = {Nature Food},
	volume = {4},
	number = {11},
	pages = {941 – 948},
	doi = {10.1038/s43016-023-00867-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175949873&doi=10.1038%2fs43016-023-00867-x&partnerID=40&md5=f86af7ea9c0d051bd769475d9b1efdb7},
	affiliations = {CSER, University of Cambridge, Cambridge, United Kingdom; School of Sustainability, Reichman University, Herzliya, Israel; International Institute of Tropical Agriculture (IITA), CGIAR, Ibadan, Nigeria; Department of Engineering, University of Cambridge, Cambridge, United Kingdom; International Center for Tropical Agriculture (CIAT), CGIAR, Nairobi, Kenya; International Food Policy Research Institute (IFPRI), CGIAR, Washington, DC, United States; Agstack Project, Linux Foundation, San Francisco, CA, United States; Digital and Data Innovation Accelerator, CGIAR, Palmira, Colombia},
	abstract = {Several factors have traditionally hampered the effectiveness of agricultural extension services, including limited institutional capacity and reach. Here we assess the potential of large language models (LLMs), specifically Generative Pre-trained Transformer (GPT), to transform agricultural extension. We focus on the ability of LLMs to simplify scientific knowledge and provide personalized, location-specific and data-driven agricultural recommendations. We emphasize shortcomings of this technology, informed by real-life testing of GPT to generate technical advice for Nigerian cassava farmers. To ensure a safe and responsible dissemination of LLM functionality across farming worldwide, we propose an idealized LLM design process with human experts in the loop. © 2023, Springer Nature Limited.},
	keywords = {Agriculture; Black People; Farms; Humans; Language; Technology; agricultural worker; article; cassava; generative pretrained transformer; human; human experiment; nonhuman; agriculture; Black person; language; technology},
	correspondence_address = {A. Tzachor; CSER, University of Cambridge, Cambridge, United Kingdom; email: atzachor@runi.ac.il},
	publisher = {Springer Nature},
	issn = {26621355},
	pmid = {37932438},
	language = {English},
	abbrev_source_title = {Nat. Food.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mohapatra2023413,
	author = {Mohapatra, Devi Prasad and Thiruvoth, Friji Meethale and Tripathy, Satyaswarup and Rajan, Sheeja and Vathulya, Madhubari and Lakshmi, Palukuri and Singh, Veena K. and Haq, Ansar Ul},
	title = {Leveraging Large Language Models (LLM) for the Plastic Surgery Resident Training: Do They Have a Role?},
	year = {2023},
	journal = {Indian Journal of Plastic Surgery},
	volume = {56},
	number = {5},
	pages = {413 – 420},
	doi = {10.1055/s-0043-1772704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178156684&doi=10.1055%2fs-0043-1772704&partnerID=40&md5=085fd8d2c31ca5dc8dd3e230a276f17c},
	affiliations = {Department of Plastic Surgery, Jawaharlal Institute of Postgraduate Medical Education and Research (JIPMER), Pondicherry, India; Department of Plastic Surgery, Post Graduate Institute of Medical Education and Research, Chandigarh, India; Department of Plastic Surgery, Government Medical College, Kerala, Thrissur, India; Department of Burns and Plastic Surgery, All India Institute of Medical Sciences (AIIMS), Uttarakhand, Rishikesh, India; Department of Plastic Surgery, Osmania General Hospital, Telangana, Hyderabad, India; Department of Burns and Plastic Surgery, All India Institute of Medical Sciences (AIIMS), Bihar, Patna, India},
	abstract = {Introduction Large language models (LLMs) are designed for recognizing, summarizing, translating, predicting, and generating text-based content from knowledge gained from extensive data sets. ChatGPT4 (Generative Pre-trained Transformer 4) (OpenAI, San Francisco, California, United States) is a transformer-based LLM model pretrained on public data as well as data obtained from third-party sources using deep learning techniques of fine tuning and reinforcement learning from human feedback to predict the next text. We wanted to explore the role of LLM as a teaching assistant (TA) in plastic surgery. Material and Methods TA roles were first identified in available literature, and based on the roles, a list of suitable tasks was created where LLM could be used to perform the task. Prompts designed to be fed in to the LLM (specifically ChatGPT) to generate appropriate output, were then created and fed to the ChatGPT model. The outputs generated were scored by evaluators and compared for interobserver agreement. Results A final set of eight TA roles were identified where a LLM could be utilized to generate content. These contents were scored for usefulness and accuracy. These were scored independently by the eight study authors in a scoring sheet created for the study. Interobserver agreements for content accuracy, usefulness, and clarity were 100% for content generated for the following: interactive case studies (generation), simulation of preoperative consultations, and generation of ethical considerations. Discussion LLMs in general and ChatGPT (on which this study is based) in specific, can generate answers to questions and prompts based on huge amount of text fed into the model for training the underlying language model. The answers generated have been found to be accurate, readable, and even indistinguishable from human-generated text. This capability of automated content synthesis can be exploited to generate summaries to text, answer short and long answers, and generate case scenarios. We could identify a few such scenarios where the LLM could in general be utilized to play the role of a TA and aid plastic surgery residents in particular. In addition, these models could also be used by students to obtain feedback and gain reflection which itself stimulates critical thinking. Conclusion Incorporating LLMs into the educational arsenal of plastic surgery residency programs can provide a dynamic, interactive, and individualized learning experience for residents and prove to be worthy TAs of future. © 2023 Georg Thieme Verlag. All rights reserved.},
	author_keywords = {ChatGPT in education; educational technology; future of surgical training; large language models (LLM); plastic surgical education},
	correspondence_address = {D.P. Mohapatra; Department of Plastic Surgery, Superspeciality Block, Jawaharlal Institute of Postgraduate Medical Education and Research (JIPMER), Pondicherry, 605006, India; email: devimohapatra1@gmail.com},
	publisher = {Georg Thieme Verlag},
	issn = {09700358},
	language = {English},
	abbrev_source_title = {Indian J. Plast. Surg.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sun2023425,
	author = {Sun, Yuqian and Li, Zhouyi and Fang, Ke and Lee, Chang Hee and Asadipour, Ali},
	title = {Language as Reality: A Co-creative Storytelling Game Experience in 1001 Nights Using Generative AI},
	year = {2023},
	journal = {Proceedings - AAAI Artificial Intelligence and Interactive Digital Entertainment Conference, AIIDE},
	volume = {19},
	number = {1},
	pages = {425 – 434},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175400006&partnerID=40&md5=f971f69d88e63d98469e6a6d3c310d6b},
	affiliations = {Computer Science Research Centre, Royal College of Art, London, United Kingdom; Tsinghua University, Shenzhen, China; Affective System and Cognition Lab, KAIST, Daejeon, South Korea; Ada Eden},
	abstract = {Generative AI (GenAI), encompassing image generation and large language models (LLMs), has opened new avenues for gameplay experiences. This paper introduces “1001 Nights”, a narrative game centered on GenAI. Drawing inspiration from Wittgenstein’s note, “The limits of my language mean the limits of my world”, the game exemplifies the concept of language as reality. The protagonist, Shahrzad, possesses a unique power: specific keywords, such as “sword” or “shield”, when spoken by others in tales, materialize as tangible weapons, serving as battle equipment against the King. Players guide the LLM-driven King in co-creating narratives, with GPT-4 employing LLM reasoning methods to ensure story consistency. As these narratives progress, the depicted world is dynamically generated and visualized through Stable Diffusion, blurring the boundaries between narrative and in-game reality. This fusion of interactive storytelling combines gameplay paradigms and story together with dynamic content generation. Players not only aim to alter Shahrzad’s fate from the original folklore, but also leverage the power of natural language to shape the game’s world. With this example, we propose the term “AI-Native games” to categorize innovative games where GenAI is fundamental to the game’s novel mechanics and very existence. Copyright © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Creatives; Game experience; Gameplay experiences; Image generations; Interactive storytelling; Language model; Model reasonings; Model-driven; Power; Reasoning methods; Artificial intelligence},
	editor = {Eger M. and Cardona-Rivera R.E.},
	publisher = {Association for the Advancement of Artificial Intelligence},
	issn = {2326909X},
	isbn = {157735883X; 978-157735883-1},
	language = {English},
	abbrev_source_title = {Proc. AAAI Conf. Artif. Intell. Interact. Digit. Entertain., AIIDE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hua2023195,
	author = {Hua, Wenyue and Xu, Shuyuan and Ge, Yingqiang and Zhang, Yongfeng},
	title = {How to Index Item IDs for Recommendation Foundation Models},
	year = {2023},
	journal = {SIGIR-AP 2023 - Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
	pages = {195 – 204},
	doi = {10.1145/3624918.3625339},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175967714&doi=10.1145%2f3624918.3625339&partnerID=40&md5=aad24b0fb64b34e4c9e475d834e552ed},
	affiliations = {Rutgers University, United States},
	abstract = {Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item as in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text and hallucinated recommendations when deciding which item(s) to recommend, creating LLM-compatible item IDs to uniquely identify each item is essential for recommendation foundation models. In this study, we systematically examine the item ID creation and indexing problem for recommendation foundation models, using P5 as an example of the backbone LLM. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as random indexing, title indexing, and independent indexing. We then propose four simple yet effective solutions, including sequential indexing, collaborative indexing, semantic (content-based) indexing, and hybrid indexing. Our study highlights the significant influence of item indexing methods on the performance of LLM-based recommendation, and our results on real-world datasets validate the effectiveness of our proposed solutions. The research also demonstrates how recent advances on language modeling and traditional IR principles such as indexing can help each other for better learning and inference. Source code and data are available at https://github.com/Wenyueh/LLM-RecSys-ID.  © 2023 ACM.},
	author_keywords = {Item ID and Indexing; Large Language Model; Recommendation},
	keywords = {Computational linguistics; Foundations; Indexing (of information); Modeling languages; Natural language processing systems; Semantics; Foundation models; Indexing methods; Item ID and indexing; Language model; Large language model; Multi-stages; Natural languages; Random indexing; Recommendation; Single stage; Recommender systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070408-6},
	language = {English},
	abbrev_source_title = {SIGIR-AP - Annu. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr. Asia Pac. Reg.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Liu202310,
	author = {Liu, Sijie and Fang, Yiquan and Cheng, Hua and Pan, Yiming and Liu, Yufei and Gao, Caiting},
	title = {Large Language Models guided Generative Prompt for Dialogue Generation},
	year = {2023},
	journal = {Proceedings - 2023 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery, CyberC 2023},
	pages = {10 – 17},
	doi = {10.1109/CyberC58899.2023.00013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186755286&doi=10.1109%2fCyberC58899.2023.00013&partnerID=40&md5=98bf986cfa3a092bd2855494eb6257af},
	affiliations = {East China University of Science and Technology, School of Information Science and Engineering, Shanghai, China},
	abstract = {The applications of large language models (LLMs) such as ChatGPT exhibit impressive comprehension and generative capabilities in dialogue task. LLMs require massive high-quality data and computational cost, which limits their application to low-resource tasks. Dialogue generation when using smaller language models like GPT-2 encounters difficulties in maintaining context consistency. To address the problem of dialogue generation under resource constraints, we propose an LLM-guided Generative Prompt method (LGP). LGP enhances the relevance and coherence of generated dialogues through a smaller model GPT-2 and generative prompt (GP). GP is produced by the proposed Prompt Network, which leverages prompt encoder to learn dialogue history features and utilizes LSTM to extract contextual temporal features. Therefore, GP shown as the simple fixed-length learnable embeddings can replace the original complex and redundant context in GPT-2. The few-shot training of GP is guided by the LLM's responses, which facilitates GPT-2 in generating more contextually consistent and comprehensive responses. Experiments on the DailyDialog and MultiWOZ datasets show that LGP achieves high improvements in BLEU, NIST, METEOR and ROUGE-L metrics. Remarkably, LGP achieves these results with approximately 18% of the training data, surpassing other full-data-finetuning methods in automatic evaluation metrics.  © 2023 IEEE.},
	author_keywords = {dialogue generation; few-shot; large language models; prompt learning},
	keywords = {Computational linguistics; Computer vision; Computational costs; Data costs; Dialogue generations; Few-shot; High quality data; Language model; Large language model; Learn+; Prompt learning; Resource Constraint; Long short-term memory},
	correspondence_address = {Y. Fang; East China University of Science and Technology, School of Information Science and Engineering, Shanghai, China; email: fyq@ecust.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030869-3},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Cyber-Enabled Distrib. Comput. Knowl. Discov., CyberC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Patton2023553,
	author = {Patton, Desmond Upton and Landau, Aviv Y. and Mathiyazhagan, Siva},
	title = {ChatGPT for Social Work Science: Ethical Challenges and Opportunities},
	year = {2023},
	journal = {Journal of the Society for Social Work and Research},
	volume = {14},
	number = {3},
	pages = {553 – 562},
	doi = {10.1086/726042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174781394&doi=10.1086%2f726042&partnerID=40&md5=b0f45688c75636c0c462e1c7ec05e3ed},
	affiliations = {University of Pennsylvania School of Social Policy and Practice, Annenberg School for Communication, Department of Psychiatry, United States},
	abstract = {In this invited paper, we describe the potential use of ChatGPT in social work science, exploring opportunities and ethical challenges related to the deployment of large language models (LLM), specifically ChatGPT, for social work science. We offer several preliminary recommendations for the ethical use of ChatGPT in social work science and call on the profession’s governing organizations to develop a comprehensive ethical framework for the use of LLMs such as ChatGPT in social work research. © 2023 Society for Social Work and Research. All rights reserved.},
	author_keywords = {ChatGPT; generative artificial intelligence; large language models; social work ethics; social work research},
	correspondence_address = {D.U. Patton; University of Pennsylvania School of Social Policy and Practice, Annenberg School for Communication, Department of Psychiatry, United States; email: dupatton@upenn.edu},
	publisher = {University of Chicago Press},
	issn = {23342315},
	language = {English},
	abbrev_source_title = {J. Soc. Soc. Work Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kamnis2023,
	author = {Kamnis, Spyros},
	title = {Generative pre-trained transformers (GPT) for surface engineering},
	year = {2023},
	journal = {Surface and Coatings Technology},
	volume = {466},
	doi = {10.1016/j.surfcoat.2023.129680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161333918&doi=10.1016%2fj.surfcoat.2023.129680&partnerID=40&md5=b06f0b21440221f5536c5c76bffc09dc},
	affiliations = {Castolin Eutectic-Monitor Coatings Ltd, Newcastle, NE29 8SE, United Kingdom},
	abstract = {The knowledge of scientific articles within Generative Pre-trained Transformers (GPT) is not exhaustive due to factors such as data coverage, freshness, complexity, paywalls, and context. While it can provide general information on scientific topics, it may struggle with specialized terminology, recent research, and nuanced understanding. As a result, relying on GPT as a scientific assistant tool may not be ideal. Instead, it is important to consult specialized resources and databases for a comprehensive understanding of specific scientific domains and access to the latest research. A custom data driven GPT can enhance its performance as a scientific assistant tool by improving domain knowledge, providing up-to-date information, reducing ambiguity and errors, performing customized tasks, and offering enhanced search capabilities. This work demonstrates and evaluates the use of such GPT models using a small selection of peer reviewed published thermal spray articles as the reference domain knowledge. The specific domain knowledge model works exceptionally well outperforming the general state-of-the-art large language models. © 2023 Elsevier B.V.},
	author_keywords = {Generative AI; GPT; Large language model; LLM; NLP; Thermal spray},
	keywords = {Computational linguistics; Domain Knowledge; Data coverage; Domain knowledge; Generative AI; Generative pre-trained transformer; Language model; Large language model; LLM; Scientific articles; Surface engineering; Thermalspray; Thermal Engineering},
	publisher = {Elsevier B.V.},
	issn = {02578972},
	language = {English},
	abbrev_source_title = {Surf. Coat. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Parida2023,
	author = {Parida, Shantipriya and Sekhar, Sambit and Panda, Subhadarshi and Jena, Swateek and Parida, Abhijeet and Sahoo, Soumendra Kumar and Dash, Satya Ranjan},
	title = {Olive: An Instruction Following LLaMA Model For Odia Language},
	year = {2023},
	journal = {Conference Proceedings - 2023 IEEE Silchar Subsection Conference, SILCON 2023},
	doi = {10.1109/SILCON59133.2023.10404195},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185726331&doi=10.1109%2fSILCON59133.2023.10404195&partnerID=40&md5=0b2d1eda0240d98b6fa4fcc248f0aa33},
	affiliations = {Silo Ai, Helsinki, Finland; Odia Generative Ai, Bhubaneswar, India; RightSense Inc, Bangalore, India; Odia Generative Ai, Washington, United States; Odia Generative Ai, Bangalore, India; Kiit University, Bhubaneswar, India},
	abstract = {The AI community is experiencing a profound impact from Large Language Models (LLMs), and the introduction of ChatGPT and GPT-4 is prompting a reconsideration of the potential of artificial general intelligence(AGI). However, most of the LLMs are trained in English and other high-resource languages, resulting in the unavailability of LLM and its related technologies and services for many low-resource languages. In India, where only 10% of the population is proficient in English, the need for LLM models adapted to regional languages becomes crucial.In this paper, we emphasized the need for LLM for the low-resource Odia language by evaluating the available LLM-supporting Odia language. We describe the development process of the instruction-tuning LLM model for Odia. The developed instruction tuning Odia LLM is available freely for research and non-commercial purposes. © 2023 IEEE.},
	author_keywords = {Fine-Tuning; Generative AI; LLM},
	keywords = {Artificial general intelligences; Community IS; Development process; Fine tuning; Generative AI; Language model; Large language model; Low resource languages},
	correspondence_address = {S. Parida; Silo Ai, Helsinki, Finland; email: shantipriya.parida@silo.ai},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031414-4},
	language = {English},
	abbrev_source_title = {Conf. Proc. - IEEE Silchar Subsect. Conf., SILCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Huo202311,
	author = {Huo, Siqing and Arabzadeh, Negar and Clarke, Charles},
	title = {Retrieving Supporting Evidence for Generative Question Answering},
	year = {2023},
	journal = {SIGIR-AP 2023 - Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
	pages = {11 – 20},
	doi = {10.1145/3624918.3625336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177796622&doi=10.1145%2f3624918.3625336&partnerID=40&md5=3511387a46448d4e3dd42c5021e852ad},
	affiliations = {University of Waterloo, Waterloo, ON, Canada},
	abstract = {Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer. In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately. We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence. The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material. With an accuracy of over 80%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided. However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process. While this verification process can reduce hallucinations, it can not entirely eliminate them.  © 2023 ACM.},
	keywords = {Natural language processing systems; 'current; External sources; Human levels; Language model; Natural languages; Open domain question answering; Performance; Question Answering; Simple++; Verification process; Query processing},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070408-6},
	language = {English},
	abbrev_source_title = {SIGIR-AP - Annu. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr. Asia Pac. Reg.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Pirttinen2023,
	author = {Pirttinen, Nea and Leinonen, Juho},
	title = {Could ChatGPT Be Used for Reviewing Learnersourced Exercises?},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3631802.3631845},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185534188&doi=10.1145%2f3631802.3631845&partnerID=40&md5=af95d34bcd604fa0acacdbdeb4d50a88},
	affiliations = {University of Helsinki, Helsinki, Finland; Aalto University, Espoo, Finland},
	abstract = {Large language models and tools based on large language models such as ChatGPT have received intense attention in the past year in computing education. In this work, we explore whether ChatGPT could be used to review learnersourced exercises. One of the major downsides of learnersourcing is the dubious quality of the created content, leading to many systems using peer review for curating the content. Our results suggest that ChatGPT is not yet ready for this task. © 2023 Copyright held by the owner/author(s).},
	author_keywords = {ChatGPT; crowdsourcing; generative AI; large language models; learnersourcing; LLMs; reviews},
	keywords = {Computational linguistics; ChatGPT; Computing education; Generative AI; Language model; Language tools; Large language model; Learnersourcing; LLM; Peer review; Crowdsourcing},
	publisher = {Association for Computing Machinery},
	isbn = {979-840071653-9},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ayre2023,
	author = {Ayre, Dennis and Dougherty, Carolyn and Zhao, Yitong},
	title = {IMPLEMENTATION OF AN ARTIFICIAL INTELLIGENCE (AI) INSTRUCTIONAL SUPPORT SYSTEM IN A VIRTUAL REALITY (VR) THERMAL-FLUIDS LABORATORY},
	year = {2023},
	journal = {ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)},
	volume = {8},
	doi = {10.1115/IMECE2023-112683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185393784&doi=10.1115%2fIMECE2023-112683&partnerID=40&md5=c2492592a016478a4b3591ff82a93be5},
	affiliations = {California State Polytechnic University Pomona, Pomona, CA, United States},
	abstract = {Physical laboratory experiments have long been the cornerstone of higher education, providing future engineers practical real-life experience invaluable to their careers. However, demand for laboratory time has exceeded physical capabilities. Virtual reality (VR) labs have proven to retain many benefits of attending physical labs while also providing significant advantages only available in a VR environment. Previously, our group had developed a pilot VR lab that replicated six (6) unique thermal-fluids lab experiments developed using the Unity game engine. One of the VR labs was tested in a thermal-fluid mechanics laboratory class with favorable results, but students highlighted the need for additional assistance within the VR simulation. In response to this testing, we have incorporated an artificial intelligence (AI) assistant to aid students within the VR environment by developing an interaction model. Utilizing the Generative Pre-trained Transformer 4 (GPT-4) large language model (LLM) and augmented context retrieval, the AI assistant can provide reliable instruction and troubleshoot errors while students conduct the lab procedure to provide an experience similar to a real-life lab assistant. The updated VR lab was tested in two laboratory classes and while the overall tone of student response to an AI-powered assistant was excitement and enthusiasm, observations and other recorded data show that students are currently unsure of how to utilize this new technology, which will help guide future refinement of AI components within the VR environment.  © 2023 by ASME.},
	author_keywords = {Artificial Intelligence; Engineering Education; Generative AI; GPT; Virtual Reality},
	keywords = {Artificial intelligence; E-learning; Education computing; Engineering education; Fluid mechanics; Laboratories; Professional aspects; Students; Generative ARTIFICIAL INTELLIGENCE; GPT; High educations; Instructional support; Laboratory class; Laboratory experiments; Physical laboratory; Support systems; Thermal fluids; Virtual-reality environment; Virtual reality},
	publisher = {American Society of Mechanical Engineers (ASME)},
	isbn = {978-079188765-3},
	language = {English},
	abbrev_source_title = {ASME Int Mech Eng Congress Expos Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Yamauchi2023,
	author = {Yamauchi, Yuta and Ino, Keiko and Zempo, Keiichi},
	title = {Auditory VR Generative System for Non-Experts to Reproduce Human Memories Through Natural Language Interactions},
	year = {2023},
	journal = {Proceedings - SIGGRAPH Asia 2023 Posters, SA 2023},
	doi = {10.1145/3610542.3626140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183575821&doi=10.1145%2f3610542.3626140&partnerID=40&md5=17d98ee14f5b239c06537ba3eea37011},
	affiliations = {College of Engineering Systems, University of Tsukuba, Tsukuba, Japan; National Institute of Mental Health, National Center of Neurology and Psychiatry, Kodaira, Japan; Institute of Systems and Information Engineering, University of Tsukuba, Tsukuba, Japan},
	abstract = {We propose an automatic auditory VR generative system based on natural language input and attempt to apply it to VR exposure therapy, a promising treatment for Post-Traumatic Stress Disorder (PTSD). The system consisted of the user interface, developed based on the Large Language Model (LLM), the auditory event dataset, which has metadata of “subject” and “verb” and spatial audio generator. © 2023 Copyright held by the owner/author(s).},
	keywords = {Interactive computer graphics; Large datasets; Virtual reality; Exposure therapy; Generative systems; Human memory; Language model; Natural language interaction; Natural languages; Posttraumatic stress disorder; Spatial audio; User interfaces},
	editor = {Spencer S.N.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070313-3},
	language = {English},
	abbrev_source_title = {Proc. - SIGGRAPH Asia Posters, SA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Goyal2023199,
	author = {Goyal, Nitesh and Hong, Sungsoo Ray and Mandryk, Regan L and Li, Toby Jia-Jun and Luther, Kurt and Wang, Dakuo},
	title = {SHAI 2023: Workshop on Designing for Safety in Human-AI Interactions},
	year = {2023},
	journal = {International Conference on Intelligent User Interfaces, Proceedings IUI},
	pages = {199 – 201},
	doi = {10.1145/3581754.3584169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151992963&doi=10.1145%2f3581754.3584169&partnerID=40&md5=3a69dba41524dafe2eb0327cd8821428},
	affiliations = {Google Research, United States; Information Sciences and Technology, George Mason University, United States; Department of Computer Science, University of Saskatchewan, Canada; Department of Computer Science and Engineering, University of Notre Dame, United States; Department of Computer Science, Virginia Tech, United States; Ibm Research, United States},
	abstract = {Generative ML models present a novel opportunity for a wider group of societal members to engage with AI, imagine new use cases, and applications with an increasing ability to disseminate the outcomes of such endeavors to larger audiences. However, owing to the novelty and despite best intentions, inadvertent outcomes might accrue leading to harms, especially to marginalized groups in society. As this field of Human AI Interaction advances, academic/industry researchers, and industry practitioners have an opportunity to brainstorm how to best utilize this new technology. Our workshop is aimed at such practitioners and researchers at the intersection of AI and HCI who are interested in collaboratively identifying challenges, and solutions to create safer outcomes with Generative ML models.  © 2023 Owner/Author.},
	author_keywords = {AI; Generative AI; Generative models; Harms; Human-AI interaction; LLM; ML; Responsible AI; Safety},
	keywords = {Accident prevention; Academic industry; Designing for safety; Generative AI; Generative model; Harm; Human-AI interaction; LLM; ML; Responsible AI; Software engineering},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070107-8},
	language = {English},
	abbrev_source_title = {Int Conf Intell User Interfaces Proc IUI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Rastogi2023913,
	author = {Rastogi, Charvi and Tulio Ribeiro, Marco and King, Nicholas and Nori, Harsha and Amershi, Saleema},
	title = {Supporting Human-AI Collaboration in Auditing LLMs with LLMs},
	year = {2023},
	journal = {AIES 2023 - Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {913 – 926},
	doi = {10.1145/3600211.3604712},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173629418&doi=10.1145%2f3600211.3604712&partnerID=40&md5=82372ca66a24d1439d29b25fa1318099},
	affiliations = {Carnegie Mellon University, United States; Msr Redmond, United States},
	abstract = {Large language models (LLMs) are increasingly becoming all-powerful and pervasive via deployment in sociotechnical systems. Yet these language models, be it for classification or generation, have been shown to be biased, behave irresponsibly, causing harm to people at scale. It is crucial to audit these language models rigorously before deployment. Existing auditing tools use either or both humans and AI to find failures. In this work, we draw upon literature in human-AI collaboration and sensemaking, and interview research experts in safe and fair AI, to build upon the auditing tool: AdaTest [36], which is powered by a generative LLM. Through the design process we highlight the importance of sensemaking and human-AI communication to leverage complementary strengths of humans and generative models in collaborative auditing. To evaluate the effectiveness of AdaTest++, the augmented tool, we conduct user studies with participants auditing two commercial language models: OpenAI's GPT-3 and Azure's sentiment analysis model. Qualitative analysis shows that AdaTest++ effectively leverages human strengths such as schematization, hypothesis testing. Further, with our tool, users identified a variety of failures modes, covering 26 different topics over 2 tasks, that have been shown in formal audits and also those previously under-reported.  © 2023 Owner/Author.},
	author_keywords = {auditing; biases; generative models; language models},
	keywords = {Computational linguistics; Auditing; Bias; Design-process; Generative model; Human modelling; Interview research; Language model; Sense making; Sociotechnical systems; Tool use; Sentiment analysis},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070231-0},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Maroteau2023,
	author = {Maroteau, Gaëlle and An, Jae-Sung and Murgier, Jérome and Hulet, Christophe and Ollivier, Matthieu and Ferreira, Alexandre},
	title = {Evaluation of the impact of large language learning models on articles submitted to Orthopaedics & Traumatology: Surgery & Research (OTSR): A significant increase in the use of artificial intelligence in 2023},
	year = {2023},
	journal = {Orthopaedics and Traumatology: Surgery and Research},
	volume = {109},
	number = {8},
	doi = {10.1016/j.otsr.2023.103720},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175331851&doi=10.1016%2fj.otsr.2023.103720&partnerID=40&md5=007dc3827bd878ae4888cc44b26d68f6},
	affiliations = {Unité Inserm Comète 1075, Department of Orthopaedics and Traumatology, Caen University Hospital, avenue Cote-de-Nacre, Caen, 14000, France; Tokyo Medical and Dental University, 1 Chome-5-45 Yushima, Tokyo, Bunkyo City, 113-8510, Japan; Service de chirurgie orthopédique, clinique Aguiléra, 21, rue de l'Estagnas, Biarritz, 64200, France; Institute of Movement and Locomotion, Department of Orthopaedics and Traumatology, Sainte-Marguerite Hospital, BP 29, 270, boulevard Sainte-Marguerite, Marseille, 13274, France; Aix-Marseille Unit, Institute for Locomotion, Department of Orthopaedics and Traumatology, CNRS, ISM, Sainte-Marguerite Hospital, AP–HM, Marseille, France},
	abstract = {Introduction: There has been an unprecedented rise is the use of artificial intelligence (AI) amongst medical fields. Recently, a dialogue agent called ChatGPT (Generative Pre-trained Transformer) has grown in popularity through its use of large language models (LLM) to clearly and precisely generate text on demand. However, the impact of AI on the creation of scientific articles is remains unknown. A retrospective study was carried out with the aim of answering the following questions: identify the presence of text generated by LLM before and after the increased usage of ChatGPT in articles submitted in OTSR; determine if the type of article, the year of submission, and the country of origin, influenced the proportion of text generated, at least in part by AI. Material and methods: A total of 390 English articles were submitted to OTSR in January, February and March 2022 (n = 204) and over the same months of 2023 (n = 186) were analyzed. All articles were analyzed using the ZeroGPT tool, which provides an assumed rate of AI use expressed as a percentage. A comparison of the average rate of AI use was carried out between the articles submitted in 2022 and 2023. This comparison was repeated keeping only the articles with the highest percentage of suspected AI use (greater than 10 and 20%). A secondary analysis was carried out to identify risk factors for AI use. Results: The average percentage of suspected LLM use in the entire cohort was 11% ± 6, with 160 articles (41.0%) having a suspected AI rate greater than 10% and 61 (15.6%) with an assumed AI rate greater than 20%. A comparison between articles submitted in 2022 and 2023 revealed a significant increase in the use of these tools after the launch of ChatGPT 3.5 (9.4% in 2022 and 12.6% in 2023 [p = 0.004]). The number of articles with suspected AI rates of greater than 10 and 20% were significantly higher in 2023: >10%: 71 articles (34.8%) versus 89 articles (47.8%) (p = 0.008) and >20%: 21 articles (10.3%) versus 40 articles (21.5%) (p = 0.002). A risk factor analysis for LLLM use, demonstrated that authors of Asian geographic origin, and the submission year 2023 were associated with a higher rate of suspected AI use. An AI rate >20% was associated to Asian geographical origin with an odds ratio of 1.79 (95% CI: 1.03–3.11) (p = 0.029), while the year of submission being 2023 had an odds ratio of 1.7 (95% CI: 1.1–2.5) (p = 0.02). Conclusion: This study highlights a significant increase in the use of LLM in the writing of articles submitted to the OTSR journal after the launch of ChatGPT 3.5. The increasing use of these models raises questions about originality and plagiarism in scientific research. AI offers creative opportunities but also raises ethical and methodological challenges. Level of evidence: III; case control study. © 2023 Elsevier Masson SAS},
	author_keywords = {Artificial intelligence; Chatbot; ChatGPT; Large language learning models; Scientific article},
	keywords = {Artificial Intelligence; Case-Control Studies; Humans; Language; Orthopedics; Retrospective Studies; Traumatology; article; artificial intelligence; case control study; ChatGPT; controlled study; geographic origin; human; human experiment; language development; major clinical study; orthopedics; plagiarism; retrospective study; risk factor; secondary analysis; traumatology; writing; artificial intelligence; language},
	correspondence_address = {A. Ferreira; Unité Inserm Comète 1075, Department of Orthopaedics and Traumatology, Caen University Hospital, Caen, avenue Cote-de-Nacre, 14000, France; email: alexandreferreira0891@gmail.com},
	publisher = {Elsevier Masson s.r.l.},
	issn = {18770568},
	pmid = {37866509},
	language = {English},
	abbrev_source_title = {Orthop. Traumatol.: Surg. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Peng2023,
	author = {Peng, Cheng and Yang, Xi and Chen, Aokun and Smith, Kaleb E. and PourNejatian, Nima and Costa, Anthony B. and Martin, Cheryl and Flores, Mona G. and Zhang, Ying and Magoc, Tanja and Lipori, Gloria and Mitchell, Duane A. and Ospina, Naykky S. and Ahmed, Mustafa M. and Hogan, William R. and Shenkman, Elizabeth A. and Guo, Yi and Bian, Jiang and Wu, Yonghui},
	title = {A study of generative large language model for medical research and healthcare},
	year = {2023},
	journal = {npj Digital Medicine},
	volume = {6},
	number = {1},
	doi = {10.1038/s41746-023-00958-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177043166&doi=10.1038%2fs41746-023-00958-w&partnerID=40&md5=f06447139be98245ab7a5d25fb263c56},
	affiliations = {Department of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, FL, United States; Cancer Informatics Shared Resource, University of Florida Health Cancer Center, Gainesville, FL, United States; NVIDIA, Santa Clara, CA, United States; Research Computing, University of Florida, Gainesville, FL, United States; Integrated Data Repository Research Services, University of Florida, Gainesville, FL, United States; Lillian S. Wells Department of Neurosurgery, Clinical and Translational Science Institute, University of Florida, Gainesville, FL, United States; Division of Endocrinology, Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, United States; Division of Cardiovascular Medicine, Department of Medicine, College of Medicine, University of Florida, Gainesville, FL, United States},
	abstract = {There are enormous enthusiasm and concerns in applying large language models (LLMs) to healthcare. Yet current assumptions are based on general-purpose LLMs such as ChatGPT, which are not developed for medical use. This study develops a generative clinical LLM, GatorTronGPT, using 277 billion words of text including (1) 82 billion words of clinical text from 126 clinical departments and approximately 2 million patients at the University of Florida Health and (2) 195 billion words of diverse general English text. We train GatorTronGPT using a GPT-3 architecture with up to 20 billion parameters and evaluate its utility for biomedical natural language processing (NLP) and healthcare text generation. GatorTronGPT improves biomedical natural language processing. We apply GatorTronGPT to generate 20 billion words of synthetic text. Synthetic NLP models trained using synthetic text generated by GatorTronGPT outperform models trained using real-world clinical text. Physicians’ Turing test using 1 (worst) to 9 (best) scale shows that there are no significant differences in linguistic readability (p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical relevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that physicians cannot differentiate them (p < 0.001). This study provides insights into the opportunities and challenges of LLMs for medical research and healthcare. © 2023, The Author(s).},
	keywords = {Computational linguistics; Health care; 'current; Language model; Language processing; Medical research; Medical use; Natural languages; Processing model; Real-world; Text generations; University of Florida; Article; GatorTronGPT; health care; human; large language model; medical research; natural language processing; physician; reading; Natural language processing systems},
	correspondence_address = {Y. Wu; Department of Health Outcomes and Biomedical Informatics, College of Medicine, University of Florida, Gainesville, United States; email: yonghui.wu@ufl.edu},
	publisher = {Nature Research},
	issn = {23986352},
	language = {English},
	abbrev_source_title = {npj Digit. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Soygazi202392,
	author = {Soygazi, Fatih and Oguz, Damla},
	title = {An Analysis of Large Language Models and LangChain in Mathematics Education},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {92 – 97},
	doi = {10.1145/3633598.3633614},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184128982&doi=10.1145%2f3633598.3633614&partnerID=40&md5=f59b13ae7c416a0885d8be7b30a133a7},
	affiliations = {Department of Computer Engineering, Aydln Adnan Menderes University, Aydin, Turkey; Department of Computer Engineering, Zmir Institute of Technology, Izmir, Turkey},
	abstract = {The development of large language models (LLMs) has led to the consideration of new approaches, particularly in education. Word problems, especially in subjects like mathematics, and the need to solve these problems by collectively addressing specific stages of reasoning, have raised the question of whether LLMs can be successful in this area as well. In our study, we conducted analyses by asking mathematics questions especially related to word problems using ChatGPT, which is based on the latest language models like Generative Pretrained Transformer (GPT). Additionally, we compared the correct and incorrect answers by posing the same questions to LLMMathChain, a mathematics-specific LLM based on the latest language models like LangChain. It was observed that the answers obtained were more successful with ChatGPT (GPT 3.5), particularly in the field of mathematics. However, both language models were found to be below expectations, particularly in word problems, and suggestions for improvement were provided. © 2023 ACM.},
	author_keywords = {ChatGPT; LangChain; Large Language Models (LLMs); Mathematics Education},
	keywords = {ChatGPT; Langchain; Language model; Large language model; Mathematics education; Model-based OPC; New approaches; Word problem; Computational linguistics},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070898-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lum20231623,
	author = {Lum, Zachary C.},
	title = {Can Artificial Intelligence Pass the American Board of Orthopaedic Surgery Examination? Orthopaedic Residents Versus ChatGPT},
	year = {2023},
	journal = {Clinical Orthopaedics and Related Research},
	volume = {481},
	number = {8},
	pages = {1623 – 1630},
	doi = {10.1097/CORR.0000000000002704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166170986&doi=10.1097%2fCORR.0000000000002704&partnerID=40&md5=712851bcf8ac03ff742665d9b57e628f},
	affiliations = {Nova Southeastern University, Davie, FL, United States},
	abstract = {BackgroundAdvances in neural networks, deep learning, and artificial intelligence (AI) have progressed recently. Previous deep learning AI has been structured around domain-specific areas that are trained on dataset-specific areas of interest that yield high accuracy and precision. A new AI model using large language models (LLM) and nonspecific domain areas, ChatGPT (OpenAI), has gained attention. Although AI has demonstrated proficiency in managing vast amounts of data, implementation of that knowledge remains a challenge.Questions/purposes(1) What percentage of Orthopaedic In-Training Examination questions can a generative, pretrained transformer chatbot (ChatGPT) answer correctly? (2) How does that percentage compare with results achieved by orthopaedic residents of different levels, and if scoring lower than the 10th percentile relative to 5th-year residents is likely to correspond to a failing American Board of Orthopaedic Surgery score, is this LLM likely to pass the orthopaedic surgery written boards? (3) Does increasing question taxonomy affect the LLM's ability to select the correct answer choices?MethodsThis study randomly selected 400 of 3840 publicly available questions based on the Orthopaedic In-Training Examination and compared the mean score with that of residents who took the test over a 5-year period. Questions with figures, diagrams, or charts were excluded, including five questions the LLM could not provide an answer for, resulting in 207 questions administered with raw score recorded. The LLM's answer results were compared with the Orthopaedic In-Training Examination ranking of orthopaedic surgery residents. Based on the findings of an earlier study, a pass-fail cutoff was set at the 10th percentile. Questions answered were then categorized based on the Buckwalter taxonomy of recall, which deals with increasingly complex levels of interpretation and application of knowledge; comparison was made of the LLM's performance across taxonomic levels and was analyzed using a chi-square test.ResultsChatGPT selected the correct answer 47% (97 of 207) of the time, and 53% (110 of 207) of the time it answered incorrectly. Based on prior Orthopaedic In-Training Examination testing, the LLM scored in the 40th percentile for postgraduate year (PGY) 1s, the eighth percentile for PGY2s, and the first percentile for PGY3s, PGY4s, and PGY5s; based on the latter finding (and using a predefined cutoff of the 10th percentile of PGY5s as the threshold for a passing score), it seems unlikely that the LLM would pass the written board examination. The LLM's performance decreased as question taxonomy level increased (it answered 54% [54 of 101] of Tax 1 questions correctly, 51% [18 of 35] of Tax 2 questions correctly, and 34% [24 of 71] of Tax 3 questions correctly; p = 0.034).ConclusionAlthough this general-domain LLM has a low likelihood of passing the orthopaedic surgery board examination, testing performance and knowledge are comparable to that of a first-year orthopaedic surgery resident. The LLM's ability to provide accurate answers declines with increasing question taxonomy and complexity, indicating a deficiency in implementing knowledge.Clinical RelevanceCurrent AI appears to perform better at knowledge and interpretation-based inquires, and based on this study and other areas of opportunity, it may become an additional tool for orthopaedic learning and education. © 2023 Lippincott Williams and Wilkins. All rights reserved.},
	keywords = {Aminosalicylic Acid; Artificial Intelligence; Clinical Competence; Educational Measurement; Humans; Internship and Residency; Orthopedic Procedures; Orthopedics; United States; aminosalicylic acid; Article; artificial intelligence; comprehension; data interpretation; human; knowledge; medical education; orthopedic surgeon; orthopedic surgery; postgraduate student; problem solving; recall; artificial intelligence; clinical competence; education; orthopedics; United States},
	correspondence_address = {Z.C. Lum; Nova Southeastern University, 3200 South University Drive, United States; email: zacharylum@gmail.com},
	publisher = {Wolters Kluwer Health Inc},
	issn = {0009921X},
	coden = {CORTB},
	pmid = {37220190},
	language = {English},
	abbrev_source_title = {Clin. Orthop. Relat. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Rasul202341,
	author = {Rasul, Tareq and Nair, Sumesh and Kalendra, Diane and Robin, Mulyadi and Santini, Fernando de Oliveira and Ladeira, Wagner Junior and Sun, Mingwei and Day, Ingrid and Rather, Raouf Ahmad and Heathcote, Liz},
	title = {The role of ChatGPT in higher education: Benefits, challenges, and future research directions},
	year = {2023},
	journal = {Journal of Applied Learning and Teaching},
	volume = {6},
	number = {1},
	pages = {41 – 56},
	doi = {10.37074/jalt.2023.6.1.29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162949999&doi=10.37074%2fjalt.2023.6.1.29&partnerID=40&md5=c99d56a6dc7aed575896f231ca95b798},
	affiliations = {Australian Institute of Business (AIB), Adelaide, Australia; Universidade do Vale do Rio dos Sinos (UNISINOS), Sao Leopoldo, Brazil; Scientific Independent Researcher, Anantnag, J&K, India},
	abstract = {This paper examines the potential benefits and challenges of using the generative AI model, ChatGPT, in higher education, in the backdrop of the constructivist theory of learning. This perspective-type study presents five benefits of ChatGPT: the potential to facilitate adaptive learning, provide personalised feedback, support research and data analysis, offer automated administrative services, and aid in developing innovative assessments. Additionally, the paper identifies five challenges: academic integrity concerns, reliability issues, inability to evaluate and reinforce graduate skill sets, limitations in assessing learning outcomes, and potential biases and falsified information in information processing. The paper argues that tertiary educators and students must exercise caution when using ChatGPT for academic purposes to ensure its ethical, reliable, and effective use. To achieve this, the paper proposes various propositions, such as prioritising education on the responsible and ethical use of ChatGPT, devising new assessment strategies, addressing bias and falsified information, and including AI literacy as part of graduate skills. By balancing the potential benefits and challenges, ChatGPT can enhance students’ learning experiences in higher education. © 2023. Tareq Rasul, Sumesh Nair, Diane Kalendra, Mulyadi Robin, Fernando de Oliveira Santini, Wagner Junior Ladeira, Mingwei Sun, Ingrid Day, Raouf Ahmad Rather, and Liz Heathcote.},
	author_keywords = {Academic integrity; ChatGPT; constructivist theory of learning; generative AI; higher education; Large Language Model (LLM)},
	correspondence_address = {T. Rasul; Australian Institute of Business (AIB), Adelaide, Australia; email: tfrasul@gmail.com},
	publisher = {Kaplan Singapore},
	issn = {2591801X},
	language = {English},
	abbrev_source_title = {J. Appl. Learn. Teach.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Bronze Open Access}
}

@CONFERENCE{Acher202357,
	author = {Acher, Mathieu and Martinez, Jabier},
	title = {Generative AI for Reengineering Variants into Software Product Lines: An Experience Report},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	volume = {B-2},
	pages = {57 – 66},
	doi = {10.1145/3579028.3609016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175977027&doi=10.1145%2f3579028.3609016&partnerID=40&md5=92f727bdb6821a88427bf3278f0383bf},
	affiliations = {Univ Rennes, Irisa, Inria, Cnrs, Iuf, Rennes, France; Tecnalia, Basque Research and Technology Alliance (BRTA), Pessac, France},
	abstract = {The migration and reengineering of existing variants into a software product line (SPL) is an error-prone and time-consuming activity. Many extractive approaches have been proposed, spanning different activities from feature identification and naming to the synthesis of reusable artefacts. In this paper, we explore how large language model (LLM)-based assistants can support domain analysts and developers. We revisit four illustrative cases of the literature where the challenge is to migrate variants written in different formalism (UML class diagrams, Java, GraphML, statecharts). We systematically report on our experience with ChatGPT-4, describing our strategy to prompt LLMs and documenting positive aspects but also failures. We compare the use of LLMs with state-of-the-art approach, BUT4Reuse. While LLMs offer potential in assisting domain analysts and developers in transitioning software variants into SPLs, their intrinsic stochastic nature and restricted ability to manage large variants or complex structures necessitate a semiautomatic approach, complete with careful review, to counteract inaccuracies.  © 2023 ACM.},
	keywords = {Computer software; Reengineering; Software design; Error prones; Experience report; Extractive approach; Features identification; Language model; Model-based OPC; Software Product Line; State-of-the-art approach; Statecharts; UML class diagrams; Stochastic systems},
	editor = {Arcaini P. and ter Beek M.H. and Perrouin G. and Reinhartz-Berger I. and Machado I. and Vergilio S.R. and Rabiser R. and Yue T. and Devroey X. and Pinto M. and Washizaki H.},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070092-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Young2023,
	author = {Young, Brendan and Anderson, Derek T. and Keller, James M. and Petry, Fred and Michael, Chris J.},
	title = {Generative Neural Net for Spatial Concept-To-Image},
	year = {2023},
	journal = {Proceedings - Applied Imagery Pattern Recognition Workshop},
	doi = {10.1109/AIPR60534.2023.10440716},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186721524&doi=10.1109%2fAIPR60534.2023.10440716&partnerID=40&md5=a14b6c2d4ebcd04d6c903825535e7a5a},
	affiliations = {University of Missouri, Electrical Engineering and Computer Science Department, Columbia, MO, United States; Stennis Space Center, MS, U.S. Naval Research Laboratory, United States},
	abstract = {Numerous artificial intelligence (AI) approaches, such as generative AI (GAI), large language models (LLM) and text-To-image networks, necessitate spatial intelligence for effective operation. Yet, a prevailing ideology embedded in contemporary solutions is their inclination to strictly adhere to a data-driven approach when addressing spatial learning. This viewpoint leads to opaque solutions, aka "black boxes", and it presupposes that the intricacies of spatial reasoning will effortlessly surface as an inherent byproduct of extensive data exposure. This simplistic reliance on data overlooks the wealth of established psychology and mathematics governing spatial relations and their inherent uncertainties. In this article, we delve into neural networks and learning strategies for incorporating well-established spatial relations mathematics into an effective and explainable GAI. Specifically, we showcase how to translate abstract concepts, expressed as sets of spatial relations, into visual imagery. This resulting imagery can be immediately used or passed on as a spatial prior to a larger and more sophisticated GAI. We present two synthetic use cases wherein spatial concepts materialize as intricate arrangements of multi-part colored geometric primitives, undergoing a spectrum of diverse planar affine transformations. Our exploration is categorized into two dimensions: discerning spatial placements (aka the "where") and shape depiction (aka the "what"). Overall, we've noted a strength in our proposed neural networks in discerning spatial placements. However, while our nets also exhibit a competence in determining "what"to depict, we recognize the necessity for additional fine-Tuning to achieving visual imagery consistent with state-of-The-Art works like DALL-E and stable diffusion. © 2023 IEEE.},
	author_keywords = {generative neural network; histogram of forces; spatial concept; spatial reasoning},
	keywords = {Computer vision; Data-driven approach; Generative neural network; Histogram of force; Language model; Neural-networks; Spatial concepts; Spatial intelligence; Spatial reasoning; Spatial relations; Visual imagery; Abstracting},
	correspondence_address = {B. Young; University of Missouri, Electrical Engineering and Computer Science Department, Columbia, United States; email: bmywzx@umsystem.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21642516},
	isbn = {979-835035952-7},
	language = {English},
	abbrev_source_title = {Proc. Appl. Imagery Pattern. Recogn. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu2023273,
	author = {Liu, Junwen and Zhang, Zheyu and Xiao, Jifeng and Jin, Zhijia and Zhang, Xuekun and Ma, Yuanyuan and Yan, Fuhua and Wen, Ning},
	title = {Large Language Model Locally Fine-tuning (LLMLF) on Chinese Medical Imaging Reports},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {273 – 279},
	doi = {10.1145/3627377.3627445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180123514&doi=10.1145%2f3627377.3627445&partnerID=40&md5=ea800dc494c098fdfb143b2152000da1},
	affiliations = {Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China; The Global Institute of Future Technology, Shanghai Jiaotong University, Shanghai, China; SJTU-Ruijin-UIH Institute for Medical Imaging Technology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China},
	abstract = {The emergence of large language models exerts significant impact in the field of natural language processing. These models, which are based on attention networks, have shown remarkable capabilities in understanding and generating human conversation context, surpassing most of the state-of-the-art models in Natural Language Processing (NLP). Though Generative Pre-trained GPT-series open their public Application Programming Interfaces (APIs) for direct inference, such services require users to upload (relinquish) their data to servers, thus not suitable for domains operating sensitive data, such as the medical field. Due to comparable smaller model size, existing local pre-trained model deployments are usually not that helpful on domain-specific data without further fine-tuning. In this paper, we leverage Microsoft's recent open source DeepSpeed-Chat platform and one of our selected pre-trained models, to locally conduct fine-tuning on our medical imaging reports (in Chinese), to infer diagnosis recommendations based on the imaging description. Our output models show very promising results according to both NLP metrics and experts' evaluation criteria. This paper provides an initial report on our latest progress on locally fine-tuning large language model for medical data. © 2023 ACM.},
	author_keywords = {Chinese Medical Imaging Reports; Large Language Model (LLM); Locally fine-tuning; NLP},
	keywords = {Diagnosis; Medical imaging; Natural language processing systems; Sensitive data; ART model; Chinese medical imaging report; Fine tuning; Language model; Language processing; Large language model; Locally fine-tuning; Natural language processing; Natural languages; State of the art; Application programming interfaces (API)},
	correspondence_address = {J. Liu; Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China; email: ljwb5009@rjh.com.cn; Z. Jin; Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China; email: jzj12602@rjh.com.cn; X. Zhang; Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China; email: zxk12209@rjh.com.cn; Y. Ma; Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China; email: myy12135@rjh.com.cn; F. Yan; Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China; email: yfh11655@rjh.com.cn; N. Wen; Department of Radiology, Ruijin Hospital, Shanghai Jiaotong University, School of Medicine, Shanghai, China; email: wn12479@rjh.com.cn},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070766-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Head202333,
	author = {Head, Cari Beth and Jasper, Paul and McConnachie, Matthew and Raftree, Linda and Higdon, Grace},
	title = {Large language model applications for evaluation: Opportunities and ethical implications},
	year = {2023},
	journal = {New Directions for Evaluation},
	volume = {2023},
	number = {178-179},
	pages = {33 – 46},
	doi = {10.1002/ev.20556},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176012322&doi=10.1002%2fev.20556&partnerID=40&md5=2bfb8038a61363842eb8fb036b15fa63},
	affiliations = {Department of Sociology, University of Florida, Gainesville, United States; Principal Consultant, Data Innovation, Oxford Policy Management, Oxford, United Kingdom; Principal Consultant, NIRAS, Edinburgh, United Kingdom; Natural Language Processing Community of Practice, MERL Tech, Brooklyn, United States; Data Strategy and Policy, Development Gateway, Washington, DC, United States},
	abstract = {Large language models (LLMs) are a type of generative artificial intelligence (AI) designed to produce text-based content. LLMs use deep learning techniques and massively large data sets to understand, summarize, generate, and predict new text. LLMs caught the public eye in early 2023 when ChatGPT (the first consumer facing LLM) was released. LLM technologies are driven by recent advances in deep-learning AI techniques, where language models are trained on extremely large text data from the internet and then re-used for downstream tasks with limited fine-tuning required. They offer exciting opportunities for evaluators to automate and accelerate time-consuming tasks involving text analytics and text generation. We estimate that over two-thirds of evaluation tasks will be affected by LLMs in the next 5 years. Use-case examples include summarizing text data, extracting key information from text, analyzing and classifying text content, writing text, and translation. Despite the advances, the technologies pose significant challenges and risks. Because LLM technologies are generally trained on text from the internet, they tend to perpetuate biases (racism, sexism, ethnocentrism, and more) and exclusion of non-majority languages. Current tools like ChatGPT have not been specifically developed for monitoring, evaluation, research, and learning (MERL) purposes, possibly limiting their accuracy and usefulness for evaluation. In addition, technical limitations and challenges with bias can lead to real world harm. To overcome these technical challenges and ethical risks, the evaluation community will need to work collaboratively with the data science community to co-develop tools and processes and to ensure the application of quality and ethical standards. © 2023 American Evaluation Association and Wiley Periodicals LLC.},
	correspondence_address = {L. Raftree; MERL Tech, Brooklyn, United States; email: linda@merltech.org},
	publisher = {John Wiley and Sons Inc},
	issn = {10976736},
	language = {English},
	abbrev_source_title = {New Dir. Eval.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access}
}

@ARTICLE{Park20231187,
	author = {Park, Daeseung and An, Gi-Taek and Kamyod, Chayapol and Kim, Cheong Ghil},
	title = {A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model},
	year = {2023},
	journal = {Journal of Web Engineering},
	volume = {22},
	number = {8},
	pages = {1187 – 1206},
	doi = {10.13052/jwe1540-9589.2285},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187943790&doi=10.13052%2fjwe1540-9589.2285&partnerID=40&md5=48efd3c781a784503fb49b662f988b79},
	affiliations = {Department of Computer Science, Namseoul University, Cheonan, South Korea; Korea Food Research Institute, Wanju-gun, 55365, South Korea; Computer and Communication Engineering for Capacity Building Research Center, School of Information Technology, Mae Fah Luang University, Chiang Rai, 57100, Thailand},
	abstract = {In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance. © 2024 River Publishers.},
	author_keywords = {AI; AI Chatbot; few-shot learning; generative AI; large language model; prompt engineering},
	correspondence_address = {C.G. Kim; Department of Computer Science, Namseoul University, Cheonan, South Korea; email: cgkim@nsu.ac.kr},
	publisher = {River Publishers},
	issn = {15409589},
	language = {English},
	abbrev_source_title = {J. Web Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Gekhman20232053,
	author = {Gekhman, Zorik and Herzig, Jonathan and Aharoni, Roee and Elkind, Chen and Szpektor, Idan},
	title = {TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {2053 – 2070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184828559&partnerID=40&md5=9eea629d4da55ed756da0f061f2a5714},
	affiliations = {Technion - Israel Institute of Technology, Israel; Google Research},
	abstract = {Factual consistency evaluation is often conducted using Natural Language Inference (NLI) models, yet these models exhibit limited success in evaluating summaries. Previous work improved such models with synthetic training data. However, the data is typically based on perturbed human-written summaries, which often differ in their characteristics from real model-generated summaries and have limited coverage of possible factual errors. Alternatively, large language models (LLMs) have recently shown promising results in directly evaluating generative tasks, but are too computationally expensive for practical use. Motivated by these limitations, we introduce TrueTeacher, a method for generating synthetic data by annotating diverse model-generated summaries using a LLM. Unlike prior work, TrueTeacher does not rely on human-written summaries, and is multilingual by nature. Experiments on the TRUE benchmark show that a student model trained using our data, substantially outperforms both the state-of-the-art model with similar capacity, and the LLM teacher. In a systematic study, we compare TrueTeacher to existing synthetic data generation methods and demonstrate its superiority and robustness to domain-shift. We also show that our method generalizes to multilingual scenarios. Lastly, we release our large-scale synthetic dataset (1.4M examples), generated using TrueTeacher, and a checkpoint trained on this data. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Inference models; Language inference; Language model; Natural languages; Practical use; Real models; State of the art; Student Modeling; Synthetic data; Synthetic training data; Large datasets},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Lozić2023,
	author = {Lozić, Edisa and Štular, Benjamin},
	title = {Fluent but Not Factual: A Comparative Analysis of ChatGPT and Other AI Chatbots’ Proficiency and Originality in Scientific Writing for Humanities},
	year = {2023},
	journal = {Future Internet},
	volume = {15},
	number = {10},
	doi = {10.3390/fi15100336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174905967&doi=10.3390%2ffi15100336&partnerID=40&md5=9644f7649ddf71bafdf7e546325c197a},
	affiliations = {Research Centre of the Slovenian Academy of Sciences and Arts, Ljubljana, 1000, Slovenia},
	abstract = {Historically, mastery of writing was deemed essential to human progress. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI-generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness in a manner similar to grading students, while qualitative precision gauged the scientific contribution similar to reviewing a scientific article. In the quantitative test, ChatGPT-4 scored near the passing grade (−5) whereas ChatGPT-3.5 (−18), Bing (−21) and Bard (−31) were not far behind. Claude 2 (−75) and Aria (−80) scored much lower. In the qualitative test, all AI chatbots, but especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, but all failed to generate original scientific content. As a side note, our results suggest that with ChatGPT-4, the size of large language models has reached a plateau. Furthermore, this paper underscores the intricate and recursive nature of human research. This process of transforming raw data into refined knowledge is computationally irreducible, highlighting the challenges AI chatbots face in emulating human originality in scientific writing. Our results apply to the state of affairs in the third quarter of 2023. In conclusion, while large language models have revolutionised content generation, their ability to produce original scientific contributions in the humanities remains limited. We expect this to change in the near future as current large language model-based AI chatbots evolve into large language model-powered software. © 2023 by the authors.},
	author_keywords = {Bard; Bing; ChatGPT; digital humanities; generative AI; large language model (LLM); scientific writing},
	keywords = {Computational linguistics; Grading; Bard; Bing; Chatbots; ChatGPT; Digital humanities; Generative AI; Language model; Large language model; Quantitative accuracy; Scientific writing; Metadata},
	correspondence_address = {B. Štular; Research Centre of the Slovenian Academy of Sciences and Arts, Ljubljana, 1000, Slovenia; email: benjamin.stular@zrc-sazu.si},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {19995903},
	language = {English},
	abbrev_source_title = {Future Internet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Acher20238,
	author = {Acher, Mathieu and Duarte, José Galindo and Jézéquel, Jean-Marc},
	title = {On Programming Variability with Large Language Model-based Assistant},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	volume = {A-1},
	pages = {8 – 14},
	doi = {10.1145/3579027.3608972},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174996771&doi=10.1145%2f3579027.3608972&partnerID=40&md5=d52b873a0f1e4d8920ef94585166e866},
	affiliations = {University of Rennes, Insa, Irisa, Inria, Iuf, Rennes, France; University of Sevilla, Sevilla, Spain; University of Rennes, Irisa, Inria, Iuf, Rennes, France},
	abstract = {Programming variability is central to the design and implementation of software systems that can adapt to a variety of contexts and requirements, providing increased flexibility and customization. Managing the complexity that arises from having multiple features, variations, and possible configurations is known to be highly challenging for software developers. In this paper, we explore how large language model (LLM)-based assistants can support the programming of variability.We report on new approaches made possible with LLM-based assistants, like: features and variations can be implemented as prompts; augmentation of variability out of LLM-based domain knowledge; seamless implementation of variability in different kinds of artefacts, programming languages, and frameworks, at different binding times (compile-time or run-time). We are sharing our data (prompts, sessions, generated code, etc.) to support the assessment of the effectiveness and robustness of LLMs for variability-related tasks.  © 2023 ACM.},
	author_keywords = {generative AI; large language model; programming; software product lines; variability},
	keywords = {Computational linguistics; Computer software; Design and implementations; Generative AI; Increased flexibility; Language model; Large language model; Model-based OPC; Programming; Software Product Line; Software-systems; Variability; Domain Knowledge},
	editor = {Arcaini P. and ter Beek M.H. and Perrouin G. and Reinhartz-Berger I. and Luaces M.R. and Schwanninger C. and Ali S. and Varshosaz M. and Gargantini A. and Gnesi S. and Lochau M. and Semini L. and Washizaki H.},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070091-0},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Niszczota2023101,
	author = {Niszczota, Paweł and Conway, Paul},
	title = {Judgements of research co-created by Generative AI: Experimental evidence},
	year = {2023},
	journal = {Economics and Business Review},
	volume = {9},
	number = {2},
	pages = {101 – 114},
	doi = {10.18559/ebr.2023.2.744},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168341701&doi=10.18559%2febr.2023.2.744&partnerID=40&md5=9a4ce2a402944c25bc4e6b722404c6c1},
	affiliations = {Poznań University of Economics and Business, Humans & AI Laboratory (HAI Lab), Department of International Finance, al. Niepodległości 10, Poznań, 61-875, Poland; University of Southampton, Department of Psychology, B44 University Road, Southampton, SO17 1PS, United Kingdom},
	abstract = {The introduction of ChatGPT has fuelled a public debate on the appropriateness of using Generative AI (large language models; LLMs) in work, including a debate on how they might be used (and abused) by researchers. In the current work, we test whether delegating parts of the research process to LLMs leads people to distrust researchers and devalues their scientific work. Participants (N = 402) considered a researcher who delegates elements of the research process to a PhD student or LLM and rated three aspects of such delegation. Firstly, they rated whether it is morally appropriate to do so. Secondly, they judged whether - after deciding to delegate the research process - they would trust the scientist (that decided to delegate) to oversee future projects. Thirdly, they rated the expected accuracy and quality of the output from the delegated research process. Our results show that people judged delegating to an LLM as less morally acceptable than delegating to a human (d = -0.78). Delegation to an LLM also decreased trust to oversee future research projects (d = -0.80), and people thought the results would be less accurate and of lower quality (d = -0.85). We discuss how this devaluation might transfer into the underreporting of Generative AI use.  © 2023 Paweł Niszczota et al., published by Sciendo.},
	author_keywords = {ChatGPT; experiment; Generative AI; GPT; large language models; metascience; trust in science},
	correspondence_address = {P. Niszczota; Poznań University of Economics and Business, Humans & AI Laboratory (HAI Lab), Department of International Finance, Poznań, al. Niepodległości 10, 61-875, Poland; email: pawel.niszczota@ue.poznan.pl},
	publisher = {Sciendo},
	issn = {23921641},
	language = {English},
	abbrev_source_title = {Econ. Bus. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Meskó2023,
	author = {Meskó, Bertalan and Topol, Eric J.},
	title = {The imperative for regulatory oversight of large language models (or generative AI) in healthcare},
	year = {2023},
	journal = {npj Digital Medicine},
	volume = {6},
	number = {1},
	doi = {10.1038/s41746-023-00873-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164295991&doi=10.1038%2fs41746-023-00873-0&partnerID=40&md5=657da2c6a8b235b18551d0094cd60b67},
	affiliations = {The Medical Futurist Institute, Budapest, Hungary; Department of Behavioural Sciences, Semmelweis University, Budapest, Hungary; Scripps Research Translational Institute, Scripps Research, La Jolla, CA, United States},
	abstract = {The rapid advancements in artificial intelligence (AI) have led to the development of sophisticated large language models (LLMs) such as GPT-4 and Bard. The potential implementation of LLMs in healthcare settings has already garnered considerable attention because of their diverse applications that include facilitating clinical documentation, obtaining insurance pre-authorization, summarizing research papers, or working as a chatbot to answer questions for patients about their specific data and concerns. While offering transformative potential, LLMs warrant a very cautious approach since these models are trained differently from AI-based medical technologies that are regulated already, especially within the critical context of caring for patients. The newest version, GPT-4, that was released in March, 2023, brings the potentials of this technology to support multiple medical tasks; and risks from mishandling results it provides to varying reliability to a new level. Besides being an advanced LLM, it will be able to read texts on images and analyze the context of those images. The regulation of GPT-4 and generative AI in medicine and healthcare without damaging their exciting and transformative potential is a timely and critical challenge to ensure safety, maintain ethical standards, and protect patient privacy. We argue that regulatory oversight should assure medical professionals and patients can use LLMs without causing harm or compromising their data or privacy. This paper summarizes our practical recommendations for what we can expect from regulators to bring this vision to reality. © 2023, The Author(s).},
	keywords = {Biomedical engineering; Computational linguistics; Health care; Artificial intelligence in medicine; Chatbots; Clinical documentation; Critical challenges; Diverse applications; Ethical standards; Language model; Medical technologies; Regulatory oversight; Research papers; adult; article; artificial intelligence; drug safety; human; language; privacy; reliability; vision; Clinical research},
	correspondence_address = {B. Meskó; The Medical Futurist Institute, Budapest, Hungary; email: berci@medicalfuturist.com},
	publisher = {Nature Research},
	issn = {23986352},
	language = {English},
	abbrev_source_title = {npj Digit. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 62; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Alaofi20231869,
	author = {Alaofi, Marwah and Gallagher, Luke and Sanderson, Mark and Scholer, Falk and Thomas, Paul},
	title = {Can Generative LLMs Create Query Variants for Test Collections? An Exploratory Study},
	year = {2023},
	journal = {SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {1869 – 1873},
	doi = {10.1145/3539618.3591960},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168705068&doi=10.1145%2f3539618.3591960&partnerID=40&md5=7768fe10986d51dd831a5f2369409508},
	affiliations = {RMIT University, Melbourne, Australia; Microsoft, Adelaide, Australia},
	abstract = {This paper explores the utility of a Large Language Model (LLM) to automatically generate queries and query variants from a description of an information need. Given a set of information needs described as backstories, we explore how similar the queries generated by the LLM are to those generated by humans. We quantify the similarity using different metrics and examine how the use of each set would contribute to document pooling when building test collections. Our results show potential in using LLMs to generate query variants. While they may not fully capture the wide variety of human-generated variants, they generate similar sets of relevant documents, reaching up to 71.1% overlap at a pool depth of 100. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Information retrieval; LLMs; query variants; test collections},
	keywords = {Exploratory studies; Language model; LLM; Query variant; Relevant documents; Test Collection; Information retrieval},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039408-6},
	language = {English},
	abbrev_source_title = {SIGIR - Proc. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Adão2023,
	author = {Adão, Telmo and Oliveira, João and Shahrabadi, Somayeh and Jesus, Hugo and Fernandes, Marco and Costa, Ângelo and Ferreira, Vânia and Gonçalves, Martinho Fradeira and Lopéz, Miguel A. Guevara and Peres, Emanuel and Magalhães, Luís Gonzaga},
	title = {Empowering Deaf-Hearing Communication: Exploring Synergies between Predictive and Generative AI-Based Strategies towards (Portuguese) Sign Language Interpretation},
	year = {2023},
	journal = {Journal of Imaging},
	volume = {9},
	number = {11},
	doi = {10.3390/jimaging9110235},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178285214&doi=10.3390%2fjimaging9110235&partnerID=40&md5=5a4df4570bbda9ab330026683f7b8cd8},
	affiliations = {Department of Engineering, School of Sciences and Technology, University of Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal; ALGORITMI Research Centre/LASI, University of Minho, Guimarães, 4800-058, Portugal; Centro de Computação Gráfica-CCG/zgdv, University of Minho, Campus de Azurém, Edifício 14, Guimarães, 4800-058, Portugal; Polytechnic Institute of Bragança, School of Communication, Administration and Tourism, Campus do Cruzeiro, Mirandela, 5370-202, Portugal; Associação Portuguesa de Surdos (APS), Lisboa, 1600-796, Portugal; Instituto Politécnico de Setúbal, Escola Superior de Tecnologia de Setúbal, Setúbal, 2914-508, Portugal; Centre for the Research and Technology of Agro-Environmental and Biological Sciences, University of Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal; Institute for Innovation, Capacity Building and Sustainability of Agri-Food Production, University of Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal},
	abstract = {Communication between Deaf and hearing individuals remains a persistent challenge requiring attention to foster inclusivity. Despite notable efforts in the development of digital solutions for sign language recognition (SLR), several issues persist, such as cross-platform interoperability and strategies for tokenizing signs to enable continuous conversations and coherent sentence construction. To address such issues, this paper proposes a non-invasive Portuguese Sign Language (Língua Gestual Portuguesa or LGP) interpretation system-as-a-service, leveraging skeletal posture sequence inference powered by long-short term memory (LSTM) architectures. To address the scarcity of examples during machine learning (ML) model training, dataset augmentation strategies are explored. Additionally, a buffer-based interaction technique is introduced to facilitate LGP terms tokenization. This technique provides real-time feedback to users, allowing them to gauge the time remaining to complete a sign, which aids in the construction of grammatically coherent sentences based on inferred terms/words. To support human-like conditioning rules for interpretation, a large language model (LLM) service is integrated. Experiments reveal that LSTM-based neural networks, trained with 50 LGP terms and subjected to data augmentation, achieved accuracy levels ranging from 80% to 95.6%. Users unanimously reported a high level of intuition when using the buffer-based interaction strategy for terms/words tokenization. Furthermore, tests with an LLM—specifically ChatGPT—demonstrated promising semantic correlation rates in generated sentences, comparable to expected sentences. © 2023 by the authors.},
	author_keywords = {deaf-hearing communication; generative pre-trained transformer (GPT); inclusion; large language models (LLM); long-short term memory (LSTM); machine learning (ML); Portuguese Sign Language; sign language recognition (SLR); video-based motion analytics},
	keywords = {Audition; Brain; Computational linguistics; Embeddings; Natural language processing systems; Predictive analytics; Semantics; Deaf-hearing communication; Generative pre-trained transformer; Language model; Large language model; Long-short term memory; Machine learning; Machine-learning; Portuguese sign language; Sign language; Sign language recognition; Video-based motion analytic; Long short-term memory},
	correspondence_address = {T. Adão; Department of Engineering, School of Sciences and Technology, University of Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal; email: telmoadao@utad.pt},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {2313433X},
	language = {English},
	abbrev_source_title = {J. Imaging},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhou202333,
	author = {Zhou, Yajie and Yu, Nengneng and Liu, Zaoxing},
	title = {Towards Interactive Research Agents for Internet Incident Investigation},
	year = {2023},
	journal = {HotNets 2023 - Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
	pages = {33 – 40},
	doi = {10.1145/3626111.3628212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179843723&doi=10.1145%2f3626111.3628212&partnerID=40&md5=d9f4bd76024398bc7584375a1f25004b},
	affiliations = {University of Maryland, United States},
	abstract = {Investigating Internet incidents involves significant human effort and is limited by the domain knowledge of network researchers and operators. In this paper, we propose to develop computational software agents based on emerging language models (e.g., GPT-4) that can simulate the behaviors of knowledgeable researchers to assist in investigating certain Internet incidents and understanding their impacts. Our agent training framework uses Auto-GPT as an autonomous interface to interact with GPT-4 and gain knowledge by memorizing related information retrieved from online resources. The agent uses the model to reason the investigation questions and continuously performs knowledge testing to see if the conclusion is sufficiently confident or more information is needed. In our preliminary experiment, we build an agent Bob, who studies the impact of solar superstorms on the Internet and draws conclusions similar to those from a recent SIGCOMM paper written by a knowledgeable researcher. We envision this as a first step toward developing a future highly knowledgeable Internet researcher simulacra. © 2023 ACM.},
	author_keywords = {Generative AI; Internet Investigation; Internet Resilience; LLM; Software Agent},
	keywords = {Behavioral research; Domain Knowledge; Agent based; Computational software; Domain knowledge; Generative AI; Incident investigation; Internet investigation; Internet resilience; Language model; LLM; Training framework; Autonomous agents},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070415-4},
	language = {English},
	abbrev_source_title = {HotNets - Proc. ACM Workshop Hot Top. Networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Badini2023278,
	author = {Badini, Silvia and Regondi, Stefano and Frontoni, Emanuele and Pugliese, Raffaele},
	title = {Assessing the capabilities of ChatGPT to improve additive manufacturing troubleshooting},
	year = {2023},
	journal = {Advanced Industrial and Engineering Polymer Research},
	volume = {6},
	number = {3},
	pages = {278 – 287},
	doi = {10.1016/j.aiepr.2023.03.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151402811&doi=10.1016%2fj.aiepr.2023.03.003&partnerID=40&md5=1c82112e13c9fdf41f6b4435bcd10c72},
	affiliations = {NeMO Lab, ASST GOM Niguarda Cà Granda Hospital, Milan, Italy; VRAI Lab, SPOCRI Department, University of Macerata, Macerata, Italy},
	abstract = {This paper explores the potential of using Chat Generative Pre-trained Transformer (ChatGPT), a Large Language Model (LLM) developed by OpenAI, to address the main challenges and improve the efficiency of the Gcode generation process in Additive Manufacturing (AM), also known as 3D printing. The Gcode generation process, which controls the movements of the printer's extruder and the layer-by-layer build process, is a crucial step in the AM process and optimizing the Gcode is essential for ensuring the quality of the final product and reducing print time and waste. ChatGPT can be trained on existing Gcode data to generate optimized Gcode for specific polymeric materials, printers, and objects, as well as analyze and optimize the Gcode based on various printing parameters such as printing temperature, printing speed, bed temperature, fan speed, wipe distance, extrusion multiplier, layer thickness, and material flow. Here the capability of ChatGPT in performing complex tasks related to AM process optimization was demonstrated. In particular performance tests were conducted to evaluate ChatGPT's expertise in technical matters, focusing on the evaluation of printing parameters and bed detachment, warping, and stringing issues for Fused Filament Fabrication (FFF) methods using thermoplastic polyurethane polymer as feedstock material. This work provides effective feedback on the performance of ChatGPT and assesses its potential for use in the AM field. The use of ChatGPT for AM process optimization has the potential to revolutionize the industry by offering a user-friendly interface and utilizing machine learning algorithms to improve the efficiency and accuracy of the Gcode generation process and optimal printing parameters. Furthermore, the real-time optimization capabilities of ChatGPT can lead to significant time and material savings, making AM a more accessible and cost-effective solution for manufacturers and industry. © 2023 Kingfa Scientific and Technological Co. Ltd.},
	author_keywords = {3D printing; Accuracy; Additive manufacturing; ChatGPT; Efficiency; Gcode; Machine learning; Material savings; Optimization; Process control; Time savings},
	keywords = {3D printing; Additives; Cost effectiveness; Learning algorithms; Machine learning; Optimization; Parameter estimation; Printing presses; Process control; 3-D printing; 3D-printing; Accuracy; Chat generative pre-trained transformer; Gcode; Generation process; Machine-learning; Materials - savings; Optimisations; Time saving; Efficiency},
	correspondence_address = {R. Pugliese; NeMO Lab, ASST GOM Niguarda Cà Granda Hospital, Milan, Italy; email: raffaele.pugliese@nemolab.it},
	publisher = {KeAi Communications Co.},
	issn = {25425048},
	language = {English},
	abbrev_source_title = {Adv. Ind. Eng. Polym. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access}
}

@CONFERENCE{Wang2023296,
	author = {Wang, Zhiyuan and Zhou, Qiang and Junfeng, Zhao and Wang, Yasha and Ding, Hongxin and Song, Jiahe},
	title = {A Knowledge-Enhanced Medical Named Entity Recognition Method that Integrates Pre-Trained Language Models},
	year = {2023},
	journal = {Proceedings - 2023 1st IEEE International Conference on Medical Artificial Intelligence, MedAI 2023},
	pages = {296 – 301},
	doi = {10.1109/MedAI59581.2023.00046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185217688&doi=10.1109%2fMedAI59581.2023.00046&partnerID=40&md5=da1f7cb03d4df335ecc56f413487e48f},
	affiliations = {Peking University, Key Lab of Hcst (PKU), Moe, Scs, Beijing, China; School of Software & Microelectronics, Peking University, Beijing, China; Shenzhen Emergency Medical Center, Shenzhen, China; Research Center of Big Data Technology, Nanhu Laboratory, Jiaxing, China; School of Computer Science, Peking University, Beijing, China},
	abstract = {Medical Named Entity Recognition (NER) is a critical task in medical text processing. But medical documents exhibit high variability in terms of language usage, abbreviations, synonyms, misspellings, and typographical errors, so the precise extraction of named entities is challenging. Although large language models (LLMs) have shown good performance in medical knowledge extraction tasks in few-shot settings, their performance is difficult to fully leverage in supervised medical named entity recognition (NER) tasks. This is because NER is a sequence labeling task, while LLMs are more suitable for tasks such as text generation. Furthermore, the structured output of NER tasks leads to a performance loss when LLMs convert it into generative text. Therefore, it is a challenging problem to utilize LLMs to improve the accuracy of medical named entity recognition tasks. On this paper, we propose a method that integrates LLM knowledge to enhance the performance of medical NER models. Firstly, we improve the structure of the LLM model to make it more adaptable to NER tasks. Secondly, we adopt the LoRA method and incorporate Chinese vocabulary information into the model training. Finally, to fully utilize the fine-tuned LLM to enhance the medical NER model, we convert the output of the LLM into a knowledge concentration matrix and inject it into the NER model. We have verify the effectiveness of our new method on the CMeEE dataset. The results demonstrate that our method can efficiently fine-tune the LLM and improve its performance. Moreover, our method can also leverage the prior knowledge of the fine-tuned LLM to enhance the BERT-based medical NER model. In addition, our method demonstrates good generalization and can tackle entity recognition tasks in other domains. We validated the superiority of our approach on the resume-zh dataset.  © 2023 IEEE.},
	author_keywords = {Knowledge Enhancement; Large Language Model; Large Model Finetuning; Named-entity Recognition},
	keywords = {Character recognition; Computational linguistics; Knowledge management; Natural language processing systems; Text processing; Critical tasks; Knowledge enhancement; Language model; Large language model; Large model finetuning; Large models; Named entity recognition; Performance; Recognition methods; Recognition models; Extraction},
	correspondence_address = {Q. Zhou; Shenzhen Emergency Medical Center, Shenzhen, China; email: zq_shenzhen2023@163.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835035878-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Med. Artif. Intell., MedAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Griewing2023,
	author = {Griewing, Sebastian and Gremke, Niklas and Wagner, Uwe and Lingenfelder, Michael and Kuhn, Sebastian and Boekhoff, Jelena},
	title = {Challenging ChatGPT 3.5 in Senology—An Assessment of Concordance with Breast Cancer Tumor Board Decision Making},
	year = {2023},
	journal = {Journal of Personalized Medicine},
	volume = {13},
	number = {10},
	doi = {10.3390/jpm13101502},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175246847&doi=10.3390%2fjpm13101502&partnerID=40&md5=286780525d8999c464583ad842ea4270},
	affiliations = {Institute for Digital Medicine, University Hospital Marburg, Philipps-University Marburg, Baldingerstraße, Marburg, 35043, Germany; Department of Gynecology and Obstetrics, University Hospital Marburg, Philipps-University Marburg, Baldingerstraße, Marburg, 35043, Germany; Institute for Healthcare Management, Chair of General Business Administration, Philipps-University Marburg, Universitätsstraße 24, Marburg, 35037, Germany},
	abstract = {With the recent diffusion of access to publicly available large language models (LLMs), common interest in generative artificial-intelligence-based applications for medical purposes has skyrocketed. The increased use of these models by tech-savvy patients for personal health issues calls for a scientific evaluation of whether LLMs provide a satisfactory level of accuracy for treatment decisions. This observational study compares the concordance of treatment recommendations from the popular LLM ChatGPT 3.5 with those of a multidisciplinary tumor board for breast cancer (MTB). The study design builds on previous findings by combining an extended input model with patient profiles reflecting patho- and immunomorphological diversity of primary breast cancer, including primary metastasis and precancerous tumor stages. Overall concordance between the LLM and MTB is reached for half of the patient profiles, including precancerous lesions. In the assessment of invasive breast cancer profiles, the concordance amounts to 58.8%. Nevertheless, as the LLM makes considerably fraudulent decisions at times, we do not identify the current development status of publicly available LLMs to be adequate as a support tool for tumor boards. Gynecological oncologists should familiarize themselves with the capabilities of LLMs in order to understand and utilize their potential while keeping in mind potential risks and limitations. © 2023 by the authors.},
	author_keywords = {artificial intelligence; gynecology; large language models; oncology; tumor board},
	keywords = {estrogen receptor; progesterone receptor; Article; artificial intelligence; breast cancer; cancer staging; cell proliferation; ChatGPT; computer model; decision making; genetic screening; gynecologic oncologist; gynecologist; gynecology; health care personnel; hormonal therapy; human; immunohistology; in situ hybridization; invasive breast cancer; large language model; metastasis; oncology; qualitative analysis; questionnaire},
	correspondence_address = {S. Griewing; Institute for Digital Medicine, University Hospital Marburg, Philipps-University Marburg, Marburg, Baldingerstraße, 35043, Germany; email: griewin4@staff.uni-marburg.de},
	publisher = {Multidisciplinary Digital Publishing Institute (MDPI)},
	issn = {20754426},
	language = {English},
	abbrev_source_title = {J. Pers. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zeng202373,
	author = {Zeng, Zhen and Watson, William and Cho, Nicole and Rahimi, Saba and Reynolds, Shayleen and Balch, Tucker and Veloso, Manuela},
	title = {FlowMind: Automatic Workflow Generation with LLMs},
	year = {2023},
	journal = {ICAIF 2023 -  4th ACM International Conference on AI in Finance},
	pages = {73 – 81},
	doi = {10.1145/3604237.3626908},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179844351&doi=10.1145%2f3604237.3626908&partnerID=40&md5=e4445c73cda1d98ae2537cc4ded6d0b1},
	affiliations = {J.P. Morgan Ai Research, New York, NY, United States},
	abstract = {The rapidly evolving field of Robotic Process Automation (RPA) has made significant strides in automating repetitive processes, yet its effectiveness diminishes in scenarios requiring spontaneous or unpredictable tasks demanded by users. This paper introduces a novel approach, FlowMind, leveraging the capabilities of Large Language Models (LLMs) such as Generative Pretrained Transformer (GPT), to address this limitation and create an automatic workflow generation system. In FlowMind, we propose a generic prompt recipe for a lecture that helps ground LLM reasoning with reliable Application Programming Interfaces (APIs). With this, FlowMind not only mitigates the common issue of hallucinations in LLMs, but also eliminates direct interaction between LLMs and proprietary data or code, thus ensuring the integrity and confidentiality of information - a cornerstone in financial services. FlowMind further simplifies user interaction by presenting high-level descriptions of auto-generated workflows, enabling users to inspect and provide feedback effectively. We also introduce NCEN-QA, a new dataset in finance for benchmarking question-answering tasks from N-CEN reports on funds. We used NCEN-QA to evaluate the performance of workflows generated by FlowMind against baseline and ablation variants of FlowMind. We demonstrate the success of FlowMind, the importance of each component in the proposed lecture recipe, and the effectiveness of user interaction and feedback in FlowMind. © 2023 ACM.},
	author_keywords = {cognitive workflow; information retrieval; user query},
	keywords = {Information retrieval; Natural language processing systems; User interfaces; Applications programming interfaces; Cognitive workflow; Generation systems; Language model; Model reasonings; Process automation; Repetitive process; User interaction; User query; Work-flows; Application programming interfaces (API)},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070240-2},
	language = {English},
	abbrev_source_title = {ICAIF - ACM Int. Conf. AI Financ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{McGowan2023,
	author = {McGowan, Alessia and Gui, Yunlai and Dobbs, Matthew and Shuster, Sophia and Cotter, Matthew and Selloni, Alexandria and Goodman, Marianne and Srivastava, Agrima and Cecchi, Guillermo A. and Corcoran, Cheryl M.},
	title = {ChatGPT and Bard exhibit spontaneous citation fabrication during psychiatry literature search},
	year = {2023},
	journal = {Psychiatry Research},
	volume = {326},
	doi = {10.1016/j.psychres.2023.115334},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165713711&doi=10.1016%2fj.psychres.2023.115334&partnerID=40&md5=98cb9d045ca7154377e7aa08b55d008a},
	affiliations = {Icahn School of Medicine at Mount Sinai, New York, NY, United States; James J. Peters Veterans Administration, Bronx, NY, United States; IBM TJ Watson Research Center, Yorktown Heights, NY, United States},
	abstract = {ChatGPT (Generative Pre-Trained Transformer) is a large language model (LLM), which comprises a neural network that has learned information and patterns of language use from large amounts of text on the internet. ChatGPT, introduced by OpenAI, responds to human queries in a conversational manner. Here, we aimed to assess whether ChatGPT could reliably produce accurate references to supplement the literature search process. We describe our March 2023 exchange with ChatGPT, which generated thirty-five citations, two of which were real. 12 citations were similar to actual manuscripts (e.g., titles with incorrect author lists, journals, or publication years) and the remaining 21, while plausible, were in fact a pastiche of multiple existent manuscripts. In June 2023, we re-tested ChatGPT's performance and compared it to that of Google's GPT counterpart, Bard 2.0. We investigated performance in English, as well as in Spanish and Italian. Fabrications made by LLMs, including erroneous citations, have been called “hallucinations”; we discuss reasons for which this is a misnomer. Furthermore, we describe potential explanations for citation fabrication by GPTs, as well as measures being taken to remedy this issue, including reinforcement learning. Our results underscore that output from conversational LLMs should be verified. © 2023 Elsevier B.V.},
	author_keywords = {Artificial intelligence; Bard; ChatGPT; Citations; Fabrication; Large language models; Linguistic; Literature search; Natural language processing; References},
	keywords = {Communication; Dietary Supplements; Hallucinations; Humans; Language; Psychiatry; accuracy; Article; ChatGPT; citation analysis; large language model; natural language processing; psychiatry; reinforcement learning (machine learning); statistical error; dietary supplement; hallucination; human; interpersonal communication; language},
	correspondence_address = {C.M. Corcoran; Icahn School of Medicine at Mount Sinai, New York, United States; email: cheryl.corcoran@mssm.edu},
	publisher = {Elsevier Ireland Ltd},
	issn = {01651781},
	coden = {PSRSD},
	pmid = {37499282},
	language = {English},
	abbrev_source_title = {Psychiatry Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18}
}

@CONFERENCE{Bariah20236542,
	author = {Bariah, Lina and Zou, Hang and Zhao, Qiyang and Mouhouche, Belkacem and Bader, Faouzi and Debbah, Merouane},
	title = {Understanding Telecom Language Through Large Language Models},
	year = {2023},
	journal = {Proceedings - IEEE Global Communications Conference, GLOBECOM},
	pages = {6542 – 6547},
	doi = {10.1109/GLOBECOM54140.2023.10437725},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187391044&doi=10.1109%2fGLOBECOM54140.2023.10437725&partnerID=40&md5=e79e60e115b7eceefaf3df30537b41e8},
	affiliations = {Technology Innovation Institute, Abu Dhabi, 9639, United Arab Emirates; Khalifa University, Abu Dhabi, 127788, United Arab Emirates},
	abstract = {The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain. © 2023 IEEE.},
	author_keywords = {3GPP; Generative AI; Large Language Models; Pre-trained Transformer; Telecom Language},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23340983},
	isbn = {979-835031090-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Glob. Commun. Conf., GLOBECOM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fischer2023,
	author = {Fischer, Joel E},
	title = {Generative AI Considered Harmful},
	year = {2023},
	journal = {Proceedings of the 5th International Conference on Conversational User Interfaces, CUI 2023},
	doi = {10.1145/3571884.3603756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167780180&doi=10.1145%2f3571884.3603756&partnerID=40&md5=bfdb0e0fcce508fb5cd2a6db5b77741d},
	affiliations = {Mixed Reality Laboratory, School of Computer Science, University of Nottingham, United Kingdom},
	abstract = {The recent months have seen an explosion of interest, hype, and concern about generative AI, driven by the release of ChatGPT. In this article I seek to explicate some potential and actual harms of the engineering and use of generative AI such as ChatGPT. With this I also suggest a reframing for researchers with an interest in interaction. With this reframing I seek to provoke researchers to consider studying the settings of ChatGPT development and use as active sites of production. Research should focus on the organisational, technological and interactional practices and contexts in and through which generative AI and its outputs - harmful and otherwise - are produced, by whom, to what end, and with what consequences on societies.  © 2023 Owner/Author.},
	author_keywords = {ChatGPT; generative AI; GPT-3; GPT-4; Large Language Models; LLM; natural language; NLG; NLP; text generation},
	keywords = {Computer programming; ChatGPT; Generative AI; GPT-3; GPT-4; Language model; Large language model; LLM; Natural languages; NLG; Text generations; Natural language processing systems},
	correspondence_address = {J.E. Fischer; Mixed Reality Laboratory, School of Computer Science, University of Nottingham, United Kingdom; email: joel.fischer@nottingham.ac.uk},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070014-9},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Conversational User Interfaces, CUI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Nascimento20234674,
	author = {Nascimento, Nathalia and Alencar, Paulo and Cowan, Donald},
	title = {GPT-in-the-Loop: Supporting Adaptation in Multiagent Systems},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {4674 – 4683},
	doi = {10.1109/BigData59044.2023.10386490},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184981960&doi=10.1109%2fBigData59044.2023.10386490&partnerID=40&md5=4d26b5230d2c3607075f79c553d9e41d},
	affiliations = {University of Waterloo (UW), David R. Cheriton School of Computer Science, Waterloo, Canada},
	abstract = {This paper introduces the 'GPT-in-the-loop' approach, which seeks to investigate the reasoning capabilities of Large Language Models (LLMs) like Generative Pre-trained Transformers (GPT) within multiagent systems (MAS). Moving beyond traditional adaptive approaches that generally require long training processes, our framework employs GPT-4 to enhance problem-solving and explanation skills. To explore this approach, we apply it to a smart streetlight application in the Internet of Things (IoT) context, wherein each streetlight is controlled by an autonomous agent equipped with sensors and actuators, tasked with creating an energy-efficient lighting system. With the integration of GPT-4, these agents have shown enhanced decision-making and adaptability, without necessitating prolonged training. We compare this approach with both conventional neuroevolutionary methods and manually crafted solutions by software engineers, underscoring the potential of GPT-driven behavior in multiagent systems. It is important to note that these comparisons are preliminary, and further, more extensive testing is critical to determine the approach's applicability across a wider range of MAS scenarios. Structurally, the paper delineates the incorporation of GPT into the agent-driven Framework for the Internet of Things (FIoT), details our proposed GPT-in-the-loop approach, presents comparative results within the IoT setting, and concludes with insights and prospective future directions.  © 2023 IEEE.},
	author_keywords = {Generative pre-trained transformer (GPT); GPT-in-the-loop; LLM-in-the-loop; Multiagent system (MAS); self-adaptation},
	correspondence_address = {N. Nascimento; University of Waterloo (UW), David R. Cheriton School of Computer Science, Waterloo, Canada; email: nmoraesd@uwaterloo.ca},
	editor = {He J. and Palpanas T. and Hu X. and Cuzzocrea A. and Dou D. and Slezak D. and Wang W. and Gruca A. and Lin J.C.-W. and Agrawal R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032445-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sen202310480,
	author = {Sen, Indira and Assenmacher, Dennis and Samory, Mattia and Augenstein, Isabelle and van der Aalst, Wil and Wagner, Claudia},
	title = {People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {10480 – 10504},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184803430&partnerID=40&md5=dcaa391369fd482ec2ebda8a33cca694},
	affiliations = {RWTH Aachen University, Germany; University of Konstanz, Germany; GESIS - Leibniz Institute for Social Sciences, Germany; Sapienza University of Rome, Italy; University of Copenhagen, Denmark},
	abstract = {NLP models are used in a variety of critical social computing tasks, such as detecting sexist, racist, or otherwise hateful content. Therefore, it is imperative that these models are robust to spurious features. Past work has attempted to tackle such spurious features using training data augmentation, including Counterfactually Augmented Data (CADs). CADs introduce minimal changes to existing training data points and flip their labels; training on them may reduce model dependency on spurious features. However, manually generating CADs can be time-consuming and expensive. Hence in this work, we assess if this task can be automated using generative NLP models. We automatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate their usefulness in improving model robustness compared to manually-generated CADs. By testing both model performance on multiple out-of-domain test sets and individual data point efficacy, our results show that while manual CADs are still the most effective, CADs generated by ChatGPT come a close second. One key reason for the lower performance of automated methods is that the changes they introduce are often insufficient to flip the original label. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Computing-task; Data augmentation; Datapoints; Language detection; Model dependencies; Model robustness; Modeling performance; Social computing; Spurious features; Training data; Natural language processing systems},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Liu2023440,
	author = {Liu, Huihui and Azam, Mehreen and Bin Naeem, Salman and Faiola, Anthony},
	title = {An overview of the capabilities of ChatGPT for medical writing and its implications for academic integrity},
	year = {2023},
	journal = {Health Information and Libraries Journal},
	volume = {40},
	number = {4},
	pages = {440 – 446},
	doi = {10.1111/hir.12509},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173434724&doi=10.1111%2fhir.12509&partnerID=40&md5=59c1126085a676443b7e99290e0ccc8a},
	affiliations = {Shanxi University, Xiaodian District, Taiyuan, China; Department of Information Management, The Islamia University of Bahawalpur, Bahawalpur, Pakistan; Department of Health and Clinical Sciences, College of Health Sciences, University of Kentucky, Lexington, KY, United States},
	abstract = {The artificial intelligence (AI) tool ChatGPT, which is based on a large language model (LLM), is gaining popularity in academic institutions, notably in the medical field. This article provides a brief overview of the capabilities of ChatGPT for medical writing and its implications for academic integrity. It provides a list of AI generative tools, common use of AI generative tools for medical writing, and provides a list of AI generative text detection tools. It also provides recommendations for policymakers, information professionals, and medical faculty for the constructive use of AI generative tools and related technology. It also highlights the role of health sciences librarians and educators in protecting students from generating text through ChatGPT in their academic work. © 2023 Health Libraries Group.},
	author_keywords = {artificial intelligence (AI); librarians, health science; libraries, academic; plagiarism; students, medical},
	keywords = {Artificial Intelligence; Humans; Language; Librarians; Medical Writing; Schools; article; artificial intelligence; ChatGPT; human; human experiment; informatician; librarian; library; medical literature; medical school; plagiarism; artificial intelligence; language; school},
	correspondence_address = {M. Azam; Department of Information Management, The Islamia University of Bahawalpur, Bahawalpur, Pakistan; email: mehreenazam100@gmail.com},
	publisher = {John Wiley and Sons Inc},
	issn = {14711834},
	pmid = {37806782},
	language = {English},
	abbrev_source_title = {Health Inf. Libr. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lacey2023124,
	author = {Lacey, Melissa M. and Smith, David P.},
	title = {Teaching and assessment of the future today: higher education and AI},
	year = {2023},
	journal = {Microbiology Australia},
	volume = {44},
	number = {3},
	pages = {124 – 126},
	doi = {10.1071/MA23036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171849435&doi=10.1071%2fMA23036&partnerID=40&md5=9fc02f599d81ee4ebc2474221dc0afd2},
	affiliations = {Sheffield Hallam University, Howard Street, Sheffield, S1 1WB, United Kingdom},
	abstract = {Artificial intelligence (AI), once a subject of science fiction, is now a tangible, disruptive force in teaching and learning. In an educational setting, generative large language models (LLM), such as OpenAI's ChatGPT, perform and supplement tasks that usually require human thought, such as data analysis, understanding complex ideas, problem-solving, coding and producing written outputs. AI advances are moving quickly. From the emergence of ChatGPT 3.5 in November 2022, we have witnessed the arrival of other progressive language models, like OpenAI's GPT-4, Google's Bard AI and Microsoft's Bing AI. Most recently, AIs gained the ability to access real-time information, analyse images and are becoming directly embedded in many applications.  © 2023 CSIRO. All rights reserved.},
	keywords = {article; artificial intelligence; ChatGPT; data analysis; human; human experiment; learning; problem solving; teaching; tertiary education},
	correspondence_address = {M.M. Lacey; Sheffield Hallam University, Sheffield, Howard Street, S1 1WB, United Kingdom; email: m.lacey@shu.ac.uk},
	publisher = {CSIRO},
	issn = {13244272},
	language = {English},
	abbrev_source_title = {Microbiol.  Australia},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zamfirescu-Pereira2023,
	author = {Zamfirescu-Pereira, J.D. and Almeda, Shm Garanganao and Kim, Kyu Won and Hartmann, Bjoern},
	title = {Towards Image Design Space Exploration in Spreadsheets with LLM Formulae},
	year = {2023},
	journal = {UIST 2023 Adjunct - Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
	doi = {10.1145/3586182.3615790},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178264741&doi=10.1145%2f3586182.3615790&partnerID=40&md5=05c851d1917da9069594d83a5abf58ec},
	affiliations = {Eecs, Uc Berkeley, Berkeley, CA, United States},
	abstract = {Users of Text-to-Image (TTI) models like DALLĝ¢E and Stable Diffusion typically engage in a lot of iteration, exploring a design space with two main inputs: (1) prompt text spanning image content and style; and (2) stochastic (e.g., random seeds) and other opaque (e.g., classifier-free guidance) variables. Here, we demo an early prototype interface using a spreadsheet metaphor to enable exploration and display of multiple input changes simultaneously, and affording prompt-crafting using spreadsheet formula construction. New LLM-based functions aid rapid exploration of the prompt text input space, by generating new variations on existing prompts and context-relevant lists of prompt keyword options. © 2023 Owner/Author.},
	author_keywords = {design space exploration; generative AI; text to image},
	keywords = {Stochastic models; Stochastic systems; Design space exploration; Design spaces; Generative AI; Image content; Image modeling; Multiple inputs; Prototype interface; Random seeds; Stochastics; Text to image; Spreadsheets},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {979-840070096-5},
	language = {English},
	abbrev_source_title = {UIST Adjun. - Adjun. Proc. Annu. ACM Symp. User Interface Softw. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen20235267,
	author = {Chen, Zheng and He, Zhankui and McAuley, Julian and Jiang, Ziyan and Hou, Yupeng and Galstyan, Aram and Yang, Jie and Yang, Fan and Cho, Eunah and Hu, Xiaohua},
	title = {The First Workshop on Personalized Generative AI @ CIKM 2023: Personalization Meets Large Language Models},
	year = {2023},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5267 – 5270},
	doi = {10.1145/3583780.3615314},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178170015&doi=10.1145%2f3583780.3615314&partnerID=40&md5=18792f2e0588bfa2a7d3130983521f24},
	affiliations = {Amazon, Alexa, United States; University of California, San Diego, United States; Delft University of Technology, Netherlands; Drexel University, United States},
	abstract = {The First Workshop on Personalized Generative AI aims to be a cornerstone event fostering innovation and collaboration in the dynamic field of personalized AI. Leveraging the potent capabilities of Large Language Models (LLMs) to enhance user experiences with tailored responses and recommendations, the workshop is designed to address a range of pressing challenges including knowledge gap bridging, hallucination mitigation, and efficiency optimization in handling extensive user profiles. As a nexus for academics and industry professionals, the event promises rich discussions on a plethora of topics such as the development and fine-tuning of foundational models, strategies for multi-modal personalization, and the imperative ethical and privacy considerations in LLM deployment. Through a curated series of keynote speeches, insightful panel discussions, and hands-on sessions, the workshop aspires to be a catalyst in the development of more precise, contextually relevant, and user-centric AI systems. It aims to foster a landscape where generative AI systems are not only responsive but also anticipatory of individual user needs, marking a significant stride in personalized experiences. © 2023 Copyright held by the owner/author(s).},
	author_keywords = {Generative AI; Large Language Models; Personalization},
	keywords = {Computational linguistics; User profile; AI systems; Dynamic fields; Efficiency optimization; Generative AI; Knowledge gaps; Language model; Large language model; Personalizations; Pressung; Users' experiences; Knowledge management},
	publisher = {Association for Computing Machinery},
	isbn = {979-840070124-5},
	language = {English},
	abbrev_source_title = {Int Conf Inf Knowledge Manage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Scanlon2023,
	author = {Scanlon, Mark and Breitinger, Frank and Hargreaves, Christopher and Hilgert, Jan-Niclas and Sheppard, John},
	title = {ChatGPT for digital forensic investigation: The good, the bad, and the unknown},
	year = {2023},
	journal = {Forensic Science International: Digital Investigation},
	volume = {46},
	doi = {10.1016/j.fsidi.2023.301609},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175350369&doi=10.1016%2fj.fsidi.2023.301609&partnerID=40&md5=29d86465cb0df4623f2c0dde34d7cc76},
	affiliations = {Forensics and Security Research Group, School of Computer Science, University College Dublin, Ireland; School of Criminal Justice, University of Lausanne, Lausanne, Switzerland; Department of Computer Science, University of Oxford, United Kingdom; Fraunhofer FKIE, Bonn, Germany; Department of Computing and Mathematics, South East Technological University, Waterford, Ireland},
	abstract = {The disruptive application of ChatGPT (GPT-3.5, GPT-4) to a variety of domains has become a topic of much discussion in the scientific community and society at large. Large Language Models (LLMs), e.g., BERT, Bard, Generative Pre-trained Transformers (GPTs), LLaMA, etc., have the ability to take instructions, or prompts, from users and generate answers and solutions based on very large volumes of text-based training data. This paper assesses the impact and potential impact of ChatGPT on the field of digital forensics, specifically looking at its latest pre-trained LLM, GPT-4. A series of experiments are conducted to assess its capability across several digital forensic use cases including artefact understanding, evidence searching, code generation, anomaly detection, incident response, and education. Across these topics, its strengths and risks are outlined and a number of general conclusions are drawn. Overall this paper concludes that while there are some potential low-risk applications of ChatGPT within digital forensics, many are either unsuitable at present, since the evidence would need to be uploaded to the service, or they require sufficient knowledge of the topic being asked of the tool to identify incorrect assumptions, inaccuracies, and mistakes. However, to an appropriately knowledgeable user, it could act as a useful supporting tool in some circumstances. © 2023 The Author(s)},
	author_keywords = {Artificial intelligence; ChatGPT; Digital forensics; Generative pre-trained transformers (GPT); Large language models (LLM)},
	keywords = {Anomaly detection; Computational linguistics; Computer crime; Electronic crime countermeasures; Risk perception; ChatGPT; Forensic investigation; Generative pre-trained transformer; Language model; Large language model; Large volumes; Potential impacts; Scientific community; Scientific society; Training data; Digital forensics},
	correspondence_address = {M. Scanlon; Forensics and Security Research Group, School of Computer Science, University College Dublin, Ireland; email: mark.scanlon@ucd.ie},
	publisher = {Elsevier Ltd},
	issn = {26662825},
	language = {English},
	abbrev_source_title = {For. Sci. Int: Dig. Investigation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Wang2023233,
	author = {Wang, Yiding and Chen, Kai and Tan, Haisheng and Guo, Kun},
	title = {Tabi: An Efficient Multi-Level Inference System for Large Language Models},
	year = {2023},
	journal = {Proceedings of the 18th European Conference on Computer Systems, EuroSys 2023},
	pages = {233 – 248},
	doi = {10.1145/3552326.3587438},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160213896&doi=10.1145%2f3552326.3587438&partnerID=40&md5=9de81e8a02a2a4c616232242cc0f82c9},
	affiliations = {iSING Lab, Hong Kong University of Science and Technology, Hong Kong; University of Science and Technology of China, China; Fuzhou University, China},
	abstract = {Today’s trend of building ever larger language models (LLMs), while pushing the performance of natural language processing, adds significant latency to the inference stage. We observe that due to the diminishing returns of adding parameters to LLMs, a smaller model could make the same prediction as a costly LLM for a majority of queries. Based on this observation, we design Tabi, an inference system with a multi-level inference engine that serves queries using small models and optional LLMs for demanding applications. Tabi is optimized for discriminative models (i.e., not generative LLMs) in a serving framework. Tabi uses the calibrated confidence score to decide whether to return the accurate results of small models extremely fast or re-route them to LLMs. For re-routed queries, it uses attention-based word pruning and weighted ensemble techniques to offset the system overhead and accuracy loss. We implement and evaluate Tabi with multiple tasks and models. Our result shows that Tabi achieves 21%-40% average latency reduction (with comparable tail latency) over the state-of-the-art while meeting LLM-grade high accuracy targets. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {attention-based transformer; machine learning inference},
	keywords = {Computational linguistics; Learning algorithms; Natural language processing systems; Attention-based transformer; Inference stages; Inference systems; Language model; Language processing; Machine learning inference; Machine-learning; Multilevels; Natural languages; Performance; Machine learning},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039487-1},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Comput. Syst., EuroSys},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Qian202313,
	author = {Qian, Ming and Wu, Huaqing and Yang, Lenny and Wan, Arthur},
	title = {Augmented Machine Translation Enabled by GPT4: Performance Evaluation on Human-Machine Teaming Approaches},
	year = {2023},
	journal = {NLP4TIA 2023 - 1st Workshop on Natural Language Processing Tools and Resources for Translation and Interpreting Applications, associated with the 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023 - Proceedings},
	pages = {13 – 19},
	doi = {10.26615/978-954-452-091-5_004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184997465&doi=10.26615%2f978-954-452-091-5_004&partnerID=40&md5=bfe193151a77866b0a92a643cdcbc1dd},
	affiliations = {PathFinders Translation and Interpretation Research, Cambridge, MA, United States; American Translators Association (ATA) Certified Translator, United States; Canadian Translators,Terminologists,Interpreters Council (CTTIC) Certified Translator, Canada},
	abstract = {Translation has been modeled as a multiple-phase process where pre-editing analyses guide meaning transfer and interlingual restructure. Present-day machine translation (MT) tools provide no means for source text analyses. Generative AI with Large language modeling (LLM), equipped with prompt engineering and fine-tuning capabilities, can enable augmented MT solutions by explicitly including AI or human generated analyses/instruction, and/or human-generated reference translation as pre-editing or interactive inputs. Using an English-to-Chinese translation piece that had been carefully studied during a translator slam event, Fourt types of translation outputs on 20 text segments were evaluated: human-generated translation, Google Translate MT, instruction-augmented MT using GPT4-LLM, and Human-Machine-Teaming (HMT)-augmented translation based on both human reference translation and instruction using GPT4-LLM. While human translation had the best performance, both augmented MT approaches performed better than un-augmented MT. The HMT-augmented MT performed better than instruction-augmented MT because it combined the guidance and knowledge provided by both human reference translation and style instruction. However, since it is unrealistic to generate sentence-by-sentence human translation as MT input, better approaches to HMT-augmented MT need to be invented. The evaluation showed that generative AI with LLM can enable new MT workflow facilitating pre-editing analyses and interactive restructuring and achieving better performance. © NLP4TIA 2023 - 1st Workshop on Natural Language Processing Tools and Resources for Translation and Interpreting Applications, associated with the 14th International Conference on Recent Advances in Natural Language Processing, RANLP 2023 - Proceedings.},
	keywords = {Computational linguistics; Computer aided language translation; Modeling languages; Natural language processing systems; Fine tuning; Human-machine; Language model; Machine translations; Performance; Performances evaluation; Source text; Text analysis; Translation tools; Tuning capability; Machine translation},
	correspondence_address = {M. Qian; PathFinders Translation and Interpretation Research, Cambridge, United States; email: qianmi@pathfinders-transinterp.com},
	editor = {Gutierrez R.L. and Escribe M. and Mihajlov T. and Kunilovskaya M. and Mitkov R.},
	publisher = {Incoma Ltd},
	isbn = {978-954452091-5},
	language = {English},
	abbrev_source_title = {NLP4TIA - Workshop Nat. Lang. Process. Tools Resour. Transl. Interpret. Appl., assoc. Int. Conf. Recent Adv. Nat. Lang. Process., RANLP - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Xie20233892,
	author = {Xie, Yutong and Pan, Zhaoying and Ma, Jinge and Jie, Luo and Mei, Qiaozhu},
	title = {A Prompt Log Analysis of Text-to-Image Generation Systems},
	year = {2023},
	journal = {ACM Web Conference 2023 - Proceedings of the World Wide Web Conference, WWW 2023},
	pages = {3892 – 3902},
	doi = {10.1145/3543507.3587430},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151382509&doi=10.1145%2f3543507.3587430&partnerID=40&md5=309a3465a8de1d07a71ff62b8ce6401b},
	affiliations = {University of Michigan, Ann Arbor, MI, United States; Niantic Inc., San Francisco, CA, United States},
	abstract = {Recent developments in large language models (LLM) and generative AI have unleashed the astonishing capabilities of text-to-image generation systems to synthesize high-quality images that are faithful to a given reference text, known as a "prompt". These systems have immediately received lots of attention from researchers, creators, and common users. Despite the plenty of efforts to improve the generative models, there is limited work on understanding the information needs of the users of these systems at scale. We conduct the first comprehensive analysis of large-scale prompt logs collected from multiple text-to-image generation systems. Our work is analogous to analyzing the query logs of Web search engines, a line of work that has made critical contributions to the glory of the Web search industry and research. Compared with Web search queries, text-to-image prompts are significantly longer, often organized into special structures that consist of the subject, form, and intent of the generation tasks and present unique categories of information needs. Users make more edits within creation sessions, which present remarkable exploratory patterns. There is also a considerable gap between the user-input prompts and the captions of the images included in the open training data of the generative models. Our findings provide concrete implications on how to improve text-to-image generation systems for creation purposes. © 2023 ACM.},
	author_keywords = {AI for Creativity; AI-Generated Content (AIGC); Prompt Analysis; Query Log Analysis; Text-to-Image Generation},
	keywords = {Image analysis; Image enhancement; Information retrieval; Websites; AI for creativity; AI-generated content; Generative model; Image generations; Image-generation systems; Language model; Log analysis; Prompt analyse; Query log analysis; Text-to-image generation; Search engines},
	correspondence_address = {Y. Xie; University of Michigan, Ann Arbor, United States; email: yutxie@umich.edu; Z. Pan; University of Michigan, Ann Arbor, United States; email: panzy@umich.edu; J. Ma; University of Michigan, Ann Arbor, United States; email: jingema@umich.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039416-1},
	language = {English},
	abbrev_source_title = {ACM Web Conf. - Proc. World Wide Web Conf., WWW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@CONFERENCE{Kaplunovich20234654,
	author = {Kaplunovich, Alex},
	title = {Wealth of Nations, Wealth of Data: How GDP Shapes Diverse Large Language Models like ChatGPT : Interviewing Assorted Open Source Generative AI Models},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {4654 – 4663},
	doi = {10.1109/BigData59044.2023.10386329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184984824&doi=10.1109%2fBigData59044.2023.10386329&partnerID=40&md5=1b68921e75aa53a65983c355fe5064e8},
	affiliations = {University of Maryland, Department of Computer Science, Baltimore, 21250, MD, United States},
	abstract = {Generative large language models (such as ChatGPT) are increasingly influencing various aspects of our lives, partly due to their training on vast datasets that encompassing big data paradigms and range of topics. 'Intervista,' an award-winning Italian film by Federico Fellini, focuses on his interview with a Japanese TV crew. Inspired by this, we conducted interviews with a diverse set of open-source and OpenAI models to explore various political, economic, and cultural aspects of life, evaluating LLM performance. We also examined whether a correlation exists between a country's GDP per capita and the quality of the model's answers. To this end, we utilized a Huggingface model leaderboard to select appropriate models and deployed them in an AWS SageMaker GPU environment. The identical questions were posed about nearly 200 countries, and the responses were analyzed to verify their accuracy and correlation with Gross Domestic Product (GDP). We were amazed by the diversity, quantity, and quality of existing pretrained open-source LLMs. Our journey provided insights into model selection, inference pipeline automation, GPU configuration, generated texts benchmarking, and systematic evaluation of model quality. Overall, leading LLMs performed well, providing reasonable responses for many countries. However, we discovered that the depth and detail of the answers were influenced by a country's GDP per capita, with higher-income nations receiving more accurate responses.  © 2023 IEEE.},
	author_keywords = {Automation; AWS Sagemaker; ChatGPT; GDP per capita; Generative AI; Huggingface; Inference Analysis; LLM},
	correspondence_address = {A. Kaplunovich; University of Maryland, Department of Computer Science, Baltimore, 21250, United States; email: akaplun1@umbc.edu},
	editor = {He J. and Palpanas T. and Hu X. and Cuzzocrea A. and Dou D. and Slezak D. and Wang W. and Gruca A. and Lin J.C.-W. and Agrawal R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032445-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Shukla20232866,
	author = {Shukla, Neelesh K and Katikeri, Raghu and Raja, Msp and Sivam, Gowtham and Yadav, Shlok and Vaid, Amit and Prabhakararao, Shreenivas},
	title = {Investigating Large Language Models for Financial Causality Detection in Multilingual Setup},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {2866 – 2871},
	doi = {10.1109/BigData59044.2023.10386558},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184980349&doi=10.1109%2fBigData59044.2023.10386558&partnerID=40&md5=40e8fdbb12bcb6987434b032d93dc7f5},
	affiliations = {Artificial Intelligence Group State Street Corporation, Bengaluru, India; Artificial Intelligence Group State Street Corporation, Hyderabad, India},
	abstract = {This paper presents our contribution to the Financial Document Causality Detection (FinCausal) task, a component of the FNP-2023 workshop. The FinCausal challenge centers on the extraction of cause-and-effect relationships from financial texts written in both English and Spanish. Recent advancements in Generative AI and Large Language Models (LLMs) have instigated investigations into their reasoning abilities, propelling our exploration of LLMs' potential for causal reasoning within the financial domain. This study also ventures into the domain of non-English languages, aiming to uncover the capacity of LLMs on this front as well. Our investigation revealed that LLMs exhibit a remarkable ability to identify causal relationships, particularly when provided with few task-specific relevant examples. Additionally, our research demonstrates the effectiveness of LLMs in processing non-English languages when given the same English prompts along with language comprehension instructions. We conducted a comparative analysis between OpenAI GPT3.5 and 4, concluding that GPT-4 model is better-suited for this purpose. Our study unveils that LLMs yield semantically similar cause and effects. This discovery highlights LLMs don't rely solely on content for the predictions and so the necessity of adopting an evaluation approach for this task, one that emphasizes also on semantic similarity metrics.  © 2023 IEEE.},
	author_keywords = {Causal; Financial; Generative AI; LLM; Reasoning},
	correspondence_address = {N.K. Shukla; Artificial Intelligence Group State Street Corporation, Bengaluru, India; email: nshukla@statestreet.com},
	editor = {He J. and Palpanas T. and Hu X. and Cuzzocrea A. and Dou D. and Slezak D. and Wang W. and Gruca A. and Lin J.C.-W. and Agrawal R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032445-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Elhiny2023,
	author = {Elhiny, Lamees and Ye, Xinfeng and Speidel, Ulrich and Manoharan, Sathiamoorthy},
	title = {A Systematic Review of Recent Research on Chatbots},
	year = {2023},
	journal = {4th International Conference on Electrical, Communication and Computer Engineering, ICECCE 2023},
	doi = {10.1109/ICECCE61019.2023.10442532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187217239&doi=10.1109%2fICECCE61019.2023.10442532&partnerID=40&md5=6afa8b84c58221e810f4b2d504fe76b6},
	affiliations = {School of Computer Science, University of Auckland, New Zealand},
	abstract = {Chatbots, most notably the generative pre-trained transformer for chat (ChatGPT), have seamlessly integrated into our daily lives. Nearly every website now features a chatbot, emulating human interaction to dispense information and address inquiries. While chatbots appear in diverse forms, including physical embodiments and voice-responsive systems, our emphasis is on software-based chatbots proficient in leveraging Natural Language Processing (NLP) to understand text and provide textual responses. This paper employs a systematic review methodology for article selection, listing the most relevant and recent publications related to chatbots, with a particular focus on works cantered on ChatGPT. Furthermore, the selected articles are categorized, and prevailing publication trends are examined. This endeavor aims to offer a valuable compendium of literature for scholars and educators interested in the domain of NLP and its associated Artificial Intelligence techniques. © 2023 IEEE.},
	author_keywords = {chatbots; chatgpt; generative AI; LLMs},
	keywords = {Chatbots; Chatgpt; Daily lives; Generative AI; Humaninteraction; Language processing; LLM; Natural languages; Recent researches; Systematic Review; Natural language processing systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835036969-4},
	language = {English},
	abbrev_source_title = {Int. Conf. Electr., Commun. Comput. Eng., ICECCE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Norheim2023,
	author = {Norheim, Johannes J. and de Weck, Olivier L.},
	title = {Large Language Model Applications to Space Systems Engineering},
	year = {2023},
	journal = {Proceedings of the International Astronautical Congress, IAC},
	volume = {2023-October},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187980718&partnerID=40&md5=759795a2bf6287759e54465adf9c53de},
	affiliations = {Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, 02143, MA, United States},
	abstract = {Recent developments in large language models (LLM) have made them the topic of much media coverage and made the technology accessible to the general audience, including space systems engineers. Past research has explored the application of natural language processing to space systems, notably engineering document analysis. Most of the research has focused on requirements engineering and analysis of mission design descriptions. Past research has also explored the concept of virtual assistants for a broader scope of applications; however, the solutions proposed often require significant setup efforts. This paper explores a broad scope of systems engineering applications with pre-trained large language models requiring minimal setup. We focus on the systems design and technical management processes in NASA's systems engineering engine. We focus on the application of the pre-trained LLM GPT4 and show atomic case studies for stakeholder expectations definition, technical requirements definition, logical decomposition, design solution definition, and technical data management. We conduct a qualitative analysis of the performance of the output generated by the LLM. Our main findings are that the LLM produces meaningful output but also produces additional information that might be irrelevant or not necessary for the task. We also did not observe any hallucinations. One major result we observe is the ease for the LLM to generate system models based on only a few examples from the modeling language. These results encourage further research at a larger scale. We remark on the need for a benchmarking dataset, based on input from experts, to test the validity of this technology before an industrial-scale application of LLMs to assist with systems engineering. Copyright © 2023 by the International Astronautical Federation (IAF). All rights reserved.},
	author_keywords = {Generative Pre-trained Transformers (GPT); Large Language Models; Natural Language Processing; Space Systems; Systems Engineering},
	correspondence_address = {J.J. Norheim; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, 02143, United States; email: norheim@mit.edu},
	publisher = {International Astronautical Federation, IAF},
	issn = {00741795},
	language = {English},
	abbrev_source_title = {Proc. Int. Astronaut. Congr., IAC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Orchard20239,
	author = {Orchard, Tim and Tasiemski, Leszek},
	title = {The rise of Generative AI and possible effects on the economy},
	year = {2023},
	journal = {Economics and Business Review},
	volume = {9},
	number = {2},
	pages = {9 – 26},
	doi = {10.18559/ebr.2023.2.732},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168381943&doi=10.18559%2febr.2023.2.732&partnerID=40&md5=24541d063e98f19cb027e06bd3a03c6b},
	affiliations = {WithSecure (WITH.HE), 77 Weston Street, London, SE1 3RS, United Kingdom; WithSecure (WITH.HE), ul. Rataje 164, Poznań, 61-168, Poland},
	abstract = {The aim of the paper is to analyse the likely implications of Generative AI (GAI) on various aspects of business and the economy. Amid the rapid growth and maturing of Generative AI technologies such as Large Language Models (like ChatGPT by OpenAI) a rapid growth of both immediate and potential applications can be seen. The implications for the economy and industries of this technological shift will be discussed. The foreseeable scenarios for the level and types of adoption that GAI might achieve - from useful analytical tool, invaluable assistant to the white-collar workers of the world to being trusted with a wide array of business and life-critical decision making. Both disruptive and premium service opportunities are foreseen. For instance, general purpose models may provide quality service - such as copywriting - to overserved customers leaving human writers as the premium option. In this context, overserved customers would be those who would be satisfied with a non-human, potentially less creative content. On the other hand highly specialized models - specifically trained in a given domain and with access to proprietary knowledge can possibly provide a premium service over that provided by human experts. It is expected that some jobs will be replaced by new AI applications. However, new workplaces will emerge. Not only the obvious expert-level data scientist roles but also low grade, "model supervisors"- people training the models, assessing the quality of responses given and handling escalations. Lastly new cybercrime risks emerging from the rise of GAI are discussed.  © 2023 Tim Orchard et al., published by Sciendo.},
	author_keywords = {artificial intelligence (AI); business models; disruptive technology; Generative AI; Large Language Models (LLM)},
	correspondence_address = {L. Tasiemski; WithSecure (WITH.HE), Poznań, ul. Rataje 164, 61-168, Poland; email: leszek.tasiemski@withsecure.com},
	publisher = {Sciendo},
	issn = {23921641},
	language = {English},
	abbrev_source_title = {Econ. Bus. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Jeon202315873,
	author = {Jeon, Jaeho and Lee, Seongyong},
	title = {Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT},
	year = {2023},
	journal = {Education and Information Technologies},
	volume = {28},
	number = {12},
	pages = {15873 – 15892},
	doi = {10.1007/s10639-023-11834-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156169134&doi=10.1007%2fs10639-023-11834-1&partnerID=40&md5=184dd700327e0ff96bee09828119a3d7},
	affiliations = {Department of Literacy, Culture, and Language Education, Indiana University, 107 S. Indiana Avenue, Bloomington, 47405-7000, IN, United States; Department of English Education, Hannam University, 70 Hannam-Ro, Daedeok-Gu, Daejeon, 34430, South Korea},
	abstract = {Artificial Intelligence (AI) is developing in a manner that blurs the boundaries between specific areas of application and expands its capability to be used in a wide range of applications. The public release of ChatGPT, a generative AI chatbot powered by a large language model (LLM), represents a significant step forward in this direction. Accordingly, professionals predict that this technology will affect education, including the role of teachers. However, despite some assumptions regarding its influence on education, how teachers may actually use the technology and the nature of its relationship with teachers remain under-investigated. Thus, in this study, the relationship between ChatGPT and teachers was explored with a particular focus on identifying the complementary roles of each in education. Eleven language teachers were asked to use ChatGPT for their instruction during a period of two weeks. They then participated in individual interviews regarding their experiences and provided interaction logs produced during their use of the technology. Through qualitative analysis of the data, four ChatGPT roles (interlocutor, content provider, teaching assistant, and evaluator) and three teacher roles (orchestrating different resources with quality pedagogical decisions, making students active investigators, and raising AI ethical awareness) were identified. Based on the findings, an in-depth discussion of teacher-AI collaboration is presented, highlighting the importance of teachers’ pedagogical expertise when using AI tools. Implications regarding the future use of LLM-powered chatbots in education are also provided. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {AIEd; Artificial intelligence; Chatbot; ChatGPT; Human–computer interaction; Large language model; Large language model-powered chatbot},
	correspondence_address = {S. Lee; Department of English Education, Hannam University, Daejeon, 70 Hannam-Ro, Daedeok-Gu, 34430, South Korea; email: seongyonglee77@gmail.com},
	publisher = {Springer},
	issn = {13602357},
	language = {English},
	abbrev_source_title = {Educ. Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38}
}

@ARTICLE{Wong2023253,
	author = {Wong, IpKin Anthony and Lian, Qi Lilith and Sun, Danni},
	title = {Autonomous travel decision-making: An early glimpse into ChatGPT and generative AI},
	year = {2023},
	journal = {Journal of Hospitality and Tourism Management},
	volume = {56},
	pages = {253 – 263},
	doi = {10.1016/j.jhtm.2023.06.022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164323047&doi=10.1016%2fj.jhtm.2023.06.022&partnerID=40&md5=d8d0ab36d224b1441966f3bc67dfdf77},
	affiliations = {Faculty of Business Administration, University of Macau, Avenida da Universidade, Taipa, China; School of Tourism Management, Sun Yat-Sen University, Tangzhou Rd. 1, Zhuhai, China; Key Laboratory of Sustainable Tourism Smart Assessment Technology, Ministry of Culture and Tourism, China},
	abstract = {Generative AI technologies, including large language models (LLMs), have the potential to bring significant advancements to the tourism and hospitality industry through an array of ingenious features. ChatGPT, as a type of generative AI, is a state-of-the-art LLM that is bundled with extensive capabilities. This commentary provides an early snapshot of ChatGPT's ability to enhance the tourist decision-making process in the pre-trip, en-route, and post-trip stages. Particularly, ChatGPT greatly differentiates itself from the traditional travel decision-making process by putting the tourist in the driver's seat to actively probe for highly relevant information through a question-and-answer mode. In this research note, we present different scenarios with cases demonstrating how ChatGPT can improve tourists' experience in these three travel stages, with trip planning efficiency, customized recommendations, 24/7 personal assistant, AI-mediated communication fluency, autonomous guided tours, enriched sharing experience, and AI-induced prolonged satisfaction. In summary, these value-added autonomous services provide tourists with travel solutions that are highly cost-effective, offering customized information that allows them to travel with ease. © 2023 The Authors},
	author_keywords = {ChatGPT; Decision-making; Generative AI; Planning; Tourism},
	correspondence_address = {Q.L. Lian; School of Tourism Management, Sun Yat-Sen University, Zhuhai, Tangzhou Rd. 1, China; email: lianq33@mail2.sysu.edu.cn; D. Sun; School of Tourism Management, Sun Yat-Sen University, Zhuhai, Tangzhou Rd. 1, China; email: sundn5@mail2.sysu.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {14476770},
	language = {English},
	abbrev_source_title = {J. Hosp. Tour. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Chaddad2023439,
	author = {Chaddad, Ahmad and He, Changhong and Jiang, Yuchen},
	title = {ChatGPT: An Artificial Intelligence-Based Approach to Enhance Medical Applications},
	year = {2023},
	journal = {Proceedings - 2023 IEEE 23rd International Conference on Bioinformatics and Bioengineering, BIBE 2023},
	pages = {439 – 446},
	doi = {10.1109/BIBE60311.2023.00078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186510061&doi=10.1109%2fBIBE60311.2023.00078&partnerID=40&md5=02ce1c7945fc72e432f5fc9ca95e4576},
	affiliations = {School of Artificial Intelligence, Guilin University of Electronic Technology, Guangxi, Guilin, China; The Laboratory for Imagery, Vision and Artificial Intelligence, École de Technologie Supérieure, Montreal, QC, Canada},
	abstract = {The rapid advancement of generative artificial intelligence (AI) has initiated transformative changes in diverse sectors, the medical field being a prominent beneficiary. This article provides a comprehensive exploration of the impact of AI in medicine, delineating the range of opportunities and challenges that accompany its adoption. Many existing medical algorithms, while valuable, exhibit a propensity for singular-task orientation, potentially leading to suboptimal interactions and systemic disruption. This paper examines the potential of large language models (LLMs), such as ChatGPT, to improve medical algorithms. It discusses the basic principles of LLM and provides a detailed analysis of ChatGPT, highlighting its exceptional interactive capabilities. Additionally, the study evaluates the real-world applications of ChatGPT in the medical domain, comparing its performance with other leading LLMs through clinically relevant experiments and rigorous analysis. Although ChatGPT is still in its basic versions, this work emphasizes the need to explore and improve its capabilities for medical applications to improve interaction and reduce human costs in the future. © 2023 IEEE.},
	author_keywords = {AI; ChatGPT; Generative Pre-training Transformer},
	keywords = {Artificial intelligence; Artificial intelligence in medicine; Basic principles; ChatGPT; Generative pre-training transformer; Language model; Medical domains; Medical fields; Pre-training; Real-world; Task orientation; Medical applications},
	correspondence_address = {A. Chaddad; School of Artificial Intelligence, Guilin University of Electronic Technology, Guilin, Guangxi, China; email: ahmad8chaddad@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039311-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Bioinform. Bioeng., BIBE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Piggott2023287,
	author = {Piggott, Brett and Patil, Siddhant and Feng, Guohuan and Odat, Ibrahim and Mukherjee, Rajdeep and Dharmalingam, Balakrishnan and Liu, Anyi},
	title = {Net-GPT: A LLM-Empowered Man-in-the-Middle Chatbot for Unmanned Aerial Vehicle},
	year = {2023},
	journal = {Proceedings - 2023 IEEE/ACM Symposium on Edge Computing, SEC 2023},
	pages = {287 – 293},
	doi = {10.1145/3583740.3626809},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186120962&doi=10.1145%2f3583740.3626809&partnerID=40&md5=e2c6855449081b02c720a77217ca0da0},
	affiliations = {Oakland University, Department of Computer Science and Engineering, Rochester, MI, United States; University of Wisconsin, Department of Computer Science, Madison, WI, United States},
	abstract = {In the dynamic realm of AI, integrating Large Language Models (LLMs) with security systems reshape cybersecurity. LLMs bolster defense against cyber threats but also introduce risks, aiding adver-saries in generating malicious content, discovering vulnerabilities, and distorting perceptions. This paper presents Net-GPT, an LLM-empowered offensive chatbot that understands network protocols and launches Unmanned Aerial Vehicles (UAV)-based Man-in-the-middle (MITM) attacks against a hijack communication between UAV and Ground Control Stations (GCS). Facilitated by an edge server equipped with finely tuned LLMs, Net-GPT crafts mimicked network packets between UAV and GCS. Leveraging the adaptabil-ity of popular LLMs, Net-GPT produces context-aligned network packets. We fine-tune and assess Net-GPT's LLM-based efficacy, showing its impressive generative accuracy: 95.3% for Llama-2-13B and 94.1% for Llama-2-7B. Smaller LLMs, such as Distil-GPT-2, reach 77.9% predictive capability of Llama-2-7B but are 47x faster. Cost-efficiency tests highlight model quality's impact on accuracy while fine-tuning data quantity enhances predictability on spe-cific metrics. It holds great potential to be used in edge-computing environments with amplified computing capability. © 2023 ACM.},
	author_keywords = {Cyber Attack; Large Language Model; Man-in-the-Middle (MITM); System Security},
	keywords = {Antennas; Computational linguistics; Cyber attacks; Network protocols; Network security; Risk perception; Rock mechanics; Vehicle to vehicle communications; Aerial vehicle; Chatbots; Cyber-attacks; Ground-control stations; Language model; Large language model; Man in the middle; Man-in-the-middle; System security; Vehicle Control; Unmanned aerial vehicles (UAV)},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-840070123-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Symp. Edge Comput., SEC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Luukkonen20232710,
	author = {Luukkonen, Risto and Komulainen, Ville and Luoma, Jouni and Eskelinen, Anni and Kanerva, Jenna and Kupari, Hanna-Mari and Ginter, Filip and Laippala, Veronika and Muennighoff, Niklas and Piktus, Aleksandra and Wang, Thomas and Tazi, Nouamane and Scao, Teven Le and Wolf, Thomas and Suominen, Osma and Sairanen, Samuli and Merioksa, Mikko and Heinonen, Jyrki and Vahtola, Aija and Antao, Samuel and Pyysalo, Sampo},
	title = {FinGPT: Large Generative Models for a Small Language},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {2710 – 2726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177769563&partnerID=40&md5=0a0a8d4f206a99ac3d8353c5fd6df841},
	affiliations = {TurkuNLP Group, University of Turku, Finland; Hugging Face; National Library of Finland, Finland; AMD},
	abstract = {Large language models (LLMs) excel in many tasks in NLP and beyond, but most open models have very limited coverage of smaller languages and LLM work tends to focus on languages where nearly unlimited data is available for pretraining. In this work, we study the challenges of creating LLMs for Finnish, a language spoken by less than 0.1% of the world population. We compile an extensive dataset of Finnish combining web crawls, news, social media and eBooks. We pursue two approaches to pretrain models: 1) we train seven monolingual models from scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the pretraining of the multilingual BLOOM model on a mix of its original training data and Finnish, resulting in a 176 billion parameter model we call BLUUMI. For model evaluation, we introduce FIN-bench, a version of BIG-bench with Finnish tasks. We also assess other model qualities such as toxicity and bias. Our models and tools are openly available at https://turkunlp.org/gpt3-finnish. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; HTTP; Natural language processing systems; E-books; Excel; Finnish; Generative model; Language model; Parameter model; Pre-training; Social media; Training data; World population; Web crawler},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Feldstein2023117,
	author = {Feldstein, Steven},
	title = {The Consequences of Generative AI for Democracy, Governance and War},
	year = {2023},
	journal = {Survival},
	volume = {65},
	number = {5},
	pages = {117 – 142},
	doi = {10.1080/00396338.2023.2261260},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173443868&doi=10.1080%2f00396338.2023.2261260&partnerID=40&md5=d62dbd01fbef80e9f8119c79d6dc7e7c},
	affiliations = {Democracy, Conflict, and Governance Program at the Carnegie Endowment for International Peace, United States},
	abstract = {The potential impact of generative AI across politics, governance and war is enormous, and is the subject of considerable speculation informed by few hard facts. Yet it is possible to identify some major challenges. They include threats to democracies by privately controlled models that gain tremendous power to shape discourse and affect democratic deliberation; enhanced surveillance and propaganda dissemination by authoritarian regimes; new capacities for criminal and terrorist actors to carry out cyber attacks and related disruptions; and transformed war planning and military operations reflecting the accelerated dehumanisation of lethal force. While new innovations historically require time to take root, generative AI is likely to be adopted swiftly. Stakeholders must formulate pragmatic approaches to manage oncoming risks. © 2023 The International Institute for Strategic Studies.},
	author_keywords = {Artificial intelligence (AI); chatbots; ChatGPT; cyber attacks; large language model (LLM); military planning; propaganda; surveillance},
	publisher = {Routledge},
	issn = {00396338},
	language = {English},
	abbrev_source_title = {Survival},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Albared2023399,
	author = {Albared, Doha and Hamoud, Hadi and Zaraket, Fadi A.},
	title = {Arabic Topic Classification in the Generative and AutoML Era},
	year = {2023},
	journal = {ArabicNLP 2023 - 1st Arabic Natural Language Processing Conference, Proceedings},
	pages = {399 – 404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184516183&partnerID=40&md5=e19ab942eff62531c62341ce4b56e748},
	affiliations = {Arab Center for Research and Policy Studies, Doha, Qatar},
	abstract = {Most recent models for Arabic topic classification leveraged fine-tuning existing pre-trained transformer models and targeted a limited number of categories. More recently, advances in automated ML and generative models introduced novel potentials for the task. While these approaches work for English, it is a question of whether they perform well for low-resourced languages; Arabic in particular. This paper presents (i) ArBNTopic; a novel Arabic dataset with an extended 14-topic class set covering modern books from social sciences and humanities along with newspaper articles, and (ii) a set of topic classifiers built from it. We fine-tuned an open LLM model to build ArGTC. We compared its performance against the best models built with Vertex AI (Google), AutoML(H2O), and AutoTrain(HuggingFace). ArGTC outperformed the VertexAi and AutoML models, and was reasonably similar to the AutoTrain model. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Best model; Fine tuning; Generative model; Google+; Performance; Set coverings; Topic Classification; Transformer modeling; Classification (of information)},
	editor = {Sawaf H. and El-Beltagy S. and Zaghouani W. and Magdy W. and Tomeh N. and Abu Farha I. and Habash N. and Khalifa S. and Keleg A. and Haddad H. and Zitouni I. and Abdelali A. and Mrini K. and Almatham R.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-195942927-2},
	language = {English},
	abbrev_source_title = {ArabicNLP - Arab. Nat. Lang. Process. Conf., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chumakov2023284,
	author = {Chumakov, Stanislav and Kovantsev, Anton and Surikov, Anatoliy},
	title = {Generative approach to Aspect Based Sentiment Analysis with GPT Language Models},
	year = {2023},
	journal = {Procedia Computer Science},
	volume = {229},
	pages = {284 – 293},
	doi = {10.1016/j.procs.2023.12.030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184097714&doi=10.1016%2fj.procs.2023.12.030&partnerID=40&md5=ca9bfa6fd45bb93dfcd33c56eca1521d},
	affiliations = {National Center for Cognitive Research, ITMO University, St. Petersburg, 197101, Russian Federation},
	abstract = {Aspect Sentiment Triplet Extraction (ASTE) is a modern and effective form of sentiment analysis that enables the extraction of highly representative features of source textual data. Recent solutions rely on models built upon Bidirectional Encoder Representations from Transformers (BERT) embeddings and large manually-tagged datasets. This implies that usage of such methods requires large amounts of gold-tagged domain-specific data and is vulnerable to data drifts, while not being able to recognize segmented and summarize more complex terms. We propose an open-domain generative method for ASTE based on Generative pre-trained transformer (GPT) with few-shot and fine-tuning strategies. This method has shown to be applicable for the task, with the models being capable of consistent structuring of the output triplet, simplification of the terms without losing meaningful information, as well as successful analysis of data from unknown domains. Resulting models was tested on mixed domain Russian-language automatically tagged data with thorough manual editing by means of a large language model (LLM) with a few-shot approach and English data, which was only automatically tagged. The developed models have shown to take advantage of the ability to perform learning in a few-shot way, allowing knowledge distillation from larger to cardinally smaller ones. Models have also been tested on summarizing of large amounts of reviews and have shown results comparable to enterprise grade solutions. © 2023 The Authors. Published by Elsevier B.V.},
	author_keywords = {Data Tagging; Natural Language Processing; Russian; Sentiment Analysis},
	keywords = {Computational linguistics; Distillation; Extraction; Large datasets; Data tagging; Embeddings; Language model; Language processing; Large amounts; Natural language processing; Natural languages; Russian; Sentiment analysis; Textual data; Sentiment analysis},
	editor = {Krzhizhanovskaya V. and Daud A. and Klimova A. and LaTorre D. and Boukhanovsky A.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Cloutier20235181,
	author = {Cloutier, Nicolas Antonio and Japkowicz, Nathalie},
	title = {Fine-tuned generative LLM oversampling can improve performance over traditional techniques on multiclass imbalanced text classification},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {5181 – 5186},
	doi = {10.1109/BigData59044.2023.10386772},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183823640&doi=10.1109%2fBigData59044.2023.10386772&partnerID=40&md5=3c475d17fb687f3c28441cf3370792fd},
	affiliations = {Jackson-Reed High School, Washington, DC, United States; American University, Washington, DC, United States},
	abstract = {A common challenge in classification and data mining is the class imbalance problem, where one class in a dataset has significantly more samples than another. The presence of this problem typically worsens the performance of classifiers trained on these datasets by giving them a strong preference for better-represented classes above others. Resampling is the process of adding (oversampling) or taking away (undersampling) samples from a dataset, typically with the purpose of introducing balance to the dataset before a classifier is trained. With recent advances in generative large language models (LLMs), certain authors have proposed the use of these models to generate new samples as a form of oversampling for imbalanced text data. This method has shown initial success, but has not been systematically compared to more traditional methods of resampling across many domains. We find that this use of generative LLMs generally outperforms other methods on imbalanced multiclass classification, but not on binary classification.  © 2023 IEEE.},
	author_keywords = {imbalance; NLP; oversampling; resampling},
	editor = {He J. and Palpanas T. and Hu X. and Cuzzocrea A. and Dou D. and Slezak D. and Wang W. and Gruca A. and Lin J.C.-W. and Agrawal R.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032445-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, BigData},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Das2023441,
	author = {Das, Sanandita and Dutta, Dibyarup and Ghosh, Tanusree and Naskar, Ruchira},
	title = {Universal Detection and Source Attribution of Diffusion Model Generated Images with High Generalization and Robustness},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14301 LNCS},
	pages = {441 – 448},
	doi = {10.1007/978-3-031-45170-6_45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177849724&doi=10.1007%2f978-3-031-45170-6_45&partnerID=40&md5=6eea6e8f822659271e8b95f7c15ee7e5},
	affiliations = {Department of Information Technology, Indian Institute of Engineering, Science and Technology, Shibpur, Howrah, 711103, India},
	abstract = {The proliferation of synthetic media over the internet is posing a significant social threat. Recent advancements in Diffusion Models (DM) have made it easier to create astonishingly photo-realistic synthetic media with high stability and control. Moreover, applications like DALLE-2, powered by DM and Large Language Models (LLM), permit visual content generation from natural language description, enabling opportunities for everyone to generate visual media. Hence, there is an immediate need to identify synthetic images and attribute them to their source architectures. In this work, we propose a synthetic image detector as universal detector and a source model attributor based on a popular transfer-learning model ResNet-50 and compare the results with other popular models, including Visual Geometry Group (VGG) 16, XceptionNet and InceptionNet. The proposed universal detector attains over 96% accuracy, with a source attribution, accuracy over 93% for detection of Diffusion Model generated images. The model also succeeds in achieving significant generalization and robustness capabilities under different training-testing configurations, as proven by our experiments. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {Diffusion Model; Generative Adversarial Network; Source Attribution; Synthetic Media; Transfer Learning; Universal Detection},
	keywords = {Diffusion; Learning systems; Transfer learning; Visual languages; Diffusion model; Generalisation; Language model; Photo-realistic; Source attribution; Stability and control; Synthetic images; Synthetic media; Transfer learning; Universal detections; Generative adversarial networks},
	correspondence_address = {T. Ghosh; Department of Information Technology, Indian Institute of Engineering, Science and Technology, Howrah, Shibpur, 711103, India; email: 2021itP001.tanusree@students.iiests.ac.in},
	editor = {Maji P. and Pal N.R. and De R.K. and Huang T. and Chaudhury S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303145169-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kamalloo20235591,
	author = {Kamalloo, Ehsan and Dziri, Nouha and Clarke, Charles L.A. and Rafiei, Davood},
	title = {Evaluating Open-Domain Question Answering in the Era of Large Language Models},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {5591 – 5606},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168624058&partnerID=40&md5=cdb20dda693869f65e45e8506f00c66e},
	affiliations = {University of Alberta, Canada; University of Waterloo, Canada; Allen Institute for Artificial Intelligence},
	abstract = {Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-OPEN, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60%, making it on par with existing top models, and the InstructGPT (few-shot) model actually achieves a new state-of-the-art on NQ-OPEN. We also find that more than 50% of lexical matching failures are attributed to semantically equivalent answers. We further demonstrate that regex matching ranks QA models consistent with human judgments, although still suffering from unnecessary strictness. Finally, we demonstrate that automated evaluation models are a reasonable surrogate for lexical matching in some circumstances, but not for long-form answers generated by LLMs. The automated models struggle in detecting hallucinations in LLM answers and are thus unable to evaluate LLMs. At this time, there appears to be no substitute for human evaluation. © 2023 Association for Computational Linguistics.},
	keywords = {Gold; Zero-shot learning; Analysis of various; Evaluation methods; Generative model; Language model; Lexical matching; Matchings; Open domain question answering; Performance; Question Answering; State of the art; Computational linguistics},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {978-195942972-2},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Gehring2023541,
	author = {Gehring, Justine},
	title = {Deterministic Automatic Refactoring at Scale},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Software Maintenance and Evolution, ICSME 2023},
	pages = {541 – 546},
	doi = {10.1109/ICSME58846.2023.00069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181535790&doi=10.1109%2fICSME58846.2023.00069&partnerID=40&md5=af439f3576878b5eafb825be9fcb1583},
	affiliations = {Moderne},
	abstract = {In the context of continually growing large code repositories where code refactoring is an ongoing requirement, we highlight the effectiveness of OpenRewrite as a tool for conducting large-scale code refactoring. OpenRewrite leverages Lossless Semantic Trees (LST) to represent code and applies recipes to search and implement changes. These recipes are openly available and can be executed locally or accessed through the Moderne platform for public repositories. We provide a concise overview of the underlying technology, instructions for utilizing the tool, and we compare its performance against a manual approach and two prominent large language models (LLM): ChatGPT and StarChat-β. Our comparison is based on the execution time of the tool and the accuracy of the implemented changes. Additionally, we present three distinct use cases that demonstrate the versatile applications of the tool. A demonstration of OpenRewrite's recipe which detects vulnerabilities and automatically fixes them is available at the following link: https://www.youtube.com/watch'v=L1-cQUX-JA. © 2023 IEEE.},
	author_keywords = {AST; Automatic code refactoring; Code Migration; Generative AI; JUnit; LST; Static Code Analysis; Vulnerabilities},
	keywords = {AST; Automatic code refactoring; Automatic codes; Code migration; Code re-factoring; Generative AI; Junit; Lossless; Lossless semantic tree; Semantic tree; Static code analysis; Vulnerability; Semantics},
	correspondence_address = {J. Gehring; Moderne; email: justine@moderne.io},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032783-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Softw. Maint. Evolut., ICSME},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Asesh2023,
	author = {Asesh, Aishwarya and Dugar, Meenal},
	title = {Computational Optimizations in LLMs},
	year = {2023},
	journal = {Proceedings of the 2023 IEEE International Conference on Machine Learning and Applied Network Technologies, ICMLANT 2023},
	doi = {10.1109/ICMLANT59547.2023.10372971},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183472741&doi=10.1109%2fICMLANT59547.2023.10372971&partnerID=40&md5=5025e5159d2df334d73187f47c0f398a},
	affiliations = {University of Pennsylvania, Salt Lake City, United States},
	abstract = {Over recent years, the proliferation of microblogging and textual messaging platforms has led to an exponential surge in textual data, necessitating advanced, automated techniques for sentiment elucidation. Contemporary methodologies, despite their efficacy, often demand substantial computational expenditure and manifest pronounced overfitting in scenarios involving non-standard dataset distributions. Parameter-Efficient Transfer Learning (PETL) has emerged as a promising strategy to mitigate the exorbitant computational overheads associated with large-scale model training, albeit not without its computational burden. This research, an extension of extant literature, introduces a pioneering MINIature Orthogonal Network (MINION) approach. It synergistically couples a diminutive sequence-to-sequence recurrent neural network (RNN) with a static transformer model, eschewing the need for backpropagation through the voluminous transformer. Experimental results affirm that MINION ensures a notable reduction in computational requisites in juxtaposition with antecedent implementations and comprehensive model fine-tuning, simultaneously curtailing model over-assurance while preserving commendable accuracy metrics in sentiment categorization tasks.  © 2023 IEEE.},
	author_keywords = {Chatbot Generative Pre-trained Transformer (Chat GPT); Fine-tuning; Large Language Models (LLM); Model Calibration; Natural Language Processing (NLP); Neural Networks (NN); Parameter-Efficient Transfer Learning (PETL); Sentiment Analysis; Sequence-to-Sequence RNN; Side-tuning},
	keywords = {Recurrent neural networks; Transfer learning; Chatbot generative pre-trained transformer; Chatbots; Fine tuning; Language model; Language processing; Large language model; Model calibration; Natural language processing; Natural languages; Neural network; Neural-networks; Parameter-efficient transfer learning; Sentiment analysis; Sequence-to-sequence recurrent neural network; Side-tuning; Transfer learning; Sentiment analysis},
	correspondence_address = {A. Asesh; University of Pennsylvania, Salt Lake City, United States; email: a.asesh@gmail.com},
	editor = {Cardona M. and Solanki V.K.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030391-9},
	language = {English},
	abbrev_source_title = {Proc. IEEE Int. Conf. Mach. Learn. Appl. Netw. Technol., ICMLANT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shoeibi2023,
	author = {Shoeibi, Nastaran},
	title = {Cross-lingual Transfer in Generative AI-Based Educational Platforms for Equitable and Personalized Learning},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3542},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177038444&partnerID=40&md5=4e4bb27e6325f4cfb762c25218c46ff3},
	affiliations = {University of Salamanca, Salamanca, Spain},
	abstract = {This doctoral thesis explores the integration of Generative AI, specifically Large Language Models (LLMs) and diffusion models, in educational platforms. Emphasis is placed on cross-lingual transfer techniques to overcome language barriers and create personalized content. The study addresses the impact of Generative AI on personalized learning experiences and ethical concerns. A mixed-methods approach combines quantitative usage metrics with qualitative insights from interviews and surveys. Initial results indicate improved task performance and user engagement, but ongoing refinement is needed to address biases and ethics. The LATILL platform, a web search engine for German as Foreign Language teachers, is a case study. It leverages Generative AI to provide level-Appropriate texts, translations, and image generation. The research aims to determine this technology s impact and future potential on user experience, focusing on equitable access to personalized learning across diverse geolocations. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Bias1; Diffusion Model; Education; Equality; Generative AI; language learning; LLM; Personalized Learning},
	keywords = {Diffusion; Ethical technology; Learning systems; User interfaces; Bias1; Cross-lingual; Diffusion model; Educational platforms; Equality; Generative AI; Language learning; Language model; Large language model; Personalized learning; Search engines},
	correspondence_address = {N. Shoeibi; University of Salamanca, Salamanca, Spain; email: Nastaran@usal.es},
	editor = {Balderas A. and Martinez-Mones A. and Dodero J.M. and Ros S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sachdeva20235261,
	author = {Sachdeva, Aashraya and Padala, Sai Nishanth and Pattnaik, Anup and Nathan, Varun and George, Cijo and Kumar, Ayush and Vepa, Jithendra},
	title = {Tailored Real-Time Call Summarization System for Contact Centers},
	year = {2023},
	journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
	volume = {2023-August},
	pages = {5261 – 5262},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171579514&partnerID=40&md5=826043e2b05b6e6e0c769f605668b0c2},
	affiliations = {Observe.AI, India},
	abstract = {Contact centers are critical for delivering high-quality customer service to various businesses. Call summarization is a crucial task for contact center agents for compliance, to transfer contextual information to the next agent, or to serve as a reference for future interactions. Agents spend a substantial amount of time writing notes on or after a call, which reduces their productivity and adds to the cost per call. While there exist various pre-trained Large Language Models (LLM) for summarization, they often lack coverage of domain-specific information relevant to businesses. We propose a hybrid streaming notes generation system leveraging the generative capabilities of an LLM fine-tuned for contact center call summarization, but allowing businesses to focus notes generation around events of business interest. Our system reduces after-call work for agents by not only generating notes out-of-the-box but also allowing agents to edit them in real time due to its streaming nature. © 2023 International Speech Communication Association. All rights reserved.},
	author_keywords = {contact center efficiency; customizable summary; real-time summarization},
	keywords = {Contact center efficiency; Contact centers; Customizable; Customizable summary; High quality; Language model; Quality customers; Real- time; Real-time summarization; Summarization systems; Speech communication},
	publisher = {International Speech Communication Association},
	issn = {2308457X},
	language = {English},
	abbrev_source_title = {Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Manakul20239004,
	author = {Manakul, Potsawee and Liusie, Adian and Gales, Mark J.F.},
	title = {SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {9004 – 9017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182840561&partnerID=40&md5=d8ac6493ca5dddfdd8c188990e1ac1a8},
	affiliations = {ALTA Institute, Department of Engineering, University of Cambridge, United Kingdom},
	abstract = {Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to the output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate, often complex, modules. In this work, we propose "SelfCheckGPT", a simple sampling-based approach that can be used to fact-check the responses of black-box models in a zero-resource fashion, i.e. without an external database. SelfCheckGPT leverages the simple idea that if an LLM has knowledge of a given concept, sampled responses are likely to be similar and contain consistent facts. However, for hallucinated facts, stochastically sampled responses are likely to diverge and contradict one another. We investigate this approach by using GPT-3 to generate passages about individuals from the WikiBio dataset, and manually annotate the factuality of the generated passages. We demonstrate that SelfCheckGPT can: i) detect non-factual and factual sentences; and ii) rank passages in terms of factuality. We compare our approach to several baselines and show that our approach has considerably higher AUC-PR scores in sentence-level hallucination detection and higher correlation scores in passage-level factuality assessment compared to grey-box methods. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Black box modelling; Black boxes; External database; Fluents; Language model; Probability: distributions; Sampling-based; Sentence level; Simple samplings; Simple++; Probability distributions},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jiang202314165,
	author = {Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen},
	title = {LLM-BLENDER: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {14165 – 14178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173718054&partnerID=40&md5=f7358a6b75d20d3b1cd2ae7ce5bfc2ba},
	affiliations = {Allen Institute for Artificial Intelligence, United States; University of Southern California, United States; Zhejiang University, China},
	abstract = {We present LLM-BLENDER, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PAIRRANKER and GENFUSER, addressing the observation that optimal LLMs for different examples can significantly vary. PAIRRANKER employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PAIRRANKER exhibits the highest correlation with ChatGPT-based ranking. Then, GENFUSER aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons. Our LLM-BLENDER significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap. © 2023 Association for Computational Linguistics.},
	keywords = {Blending; Computational linguistics; Baseline methods; Benchmark datasets; Comparison methods; Language model; Large-scales; Model method; Multiple instructions; Open-source; Pair-wise comparison; Performance; Large dataset},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {978-195942972-2},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Lee2023127,
	author = {Lee, Eric and Gong, Jiayu and Cao, Qinghong},
	title = {Object Oriented BDD and Executable Human-Language Module Specification},
	year = {2023},
	journal = {2023 26th ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD-Winter 2023},
	pages = {127 – 133},
	doi = {10.1109/SNPD-Winter57765.2023.10223873},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173089442&doi=10.1109%2fSNPD-Winter57765.2023.10223873&partnerID=40&md5=6138c3b0131baee40ecd525b72ec61bc},
	affiliations = {Se Cloud (Shanghai) Intelligent Technology Co., Ltd., Shanghai, China; Shanghai Key Laboratory of Computer Software Testing & Evaluation, Shanghai Development Center of Computer Software Technology, Shanghai, China; System Operation Department, Shanghai Stock Exchange, Shanghai, China},
	abstract = {This paper presents an approach to software development which uses a generative AI Model as compiler to translate human language requirements into high-level programming language. We propose an executable human-language module specification and a tool to support it, which has been used successfully for human-language UI test automation. We anticipate further development of this approach to enable complex software to be programmed in human language, allowing for more intuitive and efficient software development. © 2023 IEEE.},
	author_keywords = {BDD; Generative AI; GPT; HLP (Human Language Programming); LLM (Large Language Model); OOBDD (Object-oriented Behavior Driven Development); SDD (Specification Driven Development)},
	keywords = {Boolean functions; High level languages; Object oriented programming; Program compilers; Software design; BDD; Generative AI; GPT; Human language; Human language programming; Language model; Large language model; Object oriented; Object-oriented behavior driven development; Specification driven development; Specifications},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034586-5},
	language = {English},
	abbrev_source_title = {ACIS Int. Winter Conf. Softw. Eng., Artif. Intell., Netw. Parallel/Distrib. Comput., SNPD-Winter},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Abburi2023,
	author = {Abburi, Harika and Suesserman, Michael and Pudota, Nirmala and Veeramani, Balaji and Bowen, Edward and Bhattacharya, Sanmitra},
	title = {Generative AI Text Classification using Ensemble LLM Approaches},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174830832&partnerID=40&md5=4b5d15c7b808753250cabbb512eafd39},
	affiliations = {Deloitte & Touche Assurance & Enterprise Risk Services India Private Limited, India; Deloitte & Touche LLP, United States},
	abstract = {Large Language Models (LLMs) have shown impressive performance across a variety of Artificial Intelligence (AI) and natural language processing tasks, such as content creation, report generation, etc. However, unregulated malign application of these models can create undesirable consequences such as generation of fake news, plagiarism, etc. As a result, accurate detection of AI-generated language can be crucial in responsible usage of LLMs. In this work, we explore 1) whether a certain body of text is AI generated or written by human, and 2) attribution of a specific language model in generating a body of text. Texts in both English and Spanish are considered. The datasets used in this study are provided as part of the Automated Text Identification (AuTexTification) shared task. For each of the research objectives stated above, we propose an ensemble neural model that generates probabilities from different pre-trained LLMs which are used as features to a Traditional Machine Learning (TML) classifier following it. For the first task of distinguishing between AI and human generated text, our model ranked in fifth and thirteenth place (with macro F1 scores of 0.733 and 0.649) for English and Spanish texts, respectively. For the second task on model attribution, our model ranked in first place with macro F1 scores of 0.625 and 0.653 for English and Spanish texts, respectively. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {ensemble; generative AI; large language models; text classification},
	keywords = {Artificial intelligence; Computational linguistics; Fake detection; Learning algorithms; Natural language processing systems; Ensemble; F1 scores; Generative artificial intelligence; Language model; Language processing; Large language model; Modeling approach; Natural languages; Performance; Text classification; Classification (of information)},
	correspondence_address = {H. Abburi; Deloitte & Touche Assurance & Enterprise Risk Services India Private Limited, India; email: abharika@deloitte.com},
	editor = {Montes-y-Gomez M. and Rangel F. and Jimenez-Zafra S.M. and Casavantes M. and Altuna B. and Alvarez-Carmona M.A. and Bel-Enguix G. and Chiruzzo L. and de la Iglesia I. and Escalante H.J. and Garcia-Cumbreras M.A. and Garcia-Diaz J.A. and Barba J.A.G. and Tamayo R.L. and Lima S. and Moral P. and del Arco F.M.P. and Valencia-Garcia R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Diamantini2023,
	author = {Diamantini, Claudia and Mircoli, Alex and Potena, Domenico and Vagnoni, Simone},
	title = {An Experimental Comparison of Large Language Models for Emotion Recognition in Italian Tweets},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3606},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182938263&partnerID=40&md5=9adce81cc38e1d7e07116cdb5aa4e2ac},
	affiliations = {Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy},
	abstract = {In recent years, the advent of Large Language Models (LLMs), which are task-agnostic models trained on huge amounts of textual data, has given momentum to a wide variety of NLP applications, ranging from chatbots to sentiment classifiers. Currently, many LLMs are publicly available, each with different features and performance, and the selection of the best LLM for a specific task may be challenging. In this work, we focus on the task of emotion recognition in Italian social media content and we present an experimental comparison among three of the most popular LLMs: Google Bidirectional Encoder Representations from Transformers (BERT), OpenAI Generative Pre-trained Transformer 3 (GPT-3) and GPT-3.5. Model specialization in emotion recognition has been achieved by using two different approaches, namely fine-tuning and prompt engineering with few-shot task transfer. The experimentation has been performed on TwIT, a corpus of about 3100 Italian tweets annotated with respect to six emotions. The results show that fine-tuning GPT-3 leads to the best performance on the considered dataset, achieving a remarkable F1=0.90. © 2023 Copyright for this paper by its authors.},
	author_keywords = {BERT; emotion recognition; emotion recognition in Italian; emotion recognition of tweets; few-shot learning; fine tuning; GPT-3; large language model; sentiment analysis},
	keywords = {Computational linguistics; Speech recognition; Bidirectional encoder representation from transformer; Emotion recognition; Emotion recognition in italian; Emotion recognition of tweet; Few-shot learning; Fine tuning; Generative pre-trained transformer 3; Language model; Large language model; Sentiment analysis; Emotion Recognition},
	correspondence_address = {A. Mircoli; Department of Information Engineering, Università Politecnica delle Marche, Ancona, Italy; email: a.mircoli@univpm.it},
	editor = {Bena N. and Di Martino B. and Maratea A. and Sperduti A. and Di Nardo E. and Ciaramella A. and Montella R. and Ardagna C.A.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Porcelli2023145,
	author = {Porcelli, Lorenzo and Ficco, Massimo and Palmieri, Francesco},
	title = {Mitigating User Exposure to Dark Patterns in Cookie Banners Through Automated Consent},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14105 LNCS},
	pages = {145 – 159},
	doi = {10.1007/978-3-031-37108-0_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168766007&doi=10.1007%2f978-3-031-37108-0_10&partnerID=40&md5=ef82e82c0e3ff3885edc2c68a18417da},
	affiliations = {Department of Computer Science, University of Salerno, SA, Fisciano, Italy},
	abstract = {The General Data Protection Regulation (GDPR) has established a de facto standard for presenting consent banners to users. To comply with the GDPR, websites are required to obtain user consent before processing their personal data, both for the provision of services and the monitoring of user behavior. Despite this, the most commonly adopted paradigm involves informing and requesting user preferences when visiting a website, often without adhering to GDPR standards and including dark patterns, such as dark nudges. In this paper, we propose a Personal Information Management Service that automatically generates consent responses based on user preferences, leveraging a Large Language Model. We demonstrate the feasibility of the proposed approach in a case study involving ChatGPT. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Cookie banner; Dark pattern; GDPR; Generative Pre-trained Transformer (GPT); Large Language Model (LLM); Nudging; Personal Information Management Service (PIMS); Transparency and Consent Framework (TCF)},
	keywords = {Behavioral research; Computational linguistics; Data handling; Information management; Cookie banner; Dark pattern; General data protection regulations; Generative pre-trained transformer; Language model; Large language model; Management service; Nudging; Personal information management; Personal information management service; Transparency and consent framework; Websites},
	correspondence_address = {L. Porcelli; Department of Computer Science, University of Salerno, Fisciano, SA, Italy; email: lporcelli@unisa.it},
	editor = {Gervasi O. and Murgante B. and Scorza F. and Rocha A.M.A.C. and Garau C. and Karaca Y. and Torre C.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303137107-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hammond2023,
	author = {Hammond, Kay M. and Lucas, Patricia and Hassouna, Amira and Brown, Stephen},
	title = {A Wolf in Sheep’s Clothing? Critical Discourse Analysis of Five Online Automated Paraphrasing Sites},
	year = {2023},
	journal = {Journal of University Teaching and Learning Practice},
	volume = {20},
	number = {7},
	doi = {10.53761/1.20.7.08},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176796676&doi=10.53761%2f1.20.7.08&partnerID=40&md5=d54594d0c8bfcf22823ba8e8fbd70036},
	affiliations = {Auckland University of Technology, New Zealand},
	abstract = {Research on academic integrity used to focus more on student character and behaviour. Now this research includes wider viewing of this issue as a current teaching and learning challenge which requires pedagogical intervention. It is now the responsibility of staff and institutions to treat the creation of a learning environment supporting academic integrity as a teaching and learning priority. Plagiarism by simply copying other people’s work is a well-known misconduct which undermines academic integrity; moreover, technological developments have evolved plagiarism to include the generation and copying of computer-generated text. Automated paraphrasing tool (APT) websites have become increasingly common, offering students machine-generated rephrased text that students input from their own or others’ writing. These developments present a creeping erosion of academic integrity under the guise of legitimate academic assistance. This also has implications for arrival of large language model (LLM) generative AI tools. In accessing these sites, students must discern what is a legitimate use of the tool and what may constitute breaching academic integrity. This study critically analysed the text from five online paraphrasing websites to examine the discourses used to legitimise and encourage APT use in both appropriate and inappropriate ways. We conceptualised these competing discourses using Sheep and Wolf metaphors. In addition, we offer a metaphor of the Educator as a Shepherd to become aware of APT website claims and assist students to develop critical language awareness when exposed to these sites. Educators can assist students with this through knowledge of how these sites use language to entice users to circumvent learning. © by the authors.},
	author_keywords = {academic integrity; Automated paraphrasing tools; critical discourse analysis; generative AI; higher education},
	publisher = {University of Wollongong},
	issn = {14499789},
	language = {English},
	abbrev_source_title = {J. Univ. Teach. Learn. Pract.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Fecher2023,
	author = {Fecher, Benedikt and Hebing, Marcel and Laufer, Melissa and Pohle, Jörg and Sofsky, Fabian},
	title = {Friend or foe? Exploring the implications of large language models on the science system},
	year = {2023},
	journal = {AI and Society},
	doi = {10.1007/s00146-023-01791-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174915037&doi=10.1007%2fs00146-023-01791-1&partnerID=40&md5=0ddfb1eb8715bb84a24bf6babf1ceb6a},
	affiliations = {Alexander von Humboldt Institute for Internet and Society, Berlin, Germany; Wissenschaft im Dialog, Berlin, Germany; DBU Digital Business University of Applied Sciences, Berlin, Germany},
	abstract = {The advent of ChatGPT by OpenAI has prompted extensive discourse on its potential implications for science and higher education. While the impact on education has been a primary focus, there is limited empirical research on the effects of large language models (LLMs) and LLM-based chatbots on science and scientific practice. To investigate this further, we conducted a Delphi study involving 72 researchers specializing in AI and digitization. The study focused on applications and limitations of LLMs, their effects on the science system, ethical and legal considerations, and the required competencies for their effective use. Our findings highlight the transformative potential of LLMs in science, particularly in administrative, creative, and analytical tasks. However, risks related to bias, misinformation, and quality assurance need to be addressed through proactive regulation and science education. This research contributes to informed discussions on the impact of generative AI in science and helps identify areas for future action. © 2023, The Author(s).},
	author_keywords = {Delphi study; Large language models; Scholarly communication; Science system},
	keywords = {Computational linguistics; Chatbots; DELPHI study; Empirical research; High educations; Language model; Large language model; Model-based OPC; Scholarly communication; Science education; Science systems; Quality assurance},
	correspondence_address = {B. Fecher; Alexander von Humboldt Institute for Internet and Society, Berlin, Germany; email: fecher@hiig.de},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zagirova20239293,
	author = {Zagirova, Diana and Pushkov, Stefan and Leung, Geoffrey Ho Duen and Liu, Bonnie Hei Man and Urban, Anatoly and Sidorenko, Denis and Kalashnikov, Aleksandr and Kozlova, Ekaterina and Naumov, Vladimir and Pun, Frank W. and Ozerov, Ivan V. and Aliper, Alex and Zhavoronkov, Alex},
	title = {Biomedical generative pre-trained based transformer language model for age-related disease target discovery},
	year = {2023},
	journal = {Aging},
	volume = {15},
	number = {18},
	pages = {9293 – 9309},
	doi = {10.18632/aging.205055},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173575764&doi=10.18632%2faging.205055&partnerID=40&md5=4491920a8e4e8aa68b5a71d6f83d8583},
	affiliations = {Insilico Medicine Hong Kong Ltd., Hong Kong Science and Technology Park, New Territories, Hong Kong; Insilico Medicine AI Limited, Level 6, Unit 08, Block A, IRENA HQ Building, Masdar City, Abu Dhabi, United Arab Emirates},
	abstract = {Target discovery is crucial for the development of innovative therapeutics and diagnostics. However, current approaches often face limitations in efficiency, specificity, and scalability, necessitating the exploration of novel strategies for identifying and validating disease-relevant targets. Advances in natural language processing have provided new avenues for predicting potential therapeutic targets for various diseases. Here, we present a novel approach for predicting therapeutic targets using a large language model (LLM). We trained a domain-specific BioGPT model on a large corpus of biomedical literature consisting of grant text and developed a pipeline for generating target prediction. Our study demonstrates that pre-training of the LLM model with task-specific texts improves its performance. Applying the developed pipeline, we retrieved prospective aging and age-related disease targets and showed that these proteins are in correspondence with the database data. Moreover, we propose CCR5 and PTH as potential novel dual-purpose anti-aging and disease targets which were not previously identified as age-related but were highly ranked in our approach. Overall, our work highlights the high potential of transformer models in novel target prediction and provides a roadmap for future integration of AI approaches for addressing the intricate challenges presented in the biomedical field. © 2023 Zagirova et al. This is an open access article distributed under the terms of the Creative Commons Attribution License (CC BY 3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	author_keywords = {aging biomarkers; deep learning; human aging; therapeutic target discovery; transformers},
	keywords = {Databases, Factual; Language; Prospective Studies; factual database; language; prospective study},
	correspondence_address = {A. Zhavoronkov; Insilico Medicine Hong Kong Ltd., Hong Kong Science and Technology Park, New Territories, Hong Kong; email: alex@insilico.com},
	publisher = {Impact Journals LLC},
	issn = {19454589},
	pmid = {37742294},
	language = {English},
	abbrev_source_title = {Aging},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Devadiga202353,
	author = {Devadiga, Dharani and Koo, Hankyu and Singh, Angad and Jin, Gordon and Han, Andrew and Chaudhari, Kinjal and Potdar, Bisti and Shringi, Anusha and Kumar, Saurav},
	title = {GLEAM: GAN and LLM for Evasive Adversarial Malware},
	year = {2023},
	journal = {International Conference on ICT Convergence},
	pages = {53 – 58},
	doi = {10.1109/ICTC58733.2023.10393706},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184590372&doi=10.1109%2fICTC58733.2023.10393706&partnerID=40&md5=60d776e3b43bf1b6881a1e95053ecdce},
	affiliations = {Green Level High School, Cary, NC, United States; Bellarmine College Prep., Cupertino, CA, United States; Robbinsville High School, Robbinsville, NJ, United States; Seven Lakes High School, Katy, TX, United States; Westlake High School, Austin, TX, United States; University of Illinois Urbana-Champaign, Champaign, IL, United States; Vernon Hills High School, Vernon Hills, IL, United States; Lynbrook High School, San Jose, CA, United States},
	abstract = {The rapid evolution of cybersecurity threats poses formidable challenges for effective malware detection. Traditional methods often struggle to keep pace with the continuously changing landscape of new malware variants. To address this issue, researchers have turned to machine-learning techniques to optimize malware detection. Yet, these approaches have overlooked the fact that evasive malware is meticulously crafted to elude detection through tactics such as exploiting software vulnerabilities, utilizing encryption, and employing obfuscation techniques. Malware authors have a strong incentive to attack malware detection systems, yet the features and methods that they exploit are limited. We propose a model named GLEAM- GAN and LLM for Evasive Adversarial Malware. This model infuses hex code and opcode features with LLM (Large Language Model) embeddings and GANs (Generative Adversarial Networks) to generate synthetic samples that closely resemble evasive mal-ware to bypass black-box machine learning detectors. Through extensive evaluation, our model achieved an average evasion rate increase of 22.6%, demonstrating its ability to effectively attack detection systems. By expanding the space for adversarial malware generation, we give modern detection systems the capability to counter the nuanced tactics of evasive malware, thus enhancing proficiency in preempting and neutralizing potential threats with heightened precision. © 2023 IEEE.},
	author_keywords = {Adversarial Malware Examples; Cybersecurity; Generative adversarial networks; Large Language Models},
	correspondence_address = {D. Devadiga; Green Level High School, Cary, United States; email: dhar.devadiga@gmail.com},
	publisher = {IEEE Computer Society},
	issn = {21621233},
	isbn = {979-835031327-7},
	language = {English},
	abbrev_source_title = {Int. Conf. ICT Convergence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Agarwal2023,
	author = {Agarwal, Parul and Asif, Aisha and Parida, Shantipriya and Sekhar, Sambit and Dash, Satya Ranjan and Panda, Subhadarshi},
	title = {Generative Chatbot Adaptation for Odia Language: A Critical Evaluation},
	year = {2023},
	journal = {2023 1st International Conference on Circuits, Power, and Intelligent Systems, CCPIS 2023},
	doi = {10.1109/CCPIS59145.2023.10291329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177554516&doi=10.1109%2fCCPIS59145.2023.10291329&partnerID=40&md5=6d3847bc6d1bcbd820551acb79321f82},
	affiliations = {Institute of Mathematics and Applications, Bhubaneswar, India; Kiit University, Bhubaneswar, India; Silo Ai, Helsinki, Finland; Odia Generative Ai, Odisha, Bhubaneswar, India; City University of New York, New York, United States},
	abstract = {Large Language Models (LLMs) have gained significant attention in the field of Natural Language Processing (NLP) and Artificial Intelligence (AI) due to their ability to generate human-like text and facilitate conversational interactions. However, the majority of LLMs are majorly developed for English, limiting their accessibility and effectiveness for non-English speaking populations. In India, where only 10% of the population is proficient in English, the need for LLM models adapted to regional languages becomes crucial. This research paper focuses on the adaptability of LLMs to the Odia language, spoken by approximately 50 million people in India. With a primary objective to cater to the Odia-speaking community, we aim to evaluate existing LLM models such as ChatGPT, and Olive, an instruction following Odia LLM, specifically in the context of generating conversational outputs in Odia. We employ a critical evaluation approach to assess the performance, language understanding, and response generation capabilities of the LLM models for the Odia language. By conducting experiments and comparative analysis, we seek to determine the strengths, weaknesses, and potential areas of improvement for the existing LLM models. Our findings will contribute to the development of more effective and contextually accurate generative chatbots for the Odia language, enabling better communication and accessibility for the Odia-speaking population.  © 2023 IEEE.},
	author_keywords = {ChatGPT; Generative AI; Large Language Models (LLM); Natural language Processing (NLP); Odia; OdiaGenAI},
	keywords = {Computational linguistics; Chatbots; ChatGPT; Generative artificial intelligence; Language model; Language processing; Large language model; Natural language processing; Natural languages; Odia; Odiagenai; Natural language processing systems},
	correspondence_address = {S.R. Dash; Kiit University, Bhubaneswar, India; email: sdashfca@kiit.ac.in},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031576-9},
	language = {English},
	abbrev_source_title = {Int. Conf. Circuits, Power, Intell. Syst., CCPIS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Yue20234615,
	author = {Yue, Xiang and Wang, Boshi and Chen, Ziru and Zhang, Kai and Su, Yu and Sun, Huan},
	title = {Automatic Evaluation of Attribution by Large Language Models},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {4615 – 4635},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178880077&partnerID=40&md5=8fb9274b6efd9a0b7bd22aa1e62d35fe},
	affiliations = {The Ohio State University, United States},
	abstract = {A recent focus of large language model (LLM) development, as exemplified by generative search engines, is to incorporate external references to generate and support its claims. However, evaluating the attribution, i.e., verifying whether the generated statement is fully supported by the cited reference, remains an open problem. Although human evaluation is common practice, it is costly and time-consuming. In this paper, we investigate automatic evaluation of attribution given by LLMs. We begin by defining different types of attribution errors, and then explore two approaches for automatic evaluation: prompting LLMs and fine-tuning smaller LMs. The fine-tuning data is repurposed from related tasks such as question answering, fact-checking, natural language inference, and summarization. We manually curate a set of test examples covering 12 domains from a generative search engine, New Bing. Our results on this curated test set and simulated examples from existing benchmarks highlight both promising signals and challenges. We hope our problem formulation, testbeds, and findings will help lay the foundation for future studies on this important problem. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Tuning; Automatic evaluation; Fine tuning; Human evaluation; Language inference; Language model; Model development; Natural languages; Question Answering; Test examples; Test sets; Search engines},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176061-5},
	language = {English},
	abbrev_source_title = {Find. Assoc. Comput. Linguist.: EMNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Singh2023,
	author = {Singh, Ajay and Jia, Tianxia and Nalagatla, Varun},
	title = {Generative AI Enabled Conversational Chatbot for Drilling and Production Analytics},
	year = {2023},
	journal = {Society of Petroleum Engineers - ADIPEC, ADIP 2023},
	doi = {10.2118/216267-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176804388&doi=10.2118%2f216267-MS&partnerID=40&md5=7ba6aec6ba1f4d0ecc1d37a891846816},
	affiliations = {Amazon Web Services, Houston, TX, United States},
	abstract = {Getting intelligent insight from large amount of dataset is critical for Energy companies to optimize their operations across various business segments such as drilling, production and completion etc. The paper proposes end-to-end workflow to 1) extract data form rig and production reports and store dataset into databases 2) build a conversational generative AI enabled chatbot which is trained to answer questions related to drilling and production monitoring, queries dataset, frequently performed diagnostic analysis and can generate recommendations to improve operations. The chatbot is integrated with large language models (LLM) and machine learning models (ML) on the cloud and based on questions asked by user it provides answers in conversational settings. Chatbot is hosted in cloud and is integrated with various databases, document repositories and several machine learning model. The machine learning models are built to enable chatbot's capability to answer questions related to drilling and production analytics. Chatbot is integrated with user interface where user can type or ask questions. Using natural language process (NLP) and artificial intelligence (Al), chatbot understands intent of question and if needed asks relevant follow-up questions to provide the answer. Chatbot can also perform statistical analysis, generate SQL queries on datasets and can use those statistics to answer questions. Further if enabled, chatbot can also search information from drilling and production reports and scientific articles. Three case studies are presented. In case study#1, chatbot was integrated with operator's historical PDF drilling reports (Volve dataset), which traditionally are not easy to extract and analyze at scale. Several thousand drilling reports were extracted and stored in database. Various capabilities were added to chatbot such has Cross-documents insights and trend, for example, well progression, operation history, can be generated and displayed on user interface and further analysis can be performed in conversational manner. The dataset created was used to perform comparative analysis identifying wells having significant higher non production time (NPT) due to repair or fishing events. In this manner, chatbot can compare one well's operational statistics with other well and generate various visuals which helps identifying possible ways to improve drilling operations. Similarly, chatbot was also trained to provide answers for production diagnostics such as comparing well's relative performances and root cause identification for poor performing wells. When analyzed on test dataset chatbot was able to identify 20% uplift in production for wells supported on plunger lift. Finally, chatbot was enabled to support NLP based searches. Engineers can ask specific questions such as "provide operational log for well F4 when fishing happened and sort the result by reporting date in ascending order. Show me both SQL query and the resulted table" and chatbot will generate SQL query and resulted table. The work demonstrates that generative AI has great potential to transform the Energy industry. © 2023, Society of Petroleum Engineers.},
	keywords = {Data Analytics; Database systems; Infill drilling; Machine learning; Natural language processing systems; Query processing; Statistical tests; User interfaces; Business segments; Case-studies; Chatbots; End to end; Energy companies; Large amounts; Machine learning models; Natural language process; Production report; SQL query; Large dataset},
	publisher = {Society of Petroleum Engineers},
	isbn = {978-195902507-8},
	language = {English},
	abbrev_source_title = {Soc. Pet. Eng. - ADIPEC, ADIP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Choi2023209,
	author = {Choi, Hyeon Seok and Song, Jun Yeong and Shin, Kyung Hwan and Chang, Ji Hyun and Jang, Bum-Sup},
	title = {Developing prompts from large language model for extracting clinical information from pathology and ultrasound reports in breast cancer},
	year = {2023},
	journal = {Radiation Oncology Journal},
	volume = {41},
	number = {3},
	pages = {209 – 216},
	doi = {10.3857/roj.2023.00633},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172908508&doi=10.3857%2froj.2023.00633&partnerID=40&md5=9468d1d30346ed4d1e7c01d0127064e4},
	affiliations = {Department of Radiation Oncology, Seoul National University Hospital, Seoul National University College of Medicine, Seoul, South Korea; Institute of Radiation Medicine, Seoul National University Medical Research Center, Seoul, South Korea},
	abstract = {Purpose: We aimed to evaluate the time and cost of developing prompts using large language model (LLM), tailored to extract clinical factors in breast cancer patients and their accuracy. Materials and Methods: We collected data from reports of surgical pathology and ultrasound from breast cancer patients who underwent radiotherapy from 2020 to 2022. We extracted the information using the Generative Pre-trained Transformer (GPT) for Sheets and Docs extension plugin and termed this the “LLM” method. The time and cost of developing the prompts with LLM methods were assessed and compared with those spent on collecting information with “full manual” and “LLM-assisted manual” methods. To assess accuracy, 340 patients were randomly selected, and the extracted information by LLM method were compared with those collected by “full manual” method. Results: Data from 2,931 patients were collected. We developed 12 prompts for Extract function and 12 for Format function to extract and standardize the information. The overall accuracy was 87.7%. For lymphovascular invasion, it was 98.2%. Developing and processing the prompts took 3.5 hours and 15 minutes, respectively. Utilizing the ChatGPT application programming interface cost US $65.8 and when factoring in the estimated wage, the total cost was US $95.4. In an estimated comparison, “LLM-assisted manual” and “LLM” methods were time-and cost-efficient compared to the “full manual” method. Conclusion: Developing and facilitating prompts for LLM to derive clinical factors was efficient to extract crucial information from huge medical records. This study demonstrated the potential of the application of natural language processing using LLM model in breast cancer patients. Prompts from the current study can be re-used for other research to collect clinical information. © 2023 The Korean Society for Radiation Oncology.},
	author_keywords = {Artificial intelligence; Automatic data processing; Breast cancer; Clinical reports; Natural language processing},
	keywords = {epidermal growth factor receptor 2; estrogen receptor; Article; artificial intelligence; breast biopsy; breast cancer; cancer radiotherapy; cancer staging; ChatGPT; clinical feature; controlled study; cost effectiveness analysis; diagnostic accuracy; diagnostic test accuracy study; echography; echomammography; female; fluorescence in situ hybridization; gene amplification; health care personnel; health insurance; human; human tissue; immunohistochemistry; in situ hybridization; language; language processing; lymph node biopsy; lymph node dissection; lymph node metastasis; lymph node ratio; major clinical study; mammography; medical record; methodology; natural language processing; neoadjuvant chemotherapy; partial mastectomy; pathology; sentinel lymph node biopsy; treatment response; tumor volume; ultrasound},
	correspondence_address = {B.-S. Jang; Department of Radiation Oncology, Seoul National University Hospital, Seoul, 101 Daehak-ro, Jongno-gu, 03080, South Korea; email: bigwiz83@gmail.com},
	publisher = {Department of Radiation Oncology},
	issn = {22341900},
	language = {English},
	abbrev_source_title = {Radiat. Oncol. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Heidrich202340,
	author = {Heidrich, David and Schreiber, Andreas},
	title = {Visualizing Source Code as Comics Using Generative AI},
	year = {2023},
	journal = {Proceedings - 2023 IEEE Working Conference on Software Visualization, VISSOFT 2023},
	pages = {40 – 44},
	doi = {10.1109/VISSOFT60811.2023.00014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182745075&doi=10.1109%2fVISSOFT60811.2023.00014&partnerID=40&md5=fcd907badaadb7aac830d7070c3a6101},
	affiliations = {Institute for Software Technology German Aerospace Center (DLR), Weβling, Germany; Institute for Software Technology German Aerospace Center (DLR), Köln, Germany},
	abstract = {The architecture and inner structure of software is often only implicitly available in the form of its source code and thus not tangible and intuitively easy to understand for non-programmers and laymen. Our goal is to create visualizations as automatically as possible, with which such people can neverthe-less understand the software or parts of the software and get a feel for the structure of the software and how its methods work. Especially for newcomers to software projects, for management or even for students and pupils, it can be helpful to get a non-technical insight into the software. We use the concept of visualizing information as comics to present aspects of the software as strikingly as possible, as comics are an effective way to present complex systems and interrelationships for certain target groups. For this purpose, we present a method to generate comics from source code. Our semi-automated process is based on generating a prompt for an LLM from source code, which in turn generates a prompt for a comic image generation using the text-to-image model Stable Diffusion. We show that generative AI methods can be used to rapidly generate human-compatible artistic representations from source code. However, further research is needed to validate the understandability of the results.  © 2023 IEEE.},
	author_keywords = {comics; generative ai; software visualization; stable diffusion; visualization},
	keywords = {Automation; Computer programming languages; Automated process; Comic; Generative ai; Image generations; Inner structure; Software project; Software visualization; Source codes; Stable diffusion; Target group; Visualization},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030829-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Work. Conf. Softw. Vis., VISSOFT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pliukhin2023,
	author = {Pliukhin, Dmitrii and Radyush, Daniil and Kovriguina, Liubov and Mouromtsev, Dmitry},
	title = {Improving Subgraph Extraction Algorithms for One-Shot SPARQL Query Generation with Large Language Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180551320&partnerID=40&md5=d3d62c78b1b2b37274a9e88314393de0},
	affiliations = {ITMO University, Kronverksky Pr. 49, bldg. A, St. Petersburg, 197101, Russian Federation; Independent Researcher, Dresden, Germany; TIB – Leibniz-Informationszentrum Technik und Naturwissenschaften und Universitätsbibliothek, Welfengarten 1B, Hannover, 30167, Germany},
	abstract = {Question answering over scholarly knowledge graphs involves many challenges: complex graph patterns, long-tail distributed data, revision and evolution of the scholarly ontologies, and knowledge graphs incompleteness due to constant research dynamics. In this work, we present an LLM-based approach for SPARQL query generation over Open Research Knowledge Graph (ORKG) for the ISWC SciQA Challenge. Our approach proposes a couple of improvements to the recently published SPARQLGEN approach, that performs one-shot SPARQL query generation by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. Similar to SPARQLGEN, we include heterogeneous data sources in the SPARQL generation prompt: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query. In the current work, we focused on designing subgraph extraction algorithms, that are close to real-life scenarios of generative KGQA, and replaced the random choice of example question-query pair with similarity scoring. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Augmented Large Language Models; Knowledge Graphs Question Answering; Scholarly Knowledge Graphs; SPARQL query generation; Subgraph Extraction},
	keywords = {Computational linguistics; Data mining; Extraction; Graphic methods; Natural language processing systems; Query processing; Resource Description Framework (RDF); Augmented large language model; Knowledge graph question answering; Knowledge graphs; Language model; Query generation; Question Answering; Scholarly knowledge graph; SPARQL query generation; Subgraph extraction; Knowledge graph},
	correspondence_address = {D. Pliukhin; ITMO University, St. Petersburg, Kronverksky Pr. 49, bldg. A, 197101, Russian Federation; email: zeionara@gmail.com; L. Kovriguina; Independent Researcher, Dresden, Germany; email: lkovriguina@gmail.com},
	editor = {Banerjee D. and Usbeck R. and Mihindukulasooriya N. and Jaradeh M.Y. and Auer S. and Singh G. and Mutharaju R. and Kapanipathi P.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lukens2023,
	author = {Lukens, Sarah and Ali, Asma},
	title = {Evaluating the Performance of ChatGPT in the Automation of Maintenance Recommendations for Prognostics and Health Management},
	year = {2023},
	journal = {Proceedings of the Annual Conference of the Prognostics and Health Management Society, PHM},
	volume = {15},
	number = {1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178387478&partnerID=40&md5=be549fa3ad918be87f801d353d413e11},
	affiliations = {LMI, Tysons, 22102, VA, United States; GE Vernova, Chicago, 60661, IL, United States},
	abstract = {Until now, automation of maintenance recommendations for Prognostics and Health Management (PHM) has been a domain-specific technical language processing (TLP) task applied to historical case data. ChatGPT, Bard, GPT-4 and Sydney are a few examples of generative large language models (LLMs) that have received significant media attention for their proficiency in natural language tasks across a variety of domains. Preliminary exploration of ChatGPT as a tool for generating maintenance recommendations has shown promise in its ability to generate and explain engineering concepts and procedures, but the precise scope of its capabilities and limitations remains uncertain. Currently we know of no performance criteria related to formally measuring how well ChatGPT performs as a tool for industrial use cases. In this paper, we propose a methodology for the evaluation of the performance of LLMs such as ChatGPT for the task of automation of maintenance recommendations. Our methodology identifies various performance criteria relevant for PHM such as engineering criteria, risk elements, human factors, cost considerations and corrections. We examine how well ChatGPT performs when tasked with generating recommendations from PHM model alerts and report our findings. We discuss the various strengths and limitations to consider in the adoption of LLM's as a computational support tool for prescriptive PHM as well as the different risks and business case considerations. © 2023 Prognostics and Health Management Society. All rights reserved.},
	keywords = {Automation; Cost engineering; Natural language processing systems; Domain specific; Generating maintenances; Language model; Language processing; Media attention; Natural languages; Performance; Performance criterion; Prognostic and health management; Technical languages; Maintenance},
	editor = {Kulkarni C.S. and Roychoudhury I.},
	publisher = {Prognostics and Health Management Society},
	issn = {23250178},
	isbn = {978-193626305-9},
	language = {English},
	abbrev_source_title = {Proc. Annu. Conf. Progn. Health Manag. Soc., PHM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Samsi2023,
	author = {Samsi, Siddharth and Zhao, Dan and McDonald, Joseph and Li, Baolin and Michaleas, Adam and Jones, Michael and Bergeron, William and Kepner, Jeremy and Tiwari, Devesh and Gadepally, Vijay},
	title = {From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference},
	year = {2023},
	journal = {2023 IEEE High Performance Extreme Computing Conference, HPEC 2023},
	doi = {10.1109/HPEC58863.2023.10363447},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182600249&doi=10.1109%2fHPEC58863.2023.10363447&partnerID=40&md5=96d913d3010c8e09071475b81f9c11b0},
	affiliations = {Mit, United States; Northeastern University, United States; Nyu, United States},
	abstract = {Large language models (LLMs) have exploded in popularity due to their new generative capabilities that go far beyond prior state-of-the-art. These technologies are increasingly being leveraged in various domains such as law, finance, and medicine. However, these models carry significant computational challenges, especially the compute and energy costs required for inference. Inference energy costs already receive less attention than the energy costs of training LLMs-despite how often these large models are called on to conduct inference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see increasing usage and deployment in various domains, a better understanding of their resource utilization is crucial for cost-savings, scaling performance, efficient hardware usage, and optimal inference strategies. In this paper, we describe experiments conducted to study the computational and energy utilization of inference with LLMs. We benchmark and conduct a preliminary analysis of the inference performance and inference energy costs of different sizes of LLaMA-a recent state-of-the-art LLM-developed by Meta AI on two generations of popular GPUs (NVIDIA V100 & A100) and two datasets (Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in research and practice. We present the results of multi-node, multi-GPU inference using model sharding across up to 32 GPUs. To our knowledge, our work is the one of the first to study LLM inference performance from the perspective of computational and energy resources at this scale.  © 2023 IEEE.},
	author_keywords = {Deep Learning; Distributed Computing; Energy; Green AI; Inference; Large Language Models; LLM; Natural Language Processing; NLP; Sustainability},
	keywords = {Benchmarking; Computational linguistics; Computing power; Cost benefit analysis; Deep learning; Energy resources; Energy utilization; Green computing; Learning algorithms; Natural language processing systems; Program processors; Deep learning; Energy; Green AI; Inference; Language model; Language processing; Large language model; Natural language processing; Natural languages; Graphics processing unit},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030860-0},
	language = {English},
	abbrev_source_title = {IEEE High Perform. Extrem. Comput. Conf., HPEC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Corici2023,
	author = {Corici, Marius and Buhr, Hauke and Magedanz, Thomas},
	title = {Generative Twin for 6G and Beyond 5G Networks: Vision, Challenges and Architecture},
	year = {2023},
	journal = {International Conference on 6G Networking, 6GNet 2023},
	doi = {10.1109/6GNet58894.2023.10317780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179753577&doi=10.1109%2f6GNet58894.2023.10317780&partnerID=40&md5=34754c2c3bb7c9526dc73eda5586b469},
	affiliations = {Fraunhofer Fokus Institute, Berlin, Germany; Technische Universität Berlin, Berlin, Germany},
	abstract = {Within the current 6G and beyond 5G research, digital twins have become an indispensable asset for network management. These digital twins offer real-time and dynamic system representations, enabling precise decision-making and comprehensive testing in simulation environments before deployment. Going further, we introduce the novel concept of 'Generative Twin', an approach enabling the automatic generation system configurations and test system situations using Generative Artificial Intelligence (AI) and surpassing the limitations of human administrators. Our work reaches further, presenting a high-level architecture that outlines the additional functional elements and interfaces required to enhance the digital twins for 5G networks. We also demonstrate a mock-up simulation of information generation using the Large Language Model (LLM) ChatGPT and a best-practices digital twin based on the Open5GCore toolkit. Furthermore, we present a practical implementation roadmap, offering guidance for effective integration of generative twins and the technology challenges that necessitate further research, highlighting the very large potential of leveraging generative AI as an integral part of network management.  © 2023 IEEE.},
	author_keywords = {5G; 6G; Digital Twin; Dynamic Twin; Generative AI},
	keywords = {Decision making; Memory architecture; Network architecture; Network management; Queueing networks; 'current; 5g; 6g; Comprehensive testing; Decisions makings; Dynamic twin; Generative artificial intelligence; Network vision; Networks management; System representation; 5G mobile communication systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030673-6},
	language = {English},
	abbrev_source_title = {Int. Conf. 6G Netw., 6GNet},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang20239850,
	author = {Zhang, Zhihan and Wang, Shuohang and Yu, Wenhao and Xu, Yichong and Iter, Dan and Zeng, Qingkai and Liu, Yang and Zhu, Chenguang and Jiang, Meng},
	title = {Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {9850 – 9867},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180294302&partnerID=40&md5=6f1757ded7f3276bc198b67c3bf9550a},
	affiliations = {University of Notre Dame, United States; Microsoft Azure AI, United States},
	abstract = {Large language models (LLMs) can perform a wide range of tasks by following natural language instructions, without the necessity of task-specific fine-tuning. Unfortunately, the performance of LLMs is greatly influenced by the quality of these instructions, and manually writing effective instructions for each task is a laborious and subjective process. In this paper, we introduce Auto-Instruct, a novel method to automatically improve the quality of instructions provided to LLMs. Our method leverages the inherent generative ability of LLMs to produce diverse candidate instructions for a given task, and then ranks them using a scoring model trained on a variety of 575 existing NLP tasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both human-written instructions and existing baselines of LLM-generated instructions. Furthermore, our method exhibits notable generalizability even with other LLMs that are not incorporated into its training process. © 2023 Association for Computational Linguistics.},
	keywords = {Black boxes; Fine tuning; Instruction generations; Language model; Natural languages; Novel methods; Performance; Quality of instructions; Scoring models; Training process; Computational linguistics},
	correspondence_address = {Z. Zhang; University of Notre Dame, United States; email: zzhang23@nd.edu},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176061-5},
	language = {English},
	abbrev_source_title = {Find. Assoc. Comput. Linguist.: EMNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Datta202316,
	author = {Datta, V Dinesh and Ganesh, Sakthi and Haas, Roland E. and Talukder, Asoke K.},
	title = {GREAT AI in Medical Appropriateness and Value-Based-Care},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14418 LNCS},
	pages = {16 – 33},
	doi = {10.1007/978-3-031-49601-1_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180527813&doi=10.1007%2f978-3-031-49601-1_2&partnerID=40&md5=4c27a648eb683a24f14789f02fc3ae5b},
	affiliations = {Kakatiya Medical College, Nizampura, Rangampet Street, Telangana, Warangal, 506007, India; XAITeck GmbH, Heinrich-Otto-Straße 71, Wendlingen, 73240, Germany; International Institute of Information Technology, 26/C, Electronics City, Hosur Road, Bengaluru, 560100, India; BlueRose Technologies, 1-1, Langford Road, Shanti Nagar, Bengaluru, 560027, India; Computer Science & Engineering, National Institute of Technology, Surathkal, India; SRIT, 113/1B ITPL Road, Brookfield, Bengaluru, 560037, India},
	abstract = {Fee For Service, also known as Volume Based Care (VBC) model of healthcare encourages service volume – more service more reward. This model of care results in unnecessary, inappropriate, and wasted medical services. In the US, Fraud, Waste, and Abuse (FWA) ranges between $760 billion to $935 billion, accounting for approximately 25% of total healthcare spending. In India, the waste caused by FWA is estimated to be as high as 35%. This is due to a lack of smart digital health, absence of AI models, and lack of preventive vigilance against inappropriate medical interventions. Inappropriate medical intervention costs valuable resources and causes patient harm. This paper proposes GREAT AI (Generative, Responsible, Explainable, Adaptive, and Trustworthy Artificial Intelligence) in Medical Appropriateness. We show how GREAT AI is used to offer appropriate medical services. Moreover, we show how GREAT AI can function in vigilance role to curb FWA. We present two GREAT AI models namely MAKG (Medical Appropriateness Knowledge Graph) and RAG-GPT (Retrieval Augmented Generation – Generative Pretrained Transformer). MAKG is used as an autonomous coarse-grained medical-inappropriateness vigilance model for payers and regulators. Whereas RAG-GPT is used as a fine-grained LLM, with human-in-the-loop for medical appropriateness and medical inappropriateness model where the actor human-in-the loop can be anybody like providers, patients, payers, regulators, funders, or researchers. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Adaptive AI; Explainable AI; Generative AI; GREAT AI; MAKG; Medical Appropriateness; RAG-GPT; Responsible AI; Trustworthy AI},
	keywords = {Patient treatment; Adaptive AI; Explainable AI; Generative AI; GREAT AI; Knowledge graphs; Medical appropriateness; Medical appropriateness knowledge graph; Responsible AI; Retrieval augmented generation – generative pretrained transformer; Trustworthy AI; Knowledge graph},
	correspondence_address = {A.K. Talukder; BlueRose Technologies, Bengaluru, 1-1, Langford Road, Shanti Nagar, 560027, India; email: asoke.talukder@bluerose-tech.com},
	editor = {Goyal V. and Kumar D. and Kumar N. and Bhowmick S.S. and Goyal P. and Goyal N.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303149600-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Barreto2023545,
	author = {Barreto, Fabian and Moharkar, Lalita and Shirodkar, Madhura and Sarode, Vidya and Gonsalves, Saniya and Johns, Aaron},
	title = {Generative Artificial Intelligence: Opportunities and Challenges of Large Language Models},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {699 LNNS},
	pages = {545 – 553},
	doi = {10.1007/978-981-99-3177-4_41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172001965&doi=10.1007%2f978-981-99-3177-4_41&partnerID=40&md5=c94228721a37ef873d9f9dfcc34282b1},
	affiliations = {Department of Electronics and Telecommunication, Xavier Institute of Engineering, Mumbai, India; Department of Applied Sciences and Humanities, Xavier Institute of Engineering, Mumbai, India; Department of Information Technology, St. Xavier’s College, Mumbai, India},
	abstract = {Artificial Intelligence (AI) research in the past decade has led to the development of Generative AI, where AI systems create new information from almost nothing after learning from trained models. Generative AI can create original work, like an article, a code, a painting, a poem, or a song. Google Brain initially used Large Language Models (LLM) for context-aware text translation, and Google went on to develop Bidirectional Encoder Representations from Transformers (BERT) and Language Model for Dialogue Applications (LaMDA). Facebook created OPT-175B and BlenderBot, while OpenAI innovated GPT-3 for text, DALL-E2 for images, and Whisper for speech. GPT-3 was trained on around 45 terabytes of text data at an estimated cost of several million dollars. Generative models have also been developed from online communities like Midjourney and open-source ones like HuggingFace. On November 30, 2022, OpenAI launched ChatGPT, which used natural language processing (NLP) techniques and was trained on LLM. There was excitement and caution as OpenAI’s ChatGPT reached one million users in just five days, and in January 2023 reached 100 million users. Many marveled at its eloquence and the limited supervision with which it generated code and answered questions. More deployments followed; Microsoft’s OpenAI-powered Bing on February 7, 2023, followed by Google’s Bard on February 8, 2023. We describe the working of LLM and their opportunities and challenges for our modern world. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Bing; chatGPT; Generative artificial intelligence; Large language models},
	keywords = {Artificial intelligence; Codes (symbols); Computational linguistics; Natural language processing systems; Artificial intelligence research; Artificial intelligence systems; Bing; Chatgpt; Context-Aware; Generative artificial intelligence; Google+; Language model; Large language model; Transformer modeling; Social networking (online)},
	correspondence_address = {F. Barreto; Department of Electronics and Telecommunication, Xavier Institute of Engineering, Mumbai, India; email: frfabiansj@xavier.ac.in},
	editor = {Balas V.E. and Semwal V.B. and Khandare A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-981993176-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Foley20237423,
	author = {Foley, Myles and Rawat, Ambrish and Lee, Taesung and Hou, Yufang and Picco, Gabriele and Zizzo, Giulio},
	title = {Matching Pairs: Attributing Fine-Tuned Models to their Pre-Trained Large Language Models},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {7423 – 7442},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174413730&partnerID=40&md5=2cc9b748989119213cf8b3a88a96a36d},
	affiliations = {Imperial College London, United Kingdom; IBM Research, United States},
	abstract = {The wide applicability and adaptability of generative large language models (LLMs) has enabled their rapid adoption. While the pretrained models can perform many tasks, such models are often fine-tuned to improve their performance on various downstream applications. However, this leads to issues over violation of model licenses, model theft, and copyright infringement. Moreover, recent advances show that generative technology is capable of producing harmful content which exacerbates the problems of accountability within model supply chains. Thus, we need a method to investigate how a model was trained or a piece of text was generated and what their pre-trained base model was. In this paper we take the first step to address this open problem by tracing back the origin of a given fine-tuned LLM to its corresponding pre-trained base model. We consider different knowledge levels and attribution strategies, and find that we can correctly trace back 8 out of the 10 fine tuned models with our best method. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Base models; Copyright infringement; Downstream applications; Generative technologies; Knowledge level; Language model; Matchings; Performance; Trace backs; Supply chains},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {978-195942972-2},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Mastropaolo2023585,
	author = {Mastropaolo, Antonio and Di Penta, Massimiliano and Bavota, Gabriele},
	title = {Towards Automatically Addressing Self-Admitted Technical Debt: How Far Are We?},
	year = {2023},
	journal = {Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023},
	pages = {585 – 597},
	doi = {10.1109/ASE56229.2023.00103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179011988&doi=10.1109%2fASE56229.2023.00103&partnerID=40&md5=80233eca294aef51c9bfa5485185c3e9},
	affiliations = {Seart @ Software Institute, Università della Svizzera Italiana (USI), Switzerland; University of Sannio, Dept. of Engineering, Italy},
	abstract = {Upon evolving their software, organizations and individual developers have to spend a substantial effort to pay back technical debt, i.e, the fact that software is released in a shape not as good as it should be, e.g, in terms of functionality, reliability, or maintainability. This paper empirically investigates the extent to which technical debt can be automatically paid back by neural-based generative models, and in particular models exploiting different strategies for pre-training and fine-tuning. We start by extracting a dateset of 5,039 Self-Admitted Technical Debt (SATD) removals from 595 open-source projects. SATD refers to technical debt instances documented (e.g, via code comments) by developers. We use this dataset to experiment with seven different generative deep learning (DL) model configurations. Specifically, we compare transformers pre-trained and fine-tuned with different combinations of training objectives, including the fixing of generic code changes, SATD removals, and SATD-comment prompt tuning. Also, we investigate the applicability in this context of a recently-available Large Language Model (LLM)-based chat bot. Results of our study indicate that the automated repayment of SATD is a challenging task, with the best model we experimented with able to automatically fix ∼2% to 8% of test instances, depending on the number of attempts it is allowed to make. Given the limited size of the fine-tuning dataset (∼5k instances), the model's pre-training plays a fundamental role in boosting performance. Also, the ability to remove SATD steadily drops if the comment documenting the SATD is not provided as input to the model. Finally, we found general-purpose LLMs to not be a competitive approach for addressing SATD.  © 2023 IEEE.},
	author_keywords = {Machine Learning for Code; Pre-trained models; Self-Admitted Technical Debt},
	keywords = {Deep learning; Learning systems; Open source software; Fine tuning; Generative model; Machine learning for code; Machine-learning; Open source projects; Pre-trained model; Pre-training; Self-admitted technical debt; Software organization; Technical debts; Software reliability},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032996-4},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Int. Conf. Autom. Softw. Eng., ASE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{He2023223,
	author = {He, Jun-Yan and Cheng, Zhi-Qi and Li, Chenyang and Sun, Jingdong and Xiang, Wangmeng and Lin, Xianhui and Kang, Xiaoyang and Jin, Zengke and Hu, Yusen and Luo, Bin and Geng, Yifeng and Xie, Xuansong},
	title = {WordArt Designer: User-Driven Artistic Typography Synthesis using Large Language Models},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Industry Track},
	pages = {223 – 232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182660611&partnerID=40&md5=7a49ce042bd7bb01fd93ba5e834f45f8},
	affiliations = {Alibaba DAMO Academy, China; Carnegie Mellon University, United States; Zhejiang Sci-Tech University, China; Royal College of Art, United Kingdom; Imperial College London, United Kingdom},
	abstract = {This paper introduces WordArt Designer, a user-driven framework for artistic typography synthesis, relying on the Large Language Model (LLM). The system incorporates four key modules: the LLM Engine, SemTypo, StyTypo, and TexTypo modules. 1) The LLM Engine, empowered by the LLM (e.g. GPT-3.5), interprets user inputs and generates actionable prompts for the other modules, thereby transforming abstract concepts into tangible designs. 2) The SemTypo module optimizes font designs using semantic concepts, striking a balance between artistic transformation and readability. 3) Building on the semantic layout provided by the SemTypo module, the StyTypo module creates smooth, refined images. 4) The TexTypo module further enhances the design's aesthetics through texture rendering, enabling the generation of inventive textured fonts. Notably, WordArt Designer highlights the fusion of generative AI with artistic typography. Experience its capabilities on ModelScope: https://www.modelscope.cn/studios/WordArt/WordArt. © 2023 Association for Computational Linguistics.},
	keywords = {Abstracting; Computational linguistics; Engines; Semantics; Abstract concept; Design aesthetics; Font design; Language model; Model engine; Semantic concept; Tangible designs; User driven; User input; Textures},
	editor = {Wang M. and Zitouni I.},
	publisher = {Association for Computational Linguistics (ACL)},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Ind. Track},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2023,
	author = {Wang, Karen D. and Burkholder, Eric and Wieman, Carl and Salehi, Shima and Haber, Nick},
	title = {Examining the potential and pitfalls of ChatGPT in science and engineering problem-solving},
	year = {2023},
	journal = {Frontiers in Education},
	volume = {8},
	doi = {10.3389/feduc.2023.1330486},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183909215&doi=10.3389%2ffeduc.2023.1330486&partnerID=40&md5=46614a40804cf67086ad7e5061938edf},
	affiliations = {Graduate School of Education, Stanford University, Stanford, CA, United States; Department of Physics, Auburn University, Auburn, AL, United States; Department of Physics, Stanford University, Stanford, CA, United States},
	abstract = {The study explores the capabilities of OpenAI's ChatGPT in solving different types of physics problems. ChatGPT (with GPT-4) was queried to solve a total of 40 problems from a college-level engineering physics course. These problems ranged from well-specified problems, where all data required for solving the problem was provided, to under-specified, real-world problems where not all necessary data were given. Our findings show that ChatGPT could successfully solve 62.5% of the well-specified problems, but its accuracy drops to 8.3% for under-specified problems. Analysis of the model's incorrect solutions revealed three distinct failure modes: (1) failure to construct accurate models of the physical world, (2) failure to make reasonable assumptions about missing data, and (3) calculation errors. The study offers implications for how to leverage LLM-augmented instructional materials to enhance STEM education. The insights also contribute to the broader discourse on AI's strengths and limitations, serving both educators aiming to leverage the technology and researchers investigating human-AI collaboration frameworks for problem-solving and decision-making. Copyright © 2024 Wang, Burkholder, Wieman, Salehi and Haber.},
	author_keywords = {authentic problems; ChatGPT; generative AI models; GPT-4; physics education; problem-solving; STEM education},
	correspondence_address = {K.D. Wang; Graduate School of Education, Stanford University, Stanford, United States; email: kdwang@stanford.edu},
	publisher = {Frontiers Media SA},
	issn = {2504284X},
	language = {English},
	abbrev_source_title = {Front. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Triantoro2023793,
	author = {Triantoro, Tamilla and Przegalinska, Aleksandra and Kovbasiuk, Anna},
	title = {HUMAN-AI COLLABORATION IN THE CONTEMPORARY WORKPLACE: THE JOB DEMANDS-RESOURCES MODEL PERSPECTIVE},
	year = {2023},
	journal = {36th Bled eConference: Digital Economy and Society: The Balancing Act for Digital Innovation in Times of Instability, BLED 2023 - Proceedings},
	pages = {793 – 798},
	doi = {10.18690/um.fov.4.2023.51},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173606329&doi=10.18690%2fum.fov.4.2023.51&partnerID=40&md5=c152f50d823c59cef1e166bec14d00de},
	affiliations = {Quinnipiac University, Hamden, CT, United States; Kozminski University, Warsaw, Poland},
	abstract = {Evaluating the impact of AI in the context of the Job Demands- Resources (JD-R) model is useful for understanding the factors that influence employee well-being in the modern workplace. The JD-R model highlights the importance of job demands and resources in predicting work-related outcomes, such as job satisfaction and burnout. However, with the increasing adoption of AI in the workplace, it is unclear how these factors interact with AI use. Evaluating the impact of AI on job demands and resources in the JD-R context can shed light on how this technology can affect employee well-being. Additionally, by understanding the factors that influence employee well-being in the presence of AI, organizations can create effective strategies to enhance human-AI collaboration, leading to increased productivity, efficiency, and ultimately, a healthier and more satisfied workforce. © University of Maribor, University Press.},
	author_keywords = {ChatGPT; future of work; generative AI; JD-R model; large language model (LLM)},
	keywords = {ChatGPT; Demand resources; Future of works; Generative AI; Job demand- resource model; Job demands; Language model; Large language model; Resource modelling; Well being; Job satisfaction},
	editor = {Pucihar A. and Borstnar M.K. and Bons R. and Bons R. and Ongena G. and Heikkila M. and Vidmar D.},
	publisher = {University of Maribor Press},
	isbn = {978-961286751-5},
	language = {English},
	abbrev_source_title = {Bled eConference: Digit. Econ. Soc.: Balanc. Act Digit. Innov. Times Instab., BLED - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ali2023135,
	author = {Ali, Farhan and Choy, Doris and Divaharan, Shanti and Tay, Hui Yong and Chen, Wenli},
	title = {Supporting self-directed learning and self-assessment using TeacherGAIA, a generative AI chatbot application: Learning approaches and prompt engineering},
	year = {2023},
	journal = {Learning: Research and Practice},
	volume = {9},
	number = {2},
	pages = {135 – 147},
	doi = {10.1080/23735082.2023.2258886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172808547&doi=10.1080%2f23735082.2023.2258886&partnerID=40&md5=96d8b6e15284ca983bf1993d3b1c30ca},
	affiliations = {Learning Sciences and Assessment Academic Group, National Institute of Education, Nanyang Technological University, Singapore},
	abstract = {Self-directed learning and self-assessment require student responsibility over learning needs, goals, processes, and outcomes. However, this student-led learning can be challenging to achieve in a classroom limited by a one-to-many teacher-led instruction. We, thus, have designed and prototyped a generative artificial intelligence chatbot application (GAIA), named TeacherGAIA, that can be used to asynchronously support students in their self-directed learning and self-assessment outside the classroom. We first identified diverse constructivist learning approaches that align with, and promote, student-led learning. These included knowledge construction, inquiry-based learning, self-assessment, and peer teaching. The in-context learning abilities of large language model (LLM) from OpenAI were then leveraged via prompt engineering to steer interactions supporting these different learning approaches. These interactions contrasted with ChatGPT, OpenAI’s chatbot which by default engaged in the traditional transmissionist mode of learning reminiscent of teacher-led instruction. Preliminary design, prompt engineering and prototyping suggested fidelity to the learning approaches, cognitive guidance, and social-emotional support, all of which were implemented in a generative AI manner without pre-specified rules or “hard-coding”. Other affordances of TeacherGAIA are discussed and future development outlined. We anticipate TeacherGAIA to be a useful application for teachers in facilitating self-directed learning and self-assessment among K-12 students. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {chatbot; generative AI; GPT-4; self-assessment; self-directed learning},
	correspondence_address = {F. Ali; Learning Sciences and Assessment Academic Group, National Institute of Education, Nanyang Technological University, 1 Nanyang Walk, 637616, Singapore; email: farhan.ali@nie.edu.sg},
	publisher = {Routledge},
	issn = {23735082},
	language = {English},
	abbrev_source_title = {Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Lucas202314279,
	author = {Lucas, Jason and Uchendu, Adaku and Yamashita, Michiharu and Lee, Jooyoung and Rohatgi, Shaurya and Lee, Dongwon},
	title = {Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {14279 – 14305},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306067&partnerID=40&md5=13af8f1445a672f4cd9ee71dbc29c82d},
	affiliations = {The Pennsylvania State University, University Park, PA, United States; MIT Lincoln Laboratory, Lexington, MA, United States},
	abstract = {Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (i.e., generating large-scale harmful and misleading content). To combat this emerging risk of LLMs, we propose a novel “Fighting Fire with Fire” (F3) strategy that harnesses modern LLMs' generative and emergent reasoning capabilities to counter human-written and LLM-generated disinformation. First, we leverage GPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content through paraphrase-based and perturbation-based prefix-style prompts, respectively. Second, we apply zero-shot in-context semantic reasoning techniques with cloze-style prompts to discern genuine from deceptive posts & news articles. In our extensive experiments, we observe GPT-3.5-turbo's zero-shot superiority for both in-distribution and out-of-distribution datasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72%, unlike the decline observed in previous customized and fine-tuned disinformation detectors. Our codebase and dataset are available at https://github.com/mickeymst/F3. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Fires; Zero-shot learning; Dual role; In contexts; Language model; Large-scales; News articles; Reasoning capabilities; Reasoning techniques; Semantic reasoning; Semantics},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Routray2023,
	author = {Routray, Sudhir K. and Javali, Abhishek and Sharmila, K.P. and Jha, Mahesh K. and Pappa, M. and Singh, Monika},
	title = {Large Language Models (LLMs): Hypes and Realities},
	year = {2023},
	journal = {2023 International Conference on Computer Science and Emerging Technologies, CSET 2023},
	doi = {10.1109/CSET58993.2023.10346621},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182026069&doi=10.1109%2fCSET58993.2023.10346621&partnerID=40&md5=c80973048449143b0dd6a063e5813f5a},
	affiliations = {Cmr University, Department of Computer Science and Engineering, Bangalore, India; Cmr Institute of Technology, Department of Electronics and Communication Engineering, Bangalore, India},
	abstract = {Artificial intelligence (AI) has created a lot of buzz in recent years. Using machine learning and other AI techniques several intelligent initiatives have been tested. The large language model is one of them. A large language model (LLM) normally refers to a type of AI model that is trained on vast amounts of text data to understand and generate human-like language outputs. These models are designed to capture the statistical patterns and structures present in the training data, enabling them to generate coherent and contextually relevant responses. The widely known ChatGPT is one of the LLMs which can do several tasks and answer many questions. It is trained with a huge number of data sets and a large number of parameters. In addition to ChatGPT, many other LLMs such as the Google Bard, Claude v1, Bison 001, Cohere, Falcon, and Guanaco-65B have surfaced in recent times. In this paper, we study the basic principles and features of LLMs. We go through their brief history, abilities, limitations, challenges and future prospects. © 2023 IEEE.},
	author_keywords = {Artificial intelligence; generative AI; hypes of LLM; large language model; realities of LLM},
	keywords = {Artificial intelligence; Artificial intelligence techniques; Generative artificial intelligence; Hype of large language model; Intelligence models; Language model; Large language model; Machine-learning; Reality of large language model; Computational linguistics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034173-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Sci. Emerg. Technol., CSET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Indran2023,
	author = {Indran, Inthrani Raja and Paramanathan, Priya and Gupta, Neelima and Mustafa, Nurulhuda},
	title = {Twelve tips to leverage AI for efficient and effective medical question generation: A guide for educators using Chat GPT},
	year = {2023},
	journal = {Medical Teacher},
	doi = {10.1080/0142159X.2023.2294703},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180907065&doi=10.1080%2f0142159X.2023.2294703&partnerID=40&md5=cf8393cb6c2c1a27141e6069e75bff56},
	affiliations = {Department of Pharmacology, National University of Singapore, Yong Loo Lin School of Medicine, Singapore, Singapore},
	abstract = {Background: Crafting quality assessment questions in medical education is a crucial yet time-consuming, expertise-driven undertaking that calls for innovative solutions. Large language models (LLMs), such as ChatGPT (Chat Generative Pre-Trained Transformer), present a promising yet underexplored avenue for such innovations. Aims: This study explores the utility of ChatGPT to generate diverse, high-quality medical questions, focusing on multiple-choice questions (MCQs) as an illustrative example, to increase educator’s productivity and enable self-directed learning for students. Description: Leveraging 12 strategies, we demonstrate how ChatGPT can be effectively used to generate assessment questions aligned with Bloom’s taxonomy and core knowledge domains while promoting best practices in assessment design. Conclusion: Integrating LLM tools like ChatGPT into generating medical assessment questions like MCQs augments but does not replace human expertise. With continual instruction refinement, AI can produce high-standard questions. Yet, the onus of ensuring ultimate quality and accuracy remains with subject matter experts, affirming the irreplaceable value of human involvement in the artificial intelligence-driven education paradigm. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {AI; Chat GPT; medical assessment; questions},
	correspondence_address = {I.R. Indran; Department of Pharmacology, National University of Singapore, Yong Loo Lin School of Medicine, MD3, 16 Medical Drive, 117600, Singapore; email: phciri@nus.edu.sg},
	publisher = {Taylor and Francis Ltd.},
	issn = {0142159X},
	coden = {MEDTD},
	language = {English},
	abbrev_source_title = {Med. Teach.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Favela2023,
	author = {Favela, Luis H. and Amon, Mary Jean},
	title = {The ethics of human digital twins: Counterfeit people, personhood, and the right to privacy},
	year = {2023},
	journal = {2023 IEEE 3rd International Conference on Digital Twins and Parallel Intelligence, DTPI 2023},
	doi = {10.1109/DTPI59677.2023.10365409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182728730&doi=10.1109%2fDTPI59677.2023.10365409&partnerID=40&md5=61799214b09adfdb9f09d3e0d1cf8a3f},
	affiliations = {University of Central Florida, Cognitive Sciences Program, Department of Philosophy, Orlando, FL, United States; University of Central Florida, School of Modeling, Simulation, and Training, Orlando, FL, United States},
	abstract = {In recent years, generative artificial intelligence (AI) in the form of large language models (LLM) have sparked the interest of society at large. The perceived capabilities of such systems have reignited discussions concerning the actual or potential threats posed by AI. According to Daniel Dennett, these systems make possible the creation of counterfeit people, who can pass as real in digital environments like social media. Dennett claims that by undermining trust in relationships, counterfeit people pose a threat to democracy and human freedom. While the idea of counterfeit people is worrisome in the context of digital manipulation, we claim that human digital twins have the potential to facilitate human rights violations that may pose even greater challenges. High-fidelity human digital twins necessitate encroaching into features that constitute a human's personhood, such as physical aspects and mental contents. In view of that, their creation raises pressing issues of consent and violations of privacy rights. As a result, because rights to privacy are rights of persons, such violations will simultaneously be human rights violations. Even with consent to use an individual's data, human digital twins may still cause issues of personhood. The rapid adoption of technologies that facilitate counterfeit people and human digital twins demands that ethical issues not be treated as aside concerns, but at the forefront of technology development. © 2023 IEEE.},
	author_keywords = {digital twin; ethics; personhood; privacy; rights},
	keywords = {Crime; Social aspects; Daniels; Digital environment; Human rights; Language model; Perceived capabilities; Personhood; Potential threats; Privacy; Right; Right to privacies; Ethical technology},
	correspondence_address = {L.H. Favela; University of Central Florida, Cognitive Sciences Program, Department of Philosophy, Orlando, United States; email: luis.favela@ucf.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031847-0},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Digit. Twins Parallel Intell., DTPI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zubiaga2023,
	author = {Zubiaga, Arkaitz},
	title = {Natural language processing in the era of large language models},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence},
	volume = {6},
	doi = {10.3389/frai.2023.1350306},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183643698&doi=10.3389%2ffrai.2023.1350306&partnerID=40&md5=91c3f264e5c325d0eca619bc8c197e0c},
	affiliations = {School of Electronic Engineering and Computer Science, Queen Mary University of London, London, United Kingdom},
	author_keywords = {generative AI; language models (LMs); large language models (LLM); natural language processing; specialty grand challenge},
	correspondence_address = {A. Zubiaga; School of Electronic Engineering and Computer Science, Queen Mary University of London, London, United Kingdom; email: a.zubiaga@qmul.ac.uk},
	publisher = {Frontiers Media SA},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Savage2023,
	author = {Savage, Thomas and Wang, John and Shieh, Lisa},
	title = {A Large Language Model Screening Tool to Target Patients for Best Practice Alerts: Development and Validation},
	year = {2023},
	journal = {JMIR Medical Informatics},
	volume = {11},
	number = {1},
	doi = {10.2196/49886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180079533&doi=10.2196%2f49886&partnerID=40&md5=987d1a6189aeb158ee224083582d56a6},
	affiliations = {Division of Hospital Medicine, Department of Medicine, Stanford University, Palo Alto, CA, United States; Divison of Gastroenterology and Hepatology, Department of Medicine, Stanford University, Palo Alto, CA, United States},
	abstract = {Background: Best Practice Alerts (BPAs) are alert messages to physicians in the electronic health record that are used to encourage appropriate use of health care resources. While these alerts are helpful in both improving care and reducing costs, BPAs are often broadly applied nonselectively across entire patient populations. The development of large language models (LLMs) provides an opportunity to selectively identify patients for BPAs. Objective: In this paper, we present an example case where an LLM screening tool is used to select patients appropriate for a BPA encouraging the prescription of deep vein thrombosis (DVT) anticoagulation prophylaxis. The artificial intelligence (AI) screening tool was developed to identify patients experiencing acute bleeding and exclude them from receiving a DVT prophylaxis BPA. Methods: Our AI screening tool used a BioMed-RoBERTa (Robustly Optimized Bidirectional Encoder Representations from Transformers Pretraining Approach; AllenAI) model to perform classification of physician notes, identifying patients without active bleeding and thus appropriate for a thromboembolism prophylaxis BPA. The BioMed-RoBERTa model was fine-tuned using 500 history and physical notes of patients from the MIMIC-III (Medical Information Mart for Intensive Care) database who were not prescribed anticoagulation. A development set of 300 MIMIC patient notes was used to determine the model’s hyperparameters, and a separate test set of 300 patient notes was used to evaluate the screening tool. Results: Our MIMIC-III test set population of 300 patients included 72 patients with bleeding (ie, were not appropriate for a DVT prophylaxis BPA) and 228 without bleeding who were appropriate for a DVT prophylaxis BPA. The AI screening tool achieved impressive accuracy with a precision-recall area under the curve of 0.82 (95% CI 0.75-0.89) and a receiver operator curve area under the curve of 0.89 (95% CI 0.84-0.94). The screening tool reduced the number of patients who would trigger an alert by 20% (240 instead of 300 alerts) and increased alert applicability by 14.8% (218 [90.8%] positive alerts from 240 total alerts instead of 228 [76%] positive alerts from 300 total alerts), compared to nonselectively sending alerts for all patients. Conclusions: These results show a proof of concept on how language models can be used as a screening tool for BPAs. We provide an example AI screening tool that uses a HIPAA (Health Insurance Portability and Accountability Act)–compliant BioMed-RoBERTa model deployed with minimal computing power. Larger models (eg, Generative Pre-trained Transformers–3, Generative Pre-trained Transformers–4, and Pathways Language Model) will exhibit superior performance but require data use agreements to be HIPAA compliant. We anticipate LLMs to revolutionize quality improvement in hospital medicine. © 2023 JMIR Publications Inc. All rights reserved.},
	author_keywords = {Artificial Intelligence; EHR; health record; health records; language model; language models; large language models; Natural Language Processing; quality improvement},
	correspondence_address = {T. Savage; Division of Hospital Medicine Department of Medicine Stanford University, Palo Alto, 300 Pasteur Drive, 94304, United States; email: tsavage@stanford.edu},
	publisher = {JMIR Publications Inc.},
	issn = {22919694},
	language = {English},
	abbrev_source_title = {JMIR Med. Inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Abburi2023699,
	author = {Abburi, Harika and Suesserman, Michael and Pudota, Nirmala and Veeramani, Balaji and Bowen, Edward and Bhattacharya, Sanmitra},
	title = {An Ensemble-Based Approach for Generative Language Model Attribution},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14306 LNCS},
	pages = {699 – 709},
	doi = {10.1007/978-981-99-7254-8_54},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175953566&doi=10.1007%2f978-981-99-7254-8_54&partnerID=40&md5=458694cce534895ab10191164e691a96},
	affiliations = {Deloitte and Touche Assurance and Enterprise Risk Services India Private Limited, Hyderabad, India; Deloitte and Touche LLP, New York, United States},
	abstract = {Recently, Large Language Models (LLMs) have gained considerable attention due to their incredible ability to automatically generate texts that closely resemble human-written text. They have become invaluable tools in handling various text-based tasks such as content creation and report generation. Nevertheless, the proliferation of these tools can create undesirable consequences such as generation of false information and plagiarism. A variety of LLMs have been operationalized in the last few years whose abilities are heavily influenced by the quality of their training corpus, model architecture, pre-training tasks, and fine-tuning processes. Our ability to attribute the generated text to a specific LLM will not only help us understand differences in the LLMs’ output characteristics, but also effectively distinguish machine-generated text from human-generated text. In this paper, we study whether a machine learning model can be effectively trained to attribute text to the underlying LLM that generated it. We propose an ensemble neural model that generates probabilities from multiple pre-trained LLMs, which are then used as features for a traditional machine learning classifier. The proposed approach is tested on Automated Text Identification (AuTexTification) datasets in English and Spanish languages. We find that our models outperform various baselines, achieving macro Fmacro scores of 0.63 and 0.65 for English and Spanish texts, respectively. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Ensemble; Generative AI; Large language models; Model Attribution},
	keywords = {Computational linguistics; Content creation; Ensemble; Generative AI; Language model; Large language model; Model attribution; Modeling architecture; Report generation; Training corpus; Written texts; Machine learning},
	correspondence_address = {H. Abburi; Deloitte and Touche Assurance and Enterprise Risk Services India Private Limited, Hyderabad, India; email: abharika@deloitte.com},
	editor = {Zhang F. and Wang H. and Barhamgi M. and Chen L. and Zhou R.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-981997253-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hsu2023,
	author = {Hsu, Hsing-Yu and Hsu, Kai-Cheng and Hou, Shih-Yen and Wu, Ching-Lung and Hsieh, Yow-Wen and Cheng, Yih-Dih},
	title = {Examining Real-World Medication Consultations and Drug-Herb Interactions: ChatGPT Performance Evaluation},
	year = {2023},
	journal = {JMIR Medical Education},
	volume = {9},
	doi = {10.2196/48433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169057594&doi=10.2196%2f48433&partnerID=40&md5=db7929a80ec2786c3d7bd9ff612c5de8},
	affiliations = {Department of Pharmacy, China Medical University Hospital, Taichung, Taiwan; Graduate Institute of Clinical Pharmacy, College of Medicine, National Taiwan University, Taipei, Taiwan; Artificial Intelligence Center, China Medical University Hospital, Taichung, Taiwan; Department of Medicine, China Medical University, Taichung, Taiwan; School of Pharmacy, College of Pharmacy, China Medical University, Taichung, Taiwan},
	abstract = {Background: Since OpenAI released ChatGPT, with its strong capability in handling natural tasks and its user-friendly interface, it has garnered significant attention. Objective: A prospective analysis is required to evaluate the accuracy and appropriateness of medication consultation responses generated by ChatGPT. Methods: A prospective cross-sectional study was conducted by the pharmacy department of a medical center in Taiwan. The test data set comprised retrospective medication consultation questions collected from February 1, 2023, to February 28, 2023, along with common questions about drug-herb interactions. Two distinct sets of questions were tested: real-world medication consultation questions and common questions about interactions between traditional Chinese and Western medicines. We used the conventional double-review mechanism. The appropriateness of each response from ChatGPT was assessed by 2 experienced pharmacists. In the event of a discrepancy between the assessments, a third pharmacist stepped in to make the final decision. Results: Of 293 real-world medication consultation questions, a random selection of 80 was used to evaluate ChatGPT’s performance. ChatGPT exhibited a higher appropriateness rate in responding to public medication consultation questions compared to those asked by health care providers in a hospital setting (31/51, 61% vs 20/51, 39%; P=.01). Conclusions: The findings from this study suggest that ChatGPT could potentially be used for answering basic medication consultation questions. Our analysis of the erroneous information allowed us to identify potential medical risks associated with certain questions; this problem deserves our close attention. ©Hsing-Yu Hsu, Kai-Cheng Hsu, Shih-Yen Hou, Ching-Lung Wu, Yow-Wen Hsieh, Yih-Dih Cheng.},
	author_keywords = {chat generative pre-trained transformer; ChatGPT; drug-herb interactions; language models; large language model; LLM; natural language processing; NLP; pharmacist; real-world medication consultation questions},
	correspondence_address = {Y.-W. Hsieh; Department of Pharmacy, China Medical University Hospital, Taichung, 2 Yuh-Der Road, 404327, Taiwan; email: yowenhsieh@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {23693762},
	language = {English},
	abbrev_source_title = {JMIR Med. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Fernandez2023,
	author = {Fernandez, Pierre and Chaffin, Antoine and Tit, Karim and Chappelier, Vivien and Furon, Teddy},
	title = {Three Bricks to Consolidate Watermarks for Large Language Models},
	year = {2023},
	journal = {WIFS 2023 - IEEE Workshop on Information Forensics and Security},
	doi = {10.1109/WIFS58808.2023.10374576},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183462229&doi=10.1109%2fWIFS58808.2023.10374576&partnerID=40&md5=4436f8f240e8941c24f4c0c25e849f31},
	affiliations = {L'Université de Rennes, Centre Inria De, France; Meta Ai, France; Imatag, France},
	abstract = {Discerning between generated and natural texts is increasingly challenging. In this context, watermarking emerges as a promising technique for ascribing text to a specific generative model. It alters the sampling generation process to leave an invisible trace in the output, facilitating later detection. This research consolidates watermarks for large language models based on three theoretical and empirical considerations. First, we introduce new statistical tests that offer robust theoretical guarantees which remain valid even at low false-positive rates (less than 10-6). Second, we compare the effectiveness of watermarks using classical benchmarks in the field of natural language processing, gaining insights into their real-world applicability. Third, we develop advanced detection schemes for scenarios where access to the LLM is available, as well as multi-bit watermarking.  © 2023 IEEE.},
	author_keywords = {Large Language Model; Watermarking},
	keywords = {Computational linguistics; Watermarking; False positive rates; Gaining insights; Generation process; Generative model; Language model; Language processing; Large language model; Model-based OPC; Natural languages; Theoretical guarantees; Natural language processing systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032491-4},
	language = {English},
	abbrev_source_title = {WIFS - IEEE Workshop Inf. Forensics Secur.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Oliveira2023444,
	author = {Oliveira, Eduardo e and Pereira, Teresa},
	title = {A New Generation? A Discussion on Deep Generative Models in Supply Chains},
	year = {2023},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {689 AICT},
	pages = {444 – 457},
	doi = {10.1007/978-3-031-43662-8_32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172418535&doi=10.1007%2f978-3-031-43662-8_32&partnerID=40&md5=73e566c63273886ce9b1bed63ed5a3bd},
	affiliations = {Instituto de Ciência e Inovação em Engenharia Mecânica e Engenharia Industrial (INEGI), Associate Laboratory for Energy, Transports and Aerospace (LAETA) - Rua Dr. Roberto Frias 400, Porto, 4200-465, Portugal; Faculdade de Engenharia da Universidade do Porto (FEUP) - Rua Dr. Roberto Frias 400, Porto, 4200-465, Portugal; Instituto Superior de Engenharia do Porto (ISEP) - Instituto Politécnico do Porto (IPP) - R. Dr. António Bernardino de Almeida 431, Porto, 4249-015, Portugal},
	abstract = {With the advent of Chat-GPT, Artificial Intelligence (AI) became one of the most discussed technological developments of today. Although there are not yet many studies discussing the application of Chat-GPT and other Large Language Models (LLM) to the Supply Chain (SC), several works have used a larger family of techniques called Deep Generative Models (DGM). DGM are deep learning networks that aim to discover complex and high-dimensional probability distributions from, instead of just discriminating between the samples. In this paper, we briefly explain the recent developments in DGM (especially Energy-based models, Variational Autoencoders, Generative Adversarial Networks, and Autoregressive models), review previous applications of these techniques to the SC, and discuss research and application opportunities. © 2023, IFIP International Federation for Information Processing.},
	author_keywords = {Artificial Intelligence; Deep Generative Models; Deep Learning; Machine Learning; Supply Chain},
	keywords = {Deep learning; Generative adversarial networks; Learning algorithms; Learning systems; Probability distributions; Variational techniques; Deep generative model; Deep learning; Generative model; High-dimensional; Higher-dimensional; Language model; Learning network; Machine-learning; Probability: distributions; Technological development; Supply chains},
	correspondence_address = {E. Oliveira; Faculdade de Engenharia da Universidade do Porto (FEUP) - Rua Dr. Roberto Frias 400, Porto, 4200-465, Portugal; email: eoliveira@inegi.up.pt},
	editor = {Alfnes E. and Romsdal A. and Strandhagen J.O. and von Cieminski G. and Romero D.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303143661-1},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Nascimento2023104,
	author = {Nascimento, Nathalia and Alencar, Paulo and Cowan, Donald},
	title = {Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Automatic Computing and Self-Organizing Systems Companion, ACSOS-C 2023},
	pages = {104 – 109},
	doi = {10.1109/ACSOS-C58168.2023.00048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181531939&doi=10.1109%2fACSOS-C58168.2023.00048&partnerID=40&md5=51bb428552c55511c72be5202308b736},
	affiliations = {David R. Cheriton School of Computer Science, University of Waterloo (UW), Waterloo, Canada},
	abstract = {The complexity of managing multiagent systems (MASs) in autonomic computing can be mitigated using a self-adaptation approach, where systems are equipped to monitor and adjust themselves based on specific concerns. Communication in these systems is key given that in scenarios involving agent interaction, it enhances cooperation and reduces coordination challenges by enabling direct, clear information exchange. However, the tasks of boosting communication expressiveness within MASs and logically processing a multitude of variables in dynamic environments are still challenging. This paper presents a novel strategy: integrating large language models (LLMs) like GPT-based technologies into MASs to boost communication and agent autonomy. Our proposal encompasses the development of a novel LLM/GPT-based agent architecture, focusing not only on advanced conversation features but also on the reasoning and decision-making capacities of these models. This is grounded in the MAPE-K model, known for supporting system adaptability in dynamic environments. We illustrate our approach through a marketplace scenario. This work represents a paradigm shift in MAS self-adaptation, utilizing LLMs' capabilities and indicating further research opportunities to assess LLMs' applicability in more complex MAS scenarios. This could pave the way for more potent problem-solving capabilities and refined communication within MASs. © 2023 IEEE.},
	author_keywords = {Generative pre-trained transformer (GPT); large language model (LLM); MAPE-K; multiagent systems; self-adaptation; software development},
	keywords = {Autonomous agents; Computational linguistics; Decision making; Software design; Agent interaction; Autonomic Computing; Dynamic environments; Generative pre-trained transformer; Language model; Large language model; Mape; MAPE-K; Model-based OPC; Self- adaptations; Multi agent systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835033746-4},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Autom. Comput. Self-Organ. Syst. Companion, ACSOS-C},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Shen20234215,
	author = {Shen, Chenhui and Cheng, Liying and Nguyen, Xuan-Phi and You, Yang and Bing, Lidong},
	title = {Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {4215 – 4233},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183310221&partnerID=40&md5=98abae56cde5b7eb8e80630829cef9ac},
	affiliations = {DAMO Academy, Alibaba Group, Singapore; National University of Singapore, Singapore; Hupan Lab, Hangzhou, 310023, China},
	abstract = {With the recent undeniable advancement in reasoning abilities in large language models (LLMs) like ChatGPT and GPT-4, there is a growing trend for using LLMs on various tasks. One area where LLMs can be employed is as an alternative evaluation metric for complex generative tasks, which generally demands expensive human judges to complement the traditional automatic metrics for various evaluation dimensions such as fluency and consistency. In this work, we conduct extensive analysis to investigate the stability and reliability of LLMs as automatic evaluators for abstractive summarization. We found that while ChatGPT and GPT-4 outperform the commonly used automatic metrics, they are not ready as human replacements due to significant limitations. That is, LLM evaluators rate each candidate system inconsistently and are dimension-dependent. They also struggle to compare candidates with close performance and become more unreliable with higher-quality summaries by obtaining a lower correlation with humans. In other words, with better abstractive summarization systems being introduced at a fast pace, LLMs may result in misleading and unreliable evaluations. © 2023 Association for Computational Linguistics.},
	keywords = {Reliability analysis; Automatic metrics; Evaluation metrics; High quality; Human levels; Language model; Lower correlation; Performance; Reasoning ability; Stability and reliabilities; Summarization systems; Computational linguistics},
	correspondence_address = {L. Bing; DAMO Academy, Alibaba Group, Singapore; email: l.bing@alibaba-inc.com},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176061-5},
	language = {English},
	abbrev_source_title = {Find. Assoc. Comput. Linguist.: EMNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Platt2023,
	author = {Platt, Moritz and Platt, Daniel},
	title = {Effectiveness of Generative Artificial Intelligence for Scientific Content Analysis},
	year = {2023},
	journal = {17th IEEE International Conference on Application of Information and Communication Technologies, AICT 2023 - Proceedings},
	doi = {10.1109/AICT59525.2023.10313167},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179525440&doi=10.1109%2fAICT59525.2023.10313167&partnerID=40&md5=5291f1f16f1e4516c2049eed1821a84c},
	affiliations = {King's College, London, United Kingdom},
	abstract = {Generative artificial intelligence (GenAI) in general, and large language models (LLMs) in particular, are highly fashionable. As they have the ability to generate coherent output based on prompts in natural language, they are promoted as tools to free knowledge workers from tedious tasks such as content writing, customer support and routine computer code generation. Unsurprisingly, their application is also attractive to professionals in the research domain, where mundane and laborious tasks, such as literature screening, are commonplace. We evaluate Vertex AI 'text-bison', a foundational LLM model, in a real-world academic scenario by replicating parts of a popular systematic review in the information management domain. By comparing the results of a zero-shot LLM-based approach with those of the original study, we gather evidence on the suitability of state-of-the-art general-purpose LLMs for the analysis of scientific content. We show that the LLM-based approach delivers good scientific content analysis performance for a general classification problem (ACC =0.9), acceptable performance for a domain-specific classification problem (ACC =0.8) and borderline performance for a text comprehension problem (ACC ≈0.69). We conclude that some content analysis tasks with moderate accuracy requirements may be supported by current LLMs. As the technology will evolve rapidly in the foreseeable future, studies on large corpora, where some inaccuracies are tolerable, or workflows that prepare large data sets for human processing, may increasingly benefit from the capabilities of GenAI.  © 2023 IEEE.},
	author_keywords = {AI-Assisted Research; Classification Performance; Content Analysis; Literature Screening; Prompt Engineering},
	keywords = {Natural language processing systems; Text processing; Zero-shot learning; AI-assisted research; Assisted researches; Classification performance; Content analysis; Language model; Literature screening; Model based approach; Performance; Prompt engineering; Scientific content; Information management},
	correspondence_address = {M. Platt; King's College, London, United Kingdom; email: moritz.platt@kcl.ac.uk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030356-8},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Appl. Inf. Commun. Technol., AICT - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Karunaratne2023147,
	author = {Karunaratne, Thashmee and Adesina, Adenike},
	title = {Is it the new Google: Impact of ChatGPT on Students' Information Search Habits},
	year = {2023},
	journal = {Proceedings of the European Conference on e-Learning, ECEL},
	volume = {2023-October},
	pages = {147 – 155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179140528&partnerID=40&md5=8867593bc785a91e26c9ae718f62c61a},
	affiliations = {Department of Computer and Systems Sciences, Stockholm University, Kista, Sweden},
	abstract = {The traditional subject of information search and retrieval (IR) paradigm shifted to an entirely new era since artificial intelligence (AI) techniques were introduced into the field. Browser-based IR solutions powered by AI for personalised recommendations-based information retrieval, such as the Google search engine, were one of the early examples. The IR field has advanced to its next level with the newest conversational applications based on large language model (LLM) techniques. It is becoming clear that Generative Pretrained Transformer (GPT) applications such as ChatGPT will significantly impact information retrieval behaviour in the education sector. Though this application has become widespread in acclaim, no previous study has shown its impact on information seeking and retrieval. However, based on the observation of the fast penetration of this technology and the growth of public interest, a pre-assumption was built that it is essential to investigate if students may also be showing a similar interest in this new tool. Hence, this study is set up to systematically and empirically explore how ChatGPT influences the IR behaviour of students in HEIs. A survey approach is utilised to collect the perceived IR behaviour through a questionnaire administered to 60 students in HEIs. The findings reveal that the tool is already widely known among HEI students. They also perceived the use of the tool in the context of information retrieval and proclaimed its usefulness, acknowledging its efficiency (reduced time) in finding information. Furthermore, the technology has considerably affected the typical use of other conventional information retrieval and search engine tools. On the contrary, 10% of the respondents are less likely to use ChatGPT during information seeking for various reasons, from credibility and relevance to technology infrastructure issues such as connectivity. Although a deeper analysis is required to establish a general conclusion on how and in which ways GPT-based models will override contemporary IR practices, the study outcome provides evidence for a possible behavioural change among HEI students in their IR habits in the future. © 2023 Academic Conferences Limited. All rights reserved.},
	author_keywords = {Artificial Intelligence; ChatGPT; Higher Education; Information Retrieval; Student behaviour},
	keywords = {Artificial intelligence; Education computing; Information retrieval; Information use; Search engines; Artificial intelligence techniques; ChatGPT; Google search engine; Google+; High educations; Information search; Information search and retrieval; Information seeking; Personalized recommendation; Students' behaviors; Students},
	editor = {Johnston S.J. and Singh S.},
	publisher = {Academic Conferences and Publishing International Limited},
	issn = {20488637},
	isbn = {978-191458790-0},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. e-Learn., ECEL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2023,
	author = {Wang, Xuena and Li, Xueting and Yin, Zi and Wu, Yue and Liu, Jia},
	title = {Emotional intelligence of Large Language Models},
	year = {2023},
	journal = {Journal of Pacific Rim Psychology},
	volume = {17},
	doi = {10.1177/18344909231213958},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177461450&doi=10.1177%2f18344909231213958&partnerID=40&md5=08c2ab89691f968175f917808be05e8d},
	affiliations = {Department of Psychology & Tsinghua Laboratory of Brain and Intelligence, Tsinghua University, Beijing, China; Department of Psychology, Renmin University of China, Beijing, China},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning. However, their alignment with human emotions and values, which is critical for real-world applications, has not been systematically evaluated. Here, we assessed LLMs' Emotional Intelligence (EI), encompassing emotion recognition, interpretation, and understanding, which is necessary for effective communication and social interactions. Specifically, we first developed a novel psychometric assessment focusing on Emotion Understanding (EU), a core component of EI. This test is an objective, performance-driven, and text-based evaluation, which requires evaluating complex emotions in realistic scenarios, providing a consistent assessment for both human and LLM capabilities. With a reference frame constructed from over 500 adults, we tested a variety of mainstream LLMs. Most achieved above-average Emotional Quotient (EQ) scores, with GPT-4 exceeding 89% of human participants with an EQ of 117. Interestingly, a multivariate pattern analysis revealed that some LLMs apparently did not rely on the human-like mechanism to achieve human-level performance, as their representational patterns were qualitatively distinct from humans. In addition, we discussed the impact of factors such as model size, training method, and architecture on LLMs' EQ. In summary, our study presents one of the first psychometric evaluations of the human-like characteristics of LLMs, which may shed light on the future development of LLMs aiming for both high intellectual and emotional intelligence. Project website: https://emotional-intelligence.github.io/ © The Author(s) 2023.},
	author_keywords = {emotional intelligence; emotional understanding; generative pretrained transformer; human-likeness; Large Language Models; psychometric assessment},
	correspondence_address = {J. Liu; Department of Psychology & Tsinghua Laboratory of Brain and Intelligence, Tsinghua University, Beijing, China; email: liujiaTHU@tsinghua.edu.cn},
	publisher = {SAGE Publications Ltd},
	issn = {18344909},
	language = {English},
	abbrev_source_title = {J. Pac. Rim Psycholog.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Mosca2023190,
	author = {Mosca, Edoardo and Abdalla, Mohamed Hesham I. and Basso, Paolo and Musumeci, Margherita and Groh, Georg},
	title = {Distinguishing Fact from Fiction: A Benchmark Dataset for Identifying Machine-Generated Scientific Papers in the LLM Era},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {190 – 207},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174862576&partnerID=40&md5=69e8aeca10ea2a3f31ba942032273eb9},
	affiliations = {TU Munich, Department of Informatics, Germany; Polytechnic of Milan, Department of EIB, Italy},
	abstract = {As generative NLP can now produce content nearly indistinguishable from human writing, it becomes difficult to identify genuine research contributions in academic writing and scientific publications. Moreover, information in NLP-generated text can potentially be factually wrong or even entirely fabricated. This study introduces a novel benchmark dataset, containing human-written and machine-generated scientific papers from SCIgen, GPT-2, GPT-3, ChatGPT, and Galactica. After describing the generation and extraction pipelines, we also experiment with four distinct classifiers as a baseline for detecting the authorship of scientific text. A strong focus is put on generalization capabilities and explainability to highlight the strengths and weaknesses of detectors. We believe our work serves as an important step towards creating more robust methods for distinguishing between human-written and machine-generated scientific papers, ultimately ensuring the integrity of scientific literature. © 2023 Proceedings of the Annual Meeting of the Association for Computational Linguistics. All rights reserved.},
	keywords = {Academic writings; Benchmark datasets; Generalization capability; Robust methods; Scientific literature; Scientific papers; Scientific publications; Scientific texts; Natural language processing systems},
	editor = {Ovalle A. and Chang K.-W. and Chang K.-W. and Mehrabi N. and Pruksachatkun Y. and Galystan A. and Galystan A. and Dhamala J. and Verma A. and Cao T. and Kumar A. and Gupta R.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {978-195942986-9},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Stewart2023164,
	author = {Stewart, Jake and Lyubashenko, Nikita and Stefanek, George},
	title = {The efficacy of detecting AI-generated fake news using transfer learning},
	year = {2023},
	journal = {Issues in Information Systems},
	volume = {24},
	number = {2},
	pages = {164 – 177},
	doi = {10.48009/2_iis_2023_114},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174260113&doi=10.48009%2f2_iis_2023_114&partnerID=40&md5=80aec32cf44a02050f59243f04cb7ff8},
	affiliations = {Purdue University Northwest, United States},
	abstract = {This research investigates the detectability of AI-generated fake news by a fine-tuned BERT transformer that does text classification. The performance of the model is evaluated by testing it on GPT-generated (Generative Pre-trained Transformer) news articles as well as real-world news articles from a Kaggle dataset. The study focuses on how fake news articles can be created by AI tools and how effective a fine-tuned, open-source large language model is at detecting the GPT-generated fake news. The model was fine-tuned with Kaggle real-world articles and GPT-generated articles from OpenAI ChatGPT and Davinci. The use of state-of-the-art tools like the BERT pre-trained, large language model transformer were found to effectively classify GPT-generated articles but were less effective at classifying fake news articles that were not GPT generated. Copyright © 2023 the Author(s).},
	author_keywords = {AI; BERT; fake news; GPT; LLM; machine learning; transfer learning},
	publisher = {International Association for Computer Information Systems},
	issn = {15297314},
	language = {English},
	abbrev_source_title = {Issue. Inf. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Savelka2023,
	author = {Savelka, Jaromir and Ashley, Kevin D.},
	title = {The unreasonable effectiveness of large language models in zero-shot semantic annotation of legal texts},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence},
	volume = {6},
	doi = {10.3389/frai.2023.1279794},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175600981&doi=10.3389%2ffrai.2023.1279794&partnerID=40&md5=6c185b1deb11c8b0cd5602a59f1404c0},
	affiliations = {School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States; School of Law, University of Pittsburgh, Pittsburgh, PA, United States},
	abstract = {The emergence of ChatGPT has sensitized the general public, including the legal profession, to large language models' (LLMs) potential uses (e.g., document drafting, question answering, and summarization). Although recent studies have shown how well the technology performs in diverse semantic annotation tasks focused on legal texts, an influx of newer, more capable (GPT-4) or cost-effective (GPT-3.5-turbo) models requires another analysis. This paper addresses recent developments in the ability of LLMs to semantically annotate legal texts in zero-shot learning settings. Given the transition to mature generative AI systems, we examine the performance of GPT-4 and GPT-3.5-turbo(-16k), comparing it to the previous generation of GPT models, on three legal text annotation tasks involving diverse documents such as adjudicatory opinions, contractual clauses, or statutory provisions. We also compare the models' performance and cost to better understand the trade-offs. We found that the GPT-4 model clearly outperforms the GPT-3.5 models on two of the three tasks. The cost-effective GPT-3.5-turbo matches the performance of the 20× more expensive text-davinci-003 model. While one can annotate multiple data points within a single prompt, the performance degrades as the size of the batch increases. This work provides valuable information relevant for many practical applications (e.g., in contract review) and research projects (e.g., in empirical legal studies). Legal scholars and practicing lawyers alike can leverage these findings to guide their decisions in integrating LLMs in a wide range of workflows involving semantic annotation of legal texts. Copyright © 2023 Savelka and Ashley.},
	author_keywords = {large language models (LLM); legal text analytics; semantic annotation; text annotation; zero-shot classification},
	correspondence_address = {J. Savelka; School of Computer Science, Carnegie Mellon University, Pittsburgh, United States; email: jsavelka@cs.cmu.edu},
	publisher = {Frontiers Media SA},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Shutske2023205,
	author = {Shutske, John M.},
	title = {Editorial: Harnessing the Power of Large Language Models in Agricultural Safety & Health},
	year = {2023},
	journal = {Journal of Agricultural Safety and Health},
	volume = {29},
	number = {4},
	pages = {205 – 224},
	doi = {10.13031/jash.15841},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178483190&doi=10.13031%2fjash.15841&partnerID=40&md5=351c606ed426a02503395b7b76d6df54},
	affiliations = {University of Wisconsin, Madison, WI, United States},
	abstract = {The age of smart digital technology is upon us, and some authors have suggested we have entered the fourth industrial age, sometimes cited as “Industry 4.0” (Liu et al., 2020). This includes the development and widespread deployment of a range of tools that include artificial intelligence, machine learning, and a host of closely interconnected methods such as deep learning. There are obviously significant implications and applications for agriculture and food production, including within the profession of agricultural safety and health. © 2023 ASABE},
	author_keywords = {Agricultural safety; Artificial intelligence; Bias; ChatGPT; Consultation; Education; Extension; Generative AI; Health; Intellectual Property; Large language models; LLM; Teaching},
	correspondence_address = {J.M. Shutske; University of Wisconsin, Madison, United States; email: shutske@wisc.edu},
	publisher = {American Society of Agricultural and Biological Engineers},
	issn = {10747583},
	coden = {JASHF},
	language = {English},
	abbrev_source_title = {J. Agric. Saf. Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Mukherjee2023382,
	author = {Mukherjee, Prasenjit and Gokul, R.S. and Sadhukhan, Sourav and Godse, Manish and Chakraborty, Baisakhi},
	title = {Detection of Autism Spectrum Disorder (ASD) from Natural Language Text using BERT and ChatGPT Models},
	year = {2023},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {14},
	number = {10},
	pages = {382 – 396},
	doi = {10.14569/IJACSA.2023.0141041},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175352568&doi=10.14569%2fIJACSA.2023.0141041&partnerID=40&md5=a73709f4e2898d46b82caf0bccaf393d},
	affiliations = {Dept. of Technology, Vodafone Intelligent Solutions, Pune, India; Dept. of Computer Science, Manipur International University, Manipur, India; Dept. of Finance, Pune Institute of Business Management, Pune, India; Dept. of IT, BizAmica Software, Pune, India; Dept. of Computer Science and Engg, National Institute of Technology, Durgapur, India},
	abstract = {ASD may be caused by a combination of genetic and environmental factors, including gene mutations and exposure to toxins. People with ASD may also have trouble forming social relationships, have difficulty with communication and language, and struggle with sensory sensitivity. These difficulties can range from mild to severe and can affect a person’s ability to interact with the world around them. Autism spectrum disorder (ASD) is a developmental disorder that affects people in different ways. But early detection of ASD in a child is a good option for parents to start corrective therapies and treatment. They can take action to reduce the ASD symptoms in their child. The proposed work is the detection of ASD in a child using a parent’s dialog. The most popular Bert model and recent ChatGPT have been utilized to analyze the sentiment of each statement from parents for the detection of symptoms of ASD. The Bert model has been developed by the transformers which are the most popular in the natural language processing field whereas the ChatGPT model is a large language model (LLM). It is based on Reinforcement learning from human feedback (RLHF) that can able to generate the sentiment of the sentence, computer language codes, text paragraphs, etc. The sentiment analysis has been done on parents’ dialog using the Bert model and ChatGPT model. The data has been prepared from various Autism groups on social sites and other resources on the internet. The data has been cleaned and prepared to train the Bert model and ChatGPT model. The Bert model is able to detect the sentiment of each sentence from parents. Any positive sentiment detection means parents should be aware of their children. The proposed model has given 83 percent accuracy according to the prepared data. © (2023) All Rights Reserved.},
	author_keywords = {autism; autism detection; BERT model; ChatGPT model; generative AI; machine learning},
	keywords = {Diseases; Reinforcement learning; Autism; Autism detection; Autism spectrum disorders; BERT model; ChatGPT model; Environmental factors; Generative AI; Genetic factors; Machine-learning; Natural languages texts; Sentiment analysis},
	publisher = {Science and Information Organization},
	issn = {2158107X},
	language = {English},
	abbrev_source_title = {Intl. J. Adv.  Comput. Sci. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kholgh2023114936,
	author = {Kholgh, Danial Khosh and Kostakos, Panos},
	title = {PAC-GPT: A Novel Approach to Generating Synthetic Network Traffic With GPT-3},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {114936 – 114951},
	doi = {10.1109/ACCESS.2023.3325727},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174813040&doi=10.1109%2fACCESS.2023.3325727&partnerID=40&md5=790c2ed8604e6384bd85d06ed6e57d08},
	affiliations = {University of Oulu, Center for Ubiquitous Computing, Oulu, 90570, Finland},
	abstract = {The application of machine learning models, particularly in cybersecurity, has surged significantly in the past few years. However, the effectiveness of these models is predominantly tethered to the quality and breadth of the training data they ingest. The scarcity of realistic datasets within the cybersecurity field constitutes a considerable challenge to the development of industry-grade tools intended for real-world application scenarios. Specifically, current datasets are either significantly outdated or fall short on both qualitative and quantitative fronts, primarily because many organizations exhibit reluctance in data sharing, stemming from privacy concerns or the potential threat to trade secrets. To address this challenge, the paper introduces PAC-GPT, a novel framework to generate reliable synthetic data for machine learning methods based on Open AI's Generative Pre-trained Transformer 3 (GPT-3). The core components of this framework are two modules, namely a Flow Generator, which is responsible for capturing and regenerating patterns in a series of network packets, and Packet Generator, which can generate individual network packets given the network flow. We also propose a packet generator based on LLM chaining and then proceed to assess, compare, and evaluate its performance using metrics such as loss, accuracy and success rate, concluding that transformers are a suitable approach for synthetic packet generation with minimal fine-tuning performed. Lastly, a streamlined command line interface (CLI) tool has been devised to facilitate the seamless access of this innovative data generation strategy by professionals from various disciplines. © 2013 IEEE.},
	author_keywords = {Artificial intelligence; cybersecurity; generative pre-trained transformer; GPT-3; LLMs; machine learning; NLP; transformer},
	keywords = {Cybersecurity; Job analysis; Learning systems; Cyber security; Generative pre-trained transformer; Generative pre-trained transformer 3; Generator; LLM; Machine-learning; Task analysis; Telecommunications traffic; Transformer; Artificial intelligence},
	correspondence_address = {P. Kostakos; University of Oulu, Center for Ubiquitous Computing, Oulu, 90570, Finland; email: panos.kostakos@oulu.fi},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Kämmer2023292,
	author = {Kämmer, Niklas and Borchert, Florian and Winkler, Silvia and de Melo, Gerard and Schapranow, Matthieu-P.},
	title = {Resolving Elliptical Compounds in German Medical Text},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {292 – 305},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174495093&partnerID=40&md5=1d91c5231dfac6cc3c4a350e9ecbc057},
	affiliations = {Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Str. 2-3, Potsdam, 14482, Germany},
	abstract = {Elliptical coordinated compound noun phrases (ECCNPs), a special kind of coordination ellipsis, are a common phenomenon in German medical texts. As their presence is known to affect the performance in downstream tasks such as entity extraction and disambiguation, their resolution can be a useful preprocessing step in information extraction pipelines. In this work, we present a new comprehensive dataset of more than 4,000 manually annotated ECCNPs in German medical text, along with the respective ground truth resolutions. Based on this data, we propose a generative encoder–decoder Transformer model, allowing for a simple end-to-end resolution of ECCNPs from raw input strings with very high accuracy (90.5 % exact match score). We compare our approach to an elaborate rule-based baseline, which the generative model outperforms by a large margin. We further investigate different scenarios for prompting large language models (LLM) to resolve ECCNPs. In a zero-shot setting, performance is remarkably poor (21.6 % exact matches), as the LLM tends to apply complex changes to the inputs unrelated to our specific task. We also find no improvement over the generative model when using the LLM for post-filtering of generated candidate resolutions. The source code including instructions on how to access the data are available at: https://github.com/hpi-dhc/ggponc_ ellipses. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Coordinated compounds; Down-stream; Ellipticals; Entity disambiguation; Entity extractions; Generative model; Language model; Noun phrase; Performance; Pre-processing step; Zero-shot learning},
	editor = {Demner-fushman D. and Ananiadou S. and Cohen K.},
	publisher = {Association for Computational Linguistics (ACL)},
	issn = {0736587X},
	isbn = {978-195942985-2},
	language = {English},
	abbrev_source_title = {Proc. Annu. Meet. Assoc. Comput Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Khan2023,
	author = {Khan, Masood M and Dong, Yu and Manesh, Nasrin Afsari},
	title = {Authentic Assessment Design for Meeting the Challenges of Generative Artificial Intelligence},
	year = {2023},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	doi = {10.1109/FIE58773.2023.10343376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182981490&doi=10.1109%2fFIE58773.2023.10343376&partnerID=40&md5=c2ba98780f6b239dd3ad24fb3111f605},
	affiliations = {Curtin University, Faculty of Science and Engineeringg, Department of Mechanical Engineering, Bentley, WA, Australia; School of Civil and Mechanical Engineering, Curtin University, Bentley, WA, Australia},
	abstract = {Authentic Assessments are generally seen as alternate to traditional assessments though the scope of an authentic assessment is much larger than that of a traditional assessment. Authentic assessments help students in comprehending the subject matter and, if properly designed, can also ensure student workplace readiness. During the authentic assessment design, five most important aspects are considered and their incorporation is sought. These aspects include; the assessment objectives, the physical context of an assessment, the social context, the outcome of the assessment and the assessment criteria. Emergence of the Generative Artificial Intelligence (GAI) supported applications and the Large Language Model (LLM) tools has posed new challenges to the authentic assessment design. Student access to these new applications and tools has also changed the socio-technological realities of the Learning and Teaching (L&T) practices. Therefore, we need to reimagine both, the L&T practices and the design and execution of authentic assessments. Keeping the prevailing socio-technological context in perspective, this work in progress paper proposes extending the scope of authentic assessments. The aim is to use them for quelling the growing problem of plagiarism as plagiarism can be facilitated by the use of GAI and LLM tools. Instead of considering authentic assessments as merely 'an alternate to the traditional examination' or 'a tool for evaluating student workplace readiness,' we propose adding 'GAI redundancy' to the scope of authentic assessments. For incorporating GAI redundancy we propose using either the game-based learning environment or a simulation environment. These two environments can be used for generating 'close to real life' problem-solving scenarios while assessing student comprehension and workplace readiness. In order to help practitioners, this paper also presents two examples of authentic assessments that were developed for combating plagiarism vis-à-vis enhancing student learning and evaluating their workplace readiness. In the first example, we show how to use a game environment and in the second example we demonstrate use of a simulation environment. The two examples also show how course contents can be embedded and how GAI redundancy can be incorporated in authentic assessments. The reported teaching assessment data and student feedback suggest that the proposed authentic assessment design and implementation strategies were able to engage students, help their comprehension and evaluate their workforce readiness. © 2023 IEEE.},
	author_keywords = {authentic assessment design; generative artificial intelligence; large language models; plagiarism; student competence; workplace readiness},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {979-835033642-9},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Merlo20238119,
	author = {Merlo, Paola},
	title = {Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {8119 – 8152},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183289662&partnerID=40&md5=14d2fb095d49dc82f9beadb0f1b4dbfc},
	affiliations = {University of Geneva, Switzerland},
	abstract = {How do we evaluate LLMs and determine the aspects and limits of their intelligent behaviour? When exposed to visual tests of analytic intelligence, human problem-solvers identify rules applied to relevant objects and attributes. Based on the induced rules, they can generalise and are able to provide a solution to the test. An analogous language task has recently been proposed (called BLM) for LLM. In this paper, we use this task to investigate what linguistic reasoning LLM develop, by asking them to solve some simple variants of the BLM task. We find that current state-of-the-art generative models can handle the task: they easily understand the instructions and can provide step-by-step explanations. The explanations show that LLMs can solve two of the main hurdles: correspondence finding (object and attribute identification) and item novelty. However, overall they struggle to find the correct underlying global rules, even when they find the right answer. We argue that these findings support the usefulness of the task as a method to test the limits and specific properties of generalisation ability in Large Language Models, providing an intrinsic evaluation method inspired by tests of human intelligence. © 2023 Association for Computational Linguistics.},
	keywords = {'current; Exposed to; Generalisation; Intelligent behavior; Language model; Linguistic reasonings; matrix; Neural-networks; Problem solvers; Simple++; Computational linguistics},
	correspondence_address = {P. Merlo; University of Geneva, Switzerland; email: Paola.Merlo@unige.ch},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176061-5},
	language = {English},
	abbrev_source_title = {Find. Assoc. Comput. Linguist.: EMNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Luo2023401,
	author = {Luo, Qing and Zeng, Wei and Chen, Manni and Peng, Gang and Yuan, Xiaofeng and Yin, Qiang},
	title = {Self-Attention and Transformers: Driving the Evolution of Large Language Models},
	year = {2023},
	journal = {2023 IEEE 6th International Conference on Electronic Information and Communication Technology, ICEICT 2023},
	pages = {401 – 405},
	doi = {10.1109/ICEICT57916.2023.10245906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173847084&doi=10.1109%2fICEICT57916.2023.10245906&partnerID=40&md5=c3558f7a3f19d5d0429b3451bce31735},
	affiliations = {School of Computer Science and Engineering, Huizhou University, Guangdong, 516007, China; School of Computer Science, Yangtze University, Hubei, 451199, China},
	abstract = {Transformers, originally introduced for machine translation, and built upon the Self-Attention mechanism, have undergone a remarkable evolution, establishing themselves as the bedrock of large language models (LLMs). Their unparalleled capacity to model intricate relationships and capture extensive dependencies within sequences has propelled their prominence. This article, presented in a popular science format, serves as an introduction to the transformer architecture, elucidating its innovative structure that enables efficient processing of long sequences and capturing dependencies over extended distances. We believe that this resource will prove valuable to college students or youth researchers aspiring to delve into the study and research of modern Artificial Intelligence (AI) domains.  © 2023 IEEE.},
	author_keywords = {generative pretrained transformer (GPT); large language model (LLM); natural language processing (NLP); Self-Attention; transformer},
	keywords = {Computational linguistics; Natural language processing systems; Attention mechanisms; Generative pretrained transformer; Language model; Language processing; Large language model; Machine translations; Natural language processing; Natural languages; Self-attention; Transformer; Students},
	correspondence_address = {W. Zeng; School of Computer Science and Engineering, Huizhou University, Guangdong, 516007, China; email: weizeng@hzu.edu.cn},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835039905-9},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Electron. Inf. Commun. Technol., ICEICT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rashidi2023,
	author = {Rashidi, Hooman H. and Fennell, Brandon D. and Albahra, Samer and Hu, Bo and Gorbett, Tom},
	title = {The ChatGPT conundrum: Human-generated scientific manuscripts misidentified as AI creations by AI text detection tool},
	year = {2023},
	journal = {Journal of Pathology Informatics},
	volume = {14},
	doi = {10.1016/j.jpi.2023.100342},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177083693&doi=10.1016%2fj.jpi.2023.100342&partnerID=40&md5=595a73a2562a129bec8efc676b3bddf4},
	affiliations = {Pathology and Laboratory Medicine Institute (PLMI), Cleveland Clinic, Cleveland, OH, United States; Department of Quantitative Health Sciences, Cleveland Clinic, Cleveland, OH, United States; University of California, San Francisco – Department of Medicine, San Francisco, CA, United States; PLMI's Center for Artificial Intelligence & Data Science, Cleveland Clinic, Cleveland, OH, United States},
	abstract = {AI Chat Bots such as ChatGPT are revolutionizing our AI capabilities, especially in text generation, to help expedite many tasks, but they introduce new dilemmas. The detection of AI-generated text has become a subject of great debate considering the AI text detector's known and unexpected limitations. Thus far, much research in this area has focused on the detection of AI-generated text; however, the goal of this study was to evaluate the opposite scenario, an AI-text detection tool's ability to discriminate human-generated text. Thousands of abstracts from several of the most well-known scientific journals were used to test the predictive capabilities of these detection tools, assessing abstracts from 1980 to 2023. We found that the AI text detector erroneously identified up to 8% of the known real abstracts as AI-generated text. This further highlights the current limitations of such detection tools and argues for novel detectors or combined approaches that can address this shortcoming and minimize its unanticipated consequences as we navigate this new AI landscape. © 2023 The Author(s)},
	author_keywords = {Chat-GPT; Generative AI; GPT; Human-generated; Large Language Model; LLM; Machine learning; Text detection},
	correspondence_address = {H.H. Rashidi; Cleveland, 9500 Euclid Ave, 44195, United States; email: rashidh@ccf.org},
	publisher = {Elsevier B.V.},
	issn = {22295089},
	language = {English},
	abbrev_source_title = {J. Pathol. Inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Lai2023318,
	author = {Lai, Viet Dac and Van Nguyen, Chien and Ngo, Nghia Trung and Nguyen, Thuat and Dernoncourt, Franck and Rossi, Ryan A. and Nguyen, Thien Huu},
	title = {Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings of the System Demonstrations},
	pages = {318 – 327},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182805634&partnerID=40&md5=b51c77be7c339ca74687bef983c73eb0},
	affiliations = {Dept. of Computer Science, University of Oregon, OR, United States; Adobe Research, United States},
	abstract = {A key technology for large language models (LLMs) involves instruction tuning that helps align the models’ responses with human expectations to realize impressive learning abilities. Two major approaches for instruction tuning characterize supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), which are applied to produce the best commercial LLMs. To improve the accessibility of LLMs, various instruction-tuned open-source LLMs have also been introduced recently. However, existing open-source LLMs have only been instruction-tuned for English and a few popular languages, thus hindering their accessibility to many other languages in the world. In addition, SFT has been used as the only approach to instruction-tune open-source LLMs for multiple languages. This has left a significant gap for fine-tuned LLMs based on RLHF in diverse languages and raised important questions on how RLHF can boost the performance of multilingual instruction tuning. To overcome this issue, we present Okapi, the first system with instruction-tuned LLMs based on RLHF for multiple languages. Okapi introduces instruction and response-ranked data in 26 diverse languages to facilitate the experiments and development of future multilingual LLM research. We also present benchmark datasets to enable the evaluation of generative LLMs in multiple languages. Our experiments demonstrate the advantages of RLHF for multilingual instruction over SFT for different base models and datasets. Our framework with created resources, fine-tuned LLMs, interaction scripts are released at https://github.com/nlp-uoregon/Okapi. A demo video to show our framework can also be found at: https://youtu.be/QFV2fkPwvi0. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; HTTP; Learning systems; Fine reinforcements; Fine tuning; Key technologies; Language model; Learning abilities; Model response; Model-based OPC; Multiple languages; Open-source; Reinforcement learnings; Reinforcement learning},
	editor = {Feng Y. and Lefever E.},
	publisher = {Association for Computational Linguistics (ACL)},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc. Syst. Demonstr.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Castillo-Segura2023,
	author = {Castillo-Segura, Pablo and Alario-Hoyos, Carlos and Kloos, Carlos Delgado and Fernandez Panadero, Carmen},
	title = {Leveraging the Potential of Generative AI to Accelerate Systematic Literature Reviews: An Example in the Area of Educational Technology},
	year = {2023},
	journal = {2023 IEEE IFEES World Engineering Education Forum and Global Engineering Deans Council: Convergence for a Better World: A Call to Action, WEEF-GEDC 2023 - Proceedings},
	doi = {10.1109/WEEF-GEDC59520.2023.10344098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182340603&doi=10.1109%2fWEEF-GEDC59520.2023.10344098&partnerID=40&md5=0d9a944b601a4ff258a27cae5209589b},
	affiliations = {Universidad Carlos Iii de Madrid, Department of Telematics Engineering, Leganés, Spain},
	abstract = {Generative Artificial Intelligence (AI) is dramatically changing the way people work in many industries, including academia. Beyond its use for teaching, generative AI can also have a major impact on accelerating research processes. For example, generative AI can facilitate the identification of relevant articles when conducting a systematic literature review (SLR). This article compares six AIs (Forefront, GetGPT, ThebAI, Claude, Bard, and H2O) with their respective large language models (LLMs) when classifying 596 articles in the screening phase of an SLR. This SLR is aimed at exploring the development of non-technical skills with the support of technology in the field of medical education. Forefront with the LLM GPT-4 was the AI that obtained better results. The impact of this research is expected to contribute towards automating some of the phases of SRLs. Nevertheless, it is important to keep in mind limitations associated with the technology used to support this research, such as the rapid changes that AIs and their LLMs are currently undergoing, or potential restrictions on the number of requests per minute that AIs can receive as well as restrictions on the geographical location (since not all these AIs are available in all countries).  © 2023 IEEE.},
	author_keywords = {educational technology; Generative AI; large language models (LLMs); screening phase; systematic literature review (SLRs)},
	keywords = {Computational linguistics; Educational technology; Medical education; Generative artificial intelligence; Geographical locations; Language model; Large language model; Non-technical skills; Research process; Screening phase; Systematic literature review; Diagnosis},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031602-5},
	language = {English},
	abbrev_source_title = {IEEE IFEES World Eng. Educ. Forum Glob. Eng. Deans Counc.: Converg. a Better World: A Call Action, WEEF-GEDC - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chang20234055,
	author = {Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, A.J. and Lezama, José and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T. and Rubinstein, Michael and Li, Yuanzhen and Krishnan, Dilip},
	title = {Muse: Text-To-Image Generation via Masked Generative Transformers},
	year = {2023},
	journal = {Proceedings of Machine Learning Research},
	volume = {202},
	pages = {4055 – 4075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174402387&partnerID=40&md5=f5fd64794bc2551701101c68cfc7053c},
	affiliations = {Google Research, United States},
	abstract = {We present Muse, a text-to-image Transformer model that achieves state-of-the-art image generation performance while being significantly more efficient than diffusion or autoregressive models. Muse is trained on a masked modeling task in discrete token space: given the text embedding extracted from a pre-trained large language model (LLM), Muse learns to predict randomly masked image tokens. Compared to pixel-space diffusion models, such as Imagen and DALL-E 2, Muse is significantly more efficient due to the use of discrete tokens and requires fewer sampling iterations; compared to autoregressive models such as Parti, Muse is more efficient due to the use of parallel decoding. The use of a pre-trained LLM enables fine-grained language understanding, which translates to high-fidelity image generation and the understanding of visual concepts such as objects, their spatial relationships, pose, cardinality etc. Our 900M parameter model achieves a new SOTA on CC3M, with an FID score of 6.06. The Muse 3B parameter model achieves an FID of 7.88 on zero-shot COCO evaluation, along with a CLIP score of 0.32. Muse also directly enables a number of image editing applications without the need to fine-tune or invert the model: inpainting, outpainting, and mask-free editing. More results and videos demonstrating editing are available at http://muse-icml.github.io. © 2023 Proceedings of Machine Learning Research. All rights reserved.},
	keywords = {Modeling languages; Zero-shot learning; Arts image; Autoregressive modelling; Diffusion model; Image generations; Image transformers; Language model; Parameter model; Performance; State of the art; Transformer modeling; Visual languages},
	correspondence_address = {H. Chang; Google Research, United States; email: huiwenchang@google.com; H. Zhang; Google Research, United States; email: zhanghan@google.com; D. Krishnan; Google Research, United States; email: dilipkay@google.com},
	editor = {Krause A. and Brunskill E. and Cho K. and Engelhardt B. and Sabato S. and Scarlett J.},
	publisher = {ML Research Press},
	issn = {26403498},
	language = {English},
	abbrev_source_title = {Proc. Mach. Learn. Res.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Burov2023129,
	author = {Burov, Vasiliy and Soshnikov, Dmitry},
	title = {FidoNet and Generative AI: A New Approach to Museumification of Historical Content Resources},
	year = {2023},
	journal = {HISTELCON 2023 - 2023 IEEE History of Electrotechnology Conference, Proceedings},
	pages = {129 – 132},
	doi = {10.1109/HISTELCON56357.2023.10365937},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182926529&doi=10.1109%2fHISTELCON56357.2023.10365937&partnerID=40&md5=81fb1625fe387d8f715ade4eb17277fa},
	affiliations = {Estonto Lab, Yerevan, Armenia; Estonto Lab, Astana, Kazakhstan},
	abstract = {This report considers the problem of visual representation of historical content resources based on user-generated content for museumification of the most important information resources in the history of digital networks development. The paper proposes an approach based on generative AI and shows its implementation in relation to FidoNet.  © 2023 IEEE.},
	author_keywords = {artificial intelligence; ChatGPT; content representation; cybernetic immortality; echomail; echos; FidoNet; generative AI; GPT model; large language model; LLM; machine learning; newsgroups; UCG; user generated content; virtual museum},
	keywords = {ChatGPT; Content representation; Cybernetic immortality; Echo; Echomail; Fidonet; Generative AI; GPT model; Language model; Large language model; LLM; Machine-learning; Newsgroups; UCG; User generated content; User-generated; Virtual museum},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835033464-7},
	language = {English},
	abbrev_source_title = {HISTELCON - IEEE Hist. Electrotechnol. Conf., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ronanki2023354,
	author = {Ronanki, Krishna and Berger, Christian and Horkoff, Jennifer},
	title = {Investigating ChatGPT's Potential to Assist in Requirements Elicitation Processes},
	year = {2023},
	journal = {Proceedings - 2023 49th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2023},
	pages = {354 – 361},
	doi = {10.1109/SEAA60479.2023.00061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175597991&doi=10.1109%2fSEAA60479.2023.00061&partnerID=40&md5=6ef7b6e358ae85e7a90276b32000b82e},
	affiliations = {University of Gothenburg, Dept. of Computer Science and Engineering, Gothenburg, Sweden},
	abstract = {Natural Language Processing (NLP) for Requirements Engineering (RE) (NLP4RE) seeks to apply NLP tools, techniques, and resources to the RE process to increase the quality of the requirements. There is little research involving the utilization of Generative AI-based NLP tools and techniques for requirements elicitation. In recent times, Large Language Models (LLM) like ChatGPT have gained significant recognition due to their notably improved performance in NLP tasks. To explore the potential of ChatGPT to assist in requirements elicitation processes, we formulated six questions to elicit requirements using ChatGPT. Using the same six questions, we conducted interview-based surveys with five RE experts from academia and industry and collected 30 responses containing requirements. The quality of these 36 responses (human-formulated + ChatGPT-generated) was evaluated over seven different requirements quality attributes by another five RE experts through a second round of interview-based surveys. In comparing the quality of requirements generated by ChatGPT with those formulated by human experts, we found that ChatGPT-generated requirements are highly Abstract, Atomic, Consistent, Correct, and Understandable. Based on these results, we present the most pressing issues related to LLMs and what future research should focus on to leverage the emergent behaviour of LLMs more effectively in natural language-based RE activities.  © 2023 IEEE.},
	author_keywords = {ChatGP; Large Language Model; NLP4R; Requirements Elicitatio},
	keywords = {Computational linguistics; Natural language processing systems; Chatgp; Language model; Language processing; Large language model; Natural languages; NLP4R; Processing technique; Requirement elicitatio; Requirement engineering; Requirements elicitation; Requirements engineering},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835034235-2},
	language = {English},
	abbrev_source_title = {Proc. - Euromicro Conf. Softw. Eng. Adv. Appl., SEAA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Giannakopoulos2023,
	author = {Giannakopoulos, Kostis and Kavadella, Argyro and Salim, Anas Aaqel and Stamatopoulos, Vassilis and Kaklamanos, Eleftherios G.},
	title = {Evaluation of the Performance of Generative AI Large Language Models ChatGPT, Google Bard, and Microsoft Bing Chat in Supporting Evidence-Based Dentistry: Comparative Mixed Methods Study},
	year = {2023},
	journal = {Journal of Medical Internet Research},
	volume = {25},
	number = {1},
	doi = {10.2196/51580},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181396069&doi=10.2196%2f51580&partnerID=40&md5=75055e76438ae649744ae2f15ccbf56c},
	affiliations = {School of Dentistry, European University Cyprus, Nicosia, Cyprus; Information Management Systems Institute, ATHENA Research and Innovation Center, Athens, Greece; School of Dentistry, Aristotle University of Thessaloniki, Thessaloniki, Greece; Mohammed Bin Rashid University of Medicine and Health Sciences, Dubai, United Arab Emirates},
	abstract = {Background: The increasing application of generative artificial intelligence large language models (LLMs) in various fields, including dentistry, raises questions about their accuracy. Objective: This study aims to comparatively evaluate the answers provided by 4 LLMs, namely Bard (Google LLC), ChatGPT-3.5 and ChatGPT-4 (OpenAI), and Bing Chat (Microsoft Corp), to clinically relevant questions from the field of dentistry. Methods: The LLMs were queried with 20 open-type, clinical dentistry-related questions from different disciplines, developed by the respective faculty of the School of Dentistry, European University Cyprus. The LLMs' answers were graded 0 (minimum) to 10 (maximum) points against strong, traditionally collected scientific evidence, such as guidelines and consensus statements, using a rubric, as if they were examination questions posed to students, by 2 experienced faculty members. The scores were statistically compared to identify the best-performing model using the Friedman and Wilcoxon tests. Moreover, the evaluators were asked to provide a qualitative evaluation of the comprehensiveness, scientific accuracy, clarity, and relevance of the LLMs' answers. Results: Overall, no statistically significant difference was detected between the scores given by the 2 evaluators; therefore, an average score was computed for every LLM. Although ChatGPT-4 statistically outperformed ChatGPT-3.5 (P=.008), Bing Chat (P=.049), and Bard (P=.045), all models occasionally exhibited inaccuracies, generality, outdated content, and a lack of source references. The evaluators noted instances where the LLMs delivered irrelevant information, vague answers, or information that was not fully accurate. Conclusions: This study demonstrates that although LLMs hold promising potential as an aid in the implementation of evidence-based dentistry, their current limitations can lead to potentially harmful health care decisions if not used judiciously. Therefore, these tools should not replace the dentist's critical thinking and in-depth understanding of the subject matter. Further research, clinical validation, and model improvements are necessary for these tools to be fully integrated into dental practice. Dental practitioners must be aware of the limitations of LLMs, as their imprudent use could potentially impact patient care. Regulatory measures should be established to oversee the use of these evolving technologies. © 2023 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {AI; artificial intelligence; ChatGPT; clinical decision-making; clinical practice; clinical practice guidelines; dental practice; dental professional; evidence-based dentistry; generative pretrained transformers; Google Bard; large language models; Microsoft Bing},
	keywords = {Artificial Intelligence; Dentists; Evidence-Based Dentistry; Humans; Language; Professional Role; Search Engine; Article; artificial intelligence chatbot; ChatGPT; clinical decision making; consensus; controlled study; evidence based dentistry; google bard; human; language; microsoft bing chat; practice guideline; qualitative analysis; quality control; artificial intelligence; dentist; evidence based dentistry; professional standard; search engine},
	correspondence_address = {K. Giannakopoulos; School of Dentistry, European University Cyprus, Nicosia, 6 Diogenis St, Engomi, 2404, Cyprus; email: k.giannakopoulos@euc.ac.cy},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {38009003},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Baez2023102,
	author = {Baez, Anthony and Saggion, Horacio},
	title = {LSLlama: Fine-Tuned LLaMA for Lexical Simplification},
	year = {2023},
	journal = {TSAR 2023 - 2nd Workshop on Text Simplification, Accessibility and Readability, associated with the 14th International Conference on Recent Advances in Natural Language Processing 2023, RANLP 2023 - Proceedings of the Workshop},
	pages = {102 – 108},
	doi = {10.26615/978-954-452-086-1_010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184658580&doi=10.26615%2f978-954-452-086-1_010&partnerID=40&md5=0d656360d6e572c7775cd71c3b6feda7},
	affiliations = {Massachusetts Institute of Technology, Cambridge, MA, United States; LaSTUS, TALN, DTIC, Universitat Pompeu Fabra, Barcelona, Spain},
	abstract = {Generative Large Language Models (LLMs), such as GPT-3, have become increasingly effective and versatile in natural language processing (NLP) tasks. One such task is Lexical Simplification, where state-of-the-art methods involve complex, multi-step processes which can use both deep learning and non-deep learning processes (Sheang et al., 2022). LLaMA, an LLM with full research access, holds unique potential for the adaption of the entire LS pipeline. This paper details the process of fine-tuning LLaMA to create LSLlama, which performs comparably to previous LS baseline models LSBert and UniHD. © 2023 TSAR 2023 - 2nd Workshop on Text Simplification, Accessibility and Readability, associated with the 14th International Conference on Recent Advances in Natural Language Processing 2023, RANLP 2023 - Proceedings of the Workshop. All rights reserved.},
	keywords = {Natural language processing systems; Baseline models; Fine tuning; Language model; Language processing; Learning process; Multisteps; Natural languages; State-of-the-art methods; Deep learning},
	editor = {Stajner S. and Saggion H. and Shardlow M. and Alva-Manchego F.},
	publisher = {Incoma Ltd},
	isbn = {978-954452086-1},
	language = {English},
	abbrev_source_title = {TSAR - Workshop Text Simpl., Acces. Readability, assoc. Int. Conf. Recent Adv. Nat. Lang. Process., RANLP - Proc. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@ARTICLE{Willey2023123,
	author = {Willey, Lorrie and White, Barbara Jo and Deale, Cynthia S.},
	title = {Teaching AI in the college course: introducing the AI prompt development life cycle (PDLC)},
	year = {2023},
	journal = {Issues in Information Systems},
	volume = {24},
	number = {2},
	pages = {123 – 138},
	doi = {10.48009/2_iis_2023_111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174247261&doi=10.48009%2f2_iis_2023_111&partnerID=40&md5=bf90b1f416de9274e54eeea7de42393a},
	affiliations = {Western Carolina University, United States; East Carolina University, United States},
	abstract = {This paper discusses how the public emergence of generative AI is compelling those in academia to rethink teaching and learning and to consider the impact AI has on higher education. The decision as to when to use generative AI in a college course, and when not to, is now a significant component in the development of student assessment and activities. Obviously, there are academic activities that require students to engage in original work. In those instances, generative AI is not appropriate, and faculty will need to consider how to avoid the tool. In those instances where generative AI is encouraged, teaching students to use the tools available to them effectively is necessary. For productive generative AI prompts, awareness of the thought process related to developing prompts, and techniques for writing prompts, is essential. This paper introduces the prompt development life cycle (PDLC) which provides a framework to introduce students to the cognitive aspects of writing a prompt and some basic techniques that can enhance their prompt development skills. Activities to assist in developing the PDLC mindset are also included. © 2023 International Association for Computer Information Systems.},
	author_keywords = {ChatGPT; generative AI; large language model; LLM; PDLC; prompt development life cycle; prompt engineering},
	publisher = {International Association for Computer Information Systems},
	issn = {15297314},
	language = {English},
	abbrev_source_title = {Issue. Inf. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Kovriguina2023,
	author = {Kovriguina, Liubov and Teucher, Roman and Radyush, Daniil and Mouromtsev, Dmitry},
	title = {SPARQLGEN: One-Shot Prompt-based Approach for SPARQL Query Generation},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3526},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176588073&partnerID=40&md5=c408e2ce15847ce28f17e9d1edb1c112},
	affiliations = {metaphacts GmbH, Daimlerstraße 36, Walldorf, 69190, Germany; ITMO University, Kronverksky Pr. 49, bldg. A, St. Petersburg, 197101, Russian Federation; Fraunhofer IAIS Dresden, Schloss Birlinghoven 1, Sankt Augustin, 53757, Germany; TIB – Leibniz-Informationszentrum Technik und Naturwissenschaften und Universitätsbibliothek, Welfengarten 1B, Hannover, 30167, Germany},
	abstract = {In this work, we present a one-shot generative approach (further referred to as SPARQLGEN) for generating SPARQL queries by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. The prompt includes heterogeneous data sources: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query for a different question. In the experiments, GPT-3, a popular pre-trained language model from OpenAI, was leveraged, but it is possible to extend the approach to any other generative LLM. We evaluate, how different types of context in the prompt influence the query generation performance on QALD-9, QALD-10 and Bestiary dataset (BESTIARY), which was created to test LLM performance on unseen data, and provide a detailed error analysis. One of the findings is that providing the model with the underlying KG and a random correct query improve the generation results. The approach shows strong results on QALD-9 dataset, but doesn’t generalize on QALD-10 and BESTIARY which can be caused by memorization problem. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Augmented Large Language Models; Knowledge Graphs Question Answering; Prompt Template Design; SPARQL query generation},
	keywords = {Computational linguistics; Knowledge graph; Natural language processing systems; Resource Description Framework (RDF); Statistical tests; Augmented large language model; Heterogeneous data sources; Knowledge graph question answering; Knowledge graphs; Language model; Prompt template design; Query generation; Question Answering; SPARQL query generation; Template designs; Query processing},
	correspondence_address = {L. Kovriguina; metaphacts GmbH, Walldorf, Daimlerstraße 36, 69190, Germany; email: lk@metaphacts.com},
	editor = {Keshan N. and Neumaier S. and Gentile A.L. and Vahdati S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kassem20234360,
	author = {Kassem, Aly M. and Mahmoud, Omar and Saad, Sherif},
	title = {Preserving Privacy Through DeMemorization: An Unlearning Technique For Mitigating Memorization Risks In Language Models},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {4360 – 4379},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184802059&partnerID=40&md5=1b14b0f9976540fa415adbe02ed47350},
	affiliations = {School of Computer Science, University of Windsor, Canada; Applied Artificial Intelligence Institute, Deakin University, Australia},
	abstract = {Large Language models (LLMs) are trained on vast amounts of data, including sensitive information that poses a risk to personal privacy if exposed. LLMs have shown the ability to memorize and reproduce portions of their training data when prompted by adversaries. Prior research has focused on addressing this memorization issue and preventing verbatim replication through techniques like knowledge unlearning and data pre-processing. However, these methods have limitations regarding the number of protected samples, limited privacy types, and potentially lower-quality generative models. To tackle this challenge more effectively, we propose “DeMem,” a novel unlearning approach that utilizes an efficient reinforcement learning feedback loop via proximal policy optimization. By fine-tuning the language model with a negative similarity score as a reward signal, we incentivize the LLMs to learn a paraphrasing policy to unlearn the pre-training data. Our experiments demonstrate that DeMem surpasses strong baselines and state-of-the-art methods in terms of its ability to generalize and strike a balance between maintaining privacy and LLM performance. ©2023 Association for Computational Linguistics.},
	keywords = {Privacy-preserving techniques; Reinforcement learning; Data preprocessing; Feedback loops; Generative model; Language model; Low qualities; Personal privacy; Policy optimization; Reinforcement learnings; Sensitive informations; Training data; Computational linguistics},
	editor = {Bouamor H. and Pino J. and Bali K.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176060-8},
	language = {English},
	abbrev_source_title = {EMNLP - Conf. Empir. Methods Nat. Lang. Process., Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus}
}

@CONFERENCE{Ou20231549,
	author = {Ou, Ruizhe and Yan, Haotian and Wu, Ming and Zhang, Chuang},
	title = {A Method of Efficient Synthesizing Post-disaster Remote Sensing Image with Diffusion Model and LLM},
	year = {2023},
	journal = {2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference, APSIPA ASC 2023},
	pages = {1549 – 1555},
	doi = {10.1109/APSIPAASC58517.2023.10317383},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180009069&doi=10.1109%2fAPSIPAASC58517.2023.10317383&partnerID=40&md5=8d92c2a44fd96e509e011b6670922e9f},
	affiliations = {Beijing University of Posts and Telecommunications, China},
	abstract = {Due to the fact that current deep learning models are typically driven by big data, existing interpretation models for emergency management lack relevant learning data. However, existing pre-trained image generative models cannot directly generate post-disaster remote sensing images without fine-tuning. In this paper, we demonstrate the ability of natural language guidance synthesizing remote sensing imagery affected by disaster by pre-trained image generative model fine-tuned with very few unlabelled images (i.e., less than 100 fine-tuning images) at very low training cost (i.e., one 2080Ti GPU). To trade for lower cost, we embrace the trend of large model, leveraging a pre-trained caption model, GPT-4 and a pre-trained text-to-image Stable Diffusion model for this task. The Stable Diffusion Model, fine-tuned with our method, successfully synthesizes remote sensing images affected by disasters using natural language guidance in both image inpainting and image generation tasks. In addition, the ground truth for other interpretation models learning. With this achievement, our method can synthesize a large amount of data for the emergency management interpretation model to learn when there is less existing data, only unlabelled data and less time, so as to achieve better interpretation performance. Furthermore, our approach highlights the significant of combining human feedback with large models in synthesizing data which is out of the prior knowledge of large model, especially when there is less data available and less computational power available. © 2023 IEEE.},
	keywords = {Deep learning; Diffusion; Image processing; Learning systems; Remote sensing; Risk management; 'current; Diffusion model; Emergency management; Generative model; Interpretation model; Large models; Learning models; Natural languages; Post disasters; Remote sensing images; Disasters},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030067-3},
	language = {English},
	abbrev_source_title = {Asia Pac. Signal Inf. Process. Assoc. Annu. Summit Conf., APSIPA ASC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee20231303,
	author = {Lee, SooHyung and Lee, HyeRin and Lee, KiSuk},
	title = {Knowledge Generation Pipeline using LLM for Building 3D Object Knowledge Base},
	year = {2023},
	journal = {International Conference on ICT Convergence},
	pages = {1303 – 1305},
	doi = {10.1109/ICTC58733.2023.10392933},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184593202&doi=10.1109%2fICTC58733.2023.10392933&partnerID=40&md5=b877638607a04e5a31a2d5723af6e11b},
	affiliations = {Electronics and Telecommunications Research Institute, Contents Research Division, DaeJeon, South Korea; Sookmyung Women's University, Department of Computer Science, Seoul, South Korea},
	abstract = {With the wide spread of XR(eXtended Reality) contents such as Metaverse and VR(Virtual Reality) / AR(Augmented Reality), the utilization and importance of 3D objects are increasing. In this paper, we describe a knowledge generation pipeline of 3D object for reuse of existing 3D objects and production of new 3D object using generative AI(Artificial Intelligence). 3D object knowledge includes not only the object itself data that are generated in object editing phase but the information for human to recognize and understand objects. The target 3D model for building knowledge is the space model of office for business Metaverse service and the model of objects composing the space. LLM(Large Language Model)-based multimodal AI was used to extract knowledge from 3D model in a systematic and automated way. We plan to expand the pipeline to utilize knowledge base for managing extracted knowledge and correcting errors occurred during the LLM process for the knowledge extraction. © 2023 IEEE.},
	author_keywords = {3D Object; Knowledge Base; Metaverse; MultiModal AI; XR},
	correspondence_address = {S. Lee; Electronics and Telecommunications Research Institute, Contents Research Division, DaeJeon, South Korea; email: soohyung@etri.re.kr},
	publisher = {IEEE Computer Society},
	issn = {21621233},
	isbn = {979-835031327-7},
	language = {English},
	abbrev_source_title = {Int. Conf. ICT Convergence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jeong20231588,
	author = {Jeong, Cheonsu},
	title = {A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture},
	year = {2023},
	journal = {Advances in Artificial Intelligence and Machine Learning},
	volume = {3},
	number = {4},
	pages = {1588 – 1618},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177608340&partnerID=40&md5=f7b18a1cd84dd138125eebd7e6d79009},
	affiliations = {Department of AI Automation Team, SAMSUNG SDS, Olympic-ro 125, Songpa-gu, Seoul, South Korea},
	abstract = {This study presents a method for implementing generative AI services by utilizing the Large Language Models (LLM) application architecture. With recent advancements in generative AI technology, LLMs have gained prominence across various domains. In this context, the research addresses the challenge of information scarcity and proposes specific remedies by harnessing LLM capabilities. The investigation delves into strategies for mitigating the issue of inadequate data, offering tailored solutions. The study delves into the efficacy of employing fine-tuning techniques and direct document integration to alleviate data insuffi-ciency. A significant contribution of this work is the development of a Retrieval-Augmented Generation (RAG) model, which tackles the aforementioned challenges. The RAG model is carefully designed to enhance information storage and retrieval processes, ensuring improved content generation. The research elucidates the key phases of the information storage and retrieval methodology underpinned by the RAG model. A comprehensive analysis of these steps is undertaken, emphasizing their significance in addressing the scarcity of data. The study highlights the efficacy of the proposed method, showcasing its applicability through illustrative instances. By implementing the RAG model for information storage and retrieval, the research not only contributes to a deeper comprehension of generative AI technology but also facilitates its practical usability within enterprises utilizing LLMs. This work holds substantial value in advancing the field of generative AI, offering insights into enhancing data-driven content generation and fostering active utilization of LLM-based services within corporate settings. © 2023 Cheonsu Jeong.},
	author_keywords = {Embedding; Generative AI; LLM framework; RAG; Vector store},
	correspondence_address = {C. Jeong; Department of AI Automation Team, SAMSUNG SDS, Seoul, Olympic-ro 125, Songpa-gu, South Korea; email: csu.jeong@samsung.com},
	publisher = {Shimur Publications},
	issn = {25829793},
	language = {English},
	abbrev_source_title = {Adv. Artif. Intell. Mach. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Laato2023226,
	author = {Laato, Samuli and Morschheuser, Benedikt and Hamari, Juho and Bjorne, Jari},
	title = {AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Advanced Learning Technologies, ICALT 2023},
	pages = {226 – 230},
	doi = {10.1109/ICALT58122.2023.00072},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174404773&doi=10.1109%2fICALT58122.2023.00072&partnerID=40&md5=0c2979f605818acdd2ec59ac90892a4c},
	affiliations = {Tampere University, Gamification Group, Tampere, Finland; Inst. of Information Systems, Fau Erlangen-Nürnberg, Nuremberg, Germany; University of Turku, Dept. of Computing, Turku, Finland},
	abstract = {The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond.  © 2023 IEEE.},
	author_keywords = {Bard; ChatGPT; generative language models; GPT-4; higher education; large language models; learning},
	keywords = {Computational linguistics; Learning systems; Students; Bard; ChatGPT; Generative language model; GPT-4; High educations; Language model; Large language model; Learning; Recent progress; Education computing},
	editor = {Chang M. and Chen N.-S. and Kuo R. and Rudolph G. and Sampson D.G. and Tlili A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835030054-3},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Adv. Learn. Technol., ICALT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Yuan20231256,
	author = {Yuan, Shuzhou and Färber, Michael},
	title = {Evaluating Generative Models for Graph-to-Text Generation},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1256 – 1264},
	doi = {10.26615/978-954-452-092-2_133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172438721&doi=10.26615%2f978-954-452-092-2_133&partnerID=40&md5=635ba4a8fe579664b6721be5ea897219},
	affiliations = {Karlsruhe Institute of Technology (KIT), Germany},
	abstract = {Large language models (LLMs) have been widely employed for graph-to-text generation tasks. However, the process of finetuning LLMs requires significant training resources and annotation work. In this paper, we explore the capability of generative models to generate descriptive text from graph data in a zeroshot setting. Specifically, we evaluate GPT-3 and ChatGPT on two graph-to-text datasets and compare their performance with that of finetuned LLM models such as T5 and BART. Our results demonstrate that generative models are capable of generating fluent and coherent text, achieving BLEU scores of 10.57 and 11.08 for the AGENDA and WebNLG datasets, respectively. However, our error analysis reveals that generative models still struggle with understanding the semantic relations between entities, and they also tend to generate text with hallucinations or irrelevant information. As a part of error analysis, we utilize BERT to detect machine-generated text and achieve high macro-F1 scores. We have made the text generated by generative models publicly available. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Semantics; Annotation work; Fluents; Generative model; Graph data; Language model; Machine-generated texts; Performance; Semantic relations; Text generations; Two-graphs; Error analysis},
	editor = {Angelova G. and Kunilovskaya M. and Mitkov R.},
	publisher = {Incoma Ltd},
	issn = {13138502},
	isbn = {978-954452092-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Jha2023944,
	author = {Jha, Sumit Kumar and Jha, Susmit and Lincoln, Patrick and Bastian, Nathaniel D. and Velasquez, Alvaro and Ewetz, Rickard and Neema, Sandeep},
	title = {Counterexample Guided Inductive Synthesis Using Large Language Models and Satisfiability Solving},
	year = {2023},
	journal = {MILCOM 2023 - 2023 IEEE Military Communications Conference: Communications Supporting Military Operations in a Contested Environment},
	pages = {944 – 949},
	doi = {10.1109/MILCOM58377.2023.10356332},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182396042&doi=10.1109%2fMILCOM58377.2023.10356332&partnerID=40&md5=71b92d09ee4ac40f697121b9983b41ac},
	affiliations = {Florida International University, Computer Science Department, United States; Computer Science Laboratory, Sri International, United States; United States Military Academy, Army Cyber Institute, United States; University of Colorado, Department of Computer Science, Boulder, United States; University of Central Florida, Electrical and Computer Engineering, United States; Vanderbilt University, Electrical and Computer Engineering, United States},
	abstract = {Generative large language models (LLMs) can follow human-provided instruction prompts and generate human-like responses. Apart from natural language responses, they have been found to be effective at generating formal artifacts such as code, plans, and logical specifications. Despite their remarkably improved accuracy, these models are still known to produce factually incorrect or contextually inappropriate results despite their syntactic coherence - a phenomenon often referred to as hallucinations. This limitation makes it difficult to use these models to synthesize formal artifacts used in safety-critical applications. Unlike tasks such as text summarization and question-answering, bugs in code, plan, and other formal artifacts produced by LLMs can be catastrophic. We posit that we can use the satisfiability modulo theory (SMT) solvers as deductive reasoning engines to analyze the generated solutions from the LLMs, produce counterexamples when the solutions are incorrect, and provide that feedback to the LLMs exploiting the dialog capability of LLMs. This interaction between inductive LLMs and deductive SMT solvers can iteratively steer the LLM to generate the correct response. In our experiments, we use planning over the domain of blocks as our synthesis task for evaluating our approach. We use GPT-4, GPT3.5 Turbo, Davinci, Curie, Babbage, and Ada as the LLMs and Z3 as the SMT solver. Our method allows the user to communicate the planning problem in natural language; even the formulation of queries to SMT solvers is automatically generated from natural language. Thus, the proposed technique can enable non-expert users to describe their problems in natural language, and the combination of LLMs and SMT solvers can produce provably correct solutions.  © 2023 IEEE.},
	keywords = {Formal logic; Natural language processing systems; Safety engineering; Human like; Language model; Logical specifications; Natural languages; Plan specification; Safety critical applications; Satisfiability modulo Theories; Satisfiability solving; Text Summarisation; Theory solvers; Iterative methods},
	correspondence_address = {S.K. Jha; Florida International University, Computer Science Department, United States; email: sumit.jha@fiu.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032181-4},
	language = {English},
	abbrev_source_title = {MILCOM - IEEE Milit. Commun. Conf.: Commun. Support. Milit. Oper. Contested Environ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{De Paoli2023,
	author = {De Paoli, Stefano},
	title = {Performing an Inductive Thematic Analysis of Semi-Structured Interviews With a Large Language Model: An Exploration and Provocation on the Limits of the Approach},
	year = {2023},
	journal = {Social Science Computer Review},
	doi = {10.1177/08944393231220483},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179340594&doi=10.1177%2f08944393231220483&partnerID=40&md5=ccb7d6a13e958aff2c0e4f31bba9417b},
	affiliations = {Abertay University, United Kingdom},
	abstract = {Large Language Models (LLMs) have emerged as powerful generative Artificial Intelligence solutions. This paper presents results and reflections of an experiment done with the LLM GPT 3.5-Turbo to perform an inductive Thematic Analysis (TA). Previous research has worked on conducting deductive analysis. Thematic Analysis is a qualitative method for analysis commonly used in social sciences and it is based on interpretations by the human analyst(s) and the identification of explicit and latent meanings in qualitative data. The paper presents the motivations for attempting this analysis; it reflects on how the six phases to a TA proposed by Braun and Clarke can partially be reproduced with the LLM and it reflects on what are the model’s outputs. The paper uses two datasets of open access semi-structured interviews, previously analysed by other researchers. The first dataset contains interviews with videogame players, and the second is a dataset of interviews with lecturers teaching data science in a University. This paper used the analyses previously conducted on these datasets to compare with the results produced by the LLM. The results show that the model can infer most of the main themes from previous research. This shows that using LLMs to perform an inductive TA is viable and offers a good degree of validity. The discussion offers some recommendations for working with LLMs in qualitative analysis. © The Author(s) 2023.},
	author_keywords = {human- AI collaboration; large language models; qualitative research; thematic analysis},
	correspondence_address = {S. De Paoli; Abertay University, United Kingdom; email: s.depaoli@abertay.ac.uk},
	publisher = {SAGE Publications Inc.},
	issn = {08944393},
	language = {English},
	abbrev_source_title = {Soc. Sci. Comput. Rev.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Danu20231102,
	author = {Danu, Manuela Daniela and Marica, George and Karn, Sanjeev Kumar and Georgescu, Bogdan and Mansoor, Awais and Ghesu, Florin and Itu, Lucian Mihai and Suciu, Constantin and Grbic, Sasa and Farri, Oladimeji and Comaniciu, Dorin},
	title = {Generation of Radiology Findings in Chest X-Ray by Leveraging Collaborative Knowledge},
	year = {2023},
	journal = {Procedia Computer Science},
	volume = {221},
	pages = {1102 – 1109},
	doi = {10.1016/j.procs.2023.08.094},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171771080&doi=10.1016%2fj.procs.2023.08.094&partnerID=40&md5=1c1d45edbf6db88d6f8eb600c34a5fb4},
	affiliations = {Advanta, Siemens SRL, 15 Noiembrie Bvd, Brasov, 500097, Romania; Automation and Information Technology, Transilvania University of Brasov, Mihai Viteazu nr. 5, Brasov, 5000174, Romania; Digital Technology and Innovation, Siemens Healthineers, 755 College Rd E, Princeton, 08540, NJ, United States; Digital Technology and Innovation, Siemens Healthineers, Henkestr. 127, Erlangen, 91052, Germany},
	abstract = {Among all the sub-sections in a typical radiology report, the Clinical Indications, Findings, and Impression often reflect important details about the health status of a patient. The information included in Impression is also often covered in Findings. While Findings and Impression can be deduced by inspecting the image, Clinical Indications often require additional context. The cognitive task of interpreting medical images remains the most critical and often time-consuming step in the radiology workflow. Instead of generating an end-to-end radiology report, in this paper, we focus on generating the Findings from automated interpretation of medical images, specifically chest X-rays (CXRs). Thus, this work focuses on reducing the workload of radiologists who spend most of their time either writing or narrating the Findings. Unlike past research, which addresses radiology report generation as a single-step image captioning task, we have further taken into consideration the complexity of interpreting CXR images and propose a two-step approach: (a) detecting the regions with abnormalities in the image, and (b) generating relevant text for regions with abnormalities by employing a generative large language model (LLM). This two-step approach introduces a layer of interpretability and aligns the framework with the systematic reasoning that radiologists use when reviewing a CXR. © 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0) Peer-review under responsibility of the scientific committee of the Tenth International Conference on Information Technology and Quantitative Management.},
	author_keywords = {abnormalities detection; chest X-ray; collaborative knowledge; Findings generation; generative large language model; radiology report},
	keywords = {Computational linguistics; Knowledge management; Medical imaging; Abnormality detection; Chest X-ray; Collaborative knowledge; Finding generation; Generative large language model; Health status; Language model; Radiology reports; Sub-sections; Two-step approach; Radiology},
	correspondence_address = {M.D. Danu; Advanta, Siemens SRL, Brasov, 15 Noiembrie Bvd, 500097, Romania; email: manuela.danu@siemens.com},
	editor = {Shi Y.},
	publisher = {Elsevier B.V.},
	issn = {18770509},
	language = {English},
	abbrev_source_title = {Procedia Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{McKenna20232758,
	author = {McKenna, Nick and Li, Tianyi and Cheng, Liang and Hosseini, Mohammad Javad and Johnson, Mark and Steedman, Mark},
	title = {Sources of Hallucination by Large Language Models on Inference Tasks},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {2758 – 2774},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182811516&partnerID=40&md5=fb6621ce5330863c8d4843ac0c318640},
	affiliations = {University of Edinburgh, United Kingdom; Google Research; Macquarie University, Australia},
	abstract = {Large Language Models (LLMs) are claimed to be capable of Natural Language Inference (NLI), necessary for applied tasks like question answering and summarization. We present a series of behavioral studies on several LLM families (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled experiments. We establish two biases originating from pretraining which predict much of their behavior, and show that these are major sources of hallucination in generative LLMs. First, memorization at the level of sentences: we show that, regardless of the premise, models falsely label NLI test samples as entailing when the hypothesis is attested in training data, and that entities are used as “indices” to access the memorized data. Second, statistical patterns of usage learned at the level of corpora: we further show a similar effect when the premise predicate is less frequent than that of the hypothesis in the training data, a bias following from previous studies. We demonstrate that LLMs perform significantly worse on NLI test samples which do not conform to these biases than those which do, and we offer these as valuable controls for future LLM evaluation. © 2023 Association for Computational Linguistics.},
	keywords = {Natural language processing systems; Behavioural studies; Controlled experiment; Language inference; Language model; Natural languages; Pre-training; Question Answering; Statistical pattern; Test samples; Training data; Computational linguistics},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {979-889176061-5},
	language = {English},
	abbrev_source_title = {Find. Assoc. Comput. Linguist.: EMNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cheng2023,
	author = {Cheng, Shu-Li and Tsai, Shih-Jen and Bai, Ya-Mei and Ko, Chih-Hung and Hsu, Chih-Wei and Yang, Fu-Chi and Tsai, Chia-Kuang and Tu, Yu-Kang and Yang, Szu-Nian and Tseng, Ping-Tao and Hsu, Tien-Wei and Liang, Chih-Sung and Su, Kuan-Pin},
	title = {Comparisons of Quality, Correctness, and Similarity Between ChatGPT-Generated and Human-Written Abstracts for Basic Research: Cross-Sectional Study},
	year = {2023},
	journal = {Journal of Medical Internet Research},
	volume = {25},
	number = {1},
	doi = {10.2196/51229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180760496&doi=10.2196%2f51229&partnerID=40&md5=94c0f68fb7c4d2a81f3d7e7d4d04ecde},
	affiliations = {Department of Nursing, Mackay Medical College, Taipei, Taiwan; Department of Psychiatry, Taipei Veterans General Hospital, Taipei, Taiwan; Division of Psychiatry, School of Medicine, National Yang-Ming University, Taipei, Taiwan; Department of Psychiatry, Kaohsiung Medical University Hospital, Kaohsiung, Taiwan; Department of Psychiatry, College of Medicine, Kaohsiung Medical University, Kaohsiung, Taiwan; Department of Psychiatry, Kaohsiung Municipal Siaogang Hospital, Kaohsiung Medical University, Kaohsiung, Taiwan; Department of Psychiatry, Kaohsiung Chang Gung Memorial Hospital, Kaohsiung, Taiwan; Department of Neurology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Institute of Epidemiology and Preventive Medicine, College of Public Health, National Taiwan University, Taipei, Taiwan; Department of Dentistry, National Taiwan University Hospital, Taipei, Taiwan; Department of Psychiatry, Tri-service Hospital, Beitou branch, Taipei, Taiwan; Department of Psychiatry, Armed Forces Taoyuan General Hospital, Taoyuan, Taiwan; Graduate Institute of Health and Welfare Policy, National Yang Ming Chiao Tung University, Taipei, Taiwan; Institute of Biomedical Sciences, Institute of Precision Medicine, National Sun Yat-sen University, Kaohsiung, Taiwan; Department of Psychology, College of Medical and Health Science, Asia University, Taichung, Taiwan; Prospect Clinic for Otorhinolaryngology and Neurology, Kaohsiung, Taiwan; Department of Psychiatry, E-Da Dachang Hospital, I-Shou University, Kaohsiung, Taiwan; Department of Psychiatry, E-Da Hospital, I-Shou University, Kaohsiung, Taiwan; Department of Psychiatry, National Defense Medical Center, Taipei, Taiwan; College of Medicine, China Medical University, Taichung, Taiwan; Mind-Body Interface Laboratory, China Medical University and Hospital, Taichung, Taiwan; An-Nan Hospital, China Medical University, Tainan, Taiwan},
	abstract = {Background: ChatGPT may act as a research assistant to help organize the direction of thinking and summarize research findings. However, few studies have examined the quality, similarity (abstracts being similar to the original one), and accuracy of the abstracts generated by ChatGPT when researchers provide full-text basic research papers. Objective: We aimed to assess the applicability of an artificial intelligence (AI) model in generating abstracts for basic preclinical research. Methods: We selected 30 basic research papers from Nature, Genome Biology, and Biological Psychiatry. Excluding abstracts, we inputted the full text into ChatPDF, an application of a language model based on ChatGPT, and we prompted it to generate abstracts with the same style as used in the original papers. A total of 8 experts were invited to evaluate the quality of these abstracts (based on a Likert scale of 0-10) and identify which abstracts were generated by ChatPDF, using a blind approach. These abstracts were also evaluated for their similarity to the original abstracts and the accuracy of the AI content. Results: The quality of ChatGPT-generated abstracts was lower than that of the actual abstracts (10-point Likert scale: mean 4.72, SD 2.09 vs mean 8.09, SD 1.03; P<.001). The difference in quality was significant in the unstructured format (mean difference -4.33; 95% CI -4.79 to -3.86; P<.001) but minimal in the 4-subheading structured format (mean difference -2.33; 95% CI -2.79 to -1.86). Among the 30 ChatGPT-generated abstracts, 3 showed wrong conclusions, and 10 were identified as AI content. The mean percentage of similarity between the original and the generated abstracts was not high (2.10%-4.40%). The blinded reviewers achieved a 93% (224/240) accuracy rate in guessing which abstracts were written using ChatGPT. Conclusions: Using ChatGPT to generate a scientific abstract may not lead to issues of similarity when using real full texts written by humans. However, the quality of the ChatGPT-generated abstracts was suboptimal, and their accuracy was not 100%. © 2023 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {abstract; abstracts; academic research; AI-generated scientific content; artificial intelligence; ChatGPT; extract; extraction; generation; generative; language model; language models; LLM; natural language processing; NLP; plagiarism; publication; publications; scientific research; text; textual},
	keywords = {Artificial Intelligence; Cross-Sectional Studies; Humans; Language; Research; Research Personnel; abstract report; accuracy; Article; artificial intelligence; basic research; blindness; ChatGPT; clinical assessment; comparative study; controlled study; correctness; cross-sectional study; data quality; human; Internet; language model; Likert scale; natural language processing; plagiarism; writing; artificial intelligence; language; personnel; research},
	correspondence_address = {T.-W. Hsu; Department of Psychiatry, E-Da Dachang Hospital, I-Shou University, Kaohsiung, No. 305 Dachang 1st Rd., Sanmin District, 807, Taiwan; email: s9801101@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {38145486},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Koziolek2023,
	author = {Koziolek, Heiko and Gruener, Sten and Ashiwal, Virendra},
	title = {ChatGPT for PLC/DCS Control Logic Generation},
	year = {2023},
	journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
	volume = {2023-September},
	doi = {10.1109/ETFA54631.2023.10275411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175444119&doi=10.1109%2fETFA54631.2023.10275411&partnerID=40&md5=8e82866feb4194a00f6ae973cb2c5719},
	affiliations = {ABB Research, Ladenburg, Germany},
	abstract = {Large language models (LLMs) providing generative AI have become popular to support software engineers in creating, summarizing, optimizing, and documenting source code. It is still unknown how LLMs can support control engineers using typical control programming languages in programming tasks. Researchers have explored GitHub CoPilot or DeepMind AlphaCode for source code generation but did not yet tackle control logic programming. A key contribution of this paper is an exploratory study, for which we created 100 LLM prompts in 10 representative categories to analyze control logic generation for of PLCs and DCS from natural language. We tested the prompts by generating answers with ChatGPT using the GPT-4 LLM. It generated syntactically correct IEC 61131-3 Structured Text code in many cases and demonstrated useful reasoning skills that could boost control engineer productivity. Our prompt collection is the basis for a more formal LLM benchmark to test and compare such models for control logic generation. © 2023 IEEE.},
	author_keywords = {Automation engineering; Benchmark; Control engineering; Control Logic Generation; Generative AI; IEC 61131-3; Large Language Models; Structured Text},
	keywords = {Computational linguistics; Engineers; Logic programming; Automation engineering; Benchmark; Control engineering; Control logic; Control logic generation; Generative AI; IEC 61131-3; Language model; Large language model; Structured text; Computer circuits},
	correspondence_address = {H. Koziolek; ABB Research, Ladenburg, Germany; email: heiko.koziolek@de.abb.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {19460740},
	isbn = {979-835033991-8},
	coden = {85ROA},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Emerging Technol. Factory Autom., ETFA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Gill2023,
	author = {Gill, Amaninder Singh},
	title = {CHAT GENERATIVE PRETRAINED TRANSFORMER: EXTINCTION OF THE DESIGNER OR RISE OF AN AUGMENTED DESIGNER},
	year = {2023},
	journal = {Proceedings of the ASME Design Engineering Technical Conference},
	volume = {3B},
	doi = {10.1115/DETC2023-116971},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179131182&doi=10.1115%2fDETC2023-116971&partnerID=40&md5=b7cfb05614b6d7f80ee47674e780aeb3},
	affiliations = {Centralia College, Centralia, WA, United States},
	abstract = {Systematic design process is used in engineering systems design to develop solutions to problems of varying complexity. There have been efforts within the community to develop tools to perform automated generative design at varying stages of the systematic design process. However, a Large Language Model (LLM) has never been used. To this end, this paper presents an initial investigation into the use of OpenAI's ChatGPT to automatically generate solutions to an engineering problem. It is demonstrated that for the most part ChatGPT is quite capable of generating conceptual design for an engineering problem. In light of this technology, this paper floats questions on the future direction of research and education for the engineering systems design community. © 2023 American Society of Mechanical Engineers (ASME). All rights reserved.},
	author_keywords = {ChatGPT; Cyber-Physical Social Systems; Function Models; Generative Design},
	keywords = {Cyber Physical System; Engineering education; Systems analysis; ChatGPT; Cybe-physical social system; Cyber physicals; Design-process; Engineering problems; Engineering system design; Function modelling; Generative design; Social systems; Systematic designs; Conceptual design},
	correspondence_address = {A.S. Gill; Centralia College, Centralia, United States; email: aman.gill@centralia.edu},
	publisher = {American Society of Mechanical Engineers (ASME)},
	isbn = {978-079188731-8},
	language = {English},
	abbrev_source_title = {Proc. ASME Des. Eng. Tech. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hingle2023,
	author = {Hingle, Ashish and Katz, Andrew and Johri, Aditya},
	title = {Exploring NLP-Based Methods for Generating Engineering Ethics Assessment Qualitative Codebooks},
	year = {2023},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	doi = {10.1109/FIE58773.2023.10342985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183006387&doi=10.1109%2fFIE58773.2023.10342985&partnerID=40&md5=fb7103fa1565b63c7170f6b971f43590},
	affiliations = {George Mason University, Information Sciences and Technology, Fairfax, United States; Virginia Polytechnic Insitute and State University, Engineering Education, Blacksburg, United States},
	abstract = {This Full Research paper presents a comparison of two codebook generation methods using natural language processing (NLP): a human and NLP collaboration method and a fully automated NLP method (referred to as Human-NLP and Auto-NLP, respectively). Codebook generation serves as a preliminary step in most qualitative projects, and using NLP as a tool can help support the analysis and efficiency of the researcher. By utilizing NLP in the early stages of codebook generation, there are opportunities for detailed and productive gains when working with large corpora of textual data. Using NLP at this stage also allows the researcher to make sense of any outputs generated through automated means rather than simply accepting the output as it is. The outcome of both methods tested in this work will be used to evaluate and apply the codes across a large dataset. The Human-NLP method involves generating the initial themes using a large-language model (LLM), and the researcher revises the codebook further. The Auto-NLP method involves generating three rounds of codes, summarizing the codes in each until a saturation level has been reached through the overarching themes. The dataset used for this study comes from an analysis of students' perception and recognition of ethical concepts after participating in a semester-long course focused on ethics, society, and technology. The course introduced students to traditional ethics topics, such as those around engineering disasters, but also explored developing topics, such as facial recognition, dataset bias, and the impact of technology on the global food supply. We collected data between fall 2020 and 2022 from six (6) iterations of a semester-long course. A total of 210 student responses to the question - what did this course teach you about ethics - were analyzed. The results from both Human-NLP and Auto-NLP methods were promising in the level of detail summarized and the similarity of themes across the data. Eight (8) themes were finalized through the Human-NLP method, and twelve (12) were generated through the Auto-NLP method. We present a discussion exploring these themes and the limitations of using these methods. © 2023 IEEE.},
	author_keywords = {codebook generation; engineering ethics; generative AI; natural language processing},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {979-835033642-9},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sarda202316,
	author = {Sarda, Komal},
	title = {Leveraging Large Language Models for Auto-remediation in Microservices Architecture},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Automatic Computing and Self-Organizing Systems Companion, ACSOS-C 2023},
	pages = {16 – 18},
	doi = {10.1109/ACSOS-C58168.2023.00025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181532727&doi=10.1109%2fACSOS-C58168.2023.00025&partnerID=40&md5=9d0c08b492211082d6fa9be6c95695b7},
	affiliations = {York University, Department of Electrical Engineering and Computer Science, Canada},
	abstract = {Microservices architecture is popular due to its scalability and flexibility. However, managing and troubleshooting distributed microservices-based systems can be challenging and time consuming. Auto-remediation of anomalies, that is the automated detection and root-causes generation and execution of repair scripts, can reduce the down-times and increase the availability of systems. This thesis will explore the potential and effectiveness of using large language models (LLMs) in auto-remediation. It will develop an auto-remediation framework to mitigate the effects of performance-based anomalies in self-adaptive microservice architectures. Multiple sample microservice applications as test-bed will be rigorously studied, and a dataset will be created to evaluate LLM-based codegeneration models using semantic, lexical, and correctness metrics in zero-shot and few-shot scenarios. Additionally, we will develop reliable prompts for automated Ansible runbook generation and assess their efficiency for orchestrating the auto-remediation process, including deployment, configuration changes, and system recovery to improve application reliability and operational efficiency. © 2023 IEEE.},
	author_keywords = {Ansible; Auto-Remediation; Generative AI; Microservices; NLP; Self-adaptive Systems; Self-healing; Software Performance},
	keywords = {Adaptive systems; Computational linguistics; Efficiency; Statistical tests; Ansible; Auto-remediation; Automated detection; Generative AI; Language model; Microservice; Root cause; Self-adaptive system; Self-healing; Software performance; Semantics},
	correspondence_address = {K. Sarda; York University, Department of Electrical Engineering and Computer Science, Canada; email: komal253@yorku.ca},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835033746-4},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Autom. Comput. Self-Organ. Syst. Companion, ACSOS-C},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Aguilar-Canto2023,
	author = {Aguilar-Canto, Fernando and Cardoso-Moreno, Marco and Jiménez, Diana and Calvo, Hiram},
	title = {GPT-2 versus GPT-3 and Bloom: LLMs for LLMs Generative Text Detection},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3496},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175314590&partnerID=40&md5=fa09987f5bf95ddddd1a8f24dd4f13c0},
	affiliations = {Computational Cognitive Sciences Laboratory, Center for Computing Research, Instituto Politécnico Nacional, Mexico City, 07700, Mexico},
	abstract = {With the advent and proliferation of advanced Large Language Models (LLMs) such as BLOOM, GPT series, and ChatGPT, there is a growing concern regarding the potential misuse of this technology. Consequently, it has become imperative to develop machine learning techniques that can discern whether a given text has been generated by an LLM or authored by a human. In this paper, we present our approach in the AuTexTification shared task, where we fine-tuned BERT-based models and GPT-2 Small. Remarkably, GPT-2 Small achieved the highest F1-macro score in the validation set, prompting us to evaluate its performance on the testing set. We achieved an F1-macro score of 0.74134, securing the third position in the benchmark. Furthermore, we extended our fine-tuning efforts to the model attribution subtask, yielding a F1-macro score of 0.52282. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {AuTexTification; Generative Text Detection; Large Language Models (LLMs); Model Attibution},
	keywords = {Blooms (metal); Learning systems; Autextification; Generative text detection; Language model; Large language model; Machine learning techniques; Model attibution; Performance; Testing sets; Text detection; Validation sets; Computational linguistics},
	correspondence_address = {M. Cardoso-Moreno; Computational Cognitive Sciences Laboratory, Center for Computing Research, Instituto Politécnico Nacional, Mexico City, 07700, Mexico; email: mcardosom2021@cic.ipn.mx},
	editor = {Montes-y-Gomez M. and Rangel F. and Jimenez-Zafra S.M. and Casavantes M. and Altuna B. and Alvarez-Carmona M.A. and Bel-Enguix G. and Chiruzzo L. and de la Iglesia I. and Escalante H.J. and Garcia-Cumbreras M.A. and Garcia-Diaz J.A. and Barba J.A.G. and Tamayo R.L. and Lima S. and Moral P. and del Arco F.M.P. and Valencia-Garcia R.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Waisberg2023,
	author = {Waisberg, Ethan and Ong, Joshua and Kamran, Sharif Amit and Masalkhi, Mouayad and Zaman, Nasif and Sarker, Prithul and Lee, Andrew G. and Tavakkoli, Alireza},
	title = {Bridging artificial intelligence in medicine with generative pre-trained transformer (GPT) technology},
	year = {2023},
	journal = {Journal of Medical Artificial Intelligence},
	volume = {6},
	doi = {10.21037/jmai-23-36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172797304&doi=10.21037%2fjmai-23-36&partnerID=40&md5=9f1ab793fe6607a5ab9208b07ce73b2c},
	affiliations = {University College Dublin School of Medicine, Belfield, Dublin, Ireland; Michigan Medicine, University of Michigan, Ann Arbor, MI, United States; Human-Machine Perception Laboratory, Department of Computer Science and Engineering, University of Nevada, Reno, NV, United States; Center for Space Medicine, Baylor College of Medicine, Houston, TX, United States; Department of Ophthalmology, Blanton Eye Institute, Houston Methodist Hospital, Houston, TX, United States; The Houston Methodist Research Institute, Houston Methodist Hospital, Houston, TX, United States; Departments of Ophthalmology, Neurology, and Neurosurgery, Weill Cornell Medicine, New York, NY, United States; Department of Ophthalmology, University of Texas Medical Branch, Galveston, TX, United States; University of Texas MD Anderson Cancer Center, Houston, TX, United States; Texas A&M College of Medicine, Bryan, TX, United States; Department of Ophthalmology, The University of Iowa Hospitals and Clinics, Iowa, IA, United States},
	abstract = {Since its public release in November 2022, the usage of ChatGPT (Open AI, USA) has been unprecedented. This large language model (LLM) can produce human-like text from deep-learning techniques. LLMs are rapidly approaching human-level performance. ChatGPT can potentially help democratize the ability to code, by allowing clinicians to be able to develop basic artificial intelligence (AI) techniques. By leveraging AI models, these clinicians can expand the scope of their research abilities, and this can potentially lead to an AI in medicine revolution, where clinicians are able to generate clinically-focused AI techniques with the goal of improving patient outcomes across all domains. In this paper, we examine the performance of ChatGPT at developing an AI program for medicine and its associated limitations and challenges. Similar to the majority of AI models, the ethical concerns surrounding its application in medicine remains, which includes biases, patient autonomy, and confidentiality, transparency, and accuracy of data. ChatGPT must also be used in accordance with local healthcare regulations, such as the Health Insurance Portability and Accountability Act (HIPAA) in the United States. All things considered, ChatGPT and future generative AI technologies will democratize the ability to code and develop AI, likely leading to breakthroughs in the medical AI sector. © Journal of Medical Artificial Intelligence. All rights reserved.},
	author_keywords = {Artificial intelligence (AI); ChatGPT; large language model (LLM); medicine},
	correspondence_address = {E. Waisberg; University College Dublin School of Medicine, Belfield, Dublin 4, D04 C1P1, Ireland; email: ethan.waisberg@ucdconnect.ie},
	publisher = {AME Publishing Company},
	issn = {26172496},
	language = {English},
	abbrev_source_title = {J. Med. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Xia2023211,
	author = {Xia, Haojun and Zheng, Zhen and Li, Yuchao and Zhuang, Donglin and Zhou, Zhongzhu and Qiu, Xiafei and Li, Yong and Lin, Wei and Song, Shuaiwen Leon},
	title = {Flash-LLM: Enabling Cost-Effective and Highly-Efficient Large Generative Model Inference with Unstructured Sparsity},
	year = {2023},
	journal = {Proceedings of the VLDB Endowment},
	volume = {17},
	number = {2},
	pages = {211 – 224},
	doi = {10.14778/3626292.3626303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182603167&doi=10.14778%2f3626292.3626303&partnerID=40&md5=4d49ac11af38fead46133552d24d3662},
	affiliations = {University of Sydney, Australia; Alibaba Group},
	abstract = {With the fast growth of parameter size, it becomes increasingly challenging to deploy large generative models as they typically require large GPU memory consumption and massive computation. Unstructured model pruning has been a common approach to reduce both GPU memory footprint and the overall computation while retaining good model accuracy. However, the existing solutions do not provide an efficient support for handling unstructured sparsity on modern GPUs, especially on the highly-structured tensor core hardware. Therefore, we propose Flash-LLM for enabling low-cost and highly efficient large generative model inference with the sophisticated support of unstructured sparsity on high-performance but highly restrictive tensor cores. Based on our key observation that the main bottleneck of generative model inference is the several skinny matrix multiplications for which tensor cores would be significantly under-utilized due to low computational intensity, we propose a general Load-as-Sparse and Compute-as-Dense methodology for unstructured sparse matrix multiplication (SpMM). The basic insight is to address the significant memory bandwidth bottleneck while tolerating redundant computations that are not critical for end-to-end performance on tensor cores. Based on this, we design an effective software framework for tensor core based unstructured SpMM, leveraging on-chip resources for efficient sparse data extraction and computation/memory-access overlapping. Extensive evaluations demonstrate that (1) at SpMM kernel level, Flash-LLM significantly outperforms the state-of-the-art library, i.e., Sputnik and SparTA by an average of 2.9× and 1.5×, respectively.(2) At endto-end framework level on OPT-30B/66B/175B models, for tokens per GPU-second, Flash-LLM achieves up to 3.8× and 3.6× improvement over DeepSpeed and FasterTransformer, respectively, with significantly lower inference cost. © 2023, VLDB Endowment. All rights reserved.},
	keywords = {Computational efficiency; Computer programming; Flash memory; Graphics processing unit; Matrix algebra; Program processors; Tensors; Cost effective; Fast growths; Generative model; MAtrix multiplication; Memory consumption; Memory footprint; Model inference; Model pruning; Sparse matrices; Unstructured model; Cost effectiveness},
	editor = {Zhang M. and Shahabi C.},
	publisher = {VLDB Endowment},
	issn = {21508097},
	language = {English},
	abbrev_source_title = {Proc. VLDB Endow.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Hanifi2023196,
	author = {Hanifi, Khadija and Cetin, Orcun and Yilmaz, Cemal},
	title = {On ChatGPT: Perspectives from Software Engineering Students},
	year = {2023},
	journal = {IEEE International Conference on Software Quality, Reliability and Security, QRS},
	pages = {196 – 205},
	doi = {10.1109/QRS60937.2023.00028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182504562&doi=10.1109%2fQRS60937.2023.00028&partnerID=40&md5=7cbc03fcc64176c6cbc27e6e2481a1be},
	affiliations = {Ericsson Research Turkey, Istanbul, Turkey; Sabanci University, Istanbul, Turkey},
	abstract = {ChatGPT, an increasingly popular Large Language Model (LLM), has found widespread acceptance, especially among the younger generation, who rely on it for various tasks, such as comprehending complex course materials and tackling homework assignments. This surge in interest has drawn the attention of researchers, leading to numerous studies that delve into the advantages and disadvantages of the upcoming LLM dominant era. In our research, we explore the influence of ChatGPT and similar models on the field of software engineering, specifically from the perspective of software engineering students. Our main objective is to gain valuable insights into their usage habits and opinions through a comprehensive survey. The survey encompassed diverse questions, addressing the specific areas where ChatGPT was utilized for assistance and gathering students' reflections on each aspect. We found that ChatGPT has garnered widespread acceptance among software engineering students, with 93% of them utilizing it for their projects. These students expressed satisfaction with the level of assistance provided, and most intend to continue using it as a valuable tool in their work. During our investigation, we also assessed the students' awareness of the underlying technologies behind ChatGPT. Approximately half of the students demonstrated awareness of these technologies, while 38.7% had made extra efforts to explore prompt engineering to enhance ChatGPT's productivity. However, an important finding was that 90.6% of the students reported experiencing hallucinations during their interactions with ChatGPT. These hallucinations were shared as examples, raising significant concerns that warrant further exploration and mitigation. Moreover, we delved into potential improvements and gathered valuable recommendations, which could help ChatGPT to become even more effective and dependable in its applications.  © 2023 IEEE.},
	author_keywords = {academic education; ChatGPT; generative AI; Large Language Models; software engineering},
	keywords = {Computational linguistics; Education computing; Engineering education; Software engineering; Academic education; ChatGPT; Course material; Generative AI; Homework assignments; Language model; Large language model; Similar models; Software engineering students; Younger generations; Students},
	correspondence_address = {K. Hanifi; Ericsson Research Turkey, Istanbul, Turkey; email: khadija.hanifi@ericsson.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {26939177},
	isbn = {979-835031958-3},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Softw. Qual., Reliab. Secur., QRS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Meskó2023,
	author = {Meskó, Bertalan},
	title = {Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial},
	year = {2023},
	journal = {Journal of Medical Internet Research},
	volume = {25},
	number = {1},
	doi = {10.2196/50638},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173015974&doi=10.2196%2f50638&partnerID=40&md5=8b7d886ab3df29d5ff01aadb60436ebd},
	affiliations = {The Medical Futurist Institute, Budapest, Hungary},
	abstract = {Prompt engineering is a relatively new field of research that refers to the practice of designing, refining, and implementing prompts or instructions that guide the output of large language models (LLMs) to help in various tasks. With the emergence of LLMs, the most popular one being ChatGPT that has attracted the attention of over a 100 million users in only 2 months, artificial intelligence (AI), especially generative AI, has become accessible for the masses. This is an unprecedented paradigm shift not only because of the use of AI becoming more widespread but also due to the possible implications of LLMs in health care. As more patients and medical professionals use AI-based tools, LLMs being the most popular representatives of that group, it seems inevitable to address the challenge to improve this skill. This paper summarizes the current state of research about prompt engineering and, at the same time, aims at providing practical recommendations for the wide range of health care professionals to improve their interactions with LLMs. ©Bertalan Meskó.},
	author_keywords = {AI; AI tool; artificial intelligence; chatbot; chatbots; ChatGPT; conversational agent; conversational agents; decision-making; digital health; engineering; future; GPT-4; healthcare professional; language model; large language models; LLM; LLMs; natural language processing; NLP; prompt; prompt engineering; prompts; technology},
	keywords = {Artificial Intelligence; Engineering; Health Personnel; Humans; Language; adult; article; artificial intelligence; ChatGPT; decision making; health care personnel; human; natural language processing; skill; engineering; health care personnel; language},
	correspondence_address = {B. Meskó; The Medical Futurist Institute, Budapest, Povl Bang-Jensen u. 2/B1. 4/1., 1118, Hungary; email: berci@medicalfuturist.com},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {37792434},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Virvou2023,
	author = {Virvou, Maria and Tsihrintzis, George A. and Sotiropouloss, Dionisios N. and Chrysafiadi, Konstantina and Sakkopoulos, Evangelos and Tsichrintzi, Evangelia-Aikaterini},
	title = {ChatGPT in Artificial Intelligence-Empowered E-Learning for Cultural Heritage: The case of Lyrics and Poems},
	year = {2023},
	journal = {14th International Conference on Information, Intelligence, Systems and Applications, IISA 2023},
	doi = {10.1109/IISA59645.2023.10345878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182021132&doi=10.1109%2fIISA59645.2023.10345878&partnerID=40&md5=0783299fac656cc74b0b4603399190b9},
	affiliations = {University of Piraeus, Department of Informatics, Piraeus, 185 34, Greece; National and Kapodistrian University of Athens, Department of Informatics and Telecommunications, Athens, Greece},
	abstract = {This paper explores the integration of ChatGPT, a state-of-the-art language model, in the domain of cultural heritage Artificial Intelligence-based e-learning, with a specific focus on the analysis and interpretation of lyrics and poems. Cultural heritage preservation and education have increasingly turned to Artificial Intelligence (AI) technologies to enhance learning experiences and promote the understanding and appreciation of diverse artistic expressions. We have conducted an initial empirical study on how ChatGPT can assist learners in analysing and interpreting poetic and lyrics works, offering insights into the historical, cultural, and literary significance embedded within the verses. Our findings highlight ChatGPT's significant potential but also major weaknesses with respect to poetry and lyrics. ChatGPT was found particularly good in the field of interpreting poetic content. Additionally, ChatGPT showed a very good performance in analogy identification, demonstrating a broad knowledge base encompassing various form of poetry, from Ancient Greek works to ecclesiastic hymns and modern compositions. However, opportunities for enhancement are evident in translation and historical context provision. Finally, ChatGPT's weakest aspect was its factual accuracy, occasionally producing errors without indicating uncertainty in its responses. Consequently, while ChatGPT displays substantial promise, its application in e-learning settings is not mature due to observed inaccuracies. Furthermore, we introduced MUSILYAN, a specialised software tool designed for musicological and lyrical analysis, complementing ChatGPT's capabilities. While Chat-GPT excels in natural language understanding and generation, MUSILYAN offers structured semantic content management and thematic organisation of lyrics. The integration of ChatGPT and MUSILYAN holds promise for enhancing the exploration and understanding of poetry and lyrics. © 2023 IEEE.},
	author_keywords = {AI-based poem analysis; Artificial Intelligence; ChatGPT; Cultural Heritage; e-learning; Generative AI; Intelligent Tutoring Systems; LLMs; machine learning; Natural Language Processing},
	keywords = {Computer aided instruction; E-learning; Historic preservation; Knowledge based systems; Learning algorithms; Learning systems; Natural language processing systems; Artificial intelligence-based poem analyse; ChatGPT; Cultural heritages; E - learning; Generative artificial intelligence; Intelligent tutoring; Intelligent tutoring system; Language processing; LLM; Machine-learning; Natural language processing; Natural languages; Tutoring system; Semantics},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031806-7},
	language = {English},
	abbrev_source_title = {Int. Conf. Inf., Intell., Syst. Appl., IISA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dhaini20231,
	author = {Dhaini, Mahdi and Poelman, Wessel and Erdogan, Ege},
	title = {Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {1 – 12},
	doi = {10.26615/issn.2603-2821.2023_001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179135838&doi=10.26615%2fissn.2603-2821.2023_001&partnerID=40&md5=ce2c74385f7603b52b3e5e17a2ae406c},
	affiliations = {Technical University of Munich, Department of Computer Science, Germany},
	abstract = {While recent advancements in the capabilities and widespread accessibility of generative language models, such as ChatGPT (OpenAI, 2022), have brought about various benefits by generating fluent human-like text, the task of distinguishing between human- and large language model (LLM) generated text has emerged as a crucial problem. These models can potentially deceive by generating artificial text that appears to be human-generated. This issue is particularly significant in domains such as law, education, and science, where ensuring the integrity of text is of the utmost importance. This survey provides an overview of the current approaches employed to differentiate between texts generated by humans and ChatGPT. We present an account of the different datasets constructed for detecting ChatGPT-generated text, the various methods utilized, what qualitative analyses into the characteristics of human versus ChatGPT-generated text have been performed, and finally, summarize our findings into general insights. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {'current; Artificial text; Fluents; Human like; Language model; Qualitative analysis; Computational linguistics},
	editor = {Hardalov M. and Kancheva Z. and Velichkov B. and Nikolova-Koleva I. and Slavcheva M.},
	publisher = {Incoma Ltd},
	issn = {13138502},
	language = {English},
	abbrev_source_title = {Int. Conf. Recent Adv. Nat. Lang. Proces., RANLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pasupuleti2023,
	author = {Pasupuleti, Rajesh and Vadapalli, Ravi and Mader, Christopher},
	title = {Cyber Security Issues and Challenges Related to Generative AI and ChatGPT},
	year = {2023},
	journal = {Proceedings - 2023 10th International Conference on Social Networks Analysis, Management and Security, SNAMS 2023},
	doi = {10.1109/SNAMS60348.2023.10375472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183457735&doi=10.1109%2fSNAMS60348.2023.10375472&partnerID=40&md5=73e27cd999c795f5b54dc44ccf4039f9},
	affiliations = {Frost Institute for Data Science and Computing (IDSC), University of Miami, Coral Gables, FL, United States; University of Miami, Idsc Advanced Computing Systems, Electrical and Computer Engineering (ECE), Coral Gables, FL, United States; Frost Institute for Data Science and Computing (IDSC), University of Miami, Systems and Data Engineering, Coral Gables, FL, United States},
	abstract = {In recent years, Generative Artificial Intelligence (AI) and ChatGPT (Generative Pre-trained Transformer) models that are capable of generating realistic human-mimicked languages have gained progressive popularity. With the evolution of technology, there has been a significant increase in the availability and usage of artificial intelligence tools, such as ChatGPT and Generative AI, that will assist in shaping the future. However, this increasing popularity poses a potential risk if used inappropriately. Threats from AI pose special challenges for government, the private sector, and national security. In this paper, we address some of key concerns of significant cyber security issues and challenges related to Generative AI and ChatGPT. With careful consideration to application usage, organizations can implement appropriate security measures to mitigate these risks. We also incorporate recommendations about ChatGPT usage and its impact on society. It is important that researchers, developers, and policymakers (CIOs, CSOs) work together to mitigate these risks and to ensure that these models are used in a responsible and ethical manner.  © 2023 IEEE.},
	author_keywords = {Challenges; ChatGPT; Cybersecurity Issues; Generative AI; LLM Models; Risks},
	keywords = {Artificial intelligence; National security; Risk assessment; Challenge; ChatGPT; Cyber security; Cybersecurity issue; Generative artificial intelligence; Issues and challenges; LLM model; Security challenges; Security issues; Transformer modeling; Cybersecurity},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835031890-6},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Soc. Networks Anal., Manag. Secur., SNAMS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Frez2023252,
	author = {Frez, Jonathan and Baloian, Nelson},
	title = {Bridging the Gap: Enhancing Geospatial Analysis with Natural Language and Scenario Generation Language},
	year = {2023},
	journal = {Lecture Notes in Networks and Systems},
	volume = {842 LNNS},
	pages = {252 – 263},
	doi = {10.1007/978-3-031-48642-5_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178633853&doi=10.1007%2f978-3-031-48642-5_24&partnerID=40&md5=73c9346ca3608a4b04d165d7f251e328},
	affiliations = {Universidad Diego Portales Vergara 435, Santiago, Chile; Department of Computer Science, Universidad de Chile, Beauchef 851, Santiago, Chile},
	abstract = {Scenario Generation Language (SGL) is a powerful tool that simplifies geospatial analysis and decision-making processes, removing the requirement for users to have expertise in GIS or SQL. However, users still need to understand the SGL grammar. This paper introduces a novel approach that utilizes GPT (Generative Pre-trained Transformer) - LLM (Large Language Model) to generate SGL statements directly from natural language questions. By leveraging the capabilities of GPT-LLM, this approach bridges the gap between user intent and technical query construction, enhancing the usability and accessibility of SGL. It enables decision-makers to interact with geospatial data using familiar natural language queries, without the need for in-depth knowledge of SGL or complex geospatial querying techniques. The integration of natural language processing with SGL empowers users to effortlessly generate accurate and syntactically correct statements, streamlining the analysis process and facilitating scenario exploration. Experimental results indicate that directly utilizing GPT-LLM for geospatial analysis may not yield satisfactory results. However, the approach presented in this paper demonstrates its effectiveness in simplifying geospatial analysis and supporting informed decision-making. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {decision-making; geospatial analysis; GPT (Generative Pre-trained Transformer); LLM (Large Language Model); Scenario Generation Language (SGL)},
	keywords = {Bridge approaches; Computational linguistics; Natural language processing systems; Query processing; Decision-making process; Decisions makings; Generative pre-trained transformer; Geo-spatial analysis; Language grammar; Language model; Large language model; Natural language generation; Scenario generation language; Scenarios generation; Decision making},
	correspondence_address = {J. Frez; Universidad Diego Portales Vergara 435, Santiago, Chile; email: jonathan.frez@mail.udp.cl},
	editor = {Bravo J. and Urzáiz G.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303148641-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Khan2023,
	author = {Khan, Rahat and Gupta, Nidhi and Sinhababu, Atasi and Chakravarty, Rupak},
	title = {Impact of Conversational and Generative AI Systems on Libraries: A Use Case Large Language Model (LLM)},
	year = {2023},
	journal = {Science and Technology Libraries},
	doi = {10.1080/0194262X.2023.2254814},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170690171&doi=10.1080%2f0194262X.2023.2254814&partnerID=40&md5=9ecc50249136a6198df0c976b023d1da},
	affiliations = {Prince Muhammed Bin Fahd University, Saudi Arabia; Government College of Education Sector-20, Chandigarh, India; Amity University Punjab, Mohali, India; DLIS, Panjab University, Chandigarh, India},
	abstract = {The study aims to examine how artificial intelligence (AI) could potentially affect specific services provided by academic libraries in the near future. To achieve this, the study uses three different Generative AI systems: ChatGPT, Perplexity, and iAsk.Ai. By analyzing the potential impact of AI on academic library services, the study aims to provide insights into how libraries can adapt to these changes to better serve their patrons. The three AI systems selected for this study represent different AI approaches that can be used in academic libraries. ChatGPT, for example, is a conversational AI system that can provide quick answers to patrons’ queries, while Perplexity is a language model that can assist with tasks such as cataloging and content classification. iAsk.Ai is a natural language processing (NLP) system that can assist with research and reference inquiries. By assessing the potential impact of these AI systems on academic library services, the study can provide insights into the future of library services and how AI could be used to enhance them. Ultimately, this could help academic libraries prepare for and adapt to the changing technological landscape, ensuring that they continue to meet the needs of their patrons in the years to come. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	author_keywords = {ChatGPT; conversational AI system; generative AI system; iAsk.Ai; libraries; perplexity},
	keywords = {Computational linguistics; Natural language processing systems; Academic libraries; Ai; Artificial intelligence systems; ChatGPT; Conversational artificial intelligence system; Generative artificial intelligence system; Iask.; Library services; Perplexity; article; artificial intelligence; ChatGPT; documentation; human; human experiment; library; natural language processing; Libraries},
	correspondence_address = {N. Gupta; Government College of Education Sector, Chandigarh, 20, India; email: nidhimahajan291@gmail.com},
	publisher = {Routledge},
	issn = {0194262X},
	coden = {STELD},
	language = {English},
	abbrev_source_title = {Sci Technol Libr},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Sarkhel20233098,
	author = {Sarkhel, Ritesh and Huang, Binxuan and Lockard, Colin and Shiralkar, Prashant},
	title = {Self-Training for Label-Efficient Information Extraction from Semi-Structured Web-Pages},
	year = {2023},
	journal = {Proceedings of the VLDB Endowment},
	volume = {16},
	number = {11},
	pages = {3098 – 3110},
	doi = {10.14778/3611479.3611511},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171883386&doi=10.14778%2f3611479.3611511&partnerID=40&md5=9bb526ff92bc19de8637716d93e8583e},
	affiliations = {Amazon, Seattle, WA, United States},
	abstract = {Information Extraction (IE) from semi-structured web-pages is a long studied problem. Training a model for this extraction task requires a large number of human-labeled samples. Prior works have proposed transferable models to improve the label-efficiency of this training process. Extraction performance of transferable models however, depends on the size of their fine-tuning corpus. This holds true for large language models (LLM) such as GPT-3 as well. Generalist models like LLMs need to be fine-tuned on in-domain, human-labeled samples for competitive performance on this extraction task. Constructing a large-scale fine-tuning corpus with human-labeled samples, however, requires significant effort. In this paper, we develop a Label-Efficient Self-Training Algorithm (LEAST) to improve the label-efficiency of this fine-tuning process. Our contributions are two-fold. First, we develop a generative model that facilitates the construction of a large-scale fine-tuning corpus with minimal human-effort. Second, to ensure that the extraction performance does not suffer due to noisy training samples in our fine-tuning corpus, we develop an uncertainty-aware training strategy. Experiments on two publicly available datasets show that LEAST generalizes to multiple verticals and backbone models. Using LEAST, we can train models with less than ten human-labeled pages from each website, outperforming strong baselines while reducing the number of human-labeled training samples needed for comparable performance by up to 11x. © 2023 VLDB Endowment.},
	keywords = {Information retrieval; Sampling; Websites; Competitive performance; Fine tuning; Language model; Large-scales; Performance; Self-training; Semi-structured; Structured web page; Training process; Training sample; Efficiency},
	editor = {Koutrika G. and Yang J.},
	publisher = {VLDB Endowment},
	issn = {21508097},
	language = {English},
	abbrev_source_title = {Proc. VLDB Endow.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Ioannidis202320,
	author = {Ioannidis, Jules and Harper, Joshua and Quah, Ming Sheng and Hunter, Dan},
	title = {Gracenote.ai: Legal Generative AI for Regulatory Compliance},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3423},
	pages = {20 – 31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163821488&partnerID=40&md5=40d805e30ec02828839820732cae5c4a},
	affiliations = {Gracenote.ai, Melbourne, Australia; The Dickson Poon School of Law, King's College London, United Kingdom},
	abstract = {We investigate the transformative potential of large language models (LLMs) in the legal and regulatory compliance domain by developing advanced generative AI solutions, including a horizon scanning tool, an obligations generation tool, and an LLM-based expert system. Our approach combines the LangChain framework, OpenAI's GPT-4, text embeddings, and prompt engineering techniques to effectively reduce hallucinations and generate reliable and accurate domain-specific outputs. A human-in-the-loop control mechanism is used as a final backstop to ensure accuracy and mitigate risk. Our findings emphasise the role of LLMs as foundation engines in specialist tools and lay the groundwork for building the next generation of legal and compliance applications. Future research will focus on extending support across multiple jurisdictions and languages, refining prompts and text embedding datasets for enhanced legal reasoning capabilities, and developing autonomous AI agents and robust LLM-based expert systems. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {AutoGPT; compliance; expert systems; GPT-4; GRC; LangChain; large language models; legal generative AI; legal text embeddings; prompt engineering; regulation},
	keywords = {Alignment; Computational linguistics; Embeddings; Expert systems; AutoGPT; Compliance; Embeddings; GPT-4; GRC; Langchain; Language model; Large language model; Legal generative AI; Legal text embedding; Legal texts; Prompt engineering; Regulation; Regulatory compliance},
	correspondence_address = {D. Hunter; Gracenote.ai, Melbourne, Australia; email: dan.hunter@kcl.ac.uk},
	editor = {Conrad J.G. and Linna D.W. and Baron J.R. and Henseler H. and Bhattacharya P. and Nielsen A. and Vinjumur J. and Pickens J. and Jones A.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xia20231482,
	author = {Xia, Chunqiu Steven and Wei, Yuxiang and Zhang, Lingming},
	title = {Automated Program Repair in the Era of Large Pre-trained Language Models},
	year = {2023},
	journal = {Proceedings - International Conference on Software Engineering},
	pages = {1482 – 1494},
	doi = {10.1109/ICSE48619.2023.00129},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167699778&doi=10.1109%2fICSE48619.2023.00129&partnerID=40&md5=3a941ab8f41127a60a9c18fbd0d93bee},
	affiliations = {University of Illinois, Urbana-Champaign, United States},
	abstract = {Automated Program Repair (APR) aims to help developers automatically patch software bugs. However, current state-of-the-art traditional and learning-based APR techniques face the problem of limited patch variety, failing to fix complicated bugs. This is mainly due to the reliance on bug-fixing datasets to craft fix templates (traditional) or directly predict potential patches (learning-based). Large Pre-Trained Language Models (LLMs), trained using billions of text/code tokens, can potentially help avoid this issue. Very recently, researchers have directly leveraged LLMs for APR without relying on any bug-fixing datasets. Meanwhile, such existing work either failed to include state-of-the-art LLMs or was not evaluated on realistic datasets. Thus, the true power of modern LLMs on the important APR problem is yet to be revealed. In this work, we perform the first extensive study on directly applying LLMs for APR. We select 9 recent state-of-the-art LLMs, including both generative and infilling models, ranging from 125M to 20B in size. We designed 3 different repair settings to evaluate the different ways we can use LLMs to generate patches: 1) generate the entire patch function, 2) fill in a chunk of code given the prefix and suffix 3) output a single line fix. We apply the LLMs under these repair settings on 5 datasets across 3 different languages and compare different LLMs in the number of bugs fixed, generation speed and compilation rate. We also compare the LLMs against recent state-of-the-art APR tools. Our study demonstrates that directly applying state-of-the-art LLMs can already substantially outperform all existing APR techniques on all our datasets. Among the studied LLMs, the scaling effect exists for APR where larger models tend to achieve better performance. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the LLMs consider correct patches to be more natural than other ones, and can even be leveraged for effective patch ranking or patch correctness checking. Lastly, we show that LLM-based APR can be further substantially boosted via: 1) increasing the sample size, and 2) incorporating fix template information. © 2023 IEEE.},
	author_keywords = {Automated Program Repair; Machine Learning},
	keywords = {Automation; Codes (symbols); Computational linguistics; Machine learning; Program debugging; 'current; Automated program repair; Bug-fixing; Infilling; Language model; Machine-learning; Recent state; Repair techniques; Software bug; State of the art; Repair},
	publisher = {IEEE Computer Society},
	issn = {02705257},
	isbn = {978-166545701-9},
	coden = {PCSED},
	language = {English},
	abbrev_source_title = {Proc Int Conf Software Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Lu20231937,
	author = {Lu, Albert and Zhang, Hongxin and Zhang, Yanzhe and Wang, Xuezhi and Yang, Diyi},
	title = {Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints},
	year = {2023},
	journal = {EACL 2023 - 17th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2023},
	pages = {1937 – 1963},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159859566&partnerID=40&md5=c5324e03193a1321e9183f491a51d307},
	affiliations = {Georgia Institute of Technology, United States; Shanghai Jiao Tong University, China; Google, United States; Stanford University, United States},
	abstract = {The limits of open-ended generative models are unclear, yet increasingly important. What causes them to succeed and what causes them to fail? In this paper, we take a prompt-centric approach to analyzing and bounding the abilities of open-ended generative models. We present a generic methodology of analysis with two challenging prompt constraint types: structural and stylistic. These constraint types are categorized into a set of well-defined constraints that are analyzable by a single prompt. We then systematically create a diverse set of simple, natural, and useful prompts to robustly analyze each individual constraint. Using the GPT-3 text-davinci-002 model as a case study, we generate outputs from our collection of prompts and analyze the model’s generative failures. We also show the generalizability of our proposed method on other large models like BLOOM and OPT. Our results and our in-context mitigation strategies reveal open challenges for future research. We have publicly released our code at https://github.com/SALT-NLP/Bound-Cap-LLM. © 2023 Association for Computational Linguistics.},
	keywords = {Case-studies; Constraint types; Davinci; Generative model; In contexts; Language model; Large models; Open text; Simple++; Text generations},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-195942947-0},
	language = {English},
	abbrev_source_title = {EACL - Conf. Eur. Chapter Assoc. Comput. Linguist., Find. EACL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Rahimzadeh202317,
	author = {Rahimzadeh, Vasiliki and Kostick-Quenet, Kristin and Blumenthal Barby, Jennifer and McGuire, Amy L.},
	title = {Ethics Education for Healthcare Professionals in the Era of ChatGPT and Other Large Language Models: Do We Still Need It?},
	year = {2023},
	journal = {American Journal of Bioethics},
	volume = {23},
	number = {10},
	pages = {17 – 27},
	doi = {10.1080/15265161.2023.2233358},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165563705&doi=10.1080%2f15265161.2023.2233358&partnerID=40&md5=b489674c154162cd0e69ad6922884ae5},
	affiliations = {Baylor College of Medicine, United States},
	abstract = {In this paper, we contend with whether we still need traditional ethics education as part of healthcare professional training given the abilities of chatGPT (generative pre-trained transformer) and other large language models (LLM). We reflect on common programmatic goals to assess the current strengths and limitations of LLMs in helping to build ethics competencies among future clinicians. Through an actual case analysis, we highlight areas in which chatGPT and other LLMs are conducive to common bioethics education goals. We also comment on where such technologies remain an imperfect substitute for human-led ethics teaching and learning. Finally, we conclude that the relative strengths of chatGPT warrant its consideration as a teaching and learning tool in ethics education in ways that account for current limitations and build in flexibility as the technology evolves. © 2023 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	author_keywords = {bioethics; chatGPT; healthcare professionals; medical education},
	keywords = {article; bioethics; case study; education; ethics; health care personnel; human; human experiment; language; learning; medical education},
	correspondence_address = {V. Rahimzadeh; Baylor College of Medicine, Houston, United States; email: Vasiliki.Rahimzadeh@bcm.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {15265161},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Torrielli2023546,
	author = {Torrielli, Federico and Rapp, Amon and Di Caro, Luigi},
	title = {How Shall a Machine Call a Thing?},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13913 LNCS},
	pages = {546 – 557},
	doi = {10.1007/978-3-031-35320-8_41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164729719&doi=10.1007%2f978-3-031-35320-8_41&partnerID=40&md5=9effe034e5578a25dbb298452859569c},
	affiliations = {Department of Computer Science, University of Torino, Turin, Italy},
	abstract = {This paper aims to investigate the feasibility of utilising Large Language Models (LLMs) and Latent Diffusion Models (LDMs) for automatically categorising word basicness and concreteness, i.e. two well-known aspects of language having significant relevance on tasks such as text simplification. To achieve this, we propose two distinct approaches: i) a generative Transformer-based LLM, and ii) a image+text multi-modal pipeline, referred to as stableKnowledge, which utilises a LDM to map terms to the image level. The evaluation results indicate that while the LLM approach is particularly well-suited for recognising word basicness, stableKnowledge outperforms the former when the task shifts to measuring concreteness. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Language Basicness; Language Concreteness; Large Language Models; Latent Diffusion Models; Text Simplification},
	keywords = {Concretes; Diffusion; Petroleum reservoir evaluation; Diffusion model; Evaluation results; Image texts; Language basicness; Language concreteness; Language model; Large language model; Latent diffusion model; Multi-modal; Text simplification; Computational linguistics},
	correspondence_address = {F. Torrielli; Department of Computer Science, University of Torino, Turin, Italy; email: federico.torrielli@unito.it},
	editor = {Métais E. and Meziane F. and Manning W. and Reiff-Marganiec S. and Sugumaran V.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303135319-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2023,
	author = {Liu, Dupeng and Sun, Ning},
	title = {Prospects of artificial intelligence in the development of sustainable separation processes},
	year = {2023},
	journal = {Frontiers in Sustainability},
	volume = {4},
	doi = {10.3389/frsus.2023.1210209},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166767661&doi=10.3389%2ffrsus.2023.1210209&partnerID=40&md5=3a4175ef4b48ea718108529501246af9},
	affiliations = {Advanced Biofuels and Bioproducts Process Development Unit, Lawrence Berkeley National Laboratory, Emeryville, CA, United States; Biological Systems and Engineering Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States},
	abstract = {Addressing the urgent need for more energy-efficient separation technologies is paramount in reducing energy consumption and lessening environmental impact as we march toward a carbon-neutral society. The rapid progression of AI and its promising applications in separation science presents new, fascinating possibilities. For instance, AI algorithms can forecast the properties of prospective new materials, speeding up the process of sorbent material innovation. With the ability to analyze vast datasets related to processes, machine learning driven by data can enhance operations to reduce energy wastage and improve error detection. The recent rise of Generative Pretrained Transformer models (GPT) has motivated researchers to construct specialized large-scale language models (LLM) based on a comprehensive scientific corpus of papers, reference materials, and knowledge bases. These models are useful tools for facilitating the rapid selection of suitable separation techniques. In this article, we present an exploration of AI's role in promoting sustainable separation processes, covering a concise history of its implementation, potential advantages, inherent limitations, and a vision for its future growth. Copyright © 2023 Liu and Sun.},
	author_keywords = {adsorption technique; artificial intelligence (AI); extraction technique; membrane technique; separation process; separation science and technology},
	correspondence_address = {N. Sun; Advanced Biofuels and Bioproducts Process Development Unit, Lawrence Berkeley National Laboratory, Emeryville, United States; email: nsun@lbl.gov},
	publisher = {Frontiers Media SA},
	issn = {26734524},
	language = {English},
	abbrev_source_title = {Front. Sustain.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Au Yeung2023,
	author = {Au Yeung, Joshua and Kraljevic, Zeljko and Luintel, Akish and Balston, Alfred and Idowu, Esther and Dobson, Richard J. and Teo, James T.},
	title = {AI chatbots not yet ready for clinical use},
	year = {2023},
	journal = {Frontiers in Digital Health},
	volume = {5},
	doi = {10.3389/fdgth.2023.1161098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153731776&doi=10.3389%2ffdgth.2023.1161098&partnerID=40&md5=be2a73712723e004798155795ba2a071},
	affiliations = {Department of Neuroscience, Kings College Hospital, London, United Kingdom; Guys & St Thomas Hospital, London, United Kingdom; Department of Biostatistics, Kings College London, London, United Kingdom; NIHR Biomedical Research Centre, South London and Maudsley NHS Foundation Trust and King's College London, London, United Kingdom},
	abstract = {As large language models (LLMs) expand and become more advanced, so do the natural language processing capabilities of conversational AI, or “chatbots”. OpenAI's recent release, ChatGPT, uses a transformer-based model to enable human-like text generation and question-answering on general domain knowledge, while a healthcare-specific Large Language Model (LLM) such as GatorTron has focused on the real-world healthcare domain knowledge. As LLMs advance to achieve near human-level performances on medical question and answering benchmarks, it is probable that Conversational AI will soon be developed for use in healthcare. In this article we discuss the potential and compare the performance of two different approaches to generative pretrained transformers—ChatGPT, the most widely used general conversational LLM, and Foresight, a GPT (generative pretrained transformer) based model focused on modelling patients and disorders. The comparison is conducted on the task of forecasting relevant diagnoses based on clinical vignettes. We also discuss important considerations and limitations of transformer-based chatbots for clinical use. 2023 Au Yeung, Kraljevic, Luintel, Balston, Idowu, Dobson and Teo.},
	author_keywords = {AI safety; chatbot; digital health; large language models; natural language processing (computer science); transformer},
	keywords = {accuracy; Article; artificial intelligence; forecasting; generative pretrained transformer; hallucination; human; information processing; large language model; natural language processing; patient safety; practice guideline; risk factor; uncertainty},
	correspondence_address = {J. Au Yeung; Department of Neuroscience, Kings College Hospital, London, United Kingdom; email: j.auyeung@nhs.net},
	publisher = {Frontiers Media S.A.},
	issn = {2673253X},
	language = {English},
	abbrev_source_title = {Front. Digit. Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 29; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Nye202378,
	author = {Nye, Benjamin D. and Mee, Dillon and Core, Mark G.},
	title = {Generative Large Language Models for Dialog-Based Tutoring: An Early Consideration of Opportunities and Concerns},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3487},
	pages = {78 – 88},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166948084&partnerID=40&md5=44ec3f8996709144c99b3d88c186f148},
	affiliations = {University of Southern California, Institute for Creative Technologies, Playa Vista, 90094, CA, United States},
	abstract = {After many years of relatively limited capabilities for generative language models, recent large language models (LLM's) have demonstrated qualitatively better capabilities for understanding, synthesis, and inference on text. Due to the prominence of ChatGPT's chat system, both the media and many educational developers have suggested using generative AI to directly tutor students. However, despite surface-level similarity between ChatGPT interactions and tutoring dialogs, generative AI has other strengths which may be substantially more relevant for intelligent tutoring (e.g., detecting misconceptions, improved language translation, content generation) and weaknesses that make it problematic for on-the-fly tutoring (e.g., hallucinations, lack of pedagogical training data). In this paper, we discuss how we are approaching generative LLM's for tutoring dialogs, for problems such as multiconcept short answer grading and semi-supervised interactive content generation. This work shows interesting opportunities for prompt engineering approaches for short-answer classification, despite sometimes quirky behavior. The time savings for high-quality content generation for tutoring is not yet clear and further research is needed. The paper concludes with a consideration of longer-term equity and access in a world where essential capabilities require low-latency real-time connections to large, pay-peruse models. Risks and mitigating technologies for this kind of “AI digital divide” are discussed, including optimized/edge-computing LLM's and using generative AI models as simulated students to train specialized tutoring models. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Content Generation; Conversational Tutoring; Generative Models; Intelligent Tutoring Systems; Large Language Models; Short Answer Grading},
	keywords = {Computational linguistics; Computer aided instruction; Education computing; Intelligent systems; Students; Content generation; Conversational tutoring; Generative model; Intelligent tutoring; Intelligent tutoring system; Language model; Large language model; Short answer grading; Tutoring dialogues; Tutoring system; Grading},
	correspondence_address = {B.D. Nye; University of Southern California, Institute for Creative Technologies, Playa Vista, 90094, United States; email: nye@ict.usc.edu},
	editor = {Moore S. and Stamper J. and Tong R. and Cao C. and Liu Z. and Hu X. and Lu Y. and Liang J. and Khosravi H. and Denny P. and Singh A. and Brooks C.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Kuzlu2023,
	author = {Kuzlu, Murat and Xiao, Zhenxin and Sarp, Salih and Catak, Ferhat Ozgur and Gurler, Necip and Guler, Ozgur},
	title = {The Rise of Generative Artificial Intelligence in Healthcare},
	year = {2023},
	journal = {12th Mediterranean Conference on Embedded Computing, MECO 2023},
	doi = {10.1109/MECO58584.2023.10155107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164906095&doi=10.1109%2fMECO58584.2023.10155107&partnerID=40&md5=4c2206e66d51bcacb55bf8fd8bec9d26},
	affiliations = {Old Dominion University, Electrical Engineering Technology, Norfolk, VA, United States; The College of William and Mary, Computational Operations Research, Williamsburg, VA, United States; Virginia Commonwealth University, Electrical and Computer Engineering, Richmond, VA, United States; University of Stavanger, Department of Electrical Engineering and Computer Science, Rogaland, Norway; EKare, Inc., Fairfax, VA, United States},
	abstract = {Generative Artificial Intelligence (GAI) is transforming various fields, including finance, education, marketing, and healthcare. Especially in healthcare, GAI has the potential to revolutionize various aspects, such as medical imaging, drug development, patient care, and treatment planning. Key stakeholders who stand to benefit from these advancements include hospitals, clinics, pharmaceutical companies, medical device manufacturers, and research institutions. However, the implementation of GAI in healthcare presents several challenges, such as ensuring data privacy and security, addressing ethical considerations, maintaining quality and accuracy, adhering to regulatory compliance, and integrating with existing systems. This paper examines the current state of GAI in healthcare, discusses its potential benefits and challenges, and highlights future directions that must be addressed to fully harness the power of GAI in improving patient outcomes and healthcare systems.  © 2023 IEEE.},
	author_keywords = {AI in Healthcare; Generative AI (GAI); Generative Pre-trained Transformer (GPT); Large Language Model (LLM)},
	keywords = {Data privacy; Medical imaging; Patient treatment; Regulatory compliance; AI in healthcare; Care planning; Drug development; Generative AI; Generative pre-trained transformer; Language model; Large language model; Patient care; Pharmaceutical company; Treatment planning; Artificial intelligence},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {979-835032291-0},
	language = {English},
	abbrev_source_title = {Mediterranean Conf. Embed. Comput., MECO},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Helfesrieder202038,
	author = {Helfesrieder, Nico and Lechler, Armin and Verl, Alexander},
	title = {Method for generating manufacturable, topology-optimized parts for laminated layer manufacturing},
	year = {2020},
	journal = {Procedia CIRP},
	volume = {93},
	pages = {38 – 43},
	doi = {10.1016/j.procir.2020.04.048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092429754&doi=10.1016%2fj.procir.2020.04.048&partnerID=40&md5=fc4a8e600ae3c6e2d8a03780ffeb8b74},
	affiliations = {University of Stuttgart, Institute for Control Engineering of Machine Tools and Manufacturing Units, Seidenstraße 36, Stuttgart, 70174, Germany},
	abstract = {The great flexibility provided by generative manufacturing offers immense potential for the structural component optimization. However, this freedom needs to be utilized by appropriate CAx tools. In this paper, we present a novel slicing method, enabling the automatic generation of topology-optimized Laminated Layer Manufacturing (LLM) parts. With this method a part of arbitrary shape can be automatically sliced and equipped with a uniform virtual grid that is suitable for manufacturing. The optimal density distribution is then mapped onto the individual slices and locally approximated through the introduction of variably shaped cavities. By using 3D modeling techniques all LLM sheets are modeled parametrically and assembled automatically. To verify the functionality of the presented method, it is applied to two practical parts and compared with a conventional topology optimization method. © 2020 The Authors.},
	author_keywords = {Hybrid manufacturing; Laminated layer manufacturing; Sheet lamination; Slicing; Topology optimization},
	keywords = {3D modeling; Laminating; Structural optimization; Arbitrary shape; Automatic Generation; Conventional topologies; Laminated layer; Optimal densities; Slicing methods; Structural component; Virtual grids; Topology},
	correspondence_address = {N. Helfesrieder; University of Stuttgart, Institute for Control Engineering of Machine Tools and Manufacturing Units, Stuttgart, Seidenstraße 36, 70174, Germany; email: nico.helfesrieder@isw.uni-stuttgart.de},
	editor = {Gao R.X. and Ehmann K.},
	publisher = {Elsevier B.V.},
	issn = {22128271},
	language = {English},
	abbrev_source_title = {Procedia CIRP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Sridhar2023139,
	author = {Sridhar, Pragnya and Doyle, Aidan and Agarwal, Arav and Bogart, Christopher and Savelka, Jaromir and Sakr, Majd},
	title = {Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3487},
	pages = {139 – 150},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166922012&partnerID=40&md5=f1a3b3aa6d8a91309667777ccb3aa97e},
	affiliations = {Language Technology Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {We evaluated the capability of a generative pre-trained transformer (GPT-4) to automatically generate high-quality learning objectives (LOs) in the context of a practically oriented university course on Artificial Intelligence. Discussions of opportunities (e.g., content generation, explanation) and risks (e.g., cheating) of this emerging technology in education have intensified, but to date there has not been a study of the models' capabilities in supporting the course design and authoring of LOs. LOs articulate the knowledge and skills learners are intended to acquire by engaging with a course. To be effective, LOs must focus on what students are intended to achieve, focus on specific cognitive processes, and be measurable. Thus, authoring high-quality LOs is a challenging and time consuming (i.e., expensive) effort. We evaluated 127 LOs that were automatically generated based on a carefully crafted prompt (detailed guidelines on high-quality LOs authoring) submitted to GPT-4 for conceptual modules and projects of an AI Practitioner course. We analyzed the generated LOs if they follow certain best practices such as beginning with action verbs from Bloom's taxonomy in regards to the level of sophistication intended. Our analysis showed that the generated LOs are sensible, properly expressed (e.g., starting with an action verb), and that they largely operate at the appropriate level of Bloom's taxonomy, respecting the different nature of the conceptual modules (lower levels) and projects (higher levels). Our results can be leveraged by instructors and curricular designers wishing to take advantage of the state-of-the-art generative models to support their curricular and course design efforts. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Automated Content Generation; Automatic Generation; Course Design Automation; Curricular Development; GPT-4; Large Language Models; Learning Objectives; LLMs},
	keywords = {Artificial intelligence; Blooms (metal); Computer aided design; Curricula; Education computing; Learning systems; Taxonomies; Automated content generation; Automatic Generation; Course design; Course design automation; Curricular development; Design automations; GPT-4; Language model; Large language model; Learning objectives; LLM; Quality control},
	correspondence_address = {P. Sridhar; Language Technology Institute, Carnegie Mellon University, Pittsburgh, United States; email: pragnyas@andrew.cmu.edu; A. Doyle; Language Technology Institute, Carnegie Mellon University, Pittsburgh, United States; email: adoyle@andrew.cmu.edu},
	editor = {Moore S. and Stamper J. and Tong R. and Cao C. and Liu Z. and Hu X. and Lu Y. and Liang J. and Khosravi H. and Denny P. and Singh A. and Brooks C.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Sheng202331094,
	author = {Sheng, Ying and Zheng, Lianmin and Yuan, Binhang and Li, Zhuohan and Ryabinin, Max and Chen, Beidi and Liang, Percy and Ré, Christopher and Stoica, Ion and Zhang, Ce},
	title = {FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU},
	year = {2023},
	journal = {Proceedings of Machine Learning Research},
	volume = {202},
	pages = {31094 – 31116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161962667&partnerID=40&md5=321ce728a16dc6b14b678f69fe988239},
	affiliations = {Stanford University, United States; UC Berkeley, United States; ETH Zurich, Switzerland; Yandex; HSE University, Russian Federation; Meta, United States; Carnegie Mellon University, United States},
	abstract = {The high computational and memory requirements of large language model (LLM) inference make it feasible only with multiple high-end accelerators. Motivated by the emerging demand for latency-insensitive tasks with batched processing, this paper initiates the study of high-throughput LLM inference using limited resources, such as a single commodity GPU. We present FlexGen, a high-throughput generation engine for running LLMs with limited GPU memory. FlexGen can be flexibly configured under various hardware resource constraints by aggregating memory and computation from the GPU, CPU, and disk. By solving a linear programming problem, it searches for efficient patterns to store and access tensors. FlexGen further compresses the weights and the attention cache to 4 bits with negligible accuracy loss. These techniques enable FlexGen to have a larger space of batch size choices and thus significantly increase maximum throughput. As a result, when running OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput compared to state-of-the-art offloading systems, reaching a generation throughput of 1 token/s for the first time with an effective batch size of 144. On the HELM benchmark, FlexGen can benchmark a 30B model with a 16GB GPU on 7 representative sub-scenarios in 21 hours. The code is available at https://github.com/FMInference/FlexGen. © 2023 Proceedings of Machine Learning Research. All rights reserved.},
	keywords = {Computational linguistics; Computer hardware; Linear programming; Machine learning; Batch sizes; Computational requirements; Emerging demands; Hardware resources; High-throughput; Language model; Linear programming problem; Memory requirements; Model inference; Resource Constraint; Graphics processing unit},
	correspondence_address = {Y. Sheng; Stanford University, United States; email: ying1123@stanford.edu},
	editor = {Krause A. and Brunskill E. and Cho K. and Engelhardt B. and Sabato S. and Scarlett J.},
	publisher = {ML Research Press},
	issn = {26403498},
	language = {English},
	abbrev_source_title = {Proc. Mach. Learn. Res.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rao2023,
	author = {Rao, Arya and Pang, Michael and Kim, John and Kamineni, Meghana and Lie, Winston and Prasad, Anoop K. and Landman, Adam and Dreyer, Keith and Succi, Marc D.},
	title = {Assessing the Utility of ChatGPT Throughout the Entire Clinical Workflow: Development and Usability Study},
	year = {2023},
	journal = {Journal of Medical Internet Research},
	volume = {25},
	doi = {10.2196/48659},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168507069&doi=10.2196%2f48659&partnerID=40&md5=238518f2a9eff0ee5e21f62d23c3226d},
	affiliations = {Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations Research Center (MESH IO), Massachusetts General Hospital, Boston, MA, United States; Harvard Medical School, Boston, MA, United States; Department of Radiology, Massachusetts General Hospital, Boston, MA, United States; Department of Radiology, Brigham and Women's Hospital, Boston, MA, United States; Data Science Office, Mass General Brigham, Boston, MA, United States; Mass General Brigham Innovation, Mass General Brigham, Boston, MA, United States; Department of Radiology, Massachusetts General Hospital, 55 Fruit Street, Boston, 02114, MA, United States},
	abstract = {Background: Large language model (LLM)–based artificial intelligence chatbots direct the power of large training data sets toward successive, related tasks as opposed to single-ask tasks, for which artificial intelligence already achieves impressive performance. The capacity of LLMs to assist in the full scope of iterative clinical reasoning via successive prompting, in effect acting as artificial physicians, has not yet been evaluated. Objective: This study aimed to evaluate ChatGPT’s capacity for ongoing clinical decision support via its performance on standardized clinical vignettes. Methods: We inputted all 36 published clinical vignettes from the Merck Sharpe & Dohme (MSD) Clinical Manual into ChatGPT and compared its accuracy on differential diagnoses, diagnostic testing, final diagnosis, and management based on patient age, gender, and case acuity. Accuracy was measured by the proportion of correct responses to the questions posed within the clinical vignettes tested, as calculated by human scorers. We further conducted linear regression to assess the contributing factors toward ChatGPT’s performance on clinical tasks. Results: ChatGPT achieved an overall accuracy of 71.7% (95% CI 69.3%-74.1%) across all 36 clinical vignettes. The LLM demonstrated the highest performance in making a final diagnosis with an accuracy of 76.9% (95% CI 67.8%-86.1%) and the lowest performance in generating an initial differential diagnosis with an accuracy of 60.3% (95% CI 54.2%-66.6%). Compared to answering questions about general medical knowledge, ChatGPT demonstrated inferior performance on differential diagnosis (β=–15.8%; P<.001) and clinical management (β=–7.4%; P=.02) question types. Conclusions: ChatGPT achieves impressive accuracy in clinical decision-making, with increasing strength as it gains more clinical information at its disposal. In particular, ChatGPT demonstrates the greatest accuracy in tasks of final diagnosis as compared to initial diagnosis. Limitations include possible model hallucinations and the unclear composition of ChatGPT’s training data set. ©Arya Rao, Michael Pang, John Kim, Meghana Kamineni, Winston Lie, Anoop K Prasad, Adam Landman, Keith Dreyer, Marc D Succi.},
	author_keywords = {accuracy; AI; artificial intelligence; chatbot; ChatGPT; clinical decision support; clinical vignettes; decision-making; development; Generative Pre-trained Transformer; GPT; large language models; LLMs; usability; utility},
	keywords = {Acceptance and Commitment Therapy; Artificial Intelligence; Clinical Decision-Making; Humans; Organizations; Workflow; adult; age; Article; ChatGPT; clinical decision support system; clinical feature; clinical reasoning; controlled study; diagnostic accuracy; diagnostic test accuracy study; differential diagnosis; female; gender; human; male; pheochromocytoma; professional knowledge; testis cancer; usability; utility value; vignette; workflow; acceptance and commitment therapy; artificial intelligence; clinical decision making; organization; workflow},
	correspondence_address = {M.D. Succi; Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations Research Center (MESH IO), Massachusetts General Hospital, Boston, United States; email: msucci@partners.org},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {37606976},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access}
}

@CONFERENCE{Leiker20233,
	author = {Leiker, Daniel and Finnigan, Sara and Gyllen, Ashley Ricker and Cukurova, Mutlu},
	title = {Prototyping the use of Large Language Models (LLMs) for adult learning content creation at scale},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3487},
	pages = {3 – 7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166949623&partnerID=40&md5=4a3457c4be3b74ed46d185dee772bb6b},
	affiliations = {UCL Knowledge Lab, London, WC1N 3QS, United Kingdom; EIT InnoEnergy, Eindhoven, Netherlands; Metropolitan State University, Denver, 80204, CO, United States},
	abstract = {As Large Language Models (LLMs) and other forms of Generative AI permeate various aspects of our lives, their application for learning and education has provided opportunities and challenges. This paper presents an investigation into the use of LLMs in asynchronous course creation, particularly within the context of adult learning, training and upskilling. We developed a course prototype leveraging an LLM, implementing a robust human-in-the-loop process to ensure the accuracy and clarity of the generated content. Our research questions focus on the feasibility of LLMs to produce high-quality adult learning content with reduced human involvement. Initial findings indicate that taking this approach can indeed facilitate faster content creation without compromising on accuracy or clarity, marking a promising advancement in the field of Generative AI for education. Despite some limitations, the study underscores the potential of LLMs to transform the landscape of learning and education, necessitating further research and nuanced discussions about their strategic and ethical use in learning design. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {AI-Generated Learning Content; Generative AI in Education; Large Language Models},
	keywords = {Computational linguistics; Adult learning; AI-generated learning content; Generative AI in education; Human-in-the-loop; Language model; Large language model; Learning content creation; Learning contents; Loop process; Research questions; Curricula},
	editor = {Moore S. and Stamper J. and Tong R. and Cao C. and Liu Z. and Hu X. and Lu Y. and Liang J. and Khosravi H. and Denny P. and Singh A. and Brooks C.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Bilgram202318,
	author = {Bilgram, Volker and Laarmann, Felix},
	title = {Accelerating Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation Methods},
	year = {2023},
	journal = {IEEE Engineering Management Review},
	volume = {51},
	number = {2},
	pages = {18 – 25},
	doi = {10.1109/EMR.2023.3272799},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159842114&doi=10.1109%2fEMR.2023.3272799&partnerID=40&md5=9cbb442269167eb1ed7e3822fa68f210},
	affiliations = {Nuremberg Institute of Technology, Nürnberg, 90489, Germany; Hyve, München, 80799, Germany},
	abstract = {Easy-to-use generative artificial intelligence (AI) is democratizing the use of AI in innovation management and may significantly change the way how we work and innovate. In this article, we show how large language models (LLMs), such as generative pretrained transformer (GPT), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. Drawing on six months of experimenting with LLMs in internal and client innovation projects, we share first-hand experiences and concrete examples of AI-assisted approaches. The article highlights a large variety of use cases for generative AI ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role LLMs may play in future knowledge management systems. Moreover, we argue that generative AI may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. Our experiences also provide insights into how human innovation teams purposively and effectively interact with AIs and integrate them into their workflows.  © 1973-2011 IEEE.},
	author_keywords = {AI-augmented innovation management; artificial intelligence (AI); digital prototyping; generative AI; idea generation; innovation; large language model (LLM); need identification; no-code prototyping; UX/UI},
	keywords = {Computational linguistics; Job analysis; Knowledge management; Software prototyping; Artificial intelligence-augmented innovation management; Chatbots; Code; Digital prototyping; Generative artificial intelligence; Idea generation; Innovation; Innovation management; Language model; Large language model; Need identification; No-code prototyping; Prototype; Task analysis; Technological innovation; UX/UI; Knowledge based systems},
	correspondence_address = {V. Bilgram; Nuremberg Institute of Technology, Nürnberg, 90489, Germany; email: volker.bilgram@th-nuernberg.de},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {03608581},
	coden = {IEMRA},
	language = {English},
	abbrev_source_title = {IEEE Eng Manage Rev},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Dergaa2023615,
	author = {Dergaa, Ismail and Chamari, Karim and Zmijewski, Piotr and Saad, Helmi Ben},
	title = {From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing},
	year = {2023},
	journal = {Biology of Sport},
	volume = {40},
	number = {2},
	pages = {615 – 622},
	doi = {10.5114/BIOLSPORT.2023.125623},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153204653&doi=10.5114%2fBIOLSPORT.2023.125623&partnerID=40&md5=72f951f36288364372691a144dec3114},
	affiliations = {Primary Health Care Corporation (PHCC), Doha, Qatar; Research Unit Physical Activity, Sport, and Health, UR18JS01, National Observatory of Sport, Tunis, 1003, Tunisia; High Institute of Sport and Physical Education, University of Sfax, Sfax, Tunisia; Aspetar, Orthopaedic and Sports Medicine Hospital, FIFA Medical Centre of Excellence, Doha, Qatar; Jozef Pilsudski University of Physical Education in Warsaw, Warsaw, Poland; University of Sousse, Farhat HACHED hospital, Service of Physiology and Functional Explorations, Sousse, Tunisia; University of Sousse, Farhat HACHED Hospital, Research Laboratory LR12SP09 «Heart Failure», Sousse, Tunisia; University of Sousse, Faculty of Medicine of Sousse, Laboratory of Physiology, Sousse, Tunisia},
	abstract = {Natural language processing (NLP) has been studied in computing for decades. Recent technological advancements have led to the development of sophisticated artificial intelligence (AI) models, such as Chat Generative Pre-trained Transformer (ChatGPT). These models can perform a range of language tasks and generate human-like responses, which offers exciting prospects for academic efficiency. This manuscript aims at (i) exploring the potential benefits and threats of ChatGPT and other NLP technologies in academic writing and research publications; (ii) highlights the ethical considerations involved in using these tools, and (iii) consider the impact they may have on the authenticity and credibility of academic work. This study involved a literature review of relevant scholarly articles published in peer-reviewed journals indexed in Scopus as quartile 1. The search used keywords such as “ChatGPT,” “AI-generated text,” “academic writing,” and “natural language processing.” The analysis was carried out using a quasi-qualitative approach, which involved reading and critically evaluating the sources and identifying relevant data to support the research questions. The study found that ChatGPT and other NLP technologies have the potential to enhance academic writing and research efficiency. However, their use also raises concerns about the impact on the authenticity and credibility of academic work. The study highlights the need for comprehensive discussions on the potential use, threats, and limitations of these tools, emphasizing the importance of ethical and academic principles, with human intelligence and critical thinking at the forefront of the research process. This study highlights the need for comprehensive debates and ethical considerations involved in their use. The study also recommends that academics exercise caution when using these tools and ensure transparency in their use, emphasizing the importance of human intelligence and critical thinking in academic work. © 2023 Institute of Sport. All rights reserved.},
	author_keywords = {Artificial Intelligence; Chatbot; Deep Learning; Google Bard; Higher Education; LLaMA; LLM; Machine Learning; Natural Language Processing; NLM; NLP; Paperpal; Peer Review; QuillBot; Rayyan; Research; Sports Medicine},
	correspondence_address = {H.B. Saad; University of Sousse, Farhat HACHED Hospital, Research Laboratory LR12SP09 «Heart Failure», Sousse, Tunisia; email: helmi.bensaad@rns.tn},
	publisher = {Institute of Sport},
	issn = {0860021X},
	language = {English},
	abbrev_source_title = {Biol. Sport},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 71}
}