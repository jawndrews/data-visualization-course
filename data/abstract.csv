"doc_id","text"
1,"The governance of AI, and now generative AI, is becoming a significant issue of concern for intellectual property law and legal regulators across the world. This article addresses this from the perspective of how the law responds when it is perceived as an obstacle to technological development and progress. It demonstrates, through the example of ‘safe harbour’, the ease with which the legal rights of copyright holders were compromised for technological progress, the problems and public backlash this led to, and how this can be seen to be reflected in a more cautious approach being taken now by some legislators against further weakening the rights of copyright holders in the name of generative AI technology. As a case study of copyright law’s reaction to challenges posed by the internet and AI technology, it re-affirms the law’s role as a fundamental safeguard of basic rights and the often necessary requirement for it to provide creative and proactive ways to ensure society can enjoy the benefits of technological progress while protecting our normative and practical liberties."
2,"Generative Artificial Intelligence (AI) based on large language models such as ChatGPT, DALL·E 2, Midjourney, Stable Diffusion, JukeBox, and MusicLM can produce text, images, and music that are indistinguishable from human-authored works. The training data for these large language models consists predominantly of copyrighted works. This Article explores how generative AI fits within fair use rulings established in relation to previous generations of copy-reliant technology, including software reverse engineering, automated plagiarism detection systems, and the text-data mining at the heart of the landmark HathiTrust and Google Books cases. Although there is no machine learning exception to the principle of nonexpressive use, the largeness of likelihood models suggest that they are capable of memorizing and reconstituting works in the training data, something that is incompatible with nonexpressive use. At the moment, memorization is an edge case. For the most part, the link between the training data and the output of generative AI is attenuated by a process of decomposition, abstraction, and remix. Generally, pseudo-expression generated by large language models does not infringe copyright because these models ""learn"" latent features and associations within the training data; they do not memorize snippets of original expression from individual works. However, this Article identifies situations in the context of text-to-image models where memorization of the training data is more likely. The computer science literature suggests that memorization is more likely when models are trained on many duplicates of the same work, images are associated with unique text descriptions, and the ratio of the size of the model to the training data is relatively large. This Article shows how these problems are accentuated in the context of copyrightable characters and proposes a set of guidelines for ""Copyright Safety for Generative AI"" to reduce the risk of copyright infringement."
3,"The purpose of this study is to explore the existing problems associated with using generative AI in education and to propose a potential solution for addressing those issues through the design of pedagogical AI agents. The existing problems are examined from two different perspectives: those of teachers and students. The proposed solutions for designing pedagogical AI agents are systematically presented, including main concepts, design considerations, functions, procedures, and structure/templates. An example of how to apply the proposed solution in designing a pedagogical AI agent is provided, illustrating its application in teaching order words (or sequencing words). Finally, the paper concludes with a discussion of potential topics for further research."
4,"We are witnessing an accelerated technological evolution that has enabled the development of artificial intelligence in various fields, allowing it to gradually infiltrate the entire society. We intend to cover only a small subset of AI technologies in our paper, that of Generative Artificial Intelligence (GenAI). Our objectives are to shed light on the legal issues that GenAI can cause and to find solutions to them. We begin with a definition of GenAI in the much broader context of AI technologies. Answers to a few essential questions are to be found: 'How does GenAI work?', 'What could GenAI be used for?', 'What legal issues could arise from using a GenAI?'. To accomplish our goals, we first conduct a literature review to define artificial intelligence (AI) in general and GenAI in particular. Several lawsuits are chosen to illustrate the magnitude of the legal problems and to test the feasibility of possible solutions in both the national and EU legal systems. Then, we analyse GenAI's output, liability for its contents and for its use, altogether with examples of related contractual clauses."
5,"The article focuses on the impact of generative Artificial Intelligence (AI) particularly in image generation, and its implications for evaluation processes, highlighting the challenges and potential changes in assessing AI-generated content. Topics include the quality and detection of AI-generated material, the complexities of evaluating visual content, and the potential transformation of art assessments and job recruitment due to AI advancements."
6,"Generative models are frequently used for de novo design in drug discovery projects to propose new molecules. However, the question of whether or not the generated molecules can be synthesized is not systematically taken into account during generation, even though being able to synthesize the generated molecules is a fundamental requirement for such methods to be useful in practice. Methods have been developed to estimate molecule ""synthesizability"", but, so far, there is no consensus on whether or not a molecule is synthesizable. In this paper we introduce the Retro-Score (RScore), which computes a synthetic accessibility score of molecules by performing a full retrosynthetic analysis through our data-driven synthetic planning software Spaya, and its dedicated API: Spaya-API (https://spaya.ai). We start by comparing several synthetic accessibility scores to a binary ""chemist score"" as estimated by chemists on a bench of generated molecules, as a first experimental validation that the RScore is a reliable synthetic accessibility score. We then describe a pipeline to generate molecules that validate a list of targets while still being easy to synthesize. We further this idea by performing experiments comparing molecular generator outputs across a range of constraints and conditions. We show that the RScore can be learned by a Neural Network, which leads to a new score: RSPred. We demonstrate that using the RScore or RSPred as a constraint during molecular generation enables our molecular generators to produce more synthesizable solutions, with higher diversity. The open-source Python code containing all the scores and the experiments can be found on (https://github.com/iktos/generation-under-synthetic-constraint)."
7,"With the wide availability of large language models and generative AI, there are four primary paradigms for human-AI collaboration: human-only, AI-only (ChatGPT-4), augmented human (where a human makes the final decision with AI output as a reference), or augmented AI (where the AI makes the final decision with human output as a reference). In partnership with one of the world's leading consulting firms, we enlisted professional content creators and ChatGPT-4 to create advertising content for products and persuasive content for campaigns following the aforementioned paradigms. First, we find that, contrary to the expectations of some of the existing algorithm aversion literature on conventional predictive AI, the content generated by generative AI and augmented AI is perceived as of higher quality than that produced by human experts and augmented human experts. Second, revealing the source of content production reduces--but does not reverse--the perceived quality gap between human- and AI-generated content. This bias in evaluation is predominantly driven by human favoritism rather than AI aversion: Knowing that the same content is created by a human expert increases its (reported) perceived quality, but knowing that AI is involved in the creation process does not affect its perceived quality. Further analysis suggests this bias is not due to a 'quality prime' as knowing the content they are about to evaluate comes from competent creators (e.g., industry professionals and state-of-the-art AI) without knowing exactly that the creator of each piece of content does not increase participants' perceived quality."
8,"Besteht die Gefahr der Verstärkung der Bildungsungleichheit durch Studierende und Institutionen, die Zugang zu den Tools und die Kompetenzen zur Nutzung haben und denen, die nicht [5]? In Anbetracht der bemerkenswerten Fortschritte, die in den letzten Monaten zu beobachten sind, sowie derjenigen, die für dieses Jahr erwartet werden, wie die Verbindung von ChatGTP und Bing im Edge-Browser, kann man wohl behaupten, dass die Auswirkungen auf die Menschheit so bedeutend sein werden wie die Verdrängung der Pferde aus den Städten mit der Einführung des Automobils. Umso wichtiger erscheint die konsequente Durchführung evidenzbasierter Lehrforschung bei allen Integrationen von gKI in unseren Lehrbetrieb: In diesem Sinne möchten die Autoren des Editorials einladen, das Sommersemester zu nutzen um Erfahrungen mit der generativen KI in Lehre und Lernen an den Hochschulen zu beschäftigen, und diese Gedanken, Vorstudien und Versuche mitzubringen zu einem Bar-camp auf der kommenden Jahrestagung der Gesellschaft für Medizinische Ausbildung in Osnabrück [https://gma2023.de/] als Beitrag einzubringen. Drehen wir den Spieß einmal um, denn die KI wird sich im Monitor einbrennen, und dennoch werden die Hochschulen und mithin die Lehre weiter existieren: Ist die Vinylplatte verschwunden, obwohl es erst CD's und jetzt Streaming gibt?."
9,"This statement revises our earlier ""WAME Recommendations on ChatGPT and Chatbots in Relation to Scholarly Publications"" (January 20, 2023). The revision reflects the proliferation of chatbots and their expanding use in scholarly publishing over the last few months, as well as emerging concerns regarding lack of authenticity of content when using chatbots. These recommendations are intended to inform editors and help them develop policies for the use of chatbots in papers published in their journals. They aim to help authors and reviewers understand how best to attribute the use of chatbots in their work and to address the need for all journal editors to have access to manuscript screening tools. In this rapidly evolving field, we will continue to modify these recommendations as the software and its applications develop."
10,"Artificial intelligence (AI)-based molecular design methods, especially deep generative models for generating novel molecule structures, have gratified our imagination to explore unknown chemical space without relying on brute-force exploration. However, whether designed by AI or human experts, the molecules need to be accessibly synthesized and biologically evaluated, and the trial-and-error process remains a resources-intensive endeavor. Therefore, AI-based drug design methods face a major challenge of how to prioritize the molecular structures with potential for subsequent drug development. This study indicates that common filtering approaches based on traditional screening metrics fail to differentiate AI-designed molecules. To address this issue, we propose a novel molecular filtering method, MolFilterGAN, based on a progressively augmented generative adversarial network. Comparative analysis shows that MolFilterGAN outperforms conventional screening approaches based on drug-likeness or synthetic ability metrics. Retrospective analysis of AI-designed discoidin domain receptor 1 (DDR1) inhibitors shows that MolFilterGAN significantly increases the efficiency of molecular triaging. Further evaluation of MolFilterGAN on eight external ligand sets suggests that MolFilterGAN is useful in triaging or enriching bioactive compounds across a wide range of target types. These results highlighted the importance of MolFilterGAN in evaluating molecules integrally and further accelerating molecular discovery especially combined with advanced AI generative models."
11,"Aim Design Methods Results Conclusions Impact Reporting method Patient or public contribution This study explores the potential of a generative artificial intelligence tool (ChatGPT) as clinical support for nurses. Specifically, we aim to assess whether ChatGPT can demonstrate clinical decision‐making equivalent to that of expert nurses and novice nursing students. This will be evaluated by comparing ChatGPT responses to clinical scenarios to those of nurses on different levels of experience.This is a cross‐sectional study.Emergency room registered nurses (i.e. experts; n = 30) and nursing students (i.e. novices; n = 38) were recruited during March–April 2023. Clinical decision‐making was measured using three validated clinical scenarios involving an initial assessment and reevaluation. Clinical decision‐making aspects assessed were the accuracy of initial assessments, the appropriateness of recommended tests and resource use and the capacity to reevaluate decisions. Performance was also compared by timing response generations and word counts. Expert nurses and novice students completed online questionnaires (via Qualtrics), while ChatGPT responses were obtained from OpenAI.Concerning aspects of clinical decision‐making and compared to novices and experts: (1) ChatGPT exhibited indecisiveness in initial assessments; (2) ChatGPT tended to suggest unnecessary diagnostic tests; (3) When new information required re‐evaluation, ChatGPT responses demonstrated inaccurate understanding and inappropriate modifications. In terms of performance, the mean number of words utilized in ChatGPT answers was 27–41 times greater than that utilized by both experts and novices; and responses were provided approximately 4 times faster than those of novices and twice faster than expert nurses. ChatGPT responses maintained logical structure and clarity.A generative AI tool demonstrated indecisiveness and a tendency towards over‐triage compared to human clinicians.The study shows that it is important to approach the implementation of ChatGPT as a nurse's digital assistant with caution. More study is needed to optimize the model's training and algorithms to provide accurate healthcare support that aids clinical decision‐making.This study adhered to relevant EQUATOR guidelines for reporting observational studies.Patients were not directly involved in the conduct of this study."
12,"AbstractThe integration of Artificial Intelligence (AI) in higher education has the power to revolutionize the learning experience by fostering engagement, personalization, efficiency, and innovation. AI offers a wide range of exciting possibilities where AI-powered tools enable students to receive tailored feedback and guidance, enabling them to learn at their own pace and excel academically. This research aims to investigate the effects of generative AI techniques and applications on students’ cognitive achievement through student behavior. Data was collected through surveys in three Arab countries including Oman, Jordan and Yemen. 768 students from these Arab country’s universities were participated in completing surveys randomly. Structure Equation Modeling SEM-PLS was adopted to analysis data. Results reveal that generative AI techniques and applications have positive and significant effects on students’ cognitive achievement in Arab higher education institutions. Results also reveal that student behavior enhances the relationship among AI techniques, applications and cognitive achievement. These results highlight the crucial role of AI applications among students in higher education while the integration of this emerging technology is still at the first stage, students’ interaction with and utility of these applications show high satisfactory level of their impact on students’ behavior and cognitive achievement. This research contributes to literature of generative AI applications giving evidence from Arab region and filling the gap regarding usage of these applications in higher education."
13,"In the year since ChatGPT was released by OpenAI, librarians, instructors, and higher education administrators have grappled with generative artificial intelligence (AI) and its implications for teaching, learning, research, and writing. Drawn from informal conversations, professional observations, discussion groups, and professional development events, this article reports on the experience of learning about generative AI at one university. This article considers ways that educators may use AI tools and reasons to resist adopting generative AI tools, situating uses on a spectrum of acceptability."
14,"AbstractThis article presents an extensive Generative AI Technology Adoption Model intended to elucidate the complex process that entrepreneurs and other innovation ecosystem actors, for instance, libraries, go through for its adoption. The model suggests that the adoption process happens in three stages: <italic>Pre-Perception & Perception, Assessment, and Outcome</italic>. During the Pre-Perception & Perception Phase, entrepreneurs initiate their technology exploration by navigating social factors, domain experience, technological familiarity, system quality, training and support, interaction convenience, and anthropomorphism; with utilitarian value and hedonic values playing an important role. As they transition to the Assessment Stage, perceived usefulness, ease of use, and a novel addition, perceived enjoyment, shape their evaluations, leading to generations of emotions toward it, with utilitarian value overweighting hedonic values. The model finishes with the Outcome Stage, where emotions developed in the Assessment Stage become tangible intentions to switch (<italic>use technology or switch to human services</italic>). The adoption model highlights the adoption factors (<italic>also called latent variables)</italic> and their relationships grounded on researcher’s professional experiences and need to be further empirically validated. Entrepreneurial implications highlight the strategic insights of the model, providing a decision-making roadmap and highlighting the interaction between utilitarian and hedonistic values. Entrepreneurs can create well-informed technological integrations that are in line with business objectives by using the incremental decision-making process. The model’s focus on comparative evaluations gives entrepreneurs the ability to strategically map the usability of technology for the best possible commercial results. The Generative AI Technology Adoption Model offers a nuanced understanding of entrepreneurs’ technology adoption processes, which is also applicable to other actors in the innovation ecosystem."
15,"Generative AI systems designed to produce text do so by drawing on inferences made from training data, which may mean they reproduce factual errors or biases contained in that data. This process is illustrated by querying ChatGPT with questions from a history of mathematics quiz designed to highlight the common occurrence of mathematical results being misattributed. ChatGPT's performance on a set of decades-old common misconceptions is mixed, illustrating the potential for these systems to reproduce and reinforce historical inaccuracies and misconceptions."
16,"AbstractWith the rapid evolution of artificial intelligence (AI), this study aims to examine the interplay among the perceived usability, perceived enjoyment, perceived responsiveness, and intention to continue using ChatGPT. Structural equation modeling (SEM) was used to investigate our proposed model. We recruited 446 ChatGPT users through an online survey conducted on the Connect platform, powered by CloudResearch. Perceived usability (<italic>β</italic> = 0.254) and enjoyment (<italic>β</italic> = 0.438) significantly influence satisfaction with ChatGPT. However, perceived responsiveness is not significantly related to perceived attachment or satisfaction. Furthermore, we established that perceived attachment (<italic>β</italic> = 0.405) and satisfaction (<italic>β</italic> = 0.447) are pivotal in shaping users’ intentions to continue using ChatGPT, providing insights into human–AI interactions. The practical implications of our findings suggest that generative AI chatbots should be crafted with a focus on enjoyable, user-centered interfaces that foster long-term user satisfaction and engagement. AI developers should design AI conversation flows and chatbot personas to optimize the user experience."
17,"The article examines how generative artificial intelligence (AI) disrupts copyright law, challenging traditional concepts of authorship and expression. It is reported that with machine authors generating content, the legal status of AI-created works is uncertain, marking a transformative moment in artistic production. It explores the evolving landscape of copyright in the era of computational art."
18,"Large language models are fundamental technologies used in interfaces like ChatGPT and are poised to change the way people access and make sense of health information. The speed of uptake and investment suggests that these will be transformative technologies, but it is not yet clear what the implications might be for health communications. In this viewpoint, we draw on research about the adoption of new information technologies to focus on the ways that generative artificial intelligence (AI) tools like large language models might change how health information is produced, what health information people see, how marketing and misinformation might be mixed with evidence, and what people trust. We conclude that transparency and explainability in this space must be carefully considered to avoid unanticipated consequences."
19,"This study investigated the impact of ChatGPT's recommendation quality and ethical concerns on travelers' acceptance, satisfaction, and perceived trustworthiness. Results showed that when quality and ethical concerns were prominent, acceptance of and satisfaction with ChatGPT's recommendations decreased significantly, and the negative effects were mediated by perceived trustworthiness. This study also identified that message framing containing ChatGPT's errors, and the information types delivered by ChatGPT, acted as moderators of the positive effect of its recommendations. These findings underscore the significance of addressing ethical and quality concerns in using AI (Artificial intelligence)-powered chatbots, with implications for AI acceptance and satisfaction."
20,"This study explores the impact of Generative AI tools on researchers and research in the context of higher education in Saudi Arabia. An online survey questionnaire was used to collect data on higher education students’ perspectives (N = 505). The findings indicate that participants hold positive attitudes and possess a high level of awareness regarding GenAI in research. They recognise the potential of these tools to revolutionise academic research. Participants report highly beneficial experiences using GenAI tools to expand project scope and improve efficiency. Additionally, participants expressed optimism about the future role of GenAI tools, expecting them to become more prevalent and transform the research landscape. However, participants emphasised the importance of adequate training, support, and guidance in using GenAI tools. Ethical considerations emerged as a significant concern, highlighting the participants’ commitment to responsible research practices and the need for transparency and addressing potential biases associated with these tools."
21,"Since the release of ChatGPT for public use in November 2022, the academic world has been debating the use and merits of generative artificial intelligence (AI) in academia and academic libraries. Is ChatGPT something that librarians should adopt, or should they shun the new technology altogether? The following articles examine the possibilities of using generative AI and ChatGPT in academic libraries. Overall, the authors see positive applications for the technologies in libraries and encourage librarians to study and learn the implications of using generative AI models in academic library services."
22,"Generative artificial intelligence (AI) has the potential to transform many aspects of scholarly publishing. Authors, peer reviewers, and editors might use AI in a variety of ways, and those uses might augment their existing work or might instead be intended to replace it. We are editors of bioethics and humanities journals who have been contemplating the implications of this ongoing transformation. We believe that generative AI may pose a threat to the goals that animate our work but could also be valuable for achieving those goals. In the interests of fostering a wider conversation about how generative AI may be used, we have developed a preliminary set of recommendations for its use in scholarly publishing. We hope that the recommendations and rationales set out here will help the scholarly community navigate toward a deeper understanding of the strengths, limits, and challenges of AI for responsible scholarly work."
23,"Generative artificial intelligence (AI) has the potential to transform many aspects of scholarly publishing. Authors, peer reviewers, and editors might use AI in a variety of ways, and those uses might augment their existing work or might instead be intended to replace it. We are editors of bioethics and humanities journals who have been contemplating the implications of this ongoing transformation. We believe that generative AI may pose a threat to the goals that animate our work but could also be valuable for achieving those goals. In the interests of fostering a wider conversation about how generative AI may be used, we have developed a preliminary set of recommendations for its use in scholarly publishing. We hope that the recommendations and rationales set out here will help the scholarly community navigate toward a deeper understanding of the strengths, limits, and challenges of AI for responsible scholarly work."
24,"The article focuses on the impact of generative AI on library workflows and operations, with insights from conversations with librarians about its use and implications. Topics include the potential opportunities of generative AI in libraries, concerns related to the accuracy and reliability of AI-generated content, and its role in tasks such as systematic reviews and information retrieval, highlighting the need for critical evaluation of AI-generated materials."
25,"The conventional approach to achieve desired effective thermal conductivity (ETC) of porous thermal interface materials (TIM) is processing-microstructure-properties forward analysis, which contains various trial-and-error cycles and is hence inefficient for materials development. Establishing the linkage from ETC to microstructure is essential; however, the recently developed methods including microstructure characterization and reconstruction are suffering from limited accuracy and computational efficiency. To address these problem, in this paper, generative artificial intelligence (AI) model was first implemented to design microstructure of porous TIM with desired ETC. Here, we introduced a representative porous TIM, sintered silver, and a typical kind of generative AI model, conditional generative adversarial network (CGAN), as an example for illustration. The CGAN model can efficiently generate sharp and crisp microstructures of sintered Ag with excellent morphology realism. Besides visual inspection, the ETC values of generated microstructures were evaluated by convolution neural network (CNN) model. It was found that the CGAN model also exhibits satisfactory performance in physical meaning, since the determination coefficient R2 between target ETC and CNN predicted ETC values is 0.985. These results confirm the effectiveness of generative AI model capable of synthesizing microstructure of porous TIM with desired ETC, and not limited to porous TIM, the approaches present here can also be generalized and applicable to design microstructure of other porous media and composites."
26,"The integration of generative artificial intelligence (AI) into academic research writing has revolutionized the field, offering powerful tools like ChatGPT and Bard to aid researchers in content generation and idea enhancement. We explore the current state of transparency regarding generative AI use in nursing academic research journals, emphasizing the need for explicitly declaring the use of generative AI by authors in the manuscript. Out of 125 nursing studies journals, 37.6% required explicit statements about generative AI use in their authors' guidelines. No significant differences in impact factors or journal categories were found between journals with and without such requirement. A similar evaluation of medicine, general and internal journals showed a lower percentage (14.5%) including the information about generative AI usage. Declaring generative AI tool usage is crucial for maintaining the transparency and credibility in academic writing. Additionally, extending the requirement for AI usage declarations to journal reviewers can enhance the quality of peer review and combat predatory journals in the academic publishing landscape. Our study highlights the need for active participation from nursing researchers in discussions surrounding standardization of generative AI declaration in academic research writing."
27,"Chatbots are now able to engage in sophisticated conversations with consumers. Due to the “black box” nature of the algorithms, it is impossible to predict in advance how these conversations will unfold. Behavioral research provides little insight into potential safety issues emerging from the current rapid deployment of this technology at scale. We begin to address this urgent question by focusing on the context of mental health and “companion AI”: Applications designed to provide consumers with synthetic interaction partners. Studies 1a and 1b present field evidence: Actual consumer interactions with two different companion AIs. Study 2 reports an extensive performance test of several commercially available companion AIs. Study 3 is an experiment testing consumer reaction to risky and unhelpful chatbot responses. The findings show that (1) mental health crises are apparent in a nonnegligible minority of conversations with users; (2) companion AIs are often unable to recognize, and respond appropriately to, signs of distress; and (3) consumers display negative reactions to unhelpful and risky chatbot responses, highlighting emerging reputational risks for generative AI companies."
28,"This study delves into the implications of incorporating AI tools, specifically ChatGPT, in higher education contexts. With a primary focus on understanding the acceptance and utilization of ChatGPT among university students, the research utilizes the Unified Theory of Acceptance and Use of Technology (UTAUT) as the guiding framework. The investigation probes into four crucial constructs of UTAUT—performance expectancy, effort expectancy, social influence and facilitating conditions—to understand their impact on the intent and actual use behaviour of students. The study relies on data collected from six universities in two countries and assessed through descriptive statistics and structural equation modelling techniques, and also takes into account participants' gender and study level. The key findings show that performance expectancy, effort expectancy, and social influence significantly influence behavioural intention. Furthermore, behavioural intention, when considered alongside facilitating conditions, influences actual use behaviour. This research also explores the moderating impact of gender and study level on the relationships among these variables. The results not only augment our comprehension of technology acceptance in the context of AI tools but also provide valuable input for formulating strategies that promote effective incorporation of ChatGPT in higher education. The study underscores the need for effective awareness initiatives, bespoke training programmes, and intuitive tool designs to bolster students' perceptions and foster the wider adoption of AI tools in education.Practitioner notesWhat is already known about this topic ChatGPT is a tool that is quickly gaining worldwide recognition. ChatGPT helps with writing essays and solving assignments. ChatGPT raises ethical concerns about authorship, plagiarism and ethics. What this paper adds This study explores students' acceptance of ChatGPT as an aid in their education, which has not been studied previously. We used the extended Unified Technology Acceptance and Use of Technology theory to test what factors mostly influence the use of ChatGPT by students. We conducted a multiple study in Poland and Egypt based on sampling strategy from six universities. Implications for practice and/or policy ChatGPT is a global game changer and should be incorporated into study programmes. The limitations of ChatGPT should be well explained and known since it is prone to making mistakes. Higher education teachers should be aware of ChatGPT's capabilities. ChatGPT is a tool that is quickly gaining worldwide recognition. ChatGPT helps with writing essays and solving assignments. ChatGPT raises ethical concerns about authorship, plagiarism and ethics. This study explores students' acceptance of ChatGPT as an aid in their education, which has not been studied previously. We used the extended Unified Technology Acceptance and Use of Technology theory to test what factors mostly influence the use of ChatGPT by students. We conducted a multiple study in Poland and Egypt based on sampling strategy from six universities. ChatGPT is a global game changer and should be incorporated into study programmes. The limitations of ChatGPT should be well explained and known since it is prone to making mistakes. Higher education teachers should be aware of ChatGPT's capabilities."
29,"As perhaps the most consequential technology of our time, Generative Foundation Models (GFMs) present unprecedented challenges for democratic institutions. By allowing deception and de-contextualized information sharing at a previously unimaginable scale and pace, GFMs could undermine the foundations of democracy. At the same time, the investment scale required to develop the models and the race dynamics around that development threaten to enable concentrations of democratically unaccountable power (both public and private). This essay examines the twin threats of collapse and singularity occasioned by the rise of GFMs."
30,"Until now, the mass spread of fake news and its negative consequences have implied mainly textual content towards a loss of citizens' trust in institutions. Recently, a new type of machine learning framework has arisen, Generative Adversarial Networks(GANs) – a class of deep neural network models capable of creating multimedia content (photos, videos, audio) that simulate accurate content with extreme precision. While there are several areas of worthwhile application of GANs – e.g., in the field of audio-visual production, human-computer interactions, satire, and artistic creativity – their deceptive uses, at least as currently foreseeable, are just as numerous and worrying. The main concern is linked to the so-called “deepfakes”, fake images or videos that simulate real events with extreme precision. When trained on a human face, GANs can make the face assume hyper-realistic movements, expressions and (verbal and non-verbal) communication abilities. This technology poses an urgent threat to the governance of democratic processes concerning the production of public opinions and political discourses, with significant potential for reality-altering and disinformation. After a short introduction of their current technical state-of-the-art, in this paper, we want to enquire about the GANs` socio-technical system alongside different and intertwined philosophical accounts. Firstly, we will argue about the conditions that make perceived GANs-generated content trustworthy, arguing also about the general effects GANs might have on the perceived trustworthiness of individuals. Thereafter, we will discuss about the inadequacy to approach GANs only as perception-altering technology. Against this backdrop, we will propose a theoretical turn that considers the human-machine relationships of trustworthiness as elements of broader hybrid socio-technical systems. This turn comes up with political repercussions that we will discuss in the last part of the paper."
31,"Humans often display a truth-bias —the perception that others are honest independent of message veracity—but does this phenomenon extend to generative artificial intelligence (AI)? We had humans and large language models make nearly 1,000 veracity judgments across different prompts. Human detection accuracies were near chance (50%–53%) with notable truth-biases (59%–64%); AI had a substantially greater truth-bias than humans (67%–99%). GPT-4 was also truth-default, not suspecting deception when veracity assessments were unprompted. Together, people and AI judge most information to be true."
32,"Generative AI, a new technology, is gaining popularity and raising questions about its future impact. One major concern is bias, as AI models trained on real-world data often encode and reinforce biases related to gender and race. Copyright issues have also arisen, with artists and writers suing tech companies for alleged infringement. The impact on jobs is a topic of discussion, with concerns that white-collar workers may be at risk. However, some argue that AI can enhance job performance. Generative AI has the potential to revolutionize image and video production, but there are concerns about inequality and misinformation. The misuse of generative models for creating fake text and images is a growing concern, as is the environmental impact of development costs. The debate surrounding the risks and benefits of AI will continue, with calls to address issues such as bias, job displacement, and misinformation."
33,"This document is a revised set of recommendations from the World Association of Medical Editors (WAME) regarding the use of chatbots and generative artificial intelligence (AI) in scholarly publications. The recommendations aim to inform editors, authors, and reviewers about the use of chatbots in papers and address concerns about authenticity, plagiarism, and biases in chatbot-generated content. The document emphasizes the need for transparency, proper attribution of sources, and the responsibility of authors and editors in ensuring the accuracy and integrity of chatbot-generated material. It also highlights the importance of providing editors with appropriate tools to detect AI-generated content."
34,"The article discusses the transformative potential of generative AI in clinical trial design, emphasizing its application in data management and the creation of high-quality datasets to inform trial simulations. Topics include data privacy concerns, the importance of data quality, and the need for robust AI approaches to ensure reliable outputs in clinical trial operations."
35,"The metaverse has been discussed in fields such as medicine, manufacturing, finance, education, and public services, but the application scenarios based on virtual reality have not truly achieved the ""real-virtual-real"" loop interaction method. Its interaction mode has also not truly given the digital world the same consciousness and perception as the physical world. Taking medicine as a case study, the prospective applications and challenges of generative artificial intelligence models in metaverse organisms were explored, including digitizing biological cells, and building connections between digitized cells and digital neurons, in order to promote metaverse life forms to have perception and biochemical reactions consistent with the physical world, thereby empowering the development of the medical field. In response to the current advantages and disadvantages of the metaverse and generative artificial intelligence models, the clever design of human-machine collaboration mechanisms was discussed to promote conscious interaction between humans and metaverse organisms in medicine."
36,"Medical imaging is playing an important role in diagnosis and treatment of diseases. Generative artificial intelligence (AI) have shown great potential in enhancing medical imaging tasks such as data augmentation, image synthesis, image-to-image translation, and radiology report generation. This commentary aims to provide an overview of generative AI in medical imaging, discussing applications, challenges, and ethical considerations, while highlighting future research directions in this rapidly evolving field."
37,"Background: The spread of artificial intelligence (AI) has led to transformative advancements in diverse sectors, including healthcare. Specifically, generative writing systems have shown potential in various applications, but their effectiveness in clinical settings has been barely investigated. In this context, we evaluated the proficiency of ChatGPT-4 in diagnosing gonarthrosis and coxarthrosis and recommending appropriate treatments compared with orthopaedic specialists. Methods: A retrospective review was conducted using anonymized medical records of 100 patients previously diagnosed with either knee or hip arthrosis. ChatGPT-4 was employed to analyse these historical records, formulating both a diagnosis and potential treatment suggestions. Subsequently, a comparative analysis was conducted to assess the concordance between the AI's conclusions and the original clinical decisions made by the physicians. Results: In diagnostic evaluations, ChatGPT-4 consistently aligned with the conclusions previously drawn by physicians. In terms of treatment recommendations, there was an 83% agreement between the AI and orthopaedic specialists. The therapeutic concordance was verified by the calculation of a Cohen's Kappa coefficient of 0.580 (p < 0.001). This indicates a moderate-to-good level of agreement. In recommendations pertaining to surgical treatment, the AI demonstrated a sensitivity and specificity of 78% and 80%, respectively. Multivariable logistic regression demonstrated that the variables reduced quality of life (OR 49.97, p < 0.001) and start-up pain (OR 12.54, p = 0.028) have an influence on ChatGPT-4's recommendation for a surgery. Conclusion: This study emphasises ChatGPT-4's notable potential in diagnosing conditions such as gonarthrosis and coxarthrosis and in aligning its treatment recommendations with those of orthopaedic specialists. However, it is crucial to acknowledge that AI tools such as ChatGPT-4 are not meant to replace the nuanced expertise and clinical judgment of seasoned orthopaedic surgeons, particularly in complex decision-making scenarios regarding treatment indications. Due to the exploratory nature of the study, further research with larger patient populations and more complex diagnoses is necessary to validate the findings and explore the broader potential of AI in healthcare. Level of Evidence: Level III evidence."
38,"The authors comments on an article by I. G. Cohen on ChatGPT's ethical implications for medical artificial intelligence (AI). Topics discussed include ChatGPT's general design as raising unique issues, key values and constant ethical concerns, and some of the least discussed but crucial values identified in the article."
39,"The article examines the role of ChatGPT and generative artificial intelligence (GenAI) in helping to revitalize bioethics by foregrounding epistemic justice. Topics include reasons why GenAI's clinical use is a big deal in bioethics, the problem of exclusivity in power and privilege and way epistemic justice lends support to understanding in bioethics."
40,"The article examines whether one should understand a fine-tuned large language model (LLM) trained on one's own past writings as a form of academic enhancement of oneself. Topics discussed include reason that current LLMs are sometimes called hallucinating bullshitters, the concept AUTOGEN-LLMs, and argument of David Chalmers, one of the two main characters behind the extended mind thesis, on LLMs."
41,"Abstract ChatGPT has garnered unprecedented popularity since its release in November 2022. This artificial intelligence (AI) large language model (LLM) is designed to generate human-like text based on patterns found in massive amounts of data scraped from the internet. ChatGPT is significantly different from previous versions of GPT by its quality of output, capability to interact and hold human-like conversations, enormous speed, and ability to have its output refined by users or experts. New iterations of ChatGPT as well as open source and alternative LLMs, and ChatGPT plugins extend the current capabilities of ChatGPT and offer unlimited opportunities to change how we do things. Despite its newfound popularity and capabilities, ChatGPT is fraught with concerns such as cheating, misinformation, bias, abuse and misuse, and privacy and safety. On the other hand, the integration of ChatGPT in the classroom prompts us to envision better ways of providing instruction and assessment of writing skills. ChatGPT also provides unparalleled approaches for personalized learning. As educators, we must consider and deal with the serious concerns of using ChatGPT but simultaneously explore how this AI technology can enhance and extend current methods of instruction. In this paper, authors explain what ChatGPT is and how it works, and future iterations of ChatGPT. They also present concerns and opportunities, and educational implications of using ChatGPT in the classroom."
42,"This article presents generative artificial intelligence (AI) as a potential new innovation platform. First this article provides the history of generative AI with a discussion of Microsoft, OpenAI, and the use of neural networks and large language models. Next, a look at whether generative AI could meet the criteria of an innovation platform. Lastly, a discussion of regulation and governance."
43,"Overview: We have all read the headlines heralding, often hyperbolically, the latest advances in text- and image-based Artificial Intelligence (AI). What is perhaps most unique about these developments is that they now make relatively good AI accessible to the average Internet user. These new services respond to human prompts, written in natural language, with generated output that appears to satisfy the prompt. Consequently, they are categorized under the term ""generative AI,"" whether they are generating text, images, or other media. They work by modeling human language statistically, to ""learn"" patterns from extremely large datasets of human-created content, with those that specifically focus on text therefore called Large Language Models (LLMs). As we have all tried products such as ChatGPT or Midjourney over the past year, we have undoubtedly begun to wonder how and when they might impact our archaeological work. Here, I review the state of this type of AI and the current challenges with using it meaningfully, and I consider its potential for archaeologists."
44,"Food material science has evolved to support the development of food products by connecting food structure, sensory, nutrition, food processing, and digestion with impact in consumers. However, food design has not evolved to deal with this increased complexity of food systems. And the ability to understand, capture the attention, and transform consumer demands into the chemical and physical attributes of the final product remains one of the biggest challenges in the food industry. As a result, new ways to support food design are necessary. This review describes the state-of-the-art of applications in food design utilizing artificial intelligence (AI)/Deep Generative Networks, including available resources and emerging capabilities and its relationship with the concept of inverse design. Food design and formulation involve complex processes and many design parameters need to be considered while developing data-driven approaches. Most approaches identified are based on the association among ingredients, but less focus has been given to functional properties. Representation of data remains a real challenge and a very important research gap toward achieving a real and applicable concept of digital food design. Overall methods based on deep learning and natural language processing are the most utilized. Deep generative-based approaches have been rarely described and remain a critical research area. [Display omitted] • Inverse design of food is enabled by data-driven methodologies and publicly available resources. • Publicly available recipes is the most common resources utilized in inverse food design. • Inverse design utilizing deep generative networks is an emerging area and offers great potential for design of novel foods. • Availability of resources such as databases and ontologies create a 'perfect storm' for food inverse design utilizing deep generative networks."
45,"Most experts agree that large language models (LLMs), such as those used by Copilot and ChatGPT, are expected to revolutionize the way in which software is developed. Many papers are currently devoted to analyzing the potential advantages and limitations of these generative AI models for writing code. However, the analysis of the current state of LLMs with respect to software modeling has received little attention. In this paper, we investigate the current capabilities of ChatGPT to perform modeling tasks and to assist modelers, while also trying to identify its main shortcomings. Our findings show that, in contrast to code generation, the performance of the current version of ChatGPT for software modeling is limited, with various syntactic and semantic deficiencies, lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role that LLMs can play in the software modeling discipline in the short term, and how the modeling community can help to improve the current capabilities of ChatGPT and the coming LLMs for software modeling."
46,"Higher educational institutions (HEIs) are facing a significant challenge in maintaining academic integrity due to the technological integration of generative artificial intelligence (AI). The widespread use of AI tools by college students has resulted in an increase in plagiarism and cheating, highlighting the need for effective implementation of this technology. However, there is a lack of research on the best practices for using AI in academic settings. HEIs must take responsibility for addressing these issues, as the majority of institutions do not have formal guidelines for AI use, leading to confusion among students and instructors. To combat academic misconduct, HEIs should establish clear objectives and policies for the equitable, inclusive, and ethical use of AI. Improving AI literacy among students and faculty is crucial, as it ensures that everyone has equal access to technology, preventing a digital divide. Moreover, proactive education on the ethical use of AI is vital for HEIs to prepare students for the AI-driven future of education and maintain academic integrity."
47,"The article offer updates on the initiative of the Florida Bar in studying the impact of generative artificial intelligence (AI) on the legal profession. Among the focus areas of research by the Special Committee on AI Tools & Resources are impact of AI on access to justice and court clerks, Rules of Professional Conduct, and AI certifications in pleadings and disclosures to the court. It cautions law firms against the potential consequences of failing to capitalize on the power of AI."
48,"This article presents the accompanying piece to the author’s first installment on legal challenges surrounding generative artificial intelligence (AI) in the July issue of Communications of the ACM. This article focuses on two lawsuits brought on for illegal use of images and captions for AI training data, where Stability AI Ltd. is the defendant in both. The author presents a look at previous copyright infringement cases and how the outcome of those might inform these current cases."
49,"Adobe certainly thinks generative AI is worth further investigation, and is putting its marketing muscle behind Generative Fill (fave.co/3DtVC5G), a new Photoshop feature that allows you to edit or manipulate your images in new ways. INSTALLING AND USING THE PHOTOSHOP BETA If you'd like to install the Photoshop beta, you'll need a valid license for Adobe Creative Cloud (fave.co/3QtrxuP) and an active internet connection, as the Generative Fill feature requires cloud processing."
50,"Plain Language Summary: Since its launch, ChatGPT has taken the internet by storm and has the potential to be used broadly in the health care system, particularly in a setting such as medical oncology.ChatGPT is well suited to review and extract key content from records of patients with cancer, interpret next‐generation sequencing reports, and offer a list of potential clinical trial options. Since its launch, ChatGPT has taken the internet by storm and has the potential to be used broadly in the health care system, particularly in a setting such as medical oncology. ChatGPT is well suited to extract key content from a large pile of medical records, interpret complex next‐generation sequencing reports, and offer a list of potential clinical trial options for the patient."
51,"The article looks at possible applications of generative AI in the field of law and at concerns some attorneys have about the technology."
52,"The article profiles NVIDIA Corp., a manufacturer of graphical processing units (GPUs), in the context of the growth of generative AI, in which the article says GPUs play a large role."
53,"The paper aims to analyze the paradigm article published by researchers from OpenAI, OpenResearch, and the University of Pennsylvania on March 23, 2023, reporting on the possible impacts of generative transformative AI (GPT) on the American labor market. From the analysis of the article and definition of an assessment of points of interest for the Brazilian Legal field, an enumeration of hypotheses will be structured to meet the objective of this paper. To guide the analytical, evaluative, and descriptive approach, the paper will also rely on other scientific articles published in databases as well as institutionally available statistical elements. Using the deductive method, this paper presents formulations, highlighting the higher probability of GPTs' impact on legal work, including that which requires more time to develop skills, except for applications of sophisticated scientific knowledge or that require critical analysis."
54,"Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions."
55,"The article informs about the transformative potential of artificial intelligence (AI) and its applications in various sectors. Topics include the evolution of AI, its benefits and risks for state and local governments, and specific applications in areas such as health and human services, sustainability, cybersecurity, higher education, and employment/unemployment insurance."
56,"The article focuses on the potential of large language models (LLMs) and generative AI in transforming customer service in contact centers. Topics include the current internal use of LLMs to enhance agent performance, the challenges of deploying generative AI for customer-facing roles, and experts' perspectives on the future applications of LLMs in customer service, emphasizing advancements in technology and the need for a strategic approach."
57,"The author comments on the articles by G. Cohen, V. Rahimzadeh and colleagues, and S. Porsdam Mann and colleagues about the ethical and conceptual challenges of large language models (LLMs) of artificial intelligence that confront bioethicists. Topics include ways that LLMs might aid those studying bioethics according to Rahimzadeh et al, syllogisms about the ethics of ectogenesis that were requested and generated within five minutes, and ethical questions considered by Porsdam Mann et al."
58,"The authors comment on an article by I. G. Cohen on the significance of ChatGPT for bioethics which suggested that little is known about the development of generative artificial intelligence (GAI) in China and other national markets. Topics discussed include China's efforts to gain competitive advantage in the global AI race, the emerging Chinese framework for AI governance, and areas of significance to bioethics."
59,"Universities are already adopting AI to automate answers to commonly asked questions and even using AI tools to review students resumes prior to them talking to career consultants. Short for ""Generative Pre-trained Transformer"", Chat GPT is an of example of generative artificial intelligence (AI) technology that allows users to converse with machines in a natural way. Headlines have touted that AI technologies will be the death of the traditional college essay or how faculty need to AI-proof their assignments, and others say that AI could be great for college essays ([3]; [4]; [6])."
60,"In response to Warschauer et al.'s paper on the affordances and contradictions of AI-generated text, we as researchers in multimodal literacy focus on discussing the two affordances of multimodal generative AI models for L2 writers, such as (1) exploring and fostering multimodal literacy and (2) developing fine-tuned prompt literacy."
61,"The article focuses on the legal challenges surrounding generative artificial intelligence (AI) and its implications for copyright laws. It reports specifically on the Doe vs. GitHub lawsuit in which a class of programmers claim their legal rights were violated when GitHub's Copilot and OpenAI's Codex AI programs used publicly available open source code that the litigants developed as training data for the programs."
62,"This article examines the use of generative artificial intelligence (AI), namely OpenAI’s ChatGPT, with an emphasis on trust as well as its impact on education and jobs. The author discusses limitations to ChatGPT and how these can lead to errors in its responses but also highlights ways chatbots can be used to assist in a professional’s work."
63,"Generative AI, short for Generative Artificial Intelligence, a class of artificial intelligence systems, is not currently the choice technology for text analysis, but prior work suggests it may have some utility to assess dynamics like emotion. The current work builds upon this empirical foundation to consider how analytic thinking scores from a large language model chatbot, ChatGPT, were linked to analytic thinking scores from dictionary-based tools like Linguistic Inquiry and Word Count (LIWC). Using over 16,000 texts from four samples and tested against three prompts and two large language models (GPT-3.5, GPT-4), the evidence suggests there were small associations between ChatGPT and LIWC analytic thinking scores (meta-analytic effect sizes: .058 < <italic>r</italic>s < .304; <italic>p</italic>s < .001). When given the formula to calculate the LIWC analytic thinking index, ChatGPT performed incorrect mathematical operations in 22% of the cases, suggesting basic word and number processing may be unreliable with large language models. Researchers should be cautious when using AI for text analysis."
64,"Litigators must apply their legal judgment and experience when using generative AI, just as when usinganother type of AI or even any other type of technology. Generative artificial intelligence (AI) is a type of AI that generates new content or data in response to aprompt, or question, by a user. Generative AI and LLMs have several known limitations and weaknesses that litigators and other legalprofessionals should be acutely aware of, in addition to yet uncovered limitations and weaknesses. What are the basics litigators should know about how generative AI and LLMs work?."
65,"ABA Model Rule of Professional Conductâ€™s Model Rule 7.1 prohibits making false or misleading communications regarding a lawyerâ€™s legal services. How are attorneys and paralegals using the software being trained (Rules 5.1 and 5.3) and how is the AI itself being supervised? Should firms offer clients an opt-out option allowing them to direct the firm not to use the technology in their matters?"
66,"Customer data isn't used to train Coda or another vendor's models, said Mehrotra. With the release of Coda 4.0 on Wednesday, Coda has joined the parade of productivity software vendors embedding generative AI features in their products. As with all office software vendors that are incorporating generative AI into their products, hallucinations - a term for inaccurate information that AI language models generate at times - are a concern for Coda too."
67,"In session, we will discuss several obstacles that must be tackled to guarantee the responsible and ethical utilization of Generative AI (Artificial Intelligence). It is vital to confront biases present in both input data and model responses to achieve fair and ethical results. As Large Language Models (LLMs) become increasingly integrated into our society, it becomes imperative to thoroughly examine and comprehend their wider effects on aspects such as employment, education, and human creativity. During the session we will provide a live DEMO with related implications in Governance AI."
68,"In alignment with climate change mitigation plans, renewable and sustainable energy integration into the industrial sector should be investigated for decarbonization purposes by 2050. This study aims to examine the feasibility of decarbonization of mega-scale industrial parks with two emerging technologies; first, an integrated energy system involving an air separation unit (ASU) and a liquid air energy storage (LAES)-based power generation system (ALPG) with the assistance of a large-scale liquified natural gas (LNG) plant and second, the green electricity predicted by various renewable energy (VRE) scenarios using an AI-driven generative model concerning techno-economic and environmental analyses. Firstly, the electricity demand of mega-scale petrochemical industrial complexes was allocated, and remote sensing data of VRE (wind and solar) were collected in South Korea. Then, the ALPG was modeled to consider the actual operation of an LNG plant near target complexes. Subsequently, the C C-informed VRE scenario generation model (C C-VRES) based on an adversarial autoencoder (AAE) algorithm was developed to generate VRE scenarios considering the CC effects. Finally, techno-economic and environmental assessments were conducted to target the mega-DIP by 2050. The results showed that the levelized cost of electricity of the proposed ALPG was 150 $/MWh, which is enough to supply the required sustainable electricity, considering the Korean energy plan and CC effects in the C C-VRES model. Therefore, the excess VRE can be used to decarbonize the target industrial parks; it is anticipated that 26,084 GW h/yr of renewable and sustainable electricity will be generated and cover the total electricity demand of Yeosu and Ulsan target complexes while reducing 13,943-kilo t CO 2 eq./yr through 2050. [Display omitted] • Study on the feasibility of mega-scale decarbonized industrial park by 2050. • Innovative power generation system integrated ASU and LAES was proposed. • AI-driven VRE scenario generation model was proposed considering climate change. • AI model can estimate future VRE to accomplish Mega-DIP through 2050. • Mega-DIP is feasible while reducing 13,943-kilo t CO 2 eq./yr by 2050."
69,"Designing building structures presents various challenges, including inefficient design processes, limited data reuse, and the underutilization of previous design experience. Generative artificial intelligence (AI) has emerged as a powerful tool for learning and creatively using existing data to generate new design ideas. Learning from past experiences, this technique can analyze complex structural drawings, combine requirement texts, integrate mechanical and empirical knowledge, and create fresh designs. In this paper, a comprehensive review of recent research and applications of generative AI in building structural design is provided. The focus is on how data is represented, how intelligent generation algorithms are constructed, methods for evaluating designs, and the integration of generation and optimization. This review reveals the significant progress generative AI has made in building structural design, while also highlighting the key challenges and prospects. The goal is to provide a reference that can help guide the transition towards more intelligent design processes. [Display omitted] • Review on research progress of generative AI design for building structures. • Data feature representation, intelligent generation algorithm, and evaluation methods. • Integration of generative AI-based and optimization-based design. • Milestones, critical challenges, and prospects of generative AI-based design."
70,"Engineered cementitious composite (ECC) has been intensively studied due to its excellent tensile performance. However, classical micro-mechanical design theory of ECC is qualitative and fails to give detailed ECC mixtures at specific tensile parameters. This study aims to develop a performance-based mixture design model to generate ECC mixtures using generative AI method. An experimental database consisting of 129 polyethylene fiber reinforced ECC (PE-ECC) records has been built. The database was used to train one invertible neural network model and two artificial neural network models. A series of PE-ECC mixtures were generated by the proposed model based on desired mechanical performance and sustainable requirements. Based on the experimental results, the developed model was proven to compose PE-ECC mixtures that satisfy the target requirements with a maximum deviation of less than 16%. The neural network-based model can be used in various application scenarios (e.g., low-cost ECC and low-carbon ECC), thus promoting the development of ECC materials in the area of research and engineering application."
71,"The article focuses on the potential impact of generative artificial intelligence (AI) on law firms, discussing how AI can be applied in various legal practice areas. It explores the potential effects on document automation, legal research, predictive analytics, contract review and due diligence, emphasizing the need for adaptation and leveraging AI's benefits. The authors also address AI's implications on firm strategy, structure, staffing needs, pricing models and strategic cannibalization."
72,"This creates tensile stresses in the casting, which can lead to the formation of hot tears. i I However, the mold material can act as a constraint, providing resistance to the contraction of the metal and reducing the level of tensile stresses in the casting. Mold materials and the use of chill molds as a way to prevent hot tears in castings are important factors that should have been included. Readers who have been following the editorials in this column may have noticed the ongoing discussion about the potential impact of cutting-edge technologies like Big Data, Machine Learning, Industry 4.0, and Artificial Intelligence (AI)."
73,"This article reflects on the transformative nature of generative AI (GenAI) tools for teaching and teacher education, both reflecting on current innovation and consider future potentials and challenges. In that sense, we aim to position the field of education going forward with the implications of new technologies like GenAI for education and educational research. We argue the need for a dual-lens approach. First and foremost, practice and research should focus on the here-and-now, i.e. how to design powerful learning experiences for pre-service and in-service teachers for them to be productive, creative, critical, and ethical users. But there is also a need for a deeper, longer view—based on sociological and historical trends and patterns that will influence the socio-techno-cultural matrix within which education functions in the long term. We begin with a brief introduction to GenAI technologies. This is followed by an in-depth discussion of the fundamental nature of GenAI tools—their similarities and differences to prior technologies, and the implications for teacher education and research."
74,"As part of a larger project, this paper reports on preliminary findings of a study exploring use cases of ChatGPT and associated behaviors and experiences among users of an online forum. Posts on a ChatGPT‐related forum on Reddit (n = 452) were analyzed using qualitative content analysis. This paper reports on themes relevant to this study, including the types of tasks for which users used ChatGPT, user experiences, and perceived impacts of ChatGPT. ChatGPT was often used to facilitate various writing tasks (e.g., writing an essay), academic tasks (e.g., finding scientific references for a research paper), everyday tasks (e.g., creating a meal plan), and conversational purposes (e.g., having a simulated conversation about a past event). Users expressed positive (e.g., excited, amazed) and negative (e.g., fooled, concerned) feelings toward the technology. They raised various issues and problems with ChatGPT at the content (e.g., inaccuracy, incompletes) and system (e.g., unavailability, instability) levels. Users discussed the perceived impacts of ChatGPT on individuals (e.g., unemployment) and society (e.g., AI divide). Study findings can inform the design of policies and guidelines for mitigating AI problems and promoting the effective and ethical use of emerging AI technologies."
75,"Generative AI tools powered by Large Language Models (LLMs) have demonstrated advanced capabilities in understanding and articulating legal facts closer to the level of legal practitioners. However, scholars hold contrasting views on the reliability of the reasoning behind a decision derived from LLMs due to its black-box nature. Law firms are vigilant in recognizing the potential risks of violating confidentiality and inappropriate exposure of sensitive legal data through the prompt sent to Generative AI. This research attempts to find an equilibrium between responsible usage and control of human legal professionals over content produced by Generative AI through regular audits. It investigates the potential of Generative AI in drafting correspondence for pre-litigation decisions derived from an eXplainable AI (XAI) algorithm. This research presents an end-to-end process of designing the architecture and methodology for a blockchain-based auditing system. It detects unauthorized alterations of data repositories containing the decisions by an XAI model and automated textual explanation by Generative AI. The automated auditing by blockchain facilitates responsible usage of AI technologies and reduces discrepancies in tracing the accountability of adversarial decisions. It conceptualizes the two algorithms. First, strategic on-chain (within blockchain) and off-chain (outside blockchain) data storage in compliance with the data protection laws and critical requirements of stakeholders in a legal firm. Second, auditing by comparison of the unique signature as Merkle roots of files stored off-chain with their immutable blockchain counterpart. A case study on liability cases under tort law demonstrates the system implementation results. • Regular audits to balance human authority and responsible use of Generative AI. • Architecture and methodology of a blockchain-based auditing system. • Generative AI potential in drafting legal decisions derived from XAI algorithms. • Ambiguous legal knowledge representation by Evidential Reasoning. • A case study on employer's liability cases to demonstrate system implementation."
76,"The article discusses the rise of generative AI, focusing on ChatGPT developed by OpenAI. It explores three ways educators can utilize generative AI in teaching, including using it as an ideation assistant, as a tool for code review, and as part of an adapted Socratic method for critical thinking. It mentions the potential of generative AI to revolutionize education and improve learning outcomes while addressing ethical considerations and limitations."
77,"The article focuses on the integration of generative artificial intelligence (genAI) into marketing technology stacks. Topics include the optimism among marketing leaders about genAI's potential, challenges in navigating the fragmented genAI landscape, steps for integrating genAI into existing martech stacks, and the importance of flexibility, experimentation, and continuous improvement in the process."
78,"Discovering new promising molecule candidates that could translate into effective drugs is a key scientific pursuit. However, factors such as the vastness and discreteness of the molecular search space pose a formidable technical challenge in this quest. AI-driven generative models can effectively learn from data, and offer hope to streamline drug design. In this article, we review state of the art in generative models that operate on molecular graphs. We also shed light on some limitations of the existing methodology and sketch directions to harness the potential of AI for drug design tasks going forward."
79,"The article discusses the growing interest and adoption of generative AI, as evidenced by surveys showing organizations experimenting with it on a small scale. It emphasizes the challenges of high-performance hardware and data processing demands, particularly in the context of large language models like GPT-4 with 1.76 trillion parameters."
80,"Nightshade is a new tool that allows artists to add invisible changes to their artwork before uploading it online. These changes can disrupt the training data used by AI models, causing them to produce unpredictable and chaotic outputs. The tool is intended to empower artists and protect their copyrights and intellectual property from being used without permission by AI companies. Nightshade exploits a vulnerability in generative AI models and can manipulate the models into learning incorrect associations between concepts. While there is a risk of misuse, the tool requires a large number of poisoned samples to cause significant damage to powerful AI models."
81,"Generative AI tools, at first glance, seem to fully automate artistic production - an impression that mirrors past instances when traditionalists viewed new technologies as threatening ""art itself."" INSIGHTS The capabilities of a new class of tools, colloquially known as generative artificial intelligence (AI), is a topic of much debate. Regardless of legal outcomes, generative AI tools are likely to transform creative work and employment. AI-generated content may also feed future models, creating a self-referential aesthetic flywheel that could perpetuate AI-driven cultural norms."
82,"In less than one year from its launch, the chatbot ChatGPT has captured widespread public attention, thanks to its ease of use and remarkable performance. However, part of this interest is due to its involvement in some data protection and data security issues. In the context of the ongoing debate surrounding similar technologies, such as generative AI, this contribution will first introduce the ""ChatGPT phenomenon"" (Sections 1 and 2). Then, it will analyse the various positions taken by some key stakeholders on the issues of above and the regulation of the design and use of such technologies, examining these perspectives through the lenses of ""Digital Constitutionalism"". Particularly, this paper will emphasise the role that civil society can play in such dynamics (Section 3). Subsequently, it will further promote an active and forward-looking approach in addressing the looming threats these and other AI-based technologies could pose to fundamental rights and society as a whole (Section 4). As we already approach the next AI era without even noticing, the question worth asking ourselves is: ""What will generative and AI-powered oracles reveal about us?"" (Section 5)."
83,"This paper takes the occasion of French DJ David Guetta's use of generative AI tools to create lyrics and a voice in the style of Eminem, which he then used in one of his concerts, as the basis for an exploration of the shifting meaning of creativity and originality in the age of generative AI. Our main contention is that the Guetta form of creativity with generative AI tools differs in certain important respects from what has come before. The paper describes an iterative, dynamic process of conception, prompting, generation, refining, and deployment to characterise creativity in this context. Nevertheless, we contend that copyright – specifically the concept of originality as articulated in US federal law – is a sufficiently durable legal mechanism that can manage these new cultural forms, and that the two basic requirements of modern copyright law (a tangible medium of expression and a modest degree of creativity) remain relevant in identifying the scope of legal protection. The paper argues that the David Guetta story reveals something more general about creativity in a digital age, namely that while hybrid-networked (i.e., human – corporate – machine) creators have always created hybrid-networked cultural forms (i.e., creations that blend human and technology-constituted elements), such hybridity becomes increasingly visible and complex in the context of a new world of generative AI. At the very least, earlier – and influential – models of creativity as human-driven involving creation ex nihilo become harder to sustain in a new age of generative AI. But this does not mean copyright or notions of originality are redundant or that copyright law cannot accommodate Guetta and other cases. Such an account seems important as it challenges the hegemonic and reductive view that AI ""generates"" artistic works autonomously and avoids reducing the copyright issues raised by such creative works to the related but distinct question of whether learning models rely on copyrighted data. As such, copyright law should remain an important mechanism to facilitate genuine creators who are using AI systems in innovative and unique ways to push the boundaries of their creativity."
84,"Recently, generative artificial intelligence (AI)-powered chatbots such as ChatGPT and Bing Chat have garnered increasing attention on a global scale. Previous studies have focused mostly on the influence of generative AI on writing while few researchers have investigated how generative AI can facilitate students' multimodal writing process. To fill in this gap, we explored the generative AI-assisted composing processes of two groups of English as a foreign language (EFL) writers over two weeks in this qualitative study. One group completed a multimodal PowerPoint (PPT) project, and the other group completed a traditional argumentative essay project. Our data consist of students' screen recordings with think-aloud protocols, final multimodal texts, and post-project interviews. Our analysis showed different patterns in text production across the two groups. Students in the PPT group tended to construct more bridge texts and examples to corroborate their sub-claims in the hierarchical order. They also inclined to borrow the summarized search results from the Bing Chat to expand texts for their PPT slides. With regard to image generation for PPT slides, descriptions of AI images from ChatGPT were used as effective prompts to generate AI images from Bing Image Creator. Moreover, students were interested in producing and refining AI images following the recommended prompts by Bing Chat. They also evaluated these AI images from different perspectives. We conclude the study with a discussion on the pedagogical implications and suggestions for further study. • This study focused on students' cognitive processes in generative AI-assisted DMC task. • Students in the PPT group constructed more bridge texts and examples. • Students inclined to directly use the summarized responses from Bing Chat. • Students exhibited unique patterns of creating images by generative AI."
85,"This Viewpoint discusses the potential use of generative artificial intelligence (AI) in medical care and the liability risks for physicians using the technology, as well as offers suggestions for safeguards to protect patients."
86,"As Alphabet declared its third-quarter earnings on Tuesday, all eyes were on the company's cloud division, Google Cloud, since - even while up to now costs have outweighed sales - it has been the biggest revenue growth driver for the company over the past several years. It appears that Google Cloud is still suffering from optimizing cloud spend trends and is not able to gain from genAI spend trends as Azure has."" The explosive growth in the demand for generative AI has been a big revenue driver for public clouds."
87,"Curious about Generative AI examples of 2024? Explore 20 real-world examples of Generative AI today."
88,"Generative AI is revolutionizing the way companies approach problem-solving. Learn about the use cases of generative AI across different industries."
89,"Generative AI models are powerful tools for producing data. Learn what generative AI models are, how they work & what benefits they offer."
90,"Generative AI is a powerful tool for the PGA Tour. Learn how the PGA Tour is using generative AI to improve their operations and enhance the fan experience."
91,"Generative AI, such as ChatGPT, has gained attention and popularity due to its ability to provide humanlike responses to user prompts. These AI models are trained on vast amounts of data and have billions to trillions of interconnected nodes. While generative AI has many potential applications, such as generating abstracts or images, there are concerns about inaccuracies, biases, and plagiarism. Additionally, these systems consume significant amounts of energy and can reflect societal biases present in the training data. It is important to approach generative AI with skepticism and view it as a tool to enhance human intelligence rather than replace it. Regulation is needed to address potential harms while allowing for the benefits of this technology."
92,"Generative AI app builders are a great way to create powerful applications quickly and easily. Discover the best generative AI app builders."
93,"The article focuses on exploring university students' perceptions of generative Artificial intelligence (AI) technologies, such as ChatGPT, in higher education, highlighting their positive attitudes towards the potential benefits for personalized learning support, and writing assistance."
94,"The article focuses on the integration of generative Artificial Intelligence (AI), like ChatGPT, into the classroom environment and its impact on student engagement and writing support. It discusses how AI tools can assist students in generating ideas for their writing assignments, promote peer interactions, and alleviate initial writing barriers, ultimately enhancing the writing process."
95,"A map could alternatively be thought of as data that is not always machine-readable. There is a growing need for realworld cartography and feature-laden maps in metaverse applications and open-world video games (Butcher et al. 2018). A precise map is required in these use cases that reflect all changes on the ground promptly. Flyover imaging planes or satellites are constantly gathering the most recent geographical data. Automating the process of creating a human-readable map from a satellite image of a given location at a specified zoom level and resolution is one way to decrease this latency. This needs an ensemble of image translation, digital image processing, and remote sensing fields and is the focus of this research study. This has applications in diverse fields ranging from on ground navigation, metaverse, architecture and open-world game development."
96,"The article discusses the use of generative artificial intelligence (AI), specifically ChatGPT, in writing college application essays and admission process, and its implications for the education sector. It explores the capabilities of generative artificial intelligence (AI) in creating compelling and coherent essays, as well as the concerns surrounding its use and potential impact on admissions processes."
97,"Curious about the best generative AI tools? Explore our 2024 list of 20 powerful solutions in creativity and automation."
98,"Interested in the dynamics between traditional AI and generative AI? Explore innovative pathways for enterprise success."
99,"Seeking insights into Generative AI and Cybersecurity? Explore our comprehensive guide now."
100,"Learn the difference between Generative AI and Predictive AI, and find out why each is an important part of modern data analysis."
101,"Tech industry thought leaders use the X platform (formerly known as Twitter) to discuss the many issues around regulating generative AI."
102,"Neil Cohen, Head of Go-To-Market Strategy for Portal26, discussed a survey of how businesses are using generative AI. It reveals major investment in AI – and also major concerns."
103,"Although ChatGPT may be capable of passing professional licensure exams, AI likely will not provide the final signature of approval for engineering designs for the foreseeable future. In a technical release, OpenAI showed that ChatGPT-4 performed well on several academic and professional exams, but civil engineering exams were not included. Artificial intelligence (AI) is the science and engineering of making intelligent machines ([2])."
104,"The article reports on the World Association of Medical Editors (WAME) Recommendations on Chatbots and Generative Artificial Intelligence in Relation to Scholarly Publications, revised on May 31, 2023. It presents specific updates including the need of editors and reviewers to specify any use of chatbots in evaluation of the manuscript and generation of reviews and correspondence. Instances where individuals in scholarly publishing may use chatbots are mentioned."
105,"The article discusses the collaboration between Senior Editor Ralph Raiola and OpenAI's ChatGPT to create an original sci-fi short story. The article provides a full transcript of the collaborative process and a partially finished product."
106,"The author discusses three key target articles about the impact of generative artificial intelligence (GenAI) on bioethics moving forward. Topics include challenges that GenAI poses for bioethics from the perspective of integration to clinical medicine, impact of large language models (LLMs) on clinical ethics pedagogy, and advantages and challenges of training an LLM."
107,"Generative AI is a powerful tool for businesses. Discover the top 7 ways generative AI can boost productivity in the workplace."
108,"Generative AI, a subset of artificial intelligence (AI), is gaining popularity for its ability to generate content in various forms, such as text, images, simulations, and computer codes. Large Language Model (LLM), a type of generative AI, is trained with massive data sets to understand, summarize, generate, and predict new content tailored to specific requirements. LLM can be fine-tuned with specific data to personalize its output. While generative AI has the potential to revolutionize machine learning and deep learning, it also poses risks, such as cybercrime and financial fraud. Responsible use of AI involves respecting societal norms, safeguarding privacy, and ensuring ease of use without prejudice."
109,"Generative AI for business use is a rising – and important – trend that's increasing productivity. Learn the key techniques, generative AI best practices and more."
110,"The article discusses the significant impact of generative Artificial Intelligence on knowledge management, emphasizing its role in providing natural language interfaces to data and knowledge systems, transforming search into question-answering, and enhancing knowledge extraction from various sources."
111,"The article focuses on the use of artificial intelligence (AI) in education within the field of chemical engineering, highlighting how ChatGPT can assist educators in refining learning outcomes and discussing the responsible use of AI in coursework. It emphasizes the importance of understanding the limitations of AI tools and developing techno-ethical frameworks for decision-making in professional and educational contexts to harness the strengths of AI effectively."
112,"In recent years, artificial intelligence (AI) has achieved numerous disruptive breakthroughs in frontier scientific and technological fields, such as AlphaFold2 for protein structure prediction, intelligent control of nuclear fusion, and drug design for COVID-19. These achievements indicate that AI for Science is becoming a new paradigm in research. To achieve fundamental scientific innovation and major technological breakthroughs in the era of intelligence, two core issues should be addressed: 1) how to harness the generality and creativity of the new-generation of AI, especially generative AI and large language models (LLMs), to promote the formation of new paradigms; 2) how to empower and transform traditional scientific facilities using AI. To tackle these challenges, this study proposes a concept of AI-enabled scientific facility (AISF) that caters to the requirements of both establishment of totally new intelligent scientific facility and AI empowerment of existing scientific facilities. It aims to construct an infrastructure system for AI for Science, enabling innovative functionalities such as scientific large language models (LLMs), generative simulation and inversion, autonomous intelligent unmanned experiments, and large-scale trustworthy scientific collaboration. These advancements will accelerate scientific discoveries, synthesis of transformative materials, and application of related engineering technologies."
113,"Microsoft and Google have experienced a resurgence in cloud revenue due to the proliferation of generative AI. Google Cloud now accounts for 10% of Alphabet's revenue, while Microsoft Cloud has surpassed $33 billion in revenue. Both companies have seen increased adoption of their AI services, with Microsoft reporting 53,000 Azure AI customers and Google introducing updates to its Vertex AI platform. The uptick in cloud revenue can be attributed to the role cloud plays in enabling generative AI and supporting digital transformation."
114,"Microsoft and Google have experienced a resurgence in cloud revenue due to the proliferation of generative AI. Google Cloud now accounts for 10% of Alphabet's revenue, while Microsoft Cloud has surpassed $33 billion in revenue. Both companies have seen increased adoption of their AI services, with Microsoft reporting 53,000 Azure AI customers and Google introducing updates to its Vertex AI platform. The uptick in cloud revenue can be attributed to the role cloud plays in enabling generative AI and supporting digital transformation."
115,"According to a report by Cloudflare, global internet traffic increased by 25% in 2023, indicating a growing reliance on online services. Google remained the most popular website, followed by Facebook, Apple, and TikTok. OpenAI emerged as the leader in generative AI services, with other notable players including Character AI, Quillbot, and Hugging Face. Financial organizations were the primary targets for cyberattacks, with deceptive links and extortion attempts in emails being the most common threats. Internet outages also increased, often due to government-imposed shutdowns. Smartphones were the preferred device for accessing the internet, with Apple devices being popular among users. Generative AI became a significant trend, with OpenAI's ChatGPT launch gaining attention. Cloudflare used its complimentary service, Cloudflare Radar, to gather data for the report. Elon Musk's Twitter, now known as X, experienced a decline in popularity throughout the year. Internet outages increased, with over 180 incidents reported globally. Security concerns included vulnerabilities like Log4j and HTTP/2 Rapid Reset, as well as ransomware, malware, and phishing attacks."
116,"The article offers a guide for strategically using ChatGPT to create an aging of accounts receivable report. Topics discussed include an example of aging of accounts receivable report, steps for creating an aging of receivables report with ChatGPT, and things that should be done and should be avoided when using ChatGPT for automating tasks."
117,"The article discusses the potential of generative artificial intelligence, focusing on ChatGPT, to aid various aspects of the research process. Topics include the use of ChatGPT in literature searching, coding survey responses, assisting in writing for non-native English speakers, formatting bibliographies, and potential challenges regarding copyright and research integrity."
118,"The article discusses the benefits of ChatGPT to accounting and finance professionals and their need to take steps to mitigate its risks. Topics include different views about ChatGPT, the challenge faced by users, especially when asking ChatGPT to answer exam questions, and how ChatGPT can be used in accounting."
119,"The article focuses on how generative artificial intelligence (AI), such as ChatGPT, is unlikely to replace jobs in service and creative positions, as human employees remain indispensable and AI often complements rather than fully replaces their work."
120,"Jithin Bhasker, General Manager and VP for App Engine at ServiceNow, details how the combination of generative AI and low code software will dramatically reshape the app development process."
121,"eWEEK content and product recommendations are editorially independent. We may make money when you click on links to our partners. Learn More. On Tuesday, November 14 at 11 AM PT, @eWEEKNews will host its monthly #eWEEKChat. The topic will be the future of generative AI, and it will be moderated by James Maguire, eWEEK's Editor-in-Chief. [...]"
122,"Generative AI is transforming the contact center. Learn more about how this new technology is making a huge impact on customer service."
123,"Generative AI is transforming the way businesses think about AI. Learn 5 key insights business leaders need to know about this revolutionary technology."
124,"Generative AI is a rapidly growing field. Discover the top startups to watch in 2023 and learn how they are using AI to create new products and services."
125,"The Wipro executive details the excitement, confusion and enormous potential of generative AI."
126,"The Kinetica executive discussed the role of generative AI in optimizing the management of a data repository."
127,"Generative adversarial networks (GANs) are increasingly attracting attention in the computer vision, natural language processing, speech synthesis and similar domains. Arguably the most striking results have been in the area of image synthesis. However, evaluating the performance of GANs is still an open and challenging problem. Existing evaluation metrics primarily measure the dissimilarity between real and generated images using automated statistical methods. They often require large sample sizes for evaluation and do not directly reflect human perception of image quality. In this work, we describe an evaluation metric we call Neuroscore , for evaluating the performance of GANs, that more directly reflects psychoperceptual image quality through the utilization of brain signals. Our results show that Neuroscore has superior performance to the current evaluation metrics in that: (1) It is more consistent with human judgment; (2) The evaluation process needs much smaller numbers of samples; and (3) It is able to rank the quality of images on a per GAN basis. A convolutional neural network (CNN) based neuro-AI interface is proposed to predict Neuroscore from GAN-generated images directly without the need for neural responses. Importantly, we show that including neural responses during the training phase of the network can significantly improve the prediction capability of the proposed model. Materials related to this work are provided at https://github.com/villawang/Neuro-AI-Interface."
128,"An interview with Sumitrajit Dhar, a professor and keynote speaker at the Researcher-Academic Town Meeting at the American Speech-Language-Hearing Association (ASHA) Convention, is presented about his vision for artificial intelligence (AI) use in communication sciences and disorders (CSD) education and research. Dhar talks about the reason for so much attention about generative AI, whether instruction about generative AI belongs in the curriculum, and how AI can enhance work efficiency."
129,"Despite advances in deep learning, current state-of-the-art speech emotion recognition (SER) systems still have poor performance due to a lack of speech emotion datasets. This paper proposes augmenting SER systems with synthetic emotional speech generated by an end-to-end text-to-speech (TTS) system based on an extended Tacotron 2 architecture. The proposed TTS system includes encoders for speaker and emotion embeddings, a sequence-to-sequence text generator for creating Mel-spectrograms, and a WaveRNN to generate audio from the Mel-spectrograms. Extensive experiments show that the quality of the generated emotional speech can significantly improve SER performance on multiple datasets, as demonstrated by a higher mean opinion score (MOS) compared to the baseline. The generated samples were also effective at augmenting SER performance."
130,"To optimize generative AI cybersecurity, business should establish rules and best practices for how to use generative AI technology in a secure manner."
131,"The article provides information on generative artificial intelligence (AI), which is being utilized by healthcare organizations in the U.S. Topics discussed include how generative AI works, remarks from John Brownstein, chief innovation officer at Boston Children's Hospital, and two school of thoughts on the potential of ChatGPT in healthcare."
132,"Pandurang Kamat, CTO of Persistent Systems, discussed generative AI's impact on customer service, navigating AI challenges, and responsible AI."
133,"Fairly Trained, a new non-profit firm, is offering certifications to generative AI systems that have been trained on ""consented"" data. The company aims to make it clear which AI companies prioritize creator consent and fair treatment. Led by CEO Ed-Newton Rex, Fairly Trained requires companies to meet certain prerequisites, such as obtaining data through contractual agreements or open licenses. The certification process involves a submission fee and an annual certification fee, and companies can have their certification rescinded if they change their training data practices. So far, eight startups have been certified by Fairly Trained."
134,"Artificial intelligence (AI) is likely to revolutionize businesses on how they communicate with their customers and advertise their products/services on social media platforms. Recently, businesses have started to implement generative AI tools for social media communication. In addition, there are four broad areas of generative AI tools: text, image, audio, and code generation; while all these AI tools use single inputs (e.g., text prompts) for outcomes. Thus, Gen-2 is coming which offers even multi-modal AI solutions that enable businesses to use diverse modes of inputs such as texts and visual stimuli (images), etc. They provide an opportunity to create videos in any style using text prompts, or videos can be generated with a driving image and text prompts. Despite increased attention from businesses and researchers, domains such as AI-infused content (e.g., visuals, texts, and both) and customer engagement behavior need to be investigated. Therefore, this research seeks to reveal what kind of effect AI-infused visuals generate on customer responses (i.e., attention, emotions) on social media platforms. Six visuals for X brand were created using a generative AI tool. Machine learning solution for the intrinsic memorability of visuals and neuromarketing technique (RealEye) (i.e., eye-tracking, emotion measurement) were integrated. The findings showed that AI-generated visuals demonstrate high memorability scores (M=0.8); thus, visuals elicited surprise emotions in customers. Meanwhile, eye-tracking data indicated that customers pay attention to unusual (e.g., the third hand) and common attributes of brand-initiated cues (e.g., logo letters). More neuromarketing research is needed regarding stimuli nature - a human touch to AI content and types (images, videos)."
135,"The article focuses on the readiness of generative artificial intelligence (AI) for customer service. Topics include its potential to enhance content creation, speed up data analysis and improve agent workflows. It also mentioned the Forrester research report which emphasizes that it's not yet suitable for customer-facing use, due to various risks and issues."
136,"The article focuses on the potential of generative Artificial intelligence (AI) to revolutionize chemical engineering processes by automating tasks and streamlining design processes. It discusses the integration of large language models (LLMs) into various aspects of chemical engineering, from problem-solving in classrooms to automating tasks like P&ID generation. It also envisions a future where different AI models work together seamlessly to accelerate chemical plant design and operation."
137,"Generative adversarial networks can be exploited to launch attacks against detection systems that rely on artificial intelligence (AI). To build effective cyberphysical systems that are operationally robust and socially accepted, we must expend significant effort to develop novel AI-based safety-critical systems."
138,"Cloud communications provider Dialpad introduces domain-specific generative AI. Learn more about DialpadGPT."
139,"Discover how AI in general differs from generative AI and how they combine to improve decision making, accuracy and results."
140,"Danel Dayan, Principal at Battery Ventures, discussed trends driving AI, and also looked ahead at the future of generative AI."
141,"The BMC executive discussed the challenges posed by generative AI and also gave advice on optimizing enterprise AI deployments."
142,"eWEEK content and product recommendations are editorially independent. We may make money when you click on links to our partners. Learn More. Generative AI models are powerful tools that data scientists are using to create powerful results, from content creation to improved data analytics performance. Yet it's becoming apparent that many users are not aware [...]"
143,"Gharib Gharibi, Head of AI for TripleBlind, talked about how to handle generative AI issues like inaccuracy and bias, and also forecast the arrival of the Singularity."
144,"Enterprise use cases for generative AI include everything from writing marketing copy to discovering new pharmaceuticals."
145,"Using Twitter, industry experts will discuss and debate the best way for companies to navigate the many challenges and opportunities posed by generative AI."
146,"Find out the similarities and differences that exist between generative AI and machine learning and how they work together to provide insight into the world around us."
147,"Generative AI models are highly scalable, accessible artificial intelligence solutions that are getting enormous publicity as they supplement and transform various business operations."
148,"Generative AI ethics is a growing concern as this AI technology gains rapid adoption. Plus: tips for creating an AI ethics policy for your company."
149,"The ThoughtSpot CEO details how generative AI is changing the data analytics market."
150,"Enterprise use cases for generative AI include everything from writing marketing copy to discovering new pharmaceuticals."
151,"The article explores the role of ""prompt engineers"" as a professional title, extending beyond the field of generative AI for developers, comparing certain tasks to the role of librarians, such as conducting search queries. It is possible for librarians to work with AI models in conjunction with traditional literature databases with emphasizing the need to recognize the distinct nature of these information resources. We should take cautious consideration of the specific skills worth acquiring to improve work efficiency, as well as an understanding of the development trends in generative AI and library science."
152,"Amazon is planning to lay off several hundred workers in its Alexa division as it shifts its focus to generative AI. The company has been developing generative AI systems, which have resulted in new offerings such as a tool for generating copy listings on its e-commerce platform. Amazon stated that these job cuts will impact staff working on Alexa-related efforts, but emphasized that the investments in generative AI are bringing them closer to their vision for a more intuitive and intelligent Alexa. This is not the first time Amazon has undertaken layoffs, as they have already cut back on their devices and services team in the past year."
153,"A recent survey conducted by Salesforce reveals that a significant number of employees are using generative AI without authorization from their employers. The survey, which included 14,000 full-time workers in 14 countries, found that 28% of respondents are using generative AI at work, with over half of them doing so without approval. Another 32% of respondents plan to start using generative AI soon. The lack of clear policies regarding the usage of generative AI is leaving enterprises vulnerable to security risks, with 73% of respondents in a previous survey stating that generative AI comes with security risks. Additionally, 64% of surveyed employees admitted to passing off generative AI work as their own, and 41% may consider overstating their generative AI skills to secure job opportunities. The lack of training on using generative AI safely and ethically is also a concern, with 70% of workers having received no training in this area."
154,"M365 Copilot, Microsoft's generative AI tool, explained: Microsoft's generative AI assistant is integrated within a host of the company's workplace apps. Microsoft expects revenue related to M365 Copilot to ""grow gradually over time"", Microsoft CFO Amy Hood said during the company's Q1 2024 earnings call. Microsoft will extend Copilot's reach into other apps workers use via ""plugins"" -- essentially third-party app integrations. To help businesses deploy the generative AI tool across their data, Microsoft created the Semantic Index for Copilot, a ""sophisticated map of your personal and your company data"", and a ""pre-requisite"" to adopting Copilot within an organization."
155,"Spending on generative AI over the four year period to 2027 is expected to reach a compound annual growth rate (CAGR) of 73.3%, a figure which IDC says is more than twice the rate of growth in overall AI spending and almost 13 times greater than the CAGR for worldwide spending on IT over the same period. Enterprise spending on generative AI services, software and infrastructure will skyrocket over the next four years, jumping from $16 billion this year to $143 billion in 2027, according to technology research and advisory firm IDC."
156,"Generative IT for Apple admins Jamf believes generative AI can be a big benefit to tech support and IT admin, and talked about its efforts at the end of an extensive Jamf Nation User Conference (JNUC) keynote. These solutions are very much works in progress, but you don't need a weatherman to see the way in which this wind blows: Generative AI will become an essential part of every IT admin's tool kit across a multitude of enterprise tools."
157,"The article discusses the growing use of generative artificial intelligence (AI) in marketing and highlights the need for guardrails and human supervision in its deployment. It notes that generative AI, including models like ChatGPT, DALL-E, Stable Diffusion, and Midjourney, has gained significant attention in various sectors, especially in marketing and advertising. Additionally, it recommends leveraging partnerships and external resources for successful generative AI deployment."
158,"The article focuses on report on teachers concluding interaction with artificial intelligence (AI) systems to be key skills needed for jobs in the future. Topics discussed include shift of education systems across the world to exclude or accomodate AI tools such as ChatGPT from students, need of adapting account for students use of AI generated content accepted by secondary school teachers, and lack of belief of teachers in rural areas of digital literacy as priority for school."
159,"Apple CEO Tim Cook has confirmed that the company is working on generative AI and plans to announce new features in this area before the end of 2024. Cook expressed excitement about the potential of gen AI and AI for Apple. Speculation suggests that Apple's implementation of AI could have deep links with its existing devices and its newest device, Vision Pro. Competitors such as Google, Meta, and Microsoft are already investing heavily in AI, and Apple's entry into the market could have a significant impact. However, only time will tell if Apple's AI efforts will be successful."
160,"Google Sheets now offers a new generative AI tool called Help Me Organize, which can create customized templates for project schedules, budgets, charts, and more. This tool, part of Google Workspace's genAI technology called Duet AI, generates tables with headings, placeholder text, and possible formulas based on user prompts. While the tool is currently only available for paying Workspace customers, those without a Workspace account can request access to Workspace Labs to try out new features. Users can access Help Me Organize from a spreadsheet in Google Sheets, write a prompt to describe the desired template, and then insert the generated template into their spreadsheet. It is important to note that the templates should be considered rough drafts and may require modifications to suit specific needs. The article provides tips on writing effective prompts and using the tool to its full potential."
161,"The National Science Foundation (NSF) has announced the National Artificial Intelligence Research Resource (NAIRR) pilot program, which aims to democratize access to generative AI (genAI) for organizations that do not have the financial resources of major tech companies or government departments. The program will provide access to datasets, AI models, and training for researchers through partnerships with federal agencies and the private sector. The goal is to support novel research into genAI and its application to various domains, while also addressing the exclusivity and expense of genAI resources. The pilot program will run for two years and will be organized into four key areas: NAIRR Open, NAIRR Secure, NAIRR Software, and NAIRR Classroom. Researchers can access the resources through an online portal, and a call for proposals will be available in spring 2024."
162,"Apple is reportedly investing heavily in artificial intelligence (AI) to enhance its virtual assistant, Siri, and compete with rivals. The company has acquired 21 AI start-ups since 2017 and is expected to make a significant acquisition in the space this year. Apple aims to develop an on-device generative AI solution, utilizing its existing chips and innovations to enable on-device intelligence. The company's plans for AI will likely be discussed at the Worldwide Developers Conference in June."
163,"BBEdit, a popular Mac text editing tool, has integrated generative AI (genAI) technology to assist developers in building projects. Users can have text-based conversations with the genAI tool within a worksheet, eliminating the need for copy and paste. This implementation by BBEdit demonstrates a focused and narrow use case for genAI, which is likely to be the most useful for pro users. Other Mac apps, such as swiftGPT and MacWhisper, have also integrated support for genAI. The integration in BBEdit suggests that Apple's own genAI models, rumored to be released at WWDC 2024, may benefit developers using Xcode."
164,"BBEdit, a popular Mac text editing tool, has integrated generative AI (genAI) technology to assist developers in building projects. Users can have text-based conversations with the genAI tool within a worksheet, eliminating the need for copy and paste. BBEdit's implementation focuses on providing the most useful features for its customers, particularly developers, and hints at the emergence of more narrow and defined use cases for AI technology. This integration is significant as Bare Bones, the company behind BBEdit, is led by Rich Siegel, a well-known industry thought leader, suggesting that other developers across Apple's platforms may adopt similar approaches."
165,"Perplexity AI, a generative AI search engine startup, has raised $73.6 million in funding from investors including Nvidia, Databricks, and Jeff Bezos. The company aims to answer users' questions in a conversational style, eliminating the need to click on multiple links or compare answers. While Perplexity AI faces competition from other startups in the market, its high valuation and backing from prominent tech leaders suggest potential for disruption in the search industry. The company plans to use the funds to expand its offerings and grow its user base."
166,"Generative AI may not be suitable for all tasks due to the high costs associated with training and running the technology. The deployment of systems like ChatGPT will likely encounter limitations and unforeseen consequences. The use of genAI will strain existing social and economic systems, and the hype surrounding it will eventually be tempered by real-life challenges. Apple's approach of finding specific domains to deploy genAI aligns with the understanding that not every task will benefit from this technology. The most successful genAI deployments will be those that have a meaningful impact on people's lives. Apple's considered approach to AI deployment reflects its tendency to thoroughly evaluate technologies before implementing them. When Apple introduces its own genAI models, they may appear more limited but potentially more profound. The future of genAI will likely be within focused domains where machine intelligence and data analytics optimize human activity. The AI bubble may burst quickly, but the technology itself will continue to be widely used where it makes sense. Apple is already looking ahead to life after the bubble and considering the implications."
167,"According to Counterpoint, nearly 1 billion smartphones equipped with generative AI (genAI) are expected to be shipped by 2027, and Apple is likely to be among the companies producing these devices. While Apple has been criticized for being late to the genAI party, it has been investing billions in research and development (R&D) and has plans to expand AI capabilities in its products. Apple aims to bring a smarter Siri to market by the end of the year and is working on running computationally intensive tasks on the device itself, rather than relying on server-based services. However, competing products that use server-based services are also advancing, so Apple faces challenges in maintaining its position in on-device AI."
168,"The article focuses on KX's launch of KDB.AI Server, a high-performance vector database designed for time-oriented generative artificial intelligence (AI) and contextual search. Topics include the ease of deployment across various environments, the incorporation of temporal and semantic context into AI applications, and the optimization for retrieval augmented generation (RAG) patterns."
169,"Generative AI has seen a significant rise in its performance and use in various fields, including academia, art, design, and software engineering. How-ever, little research has been conducted on how users interact with AI tools. This article proposes a research project that focuses on the elicitation of positive psychological experiences, such as flow, when an individual is fully immersed in a task and feels highly effective and satisfied. The study aims to investigate how AI tools may promote flow experiences by regulating cognitive load to flow-conducive levels through providing initial solutions to demanding tasks or shifting user demands from monotonous tasks to more challenging ones. The study will utilize wearable EEG recordings to generate objective insights into the dynamics of cognitive load and flow during early project stages. The research could lead to the development of neuro-adaptive recommender agents that propose AI invocation when un-desirable load levels are detected."
170,"The top technology stories of 2023 highlight the impact of generative AI and geopolitical tensions on the tech industry. The ouster and rehiring of Sam Altman as CEO of OpenAI due to concerns about the release of AI products exemplifies the conflict between commercial interests and the need for safe AI systems. The US Department of Justice's antitrust trial against Google, along with other ongoing cases against big tech companies, reflects growing unease about their dominance. Layoffs in the tech industry, regulatory scrutiny of mergers, cybersecurity breaches, and the expansion of chip export curbs to China are also significant developments. Additionally, the introduction of Apple's Vision Pro mixed-reality headset and the return-to-office mandates by companies like Zoom indicate shifts in the tech landscape. The letter signed by tech leaders warning about the risks of AI underscores the need for global attention and regulation in this field."
171,"Athenahealth, a healthcare technology provider, has been using AI for years to improve efficiency in processing healthcare requests and records. Recently, they adopted generative AI (genAI) through OpenAI's ChatGPT platform, which has allowed them to introduce new capabilities across their product line. These capabilities include intelligent summarization of patient healthcare documents and identifying missing or incorrect information before submitting a prior authorization for care. Athenahealth has invested in educating their employees on AI and has created an AI team to explore new ways of utilizing the technology. They have also taken measures to ensure the security and privacy of their sensitive healthcare data when working with AI models."
172,"Deloitte's annual 2024 Government Technology Trends report highlights six technology-related trends that are expected to be popular in the coming year. These trends include virtual reality and digital twinning for training and improving infrastructure, generative artificial intelligence (AI), different types of CPUs, GPUs, and custom chips, streamlining developer tasks to increase productivity, managing cyber threats and misinformation, and developing technical wellness plans. The report emphasizes the importance of local governments staying ahead of the technological curve to ensure the security of their constituents. It also discusses the challenges faced by local governments in adapting to evolving technology and the benefits of advancements in computing technology and AI."
173,"Generative AI examples are growing rapidly as generative AI moves toward mainstream adoption. Examples are found in nearly every industry, from healthcare to cybersecurity."
174,"A list of the leading generative AI startups -- these are the companies that will shape the future of generative AI."
175,"ChatGPT and Google Bard are both generative AI platforms. But which generative AI tool offers the greatest potential for competitive advantage?"
176,"Abstract<bold>What is the educational challenge?</bold>Incorporation of large language model (LLM) or generative artificial intelligence (AI) software poses a challenge to various areas of medical education, including problem-based learning (PBL). LLMs, such as ChatGPT, have incredible potential to transform educational systems and enhance student learning outcomes when used responsibly.<bold>What are the proposed solutions?</bold>ChatGPT can provide several ways to support students and assist facilitators with course responsibilities. Here we address factors of implementation and describe how ChatGPT can be responsibly utilized to support key elements of PBL.<bold>How was the solution implemented?</bold>Providing reasonable access is an essential element of novel software implementation. Additionally, training for both faculty and staff is vital to foster responsible usage, provide base-line proficiency, and guide users to critically evaluate the quality of output.<bold>What lessons were learned that are relevant to a wider audience?</bold>The use of LLMs or other generative AI is dramatically rising in the world. Appropriate and conscientious incorporation of AI into educational programs can foster responsible use and potentially enhance student learning.<bold>What are the next steps?</bold>Assessment of learning outcomes, student self-efficacy, group dynamics, and stakeholder feedback are required to measure the effects of ChatGPT in the PBL curriculum. Additionally, software programs competitive with ChatGPT are currently under development and will also need to be investigated for their potential role in education."
177,"The GPU and AI market leader unveils updates to Jetson for AI and robotics"
178,"A recent report from Bloomberg Philanthropies and the Centre for Public Impact reveals that while there is significant interest among mayors in using generative artificial intelligence (AI) to improve city services and efficiency, adoption rates remain low. The report found that 96% of city staff members expressed interest in using generative AI, and 78% of the 80 mayors surveyed said they are interested or extremely interested in its use. However, only 2% of cities reported actively using generative AI, with 69% testing or exploring the technology. The main barriers to adoption cited by mayors include budget constraints, technical expertise, and ethical considerations. Bloomberg Philanthropies has launched a web-based platform called City AI Connect to help officials develop and test AI applications, with 100 cities currently participating."
179,"Samsung has announced its own generative AI framework called Gauss, which will be integrated into its future products. Gauss is named after German mathematician Carl Friedrich Gauss, who made significant contributions to algebra and normal distribution theory. The framework consists of three core functions: Samsung Gauss Language, which performs generative AI tasks with text; Gauss Code, a code generation tool for software development; and Gauss Image, which generates creative images. Samsung has also emphasized its commitment to security and privacy guidelines for responsible AI development. While Gauss is currently being used internally, there is no specific timeline for public deployments."
180,"The article highlights Forrester's view on leveraging generative AI and traditional methods to enhance CX in 2024. It emphasizes the challenges and opportunities in deploying generative AI for improving customer experience, cautioning against biased or harmful experiences while urging strategic alignment of resources and budgets to ensure successful CX initiatives."
181,"We did put in place some controls, such as data loss prevention to make sure even unintentionally there is no exploitation of this technology to pull out data -- both IP and customer [personally identifiable information]. Q&A: How one CSO secured his environment from generative AI risks: Having a plan in place before deploying genAI for software product development and employee assistance tools is critical, says Navan CSO Prabhath Karanth. In February, travel and expense management company Navan (formerly TripActions) chose to go all-in on generative AI technology for a myriad of business and customer assistance uses. Speaking of CyberHaven, a recent report by them showed about one in 20 employees paste company confidential data into just chatGPT, never mind other in-house AI tools."
182,"Work management software company Smartsheet unveiled its next-generation platform today, debuting features designed to provide users with new generative-AI powered capabilities at scale. From their workday And with this announcement, we're giving customers more and better ways to visualize their work in Smartsheet"", said Ben Canning, senior vice president of product experiences at Smartsheet, during a press conference."
183,"The new generative AI tool is fueled by a large language model(LLM) that Amazon has been developing internally, as revealed byCEO Andy Jassy during the company's first-quarter earnings call inApril. News The e-commerce giant has become the latest company tooffer generative AI capabilities to its customers, rollingout a new tool that creates copy for sales listings basedon written prompts Amazon has launched a new generative AI tool that creates copylistings for users selling items on the company's e-commerceplatform."
184,"In addition to the capabilities on offer within Firefly,Adobe is also introducing a new credit-based model forgenerative AI across its newly launched Firefly webapplication, Express Premium and Creative Cloud paidplans, set to come into force from November 1. News The new generative AI image creation and editingtool has been trained on stock images and content in thepublic domain Adobe on Wednesday announced the commercial release ofFirefly, a suite of generative AI models that arenatively integrated throughout Adobe Creative Cloud apps,including Generative Fill and Generative Expand inPhotoshop, and Generative Recolor in Illustrator."
185,"The article focuses on the readiness of generative Artificial intelligence (AI) for various applications, emphasizing the distinction between traditional AI and generative AI and the potential advantages and challenges posed by the latter. It discusses the capabilities of generative AI in content creation and highlights the importance of caution when utilizing large language models (LLMs) to avoid misinformation and risks related to proprietary data."
186,"The article focuses on exploring the potentials and challenges of generative Artificial intelligence (AI) in the context of knowledge management (KM) through a webinar titled ""Recent Trends in Generative AI."" It experts discuss how generative AI can revolutionize KM, emphasizing its role in dynamic content generation, discovery automation, and enhancing data potential."
187,"The article focuses on the significance of search, particularly in the context of knowledge management, and the complexities and challenges associated with it. Topics include the integration of Generative Artificial intelligence (AI) and Large Language Models (LLMs) in search solutions, investment plans in Generative AI, and practical applications of AI and Generative AI, such as expanding insights beyond customer experience and transforming chatbots into conversational virtual assistants."
188,"The article focuses on the adoption of generative artificial intelligence by Chief Revenue Officers in their go-to-market organizations. It mentions that according to Gartner, it is predicted that by 2025, 35 percent of CROs will establish generative AI operations teams within their organizations. It foresees that the adoption of generative value messaging will enhance sales execution, optimize resource utilization and enable content customization for business-to-business revenue organizations."
189,"The article focuses on how intelligent search, content analytics, and large language models, particularly in the context of generative Artificial intelligence (AI), are revolutionizing support processes in Customer Service, Human Resource Management, and Maintenance. It highlights how these technologies can streamline ticket management, enhance self-service, and provide proactive insights, ultimately improving employee and customer engagement in these functional areas."
190,"The article offers information on the ChatGPT, a form of generative artificial intelligence (AI), help with a number of work processes. It further discusses that its a type of AI technology that can produce various types of content including text, imagery, audio and synthetic data; views of Carla Bevins, assistant teaching professor of business communication at Carnegie Mellon University's Tepper School of Business, on issue; and also mentions about content promotion and distribution."
191,"The article focuses on the potential of the metaverse and its impact on customer experience. It highlights the ability of the metaverse to display various types of information, optimize processes, resolve customer service issues, and facilitate collaboration. It also discusses the role of generative AI technologies, such as ChatGPT, Bing, and Bard, in enabling these experiences."
192,"What is a ""defensible business model"" in a tech landscape shaped by generative AI?"
193,"Krishna Subramanian, COO at Komprise, discusses the data management problems companies face when they use generative AI. She suggested a number of potential solutions."
194,"The generative AI landscape is expanding rapidly, and offers great benefits even as it presents enormous challenges."
195,"The article provides information on generative artificial intelligence (AI) and its potential integration into the healthcare sector. It raises concerns about AI-powered ChatGPT chatbot including health equity and quality issues, accuracy of information, exposure of sensitive patient information and noncompliance with the Health Insurance Portability and Accountability Act (HOPAA) of 1996. It reports the monitoring of private data repositories by healthcare organizations when testing ChatGPT."
196,"These leading generative AI tools generate text, audio, images, videos, and 3D models."
197,"Generative artificial intelligence is an AI model with benefits across industries such as retail, manufacturing, and data science."
198,"While generative artificial intelligence (AI) could benefit the ever-evolving healthcare industry, AI faces challenges in the healthcare sector."
199,"Bratin Saha, Vice President, AI & Machine Learning at AWS, details Amazon's new initiative in generative AI, and also discusses current and future trends in artificial intelligence."
200,"These top generative AI companies are creating the future of artificial intelligence."
201,"While it offers enormous potential, generative AI must be approached with caution and ethics to ensure it is used only for defensive purposes."
202,"Generative AI is poised to have a profound impact on businesses and society. Find out about this emerging AI technology."
203,"Artificial intelligence that creates: Generative AI models can carry on conversations, answer questions, write stories, produce source code, and create images and videos of almost any description. ChatGPT and DALL-E are interfaces to underlying AI functionality that is known in AI terms as a model. The emergence of generative AI Generative AI has been around for years, arguably since ELIZA, a chatbot that simulates talking to a therapist, was developed at MIT in 1966."
204,"Microsoft has introduced Copilot Studio, an automation platform that allows businesses to customize their own genAI assistant. This platform enables enterprise users to tailor Microsoft's Copilot generative AI tool to their specific workflows and create and publish their own AI assistants. Copilot Studio provides access to a wide range of applications and pre-built connectors, allowing workers to interact with relevant corporate data. Users can create custom responses and tailor interactions with employees, reducing the time required to create a genAI assistant for a specific purpose."
205,"Microsoft plans to integrate its Copilot generative AI assistant into a mixed-reality app called Dynamics 365 Guides, which provides step-by-step instructions to field workers. The integration will allow factory technicians to use natural language and physical gestures to interact with Copilot, asking for guidance on repairs and maintenance. The Copilot will search files for relevant information and present it via mixed-reality ""holograms"" overlaid on the physical equipment. This integration aims to reduce the time needed to manage and maintain industrial equipment and provide frontline workers with personalized insights to resolve issues faster."
206,"Collaborative design platform provider Figma has added a suite of generative AI features to its FigJam whiteboarding software to help users produce, summarize, and sort meeting content. FigJam's new native AI features are powered by OpenAI and will be free for all customer tiers at today's launch."
207,"The article discusses the establishment of Task Force Lima by the Defense Department to explore the potential use of generative artificial intelligence, such as large language models like ChatGPT and Bard, in military missions. Topics include the task force's focus on evaluating generative AI capabilities, addressing challenges like ""hallucinations,"" and the importance of cost considerations for the widespread adoption of this technology within the department."
208,"M365 customers that access Copilot will be required to procure a minimum of 300 Copilot seats, which is ""still a bit of a steep hill to climb. Efforts to deploy it safely and effectively Less than a year after generative AI (genAI) made a splash with the public launch of OpenAI's ChatGPT 3.5, Microsoft is about to make its Copilot assistant available within its ecosystem of productivity and collaboration applications."
209,"An introduction is presented in which the editor discusses articles in the issue on topics including the impact of generative Artificial intelligence (AI), particularly ChatGPT, on chemical engineering, highlighting its various applications but also emphasizing the need for ethical direction."
210,"Though companies are still in the discovery phase of how AIcan benefit them on a daily basis, vendors are quickly jumpingon the bandwagon, said Margo Visitacion, principal analyst forportfolio management and enterprise architecture atForrester. News Work management software company Smartsheet hasreleased a new version of its platform built for scale, addinggenerative AI capabilities to help users eliminate mundanetasks from their workday Work management software company Smartsheet unveiledits next-generation platform today, debuting featuresdesigned to provide users with new generative-AI poweredcapabilities at scale."
211,"A chip shortage not only creates problems for tech firms making LLMs, but also for user companies seeking to tweak models or build their own proprietary LLMs. AI language models need to shrink; here's why smaller may be better: Large language models (LLMs) used for generative AI tools can consume vast amounts of processor cycles and be costly to use. For example, a user organization could connect ChatGPT to its back-end applications and databases with native APIs; the genAI tool can then draw on that proprietary company information for more business-specific uses."
212,"Google and Microsoft, which also sell team collaboration applications, have been pushing ahead with their own genAI pilot projects with customers, for instance, and, in the case of Google, already bringing the technology to market. LLMs are prone to hallucinations -- the output of incorrect information in response to user prompts -- and for Slack, acknowledging the problem has been part of the genAI development process of. Here's how Slack envisions adding genAI to its software: Slack is already working to include new generative AI tools in its popular collaboration app."
213,"Financial services and small-business software providerIntuit will be rolling out an ""Intuit Assist"" feature toall of its major product lines, including TurboTax andQuickBooks, building on the development of its owngenerative AI operating system. News Generative AI may be helping businesses and consumersalike as of tax season, as Intuit rolls out Assist, an AIassistant designed to bring new functionality toTurboTax, QuickBooks, and more."
214,"In addition to controlling the use of ChatGPT and other standalone tools, companies now have to grapple with generative AI being built into the productivity apps their employees use every day Companies have already started on this journey, elevatingdata literacy among their employees as part of their push tobecoming a data-driven enterprise, said Omdia's Shimmin."" DLP (data loss prevention) tools can help companies keepsensitive data from leaving the company. Often, a company's security team might not even know that aparticular application used by the company has now addedgenerative AI tools, he said."
215,"In this paper, I will investigate how two competing visions of machine intelligence put forward by Alan Turing and J. C. R Licklider - one that emphasized automation and another that emphasized augmentation - have informed experiments in computational creativity, from early attempts at computer-generated art and poetry in the 1960s, up to recent experiments that utilise Machine Learning to generate paintings and music. I argue that while our technological capacities have changed, the foundational conflict between Turing's vision and Licklider's vision plays itself out in generations of programmers and artists who explore the computer's creative potential. Moreover, I will demonstrate that this conflict does not only inform technical/artistic practice, but speaks to a deeper philosophical and ideological divide concerning the narrative of a post-human future. While Turing's conception of human-equivalent AI informs a transhumanist imaginary of super-intelligent, conscious, anthropomorphic machines, Licklider's vision of symbiosis underpins formulations of the cyborg as human-machine hybrid, aligning more closely with a critical post-human imaginary in which boundaries between the human and technological become mutable and up for re-negotiation. In this article, I will explore how one of the functions of computational creativity is to highlight, emphasise and sometimes thematise these conflicting post-human imaginaries."
216,"B2B professionals should treat AI as a complementary tool to achieve a higher level of consumer engagement – not as a replacement for humans."
217,"The Informatica CEO discusses the challenges that companies face with scaling AI, including the need for ethics and compliance 'guardrails.'"
218,"Telco modernization will enable telcos to leverage AI to deliver a wide range of new services and automate operations."
219,"This suggests that as AI tools advance and people use it more and more, there's a good chance that, at least initially, the combination of AI and visually impaired workers will be greater than the sum of the parts. Gen AI could level the playing field The need to use a tool such as generative AI will be far greater for those with vision problems, so once they're provided with it, these workers should become proficient quickly."
220,"""Companies creating AI technology have a responsibility to ensure that it is safe, secure, and remains under human control"", Brad Smith, Microsoft vice chair and president, said in a statement. Google, OpenAI, Microsoft, and Anthropic will be the founding members of the Frontier Model Forum, an umbrella group for the generative AI industry."
221,"How can local governments regulate generative AI - Just ask ChatGPT It is important to note that the regulation of generative AI is a rapidly evolving field, and local governments should engage with experts, stakeholders and the wider AI community to develop informed and effective regulatory approaches. Hardly a day goes by without some new warning or danger being reported about artificial intelligence (AI) and, in particular, generative AI."
222,"The article focuses on the benefits of generative Artificial intelligence (AI) in improving the findability of content on websites. It discusses how generative AI can reduce the reliance on traditional FAQs, streamline search experiences, and reduce costs while highlighting the importance of combining AI-driven search with human oversight for optimal results."
223,"Since announcing a partnership with ChatGPT creatorOpenAI earlier this year, Microsoft has been deployingits Copilot generative AI assistant across its suite ofMicrosoft 365 business productivity and collaborationapps. To help businesses deploy the AI assistant across theirdata, Microsoft created the Semantic Index for Copilot, a""sophisticated map of your personal and your companydata"", and a ""pre-requisite"" to adopting Copilot withinan organization. Feature Microsoft's generative AI assistant is about to beintegrated in a host of workplace apps."
224,"And if they aren't able toarticulate what they want to another human, their ability todirect a faster, non-human AI is going to be inadequate, too.The AI tool will respond to what it thinks it was asked and,unless it has some kind of unique filter, should spit out aresult faster. Windows Into The Future Opinion Chatter about generative AI is seemingly everywhere thesedays, and seemingly overhyped. Generative AI and app creation One of the big problems when working with IT or acontractor to create an application is that communicationbetween the parties tends to be suboptimal."
225,"Cisco relies on in-house AI technology In order to develop these capabilities, Cisco is using its own large language models rather than working with other third-party generative AI vendors. Cisco is adding new generative AI capabilities to its Webex collaboration platform, aimed at increasing productivity through automated meeting and conversation summaries."
226,"The article offers information on what the nurse leaders need to know when using generative artificial intelligence (AI) in practice settings, including the definition of generative AI, its benefits in nursing and the best practices for use."
227,"Large language models (LLMs) are the foundation of chatbots like OpenAI's ChatGPT and Google's Bard. LLMs are trained on massive amounts of data, including articles, books, and internet resources, to generate human-like responses to natural language queries. They work by predicting the next word based on what they have already seen. LLMs can be biased if the data they ingest is biased, and prompt engineering is a process that allows users to train LLMs for specific purposes. Smaller LLMs are being developed to reduce costs and improve efficiency. However, there are concerns about privacy, security, and ethical use of data collected by LLMs. Efforts are being made by governments and organizations to regulate and govern AI tools."
228,"Thomson Reuters has developed a genAI platform to address the increasing demand for industry-specific information and stay ahead of competitors. The cloud-based platform integrates with Microsoft Copilot and allows employees and clients to build new AI skills using reusable components. The company has successfully rolled out three AI-enabled solutions for attorneys and plans to continue developing more. The genAI platform has enabled non-technologists to experiment with AI and contribute to innovation and ideation. Privacy and security are prioritized throughout the development process to ensure compliance with data-sensitive industries."
229,"This article discusses the challenges and considerations that enterprise executives face when choosing a partner for generative artificial intelligence (genAI) projects. The author emphasizes the importance of trust and verification in selecting a genAI partner, as companies are entrusting sensitive data to third-party providers. The article suggests that a combination of building in-house models, relying on big players like AWS or Google, and working with smaller specialty companies may be the most effective approach. The author also highlights concerns about data security, the ability to audit third-party operations, and the lack of visibility into adversarial attacks on AI systems."
230,"Sedgwick, a global insurance claims administrator, has implemented generative artificial intelligence (genAI) to streamline its document summarization process. The genAI tool, called Sidekick, uses OpenAI's GPT-4 to accurately summarize multi-page claims documents. Sedgwick has successfully piloted the tool, processing over 14,000 documents and receiving overwhelmingly positive feedback. The company plans to expand the use of genAI and integrate it into their claims system to further improve efficiency and provide prescriptive recommendations to examiners."
231,"A new study by Kaspersky Research suggests that generative artificial intelligence (genAI) could help address skills shortages in the job market. The study found that 40% of surveyed C-level executives plan to use genAI tools like ChatGPT to automate tasks and fill critical skills gaps. However, 91% of respondents admitted to not fully understanding how genAI works. While genAI offers benefits, there are concerns about high costs, uncertain return on investment, and potential exposure of sensitive data. Forrester Research predicts that genAI will replace 90,000 jobs in 2023 and 2.4 million jobs by 2030, but job losses will be lower than expected."
232,"The widespread adoption of advanced technologies, such as Artificial Intelligence (AI), Machine Learning, and Robotics, is rapidly increasing across the globe. This accelerated pace of change is drastically transforming various aspects of our lives and work, resulting in what is now known as Industry 4.0. As businesses integrate these technologies into their daily operations, it significantly impacts their work tasks and required skill sets. However, the approach to technological transformation varies depending on location, industry, and organization. However, there are no published methods that can adequately forecast the adoption of technology and its impact on society. It is essential to prepare for the future impact of Industry 4.0, and this requires policymakers and business leaders to be equipped with scientifically validated models and metrics. Data-driven scenario planning and decision-making can lead to better outcomes in every area of the business, from learning and development to technology investment. However, the current literature falls short in identifying effective and globally applicable strategies to predict the adoption rate of emerging technologies. Therefore, this paper proposes a novel parametric mathematical model for predicting the adoption rate of emerging technologies through a unique data-driven pipeline. This approach utilizes global indicators for countries to predict the technology adoption curves for each country and industry. The model is thoroughly validated, and the paper outlines highly promising evaluation results. The practical implications of this proposed approach are significant because it provides policymakers and business leaders with valuable insights for decision-making and scenario planning."
233,"Generative AI refers to machine learning algorithms that can form new meaning from unstructured or structured input, such as text, images, and video."
234,"The article focuses on the concerns and risks associated with generative AI tools like ChatGPT. It raises questions about the spread of misinformation, liability for content, professional obligations, education implications, bias in AI, privacy, and sustainability, among other issues. It author emphasizes the need to carefully consider the implications of these tools as they become more prevalent."
235,"The article focuses on the cautious approach that Forrester Research advises customer service organizations to take when implementing artificial intelligence (AI) technology, particularly generative bots and chatbots. Topics discussed include the limitations of optimizing chatbots and interactive voice response systems, with diminishing returns expected beyond a certain percentage."
236,"The article focuses on the policy of the Journal of Children's Orthopaedics (JCO) regarding the use of large language models (LLMs) and generative AI by authors in preparing their articles. Topics include the recognition of LLMs as valuable productivity tools with limitations; the importance of human intervention to ensure accuracy and appropriateness of content; and the potential biases, inaccuracies, and contextual understanding challenges associated with the use of LLMs in submissions."
237,"Amazon's intent to overhaul its search feature inside its application comes at a time when rivals such as Microsoft and Google have been adding their own generative AI engine across their product portfolio. Amazon is working on infusing generative AI features akin to OpenAI's ChatGPT and Google's Bard AI to its shopping application and website in an effort to provide a more conversational experience, job postings on the company's career section indicate."
238,"Slack GPT brings native generative AI to chat app: Not long after announcing its ChatGPT integration, Slack has unveiled plans to incorporate generative AI features such as conversation summaries directly into its collaboration platform. It expanded on those plans Thursday at parent company Salesforce's World Tour event with the unveiling of Slack GPT, which will see generative AI integrated directly into the Slack app in a variety of ways. Slack's popularity as a workplace collaboration platform provides it with some important advantages when incorporating generative AI, said Ali Rayl, Slack's vice president of customer experience."
239,"Using generative AI to code is dangerous for a variety of reasons, but its efficiencies will tempt corporate leaders -- especially CIOs and business execs -- to use it anyway. Do the productivity gains from generative AI outweigh the security risks? Hodgson noted Saha's comments about AI efficiencies being highest when replacing junior coders."
240,"Do the productivity gains from generative AI outweigh the security risks? Hodgson noted Saha's comments about AI efficiencies beinghighest when replacing junior coders. Using generative AI to code is dangerous for a variety of reasons, but its efficiencies will tempt corporate leaders -- especially CIOs and business execs -- to use it anyway."
241,"In the very near future, its possible everything from brand assets to illustrations will be partially created using Adobe's creative and enterprise apps and its own generative AI, Firefly Adobe enters the age of generative AI with creative and enterprise apps: Reality? Soon, apparently, everything from brand assets to corporate videos to illustrations will be created differently using Adobe's creative and enterprise apps and its generative AI tool Firefly."
242,"Generative artificial intelligence (AI), applied to power simulation technologies, offers profound opportunities to supplement practitioner workflows in crisis management, conceptualized by Coombs as the prevention, preparation, response, and revision phases. Synthesizing insights from crisis management and computer science, I envision how such tools could aid crisis practitioners in decision-making and communication, augmenting processes for the identification of organizational risks and the iteration of communication strategies and content. I then discuss opportunities, risks, and critical outstanding questions and ethical considerations given current and foreseeable instantiations of AI in driving simulation tools for crisis management."
243,"Where does that data go?"" Data analytics expert Pam Baker -- author of Data Divination: Big Data Strategies -- saw the Zoom move as potentially even more dangerous. Zoom goes for a blatant genAI data grab; enterprises, beware (updated): Zoom stirred up a kerfuffle this month when it amended its terms of service to make execs comfortable that it wouldn't use Zoom data to train generative AI models. Zoom discussed this in a blog post: ""There is certain information about how our customers in the aggregate use our product -- telemetry, diagnostic data, etc."
244,"As generative AI becomes entrenched in our everyday lives, concerns about the potential consequences of biased models on minority groups need to be addressed, says Google cloud executive Helen Kelisky However, an AI system can only be as good as the data it is trained on, and with humans controlling the data and criteria behind every AI-enhanced solution, more diverse human input means better results. Q&A: Why does Google care so much about hiring diverse AI teams?."
245,"Generative AI, led by Microsoft and Microsoft-backed OpenAI, has turned into what seems an unstoppable juggernaut. Multibillion-dollar lawsuits against Microsoft and OpenAI The FTC move isn't the only legal action Microsoft and OpenAI face. The seemingly unstoppable juggernaut launched by OpenAI late last year might soon run into headwinds from the FTC, the EU -- and in court."
246,"Bloomberg (which also today reported plans for Apple to buy Disney), says Apple has crafted its own internal framework to build LLM models. Apple has created its own generative AI tools to compete with large language model (LLM) services such as ChatGPT or Google Bard, Bloomberg reported on Wednesday."
247,"News The updates introduced at the company's annualInspire conference also include a new Sales Copilot andtwo new copilot abilities for Micosoft's Dynamics 365marketing suite. Related: * Generative AI * Microsoft 365 * Productivity Software * ERP Systems * Enterprise Applications * Microsoft Microsoft."
248,"Where we need AI to focus When it comes to productivity improvements, the first step must be to analyze where improvements are needed, identify the critical paths, and then develop a plan that will have the greatest impact on productivity at the lowest cost. Years ago, one of my clients had a ""productivity problem"" and instituted a program called ""back to basics"" -- employees had to clock-in and clock-out because management was convinced they were skipping out on work. Digital transformation, AI, and the productivity problem: There's a lot of talk about generative AI could boost productivity at companies in the midst of digital transformation."
249,"News The idea is that IT admins can use natural languageto create scripts for fleets of managed Macs Apple Vision may mix reality, but the news hasn't shiftedthis year's big storyline: the steady progress ofGenerative AI. The company has introduced Mosyle AIScript, which it saysis the first generative AI-powered macOS scripting tool.The thinking is that IT admins can use natural languagewith it to create scripts to manage Mac hardware fleets. Related: * Apple * Mobile Device Management * IT Management * MacOS * Genterative AI."
250,"Adobe's latest product offering is Firefly, a generative-AI powered image maker that is designed to be ""safe for commercial use"" -- so much so that Adobe is offering IP indemnification for any legal issues arising from its use. The indemnification offer is similar to the one available for Adobe's Stock assets product -- though not, according to an Adobe spokesperson, identical."
251,"One of the bills introduced in the Senate necessitates US government bodies or agencies to let citizens or users know when AI is being used to interact with them. US lawmakers on Thursday introduced two bills related to artificial intelligence in the Senate as the proliferation of the technology continues to gather momentum after the launch of Microsoft-owned OpenAI's generative AI driven ChatGPT and Google's Bard."
252,"The article discusses the potential risks and implications of generative Artificial Intelligence such as copyright infringement, as it relies on content created by others. It explores the conflicting interests between protecting intellectual property and promoting AI development, and highlights the challenges of proving liability and ensuring accuracy in AI-generated content."
253,"The DataStax executive discusses generative AI's relationship with the cloud, private data centers and data analytics."
254,"AI Chat Bots such as ChatGPT are revolutionizing our AI capabilities, especially in text generation, to help expedite many tasks, but they introduce new dilemmas. The detection of AI-generated text has become a subject of great debate considering the AI text detector’s known and unexpected limitations. Thus far, much research in this area has focused on the detection of AI-generated text; however, the goal of this study was to evaluate the opposite scenario, an AI-text detection tool's ability to discriminate human-generated text. Thousands of abstracts from several of the most wellknown scientific journals were used to test the predictive capabilities of these detection tools, assessing abstracts from 1980 to 2023. We found that the AI text detector erroneously identified up to 8% of the known real abstracts as AI-generated text. This further highlights the current limitations of such detection tools and argues for novel detectors or combined approaches that can address this shortcoming and minimize its unanticipated consequences as we navigate this new AI landscape."
255,"Or imagine a competitor gaining access to thiskind of information; they could effectively create a digitalclone of the firm -- and use it to better anticipate andmore aggressively respond to competitive actions by thecompany using generative AI. It gets better -- and worse Once you aggregate training sets across a company, you couldgain insights about the firm's operations that could lead toa far more efficient and profitable company. Opinion Windows Into The Future While AI-based tools could deliver a major boost inproductivity and efficiency, there's a dark side to them, aswell Generative AI continues to take the world by storm, butthere are growing concerns this technology could, if notaggressively managed and regulated, do a great deal of harm."
256,"New types of jobs might be needed down the road, from achief AI officer to AI trainers, auditors, and promptengineers who understand how to create queries tailored foreach generative AI tool so you get the results you want. Indeed, generative AI ""can be wrong more than it's right,""says Alex Zhavoronkov, CEO of Insilico Medicine, apharmaceutical and AI firm that has based its businessmodel around generative AI."
257,"Cisco At a briefing this week, Cisco announced plans to use AI aggressively to manage and secure networks. Generative AI tools can be a force for good -- increased productivity, new skills -- or bad, if workers can be replaced. Microsoft's move is foundational in that it will force users of Microsoft products to learn how to interact with AI tools and make those users more valuable as AI moves into more products."
258,"Google has added code generation and debugging capabilities to its generative AI offering, dubbed Bard AI, in response to rival offerings from Microsoft's GitHub Copilot and Amazon CodeWhisperer. GitHub Copilot, which uses OpenAI's GPT-3 engine for providing generative AI capabilities, has already announced its next iteration Copilot X and expects to add more advanced generative AI-based capabilities to the software tool."
259,"News As generative AI continues to roil the tech industry, governmentsaround the world are starting to consider regulation in order tocombat its potential to aid criminality and promote bias. The news comes on the same day that the CyberspaceAdministration of China (CAC) unveiled a number of draft measuresfor managing generative AI services, including making providersresponsible for the validity of data used to train generative AI tools."
260,"Opinion Generative AI is here to stay, and companies arealready finding innovate ways to roll it into theirproducts Generative artificial intelligence (AI), particularlyChatGPT, has taken an AI market that seemed far off intothe future and quickly catapulted it into our world. Generative AI could look at an email sentfrom someone else and craft a recommended response,allowing Ballmer (or anyone who hates writing emails) toappear much more empathetic and engaged withoutsignificantly increasing their workload. This tool would have allowed Ballmer todo his limited-response thing, but still deliver a far morecomplete email."
261,"DuckDuckGo, the search engine focused on user privacy, announced today that it is rolling out an AI-powered instant answer service, which it calls DuckAssist, as part of a larger plan to integrate AI across its product lineup. DuckAssist, in broad strokes, is a generative AI system that uses technology from ChatGPT makers OpenAI as well as another generative AI company, Anthropic, to generate its own answers to certain types of question."
262,"The past decade has represented something of an AI summer both for researchers looking to improve AI learning capabilities and companies seeking to deploy AIs. If the frothy bubble of business expectations around generative AI builds to unsustainable levels and eventually bursts, that could also dampen future AI development in general, says Sasha Luccioni, an AI research scientist at Hugging Face. ChatGPT is very far from that goal but, on 22 March, AI researchers such as Yoshua Bengio and tech industry figures such as Elon Musk signed an open letter asking research labs to pause giant AI experiments, while referring to AIs as ""nonhuman minds that might eventually outnumber, outsmart, obsolete and replace us"". 2022 OpenAI makes an AI chatbot known as ChatGPT publicly available, accelerating a scramble to commercialise generative AI and large language models. mid-2023 The European Union passes its Artificial Intelligence Act."
263,"AbstractWith the advancement of AI, even people without professional experience can create artworks using AI-based image generation systems like DALL-E 2. However, little is known about how users interact with these new AI algorithms, much less how AI-infused systems can be designed. We explore the user experience of these new technologies and their potential to foster creativity. A user study was carried out where 13 participants executed tasks of creating artworks using DALL-E 2 alongside in-depth interviews related to their experience. The results showed that users had ambivalent opinions regarding the algorithm’s performance. When users were informed of the system’s capabilities, they subsequently utilized more specific prompts to generate the intended output. Users also optimized their prompts (the queries they entered to create artworks) based on how algorithms worked to achieve their desired outcome. The users wanted a two-way interaction where AI explained the outcome and accepted feedback rather than simply accepting unilateral instructions. We discuss the implications for designing interfaces that maximize creativity while providing comfort for the users."
264,"The article highlights the collaboration between United States Steel and Google Cloud to develop generative artificial intelligence (GenAI) applications for the manufacturing industry, aiming to enhance efficiencies and improve employee experiences. The first GenAI-driven application is set to streamline equipment maintenance, save time and costs, and boost productivity."
265,"The market for software that uses artificial intelligence (AI) to automate tasks and generate content in response to user prompts is expected to grow nearly four-fold through 2027. AI AD&D Software represents tools and platforms used primarily by developers to build, test, and deploy software, such as AI-powered app development, AI-powered data management, and AI-powered app platforms."
266,"""Think of it as the process of interacting with a machine to get it to produce the results you'd like"", said Sameer Maskey, a Columbia University AI professor and CEO of Fusemachines, an AI consultancy. So important that Erick Brethenoux, an adjunct professor at the Illinois Institute of Technology, said all of his engineering graduate students have put artificial intelligence (AI) prompt-engineering skills on their resumes and LinkedIn profiles."
267,"The article focuses on the challenges posed by generative artificial intelligence (GAI) to the balance between copyright and free speech in the publishing industry. Topics include how GAI's ability to mimic human responses challenges copyright protection, the application of fair use in the context of GAI-generated content, and the need for the publishing industry to actively shape the future of AI through legislation, licensing, and curated data sets."
268,"Google today announced it is embedding its conversational,Bard chatbot into many of its most popular apps, allowing users to get human-like responses to questions, summarize Gmail messages, and search Google Docs and Youtube. Microsoft has added ChatGPT functionality to its suite of Microsoft 365 business productivity and collaboration apps through its own Copilot chatbot assistant."
269,"Background: Generative Artificial Intelligence (AI) technology, for instance Chat Generative Pre-trained Transformer (ChatGPT), is continuously evolving, and its userbase is growing. These technologies are now being experimented by the businesses to leverage their potential and minimise their risks in business operations. The continuous adoption of the emerging Generative AI technologies will help startups gain more and more experience with adoptions, helping them to leverage continuously evolving technological innovation landscape. However, there is a dearth of prior research on ChatGPT adoption in the startup context, especially from Entrepreneur perspective, highlights the urgent need for a thorough investigation to identify the variables influencing this technological adoption. The primary objective of this study is to ascertain the factors that impact the uptake of ChatGPT technology by startups, anticipate their influence on the triumph of companies, and offer pragmatic suggestions for various stakeholders, including entrepreneurs, and policymakers. Method and analysis: This study attempts to explore the variables impacting startups' adoption of ChatGPT technology, with an emphasis on comprehending entrepreneurs' attitudes and perspectives. To identify and then empirically validate the Generative AI technology adoption framework, the study uses a two-stage methodology that includes experience-based research, and survey research. The research method design is descriptive and Correlational design. Stage one of the research study is descriptive and involves adding practical insights, and real-world context to the model by drawing from the professional consulting experiences of the researchers with the SMEs. The outcome of this stage is the adoption model (also called as research framework), building Upon Technology Adoption Model (TAM), that highlight the technology adoption factors (also called as latent variables) connected with subset of each other and finally to the technology adoption factor (or otherwise). Further, the latent variables and their relationships with other latent variables as graphically highlighted by the adoption model will be translated into the structured questionnaire. Stage two involves survey based research. In this stage, structured questionnaire is tested with small group of entrepreneurs (who has provided informed consent) and finally to be distributed among startup founders to further validate the relationships between these factors and the level of influence individual factors have on overall technology adoption. Partial Least Squares Structural Equation Modeling (PLS-SEM) will be used to analyze the gathered data. This multifaceted approach allows for a comprehensive analysis of the adoption process, with an emphasis on understanding, describing, and correlating the key elements at play. Discussion: This is the first study to investigate the factors that impact the adoption of Generative AI, for instance ChatGPT technology by startups from the Entrepreneurs perspectives. The study's findings will give Entrepreneurs, Policymakers, technology providers, researchers, and Institutions offering support for entrepreneurs like Academia, Incubators and Accelerators, University libraries, public libraries, chambers of commerce, and foreign embassies important new information that will help them better understand the factors that encourage and hinder ChatGPT adoption. This will allow them to make well-informed strategic decisions about how to apply and use this technology in startup settings thereby improving their services for businesses."
270,"Psoriatic arthritis (PsA) is a chronic inflammatory systemic disease whose activity is often assessed using the Disease Activity Score 28 (DAS28-CRP). The present study was designed to investigate the significance of individual components within the score for PsA activity. A cohort of 80 PsA patients (44 women and 36 men, aged 56.3 ± 12 years) with a range of disease activity from remission to moderate was analyzed using unsupervised and supervised methods applied to the DAS28-CRP components. Machine learning-based permutation importance identified tenderness in the metacarpophalangeal joint of the right index finger as the most informative item of the DAS28-CRP for PsA activity staging. This symptom alone allowed a machine learned (random forests) classifier to identify PsA remission with 67% balanced accuracy in new cases. Projection of the DAS28-CRP data onto an emergent self-organizing map of artificial neurons identified outliers, which following augmentation of group sizes by emergent self-organizing maps based generative artificial intelligence (AI) could be defined as subgroups particularly characterized by either tenderness or swelling of specific joints. AI-assisted re-evaluation of the DAS28-CRP for PsA has narrowed the score items to a most relevant symptom, and generative AI has been useful for identifying and characterizing small subgroups of patients whose symptom patterns differ from the majority. These findings represent an important step toward precision medicine that can address outliers."
271,"Developing compounds with novel structures is important for the production of new drugs. From an intellectual perspective, confirming the patent status of newly developed compounds is essential, particularly for pharmaceutical companies. The generation of a large number of compounds has been made possible because of the recent advances in artificial intelligence (AI). However, confirming the patent status of these generated molecules has been a challenge because there are no free and easy-to-use tools that can be used to determine the novelty of the generated compounds in terms of patents in a timely manner; additionally, there are no appropriate reference databases for pharmaceutical patents in the world. In this study, two public databases, SureChEMBL and Google Patents Public Datasets, were used to create a reference database of drug-related patented compounds using international patent classification. An exact structure search system was constructed using InChIKey and a relational database system to rapidly search for compounds in the reference database. Because drug-related patented compounds are a good source for generative AI to learn useful chemical structures, they were used as the training data. Furthermore, molecule generation was successfully directed by increasing and decreasing the number of generated patented compounds through incorporation of patent status (i.e., patented or not) into learning. The use of patent status enabled generation of novel molecules with high drug-likeness. The generation using generative AI with patent information would help efficiently propose novel compounds in terms of pharmaceutical patents. Scientific contribution: In this study, a new molecule-generation method that takes into account the patent status of molecules, which has rarely been considered but is an important feature in drug discovery, was developed. The method enables the generation of novel molecules based on pharmaceutical patents with high drug-likeness and will help in the efficient development of effective drug compounds."
272,"Large language models are the algorithmic basis for chatbots like OpenAI's ChatGPT and Google's Bard. What are LLMs, and how are they used in generative AI? When LLMs focus their AI and compute power on smaller datasets, however, they perform as well or better than the enormous LLMs that rely on massive, amorphous data sets. The chatbot's foundation is the GPT large language model (LLM), a computer algorithm that processes natural language inputs and predicts the next word based on what it's already seen."
273,"Microsoft advances mixed-reality plans with Teams avatars, Mesh update: Though generative AI was the main focus at Build this year, Microsoft is still working on a ""metaverse"" for the workplace Amid the numerous AI-related announcements at its Build developer conference this week, Microsoft also delivered updates on key aspects of its vision of a workplace ""metaverse"", with the release of avatars for Teams and private previews of its Mesh mixed-reality tools. Avatars within Teams are now generally available to Microsoft 365 Business and Enterprise customers via the Teams desktop client for macOS and Windows."
274,"Adobe has thrown a grenade at the heart of the creative industries with the introduction of generative AI-driven features in the latest beta of its classic creative application, Photoshop. The beta release of Photoshop is Adobe's first Creative Cloud application to integrate Firefly, though it's worth pointing out the company has been integrating AI in its products ever since it introduced Adobe Sensei."
275,"Altman suggested the US government craft a three-point AI oversight plan: Form a government agency charged to license large AI models and revoke those that don't meet government standards. Leaders of the Group of Seven (G7) nations on Saturday called for the creation of technical standards to keep artificial intelligence (AI) in check, saying AI has outpaced oversight for safety and security. G7 leaders warn of AI dangers, say the time to act is now: Over the weekend, G7 members met to discuss a variety of issues, including one topic not normally on the agenda: the dangers of generative AI."
276,"ChatGPT's paid subscribers gain access this week to plugins allowing access to websites and Bing internet search, according to Microsoft-backed OpenAI, the creator of the generative AI application. Plugins, including browsing, will roll out to users of ChatGPT's paid tier, which was dubbed ChatGPT Plus on its release in February."
277,"In October, the administration unveiled a blueprint for a so-called ""AI Bill of Rights"" as well as an AI Risk Management Framework; more recently, it has pushed for a roadmap for standing up a National AI Research Resource. The Biden administration today announced a new effort to address the risks around generative artificial intelligence (AI), which has been advancing at breakneck speeds and setting off alarm bells among industry experts. Technologies such as ChatGPT."
278,"The article focuses on Accenture's report highlighting generative artificial intelligence (AI) and other rapidly evolving technologies as catalysts for a future where the physical and digital worlds become interconnected."
279,"Generative AI is about to destroy your company. Stunningly, some enterprise execs seem to be just fine with that -- as long as AI continues to code quickly and for so little money One option that's been bandied about would see junior programmers, who can be more efficiently replaced by AI than experienced coders, retrained as cybersecurity specialists who could not only fix AI-generated coding problems but handle other security tasks."
280,"You can highlighta term and ask Atlassian Intelligence to explain it withthe definition, source of information, internal subjectmatter experts, and how it connects to related work basedon the teamwork graph, Atlassian said. News The new AI capabilities, dubbed AtlassianIntelligence, are designed to help workers be moreefficient while ensuring users remain in controlof data Atlassian is rolling out new generative AI capabilitiesthat will be embedded in the company's entire portfolio ofworkforce management cloud products and are designed tohelp both service-based and project-based work teams bemore efficient."
281,"Though Apple doesn't yet have its own Designed InCupertino take on Generative AI waiting in the wings, it'sinevitable that as the risks of the ChatGPT model becomemore widely understood, the demand for private andsecure access to similar tools will only expand. Apple Holic Opinion Enterprise professionals may be buying into thegenerative AI hype without considering the risk of theseLLMs."
282,"Windows Into The Future Opinion Change is coming fast for many companies, courtesya raft of new AI-based tools like ChatGPT. At the moment,companies are focused on generative AI tools such asChatGPT -- largely because Microsoft is tacking hardto this technology."
283,"Artificial intelligence should help, not hinder,workers Where other collaboration and work management platforms havebeen adding generative AI capabilities to their offerings inrecent months, the new features unveiled by Asana todayrepresent ""pre-AI"" era, Hood said, while trying to give asense of the company's roadmap. News Work management platform Asana has announced three newfeatures designed to provide greater cross-organizationaltransparency and improved insights into how employees arecollaborating."
284,"The LLM used by Bard is a lightweight variant of LaMDA, Google's main natural-language processing model. Search and hyperscale computing giant Google said today that it has opened up access to Bard, a generative AI chatbot meant to compete with similar services offered by Microsoft and OpenAI, among others."
285,"The article discusses the role of librarians in helping patrons work with generative artificial intelligence (AI). Topics include the potential of this technology to automate repetitive, time-consuming task in many different fields, impact of the growing concern about the potential impact of generative AI on the jobs of screenwriters and actors, and ethical concerns on generative AI."
286,"Q&A: ChatGPT isn't sentient, it's a next-word prediction engine: Consulting firm Ernst & Young is already educating clients on how to create business models around generative AI engines like ChatGPT. Does hosting this AI-based chatbot technology eat a lot of CPU cycles and energy? But the heavy hype is creating unrealistic expectations, says Dan Diasio, EY's global artificial intelligence consulting leader Dan Diasio, EY's global artificial intelligence consulting leader, works with CIOs from Fortune 500 companies and has a deep understanding of generative AI and how it can benefit businesses."
287,"Generative AI expands the race for search and meaning - Implications for society and government Early this month Google's parent company Alphabet lost $1 billion in market value in one day when their highly promoted rollout of its new Bard AI search engine ad showing a factual error. When it comes to generative artificial intelligence (AI) the public is ready - but is the technology?."
288,"The article focuses on the use of Generative Artificial Intelligence (AI) models to improve content findability and employee productivity in the changing business landscape. Topics include the integration of Generative AI in intelligent search engines, the use of SmartFAQs and SmartSuggest products to automatically generate content and user intents, and the practical value of Generative AI for large organizations."
289,"The article discusses the potential of artificial intelligence (AI) in the field of talent development (TD). It emphasizes the need for understanding the capabilities and limitations of AI and the importance of actively shaping its application in TD. The article explains the two broad categories of AI: generative and nongenerative, and highlights their strengths and weaknesses. It explores the various ways in which generative AI can be integrated into talent development, such as automating tasks, personalizing learning experiences, and providing performance support. The article also addresses the challenges and ethical considerations associated with AI integration and emphasizes the necessity of continuous learning and experimentation in this rapidly evolving field."
290,"The article offers information on integrating AI generative technology into education to enhance productivity, focusing on AI literacy for K–12 students. Topics include the background on AI, the potential and pitfalls of generative AI like ChatGPT, and introducing AI concepts to students. AI, evolving since the 1950s, has become integral in daily life, and generative AI has the transformative potential to revolutionize education."
291,"Generative AI tools, such as ChatGPT, have gained popularity and have been used for various purposes, including writing papers, generating music, and solving math problems. However, these tools can also produce misinformation and amplify biases. The development of AI systems has a long history, with early programs like ELIZA attempting to simulate conversation. While AI systems like ChatGPT show promise in reasoning, they are not equivalent to human thinking. The field of generative AI is evolving, with researchers exploring applications in fields like medicine and the military. However, there are concerns about the risks associated with these tools, such as cybersecurity and privacy issues. While AI can enhance efficiency, human ingenuity is still necessary to address the challenges that arise."
292,"As a large number of companies continue to test and deploy generative artificial intelligence (genAI) tools, many are at risk of AI errors, malicious attacks, and running afoul of regulators -- not to mention the potential exposure of sensitive data. About half of respondents to The Harris Poll, which was commissioned by systems integration services vendor Insight Enterprises, indicated they're embracing AI to ensure product quality and to address safety and security risks. -- and to avoid running afoul of regulators."
293,"During the past few months, Microsoft has been integrating Copilot widely across its various products, with versions of the AI assistant tailored to Dynamics, Microsoft 365, Power Platform, Security products, and others currently under development. But the effects of automation will be felt more widely, says Microsoft, which is bringing its Copilot AI assistant to applications used by those in frontline roles, whether that's retail workers or technicians out in the field. Microsoft 365 Copilot."
294,"Sales Copilot added to Microsoft 365 and Dynamics 365 Microsoft has also added a new role-based copilot, dubbedSales Copilot, as part of its Microsoft 365 and Dynamics365 offerings. News The updates introduced at the company's annualInspire conference also include a new Sales Copilot and twonew copilot abilities for Micosoft's Dynamics 365 marketingsuite."
295,"Apple Holic News The idea is that IT admins can use natural language tocreate scripts for fleets of managed Macs. Apple, Mac, macOS, Management, MDM, Mosyle Related: * Apple * Mobile Device Management * IT Management * MacOS * Genterative AI."
296,"""OpenAI and other responsible AI developers are aware of this risk and encourage ethical use of AI to prevent the spread of disinformation. Features Features IN OCTOBER 2021, Phil Howard, an internet researcher at the University of Oxford, was alerted to a preposterous story on social media. On one side are the social media giants and the bad actors who flood their services with malign information, now armed with generative AI. ""If the training data includes examples of disinformation or misleading information, the AI model may learn to generate similar content when prompted with certain cues."
297,"Generative artificial intelligence (AI) technology is increasingly being used to create resumes and cover letters, and according to a new survey by Resume Builder, using a chatbot improves your chances of getting the job. ""Job seekers who use ChatGPT for their cover letters and/or resumes are really no different than those going to a resume writing service or using readily available templates and online tools"", Stacie Haller, Resume Builder's chief career advisor, said in a statement."
298,"Meta, Google and Snap are preparing for generative AI, as the technology has caught on with consumers through products such as ChatGPT and they see it as a powerful tool in advertising and creator economies. Google's all-in on AI Pichai opened Google's Feb. 2 earnings call with a litany of AI developments."
299,"The gathering AI storm between Microsoft and Google: Microsoft caught Google off-guard with its recent push into generative AI, which could have big ramifications for search. Microsoft this week caught Google napping when it comes tothe future of online search -- much as Google caughtMicrosoft napping almost two decades ago when it came tothe future of web browsers. Google was blindsided because protecting search only becameimportant when it realized Microsoft was going to useChatGPT to challenge Google's leadership."
300,"It didn't help that Netscape's management made the samekind of errors Microsoft would later on with the Zune laterand tried to chase Microsoft's market dominance. Microsoft's mixed reality and generative AI moves -- girding for war? If Microsoft wants to come out ahead now, it needs toacquire a leading technology and then focus companyresources on making it a defining competitive advantageacross the Microsoft ecosystem."
301,"ChatGPT and other generative artificial intelligence (AI) programs like DALL-E are often thought of as a way to get rid of workers, but that isn't their real strength. A lot of people seem to think tools like DALL-E and ChatGPT are all about replacing workers."
302,"• We propose to solve the image deraining problem from the perspective of feature-wise disentanglement. • An end-to-end learning deraining model Asynchronous Interactive Generative Adversarial Network (AI-GAN) is proposed. • AI-GAN separates the background and rain images based on a two-branch architecture and achieves complementary optimization. • AI-GAN outperforms state-of-the-art deraining methods and benefits a large range of multimedia applications. Single image rain removal plays an important role in numerous multimedia applications. Existing algorithms usually tackle the deraining problem by the way of signal removal, which lead to over-smoothness and generate unexpected artifacts in de-rained images. This paper addresses the deraining problem from a completely different perspective of feature-wise disentanglement, and introduces the interactions and constraints between two disentangled latent spaces. Specifically, we propose an Asynchronous Interactive Generative Adversarial Network (AI-GAN) to progressively disentangle the rainy image into background and rain spaces in feature level through a two-branch structure. Each branch employs a two-stage synthesis strategy and interacts asynchronously by exchanging feed-forward information and sharing feedback gradients, achieving complementary adversarial optimization. This 'adversarial' is not only the 'adversarial' between the generator and the discriminator, but also means that the two generators are entangled, and interact with each other in the optimization process. Extensive experimental results demonstrate that AI-GAN outperforms state-of-the-art deraining methods and benefits various typical multimedia applications such as Image/Video Coding, Action Recognition, and Person Re-identification."
303,"Faking on personality tests continues to be a challenge in hiring practices, and with the increased accessibility to free, generative AI large language models (LLM), the difference between human and algorithmic responses is difficult to distinguish. Four LLMs–GPT-3.5, Jasper, Google Bard, and GPT-4 were prompted to provide ideal responses to personality measures, specific to a provided job description. Responses collected from the LLM's were compared to a previously collected student population sample who were also directed to respond in a ideal fashion to the same job description. Overall, score comparisons indicate the superior performance of GPT-4 on both the single stimulus and forced-choice personality assessments and reinforce the need to consider more advanced options in preventing faking on personality assessments. Additionally, results from this study indicate the need for future research, especially as generative AI improves and becomes more accessible to a range of candidates. • Examined whether generative AI can outperform humans in faking personality. • University students were used as the human comparators. • Both single stimulus and forced-choice assessments were utilized. • Variability existed in generative AI faking performance. • ChatGPT-4 was the clear winner, easily faking both types of assessments."
304,"As advancements in artificial intelligence (AI) technology have opened new avenues for artistic expression and creation, human‐AI collaboration in creative activities has garnered increasing attention. Through semi‐structured interviews with 15 participants, we investigate the intrinsic and extrinsic factors that motivate laypeople's engagement with AI painting, as well as challenges and concerns faced by users. Our findings reveal that laypeople engage with AI painting for emotional needs like entertainment, aesthetics, surprise, and curiosity, personal utilitarian needs such as self‐expression and customization, and social interaction through sharing and communication. Despite the appeal of novelty and unpredictability they also encountered challenges related to technical and system functionality, personal and environmental factors, as well as concerns about algorithm bias, pornography misuse, employment risks, copyright disputes and ethical implications. Findings provide preliminary evidence of the potential and limitations of AI in democratizing creative activities, and offer implications for designing and developing of AI assistance tools."
305,"Artificial intelligence (AI) has an increasing presence in scholarship, posing new challenges and opportunities for qualitative researchers. Generative AI, such as Chat-GPT, can supposedly produce humanlike responses, which has implications for online qualitative research, which relies on human participation. In this paper, we contribute to debates about AI as a research participant (‘AI-as-participant’) and the threat of imposter participation in qualitative research. We share our unexpected encounter with AI during our story completion study on mobile dating during the COVID-19 pandemic and discuss how we identified AI responses within our dataset. Central to our analysis was our theoretical grounding of feminist new materialism, which attuned us to the affective and discursive qualities of our participant data. Using our theoretical lens, in tandem with other strategies, we examined the affective forces that signalled stark differences between previous, human-generated data and that of the current study. Analysing the discursive construction of narratives further alerted us to the absence of humans within our data. We conclude that AI cannot sufficiently replicate affect or capture the richness of human experience that is central to qualitative research, and offer recommendations for future researchers to anticipate and check for AI as an unwelcome research participant."
306,"Generative artificial intelligence (AI) systems, such as large language models (LLMs), have achieved remarkable performance in various tasks such as text and image generation. We discuss the foundations of generative AI systems by comparing them with our current understanding of living organisms, when seen as active inference systems. Both generative AI and active inference are based on generative models, but they acquire and use them in fundamentally different ways. Living organisms and active inference agents learn their generative models by engaging in purposive interactions with the environment and by predicting these interactions. This provides them with a core understanding and a sense of mattering, upon which their subsequent knowledge is grounded. Future generative AI systems might follow the same (biomimetic) approach – and learn the affordances implicit in embodied engagement with the world before – or instead of – being trained passively. Prominent accounts of sentient behavior depict brains as generative models of organismic interaction with the world, evincing intriguing similarities with current advances in generative artificial intelligence (AI). However, because they contend with the control of purposive, life-sustaining sensorimotor interactions, the generative models of living organisms are inextricably anchored to the body and world. Unlike the passive models learned by generative AI systems, they must capture and control the sensory consequences of action. This allows embodied agents to intervene upon their worlds in ways that constantly put their best models to the test, thus providing a solid bedrock that is – we argue – essential to the development of genuine understanding. We review the resulting implications and consider future directions for generative AI."
307,"AbstractThis study offers a critical examination of university policies developed to address recent challenges presented by generative AI (GenAI) to higher education assessment. Drawing on Bacchi’s ‘What’s the problem represented to be’ (WPR) framework, we analysed the GenAI policies of 20 world-leading universities to explore what are considered problems in this AI-mediated assessment landscape and how these problems are represented in policies. Although miscellaneous GenAI-related problems were mentioned in these policies (e.g. reliability of AI-generated outputs, equal access to GenAI), the primary problem represented is that students may not submit original work for assessment. In the current framing, GenAI is often viewed as a type of external assistance separate from the student’s independent efforts and intellectual contribution, thereby undermining the originality of their work. We argue that such problem representation fails to acknowledge how the rise of GenAI further complicates the process of producing original work and what it means by originality in a time when knowledge production becomes increasingly distributed, collaborative and mediated by technology. Therefore, a critical silence in higher education policies concerns the evolving notion of originality in the digital age and a more inclusive approach to address the originality of students’ work is required."
308,"Because for all the promise of this kind of AI, the game to make it run natively on edge devices has already begun, and Apple has put so much work into building its Neural Engine it would seem strange if it didn't have a few cards to play. Appleholic, (noun), æp- l-h l- k: An imaginative person who thinks about what Apple is doing, why and where it is going. Apple Silicon."
309,"News The cloud content-management company has announced it will beintegrating ""advanced AI models"" into its Box Content Cloud to helpcustomers surface information and generate content. The new Box AI capabilities will be powered by OpenAI's ChatGPTAPI and at launch, will only be available inside the Box ContentCloud, although the company said it has plans to embed Box AIacross the Box product suite and support more complex use cases."
310,"The article offers information on launch of three new products by Appen Limited, the provider of high-quality data for the artificial intelligence (AI) lifecycle."
311,"News Zoom announced a new host of AI-backed capabilities forits ""smart companion"" tool, doubling down on its CEO'spromise of helping customers benefit from the technology. Similarly, Zoom IQ Email Compose takes the conversational contextfrom prior Zoom Meetings, Zoom Phone calls, and email threads todraft email suggestions. Video conferencing platform Zoom plans to expand its smartcompanion, Zoom IQ, and will work with OpenAI to bolster a moreflexible approach to AI, it said Monday."
312,"Opinion Microsoft's AI efforts took a big step forward thisweek with the unveiling of Microsoft 365 Copilot. Related: * Artificial Intelligence * Microsoft 365 * Microsoft * Microsoft Office (Microsoft is a client of the author.)."
313,"Computing giant Google announced today that it will release previews of three new AI features, including AI composition for Google Workspace, developer prototyping and coding via PaLM and MakerSuite, and validated models for its Vertex AI service. The final major piece announced today by Google is the new functionality for Vertex AI, which is aimed at letting companies use Google's own technology to create and customize their own AI applications."
314,"The article offers information on the ongoing technological trends in libraries, emphasizing the potential impact of fast-evolving technologies like generative AI. While traditional trends in library management systems and discovery services have unfolded over years, generative AI, exemplified by ChatGPT, has rapidly influenced education, business, and society within just a year."
315,"Unlike classical artificial intelligence (AI), generative AI has the potential to transform scientists into intellectual cyborgs. Leveraging embodied cognition and extended mind theories can help us understand this scientific revolution. Despite ethical concerns, generative AI can enhance research efficiency and accessibility. However, this requires unprecedented proactive regulation and responsible development."
316,"The article suggests environmental public health departments to build capacity with artificial intelligence (AI). It provides basic steps on using ChatGPT to start chat sessions to generate information on topics. It points out the limitations of generative AI such as volume of text it can accept for each prompt and specific date of events. A sample policy for environmental health departments on the use of generative AI that includes bias and harm reduction, security and privacy is presented."
317,"The use of AI in PR has been underway for years but has taken on new relevance as AI becomes more sophisticated and agencies are tasked to bolster the public reputation of brands. Brand and corporate PR - which has historically relied on interpersonal communications - is increasingly being influenced by artificial intelligence as public relations agencies adopt AI tools to monitor and place stories about their clients."
318,"But companies(and people) should embrace what's coming There's a lot of tech industry excitement these days abouttools like ChatGPT and DALL-E that fall into a class calledgenerative AI. Opinion There's a lot of buzz around ChatGPT and DALL-E rightnow -- and a lot of litigation brewing. Thesustaining skill will be learning how to properly directthis new class of AI to reduce the number of iterationsneeded to align what a user wants with what the AI creates."
319,"This article examines the effects of generative AI, specifically ChatGPT, on schools and education. Through focus groups with educational leaders, the authors found that there is a lack of understanding about the technology and a desire for more guidance from experts. The leaders discussed the potential benefits of generative AI for personalized instruction but also raised concerns about academic integrity and access to the technology. Overall, the article highlights the challenges and opportunities that generative AI presents in the education system, emphasizing the need for support and guidance in its implementation."
320,"Abstract In November 2022, OpenAI has introduced ChatGPT – a chatbot based on supervised and reinforcement learning. Not only can it answer questions emulating human-like responses, but it can also generate code from scratch or complete coding templates provided by the user. ChatGPT can generate unique responses which render any traditional anti-plagiarism tool useless. Its release has ignited a heated debate about its usage in academia, especially by students. We have found, to our surprise, that our students at POLITEHNICA University of Bucharest (UPB) have been using generative AI tools (ChatGPT and its predecessors) for solving homework, for at least 6 months. We therefore set out to explore the capabilities of ChatGPT and assess its value for educational purposes. We used ChatGPT to solve all our coding assignments for the semester from our UPB Functional Programming course. We discovered that, although ChatGPT provides correct answers in 68% of the cases, only around half of those are legible solutions which can benefit students in some form. On the other hand, ChatGPT has a very good ability to perform code review on student programming homework. Based on these findings, we discuss the pros and cons of ChatGPT in a teaching environment, as well as means for integrating GPT models for generating code reviews, in order to improve the code-writing skills of students."
321,"The objective of this study was to explore the feasibility of current 3D reconstruction in assessing the position of maxillary impacted canines from 2D panoramic X-rays. A dataset was created using pre-treatment CBCT data from a total of 123 patients, comprising 74 patients with impacted canines and 49 patients without impacted canines. From all 74 subjects, we generated a dataset containing paired 2D panoramic X-rays and pseudo-3D images. This pseudo-3D image contained information about the location of the impacted canine in the buccal/lingual, mesial/distal, and apical/coronal positions. These data were utilized to train a deep-learning reconstruction algorithm, a generative AI. The location of the crown of the maxillary impacted canine was determined based on the output of the algorithm. The reconstruction was evaluated using the structure similarity index measure (SSIM) as a metric to indicate the quality of the reconstruction. The prediction of the impacted canine's location was assessed in both the mesiodistal and buccolingual directions. The reconstruction algorithm predicts the position of the impacted canine in the buccal, middle, or lingual position with 41% accuracy, while the mesial and distal positions are predicted with 55% accuracy. The mean SSIM for the output is 0.71, with a range of 0.63 to 0.84. Our study represents the first application of AI reconstruction output for multidisciplinary care involving orthodontists, periodontists, and maxillofacial surgeons in diagnosing and treating maxillary impacted canines. Further development of deep-learning algorithms is necessary to enhance the robustness of dental reconstruction applications."
322,"There is an AI boom happening right now and, with it, a boom of legal scholarship concerning its impact on the legal profession. Most of this scholarship narrows in on balancing the efficiency gains with the ethical considerations. This Note takes a different tact and considers how vigorous adoption of generative AI engines like ChatGPT might impact the continued development of the common law. It goes deeper than the practical applications or superficial changes that might accompany such tools and weighs the threat AI might forever sever humanity's connection to the law, ceding control of its development to these complex algorithms. The legal profession cannot rely on private companies to consider this important aspect, nor can it rely on the slothful legislature to spring into action. Lawyers, jurists, and scholars carry a responsibility to maintain the human connection--or at least be mindful of it in their practice. It is no longer something taken for granted. This Note, which stretches into metaphysical understanding of our connection to the common law and the effects legal interpretation has on both the present and past, might serve as a launching point for scholarly discussion of humanity and the law in the face of the AI revolution. This Note proposes a modest starting point: amending our codes of professional responsibility to place that human connection at the moral and ethical center of our field. This Note does not claim to have the perfect fix, but it serves as an urgent call to act fast and act soon."
323,"Background: As generative artificial intelligence (AI), ChatGPT provides easy access to a wide range of information, including factual knowledge in the field of medicine. Given that knowledge acquisition is a basic determinant of physicians' performance, teaching and testing different levels of medical knowledge is a central task of medical schools. To measure the factual knowledge level of the ChatGPT responses, we compared the performance of ChatGPT with that of medical students in a progress test. Methods: A total of 400 multiple-choice questions (MCQs) from the progress test in Germanspeaking countries were entered into ChatGPT's user interface to obtain the percentage of correctly answered questions. We calculated the correlations of the correctness of ChatGPT responses with behavior in terms of response time, word count, and difficulty of a progress test question. Results: Of the 395 responses evaluated, 65.5% of the progress test questions answered by ChatGPT were correct. On average, ChatGPT required 22.8 s (SD 17.5) for a complete response, containing 36.2 (SD 28.1) words. There was no correlation between the time used and word count with the accuracy of the ChatGPT response (correlation coefficient for time rho = -0.08, 95% CI [-0.18, 0.02], t(393) = -1.55, p = 0.121; for word count rho = -0.03, 95% CI [-0.13, 0.07], t(393) = -0.54, p = 0.592). There was a significant correlation between the difficulty index of the MCQs and the accuracy of the ChatGPT response (correlation coefficient for difficulty: rho = 0.16, 95% CI [0.06, 0.25], t(393) = 3.19, p = 0.002). Conclusion: ChatGPT was able to correctly answer two-thirds of all MCQs at the German state licensing exam level in Progress Test Medicine and outperformed almost all medical students in years 1-3. The ChatGPT answers can be compared with the performance of medical students in the second half of their studies."
324,"The author examines the concerns on copyright protection for works generated by computers or artificial intelligence (AI) in the U.S. Topics discussed include the U.S. Copyright Office's position on the issue, a description of generative AI, and a review of the U.S. Constitution's Patents and Copyright Clause and how it interprets the copyright statute."
325,"The article discusses the 19th IPIL National Conference, held in Santa Fe, New Mexico on June 3, 2023. Topics discussed included the role of behavioral science in copyright doctrine, fairness in copyright fair use, copyright safety for generative AI (artificial intelligence), grounding the scènes à faire doctrine, and the structure of secondary copyright liability. It featured presentations from various scholars including Christopher Buccafusco and Rebecca Tushnet."
326,"Large language models and generative AI, such as ChatGPT, have gained influence over people's personal lives and work since their launch, and are expected to scale even further. While the promises of generative artificial intelligence are compelling, this technology harbors significant biases, including those related to gender. Gender biases create patterns of behavior and stereotypes that put women, men and gender-diverse people at a disadvantage. Gender inequalities and injustices affect society as a whole. As a social practice, gendering is achieved through the repeated citation of rituals, expectations and norms. Shared understandings are often captured in scripts, including those emerging in and from generative AI, which means that gendered views and gender biases get grafted back into social, political and economic life. This paper's central argument is that large language models work performatively, which means that they perpetuate and perhaps even amplify old and non-inclusive understandings of gender. Examples from ChatGPT are used here to illustrate some gender biases in AI. However, this paper also puts forward that AI can work to mitigate biases and act to 'undo gender'."
327,"Artificial intelligence (AI) is understandably garnering an increased share of voice in the general and specialized media. The recent release of several generative AI products has added ""touchable"" context to fears of the potential negative effects of AI—rampant job loss, ""out-of-control"" AI, and deep fake videos, to name a few. A productive conversation about AI requires the conversation to recognize AI as a very broad and diverse field with ""narrow"" and ""general"" applications. Narrow AI applications are quite common and widely deployed today. A fearless conversation can be had regarding how narrow AI can be more widely adopted while allowing for increased transparency and comfort. General AI is more complex and generally leads to what level of government regulation may be necessary (if practically possible). This essay focuses on the application of narrow AI in healthcare and fertility. Pros, cons, challenges, and recommendations are presented for a general audience seeking to understand the application of narrow AI. Successful and unsuccessful examples are provided with frameworks for approaching the narrow AI opportunity."
328,"Introduction: Open‐source generative artificial intelligence (AI) applications are fast‐transforming access to information and allow students to prepare assignments and offer quite accurate responses to a wide range of exam questions which are routinely used in assessments of students across the board including undergraduate dental students. This study aims to evaluate the performance of Chat Generative Pre‐trained Transformer (ChatGPT), a generative AI‐based application, on a wide range of assessments used in contemporary healthcare education and discusses the implications for undergraduate dental education. Materials and Methods: This was an exploratory study investigating the accuracy of ChatGPT to attempt a range of recognised assessments in healthcare education curricula. A total of 50 independent items encompassing 50 different learning outcomes (n = 10 per item) were developed by the research team. These included 10 separate items based on each of the five commonly used question formats including multiple‐choice questions (MCQs); short‐answer questions (SAQs); short essay questions (SEQs); single true/false questions; and fill in the blanks items. Chat GPT was used to attempt each of these 50 questions. In addition, ChatGPT was used to generate reflective reports based on multisource feedback; research methodology; and critical appraisal of the literature. Results: ChatGPT application provided accurate responses to majority of knowledge‐based assessments based on MCQs, SAQs, SEQs, true/false and fill in the blanks items. However, it was only able to answer text‐based questions and did not allow processing of questions based on images. Responses generated to written assignments were also satisfactory apart from those for critical appraisal of literature. Word count was the key limitation observed in outputs generated by the free version of ChatGPT. Conclusion: Notwithstanding their current limitations, generative AI‐based applications have the potential to revolutionise virtual learning. Instead of treating it as a threat, healthcare educators need to adapt teaching and assessments in medical and dental education to the benefits of the learners while mitigating against dishonest use of AI‐based technology."
329,"Background: The advancement of artificial intelligence (AI), specifically Generative Adversarial Networks (GANs), offers exciting possibilities for the enhancement of medical education, with its image-generation capabilities becoming a topic of interest. This novel study evaluates the aptitude of combining a large language model, ChatGPT, with GANs DALL-E 2, Midjourney, and Blue Willow in producing authentic images of ulcers, with a goal to enrich educational resources for surgery. Methods: First, ChatGPT-4 was prompted with definitions of different skin ulcers, and its response was inputted into the GAN models. Generated AI images were evaluated by four board-certified plastic surgeons and three plastic surgeon residents with extensive experience using a Likert scale. Results: Among the three GANs, only DALL-E showed an acceptable level of accuracy, portraying the unique characteristics of each ulcer type. However, it cannot replace conventional patient photographs in terms of authenticity and educational value. Despite presenting aesthetically pleasing images, Midjourney and Blue Willow produced highly stylized, exaggerated features unsuitable for clinical education. Conclusions: Despite these shortcomings, the future of AI-generated images remains promising, given the continuous progress of technology, in augmenting traditional medical education methodologies. Level of evidence: Not gradable."
330,"Generative artificial intelligence (AI) has been touted as a potential innovation for greater diagnostic accuracy and clinical efficiency in health care, but whether generative AI will deliver on this promise or fall to the ""productivity paradox"" is examined in this Special Communication. Importance: Since the introduction of ChatGPT in late 2022, generative artificial intelligence (genAI) has elicited enormous enthusiasm and serious concerns. Observations: History has shown that general purpose technologies often fail to deliver their promised benefits for many years (""the productivity paradox of information technology""). Health care has several attributes that make the successful deployment of new technologies even more difficult than in other industries; these have challenged prior efforts to implement AI and electronic health records. However, genAI has unique properties that may shorten the usual lag between implementation and productivity and/or quality gains in health care. Moreover, the health care ecosystem has evolved to make it more receptive to genAI, and many health care organizations are poised to implement the complementary innovations in culture, leadership, workforce, and workflow often needed for digital innovations to flourish. Conclusions and Relevance: The ability of genAI to rapidly improve and the capacity of organizations to implement complementary innovations that allow IT tools to reach their potential are more advanced than in the past; thus, genAI is capable of delivering meaningful improvements in health care more rapidly than was the case with previous technologies."
331,"This article explores the intersection of open educational resources (OER) and artificial intelligence (AI), with an emphasis on open pedagogy applications. The article comprises a document analysis to summarise expert perspectives on generative AI and two open pedagogy course concepts that explore the relationship between OER and AI through a practical lens of contexts, infrastructures, and sample work products. The expert interviews were published in the open-access magazine AACE Review and were conducted by the author to capture the dynamic field of generative AI. The two course concepts offer first-hand experiences of designing and implementing student-centred, non-disposable assignments by embedding AI tools in open-access book projects."
332,"This article features an interview with Dr. Andrew Maynard, a professor at Arizona State University, discussing the role of artificial intelligence (AI) in education and creativity. Dr. Maynard emphasizes the importance of responsible innovation and taking a long-term view when considering the impact of AI on learning. He highlights the relationship between creativity and innovation, stating that creativity is essential for generating novel ideas that lead to innovative products. Dr. Maynard also discusses the potential of AI for generative collaboration between humans and machines, and how it can inspire curiosity and creativity. He concludes by emphasizing the need for education to support the building blocks of creativity and innovation, such as wonder, curiosity, and joy. The article also addresses the impact of AI tools, such as ChatGPT, on education, discussing both the potential benefits and concerns. It emphasizes the importance of responsible innovation, diverse voices, and education in shaping the future of AI. The article acknowledges the challenges and uncertainties that come with technological advancements but expresses optimism about the potential for positive change."
333,"The abrupt emergence and rapid advancement of generative artificial intelligence (AI) technologies, transitioning from research labs to potentially all aspects of social life, has brought a profound impact on education, science, arts, journalism, and every facet of human life and communication. The purpose of this paper is to recapitulate the use of AI in education and examine potential opportunities and challenges of employing generative AI for educational assessment, with systems thinking in mind. Following a review of the opportunities and challenges, we discuss key issues and dilemmas associated with using generative AI for assessment and for education in general. We hope that the opportunities, challenges, and issues discussed in this paper could serve as a foundation for educators to harness the power of AI within the digital learning ecosystem."
334,"The article reports on the impact of artificial intelligence (AI) in parks and recreation, focusing on the rise of generative AI and its diverse applications. It discusses the current perceptions and use of AI, highlighting tools like ChatGPT and Placer.ai, and explores potential challenges, including accuracy, privacy, job displacement, bias, and the importance of policies and norms for responsible AI adoption in the field."
335,"This article presents 10 groundbreaking technologies across various fields. It explores the impact of AI, specifically generative-AI tools like ChatGPT, which have transformed the industry. The article also discusses the first gene-editing treatment for sickle-cell disease using CRISPR technology, offering hope for patients. Additionally, it delves into the use of heat pumps to decarbonize buildings and manufacturing, as well as the emergence of decentralized social media platforms as alternatives to Twitter. Enhanced geothermal systems are also highlighted for their potential to unlock more geothermal energy sources. The article further examines weight-loss drugs like Wegovy and Mounjaro, which are gaining popularity as potential solutions to the obesity crisis in the US. While these drugs can help individuals lose a significant amount of weight, they have side effects and are costly, often not covered by insurance plans. Nevertheless, weight-loss drugs have the potential to improve the health of many and alleviate symptoms of heart failure."
336,"AMD has announced the Ryzen 8040 series of laptop processors, which prioritize AI capabilities. The processors combine AMD's Zen 4 architecture, RDNA 3 GPUs, and the XDNA architecture. The chips use the Hawk Point NPU, which increases the NPU TOPS to 16 TOPS with 39 TOPS in total. AMD is also launching the Ryzen AI Software tool, which allows models developed in PyTorch or TensorFlow to run on a local AI-enabled Ryzen chip. The company is hosting the AMD Pervasive AI Contest to encourage development in robotics AI, generative AI, and PC AI."
337,"The article discusses the potential uses and implications of generative artificial intelligence (AI) tools, particularly large language models (LLMs), in scholarly publishing. The authors provide recommendations for responsible use of generative AI in scholarly publishing, including not listing AI tools as authors, transparently disclosing the use of AI, and not relying solely on AI for reviewing papers. They emphasize the importance of human authors and editors retaining final responsibility for the content and decisions in scholarly publishing. The authors acknowledge the complexity of ethical issues surrounding generative AI and call for a wider social discourse to develop professional norms for its appropriate use."
338,"The artificial intelligence (AI) tool ChatGPT, which is based on a large language model (LLM), is gaining popularity in academic institutions, notably in the medical field. This article provides a brief overview of the capabilities of ChatGPT for medical writing and its implications for academic integrity. It provides a list of AI generative tools, common use of AI generative tools for medical writing, and provides a list of AI generative text detection tools. It also provides recommendations for policymakers, information professionals, and medical faculty for the constructive use of AI generative tools and related technology. It also highlights the role of health sciences librarians and educators in protecting students from generating text through ChatGPT in their academic work."
339,"The article warns about the harmful effects of chatbots and artificial intelligence (AI) on works of art and its threat to humanity. It presents the case of Julian van Dieken's ""A Girl With Glowing Earrings,"" a recreation of the painting ""Girl With a Pearl Earring"" by Johannes Vermeer which used the generative AI program called Midjourney. It raises concerns about the possible replacement of voice actors and visual artists by AI, privacy and communist chatbots."
340,"Key digested message Much has been said of AI's risks in the hands of criminals, particularly new advances in generative AI. But should we be concerned? This article offers a perspective away from the prevailing opinion amongst experts and argues that we have less to be concerned about, than what is speculated. Fraud has been around since the dawn of the human condition. Many of our modern advances have contributed to its reach and impact, but it is doubtful that AI will be one of them."
341,"In neural decoding research, one of the most intriguing topics is the reconstruction of perceived natural images based on fMRI signals. Previous studies have succeeded in re-creating different aspects of the visuals, such as low-level properties (shape, texture, layout) or high-level features (category of objects, descriptive semantics of scenes) but have typically failed to reconstruct these properties together for complex scene images. Generative AI has recently made a leap forward with latent diffusion models capable of generating high-complexity images. Here, we investigate how to take advantage of this innovative technology for brain decoding. We present a two-stage scene reconstruction framework called ""Brain-Diffuser"". In the first stage, starting from fMRI signals, we reconstruct images that capture low-level properties and overall layout using a VDVAE (Very Deep Variational Autoencoder) model. In the second stage, we use the image-to-image framework of a latent diffusion model (Versatile Diffusion) conditioned on predicted multimodal (text and visual) features, to generate final reconstructed images. On the publicly available Natural Scenes Dataset benchmark, our method outperforms previous models both qualitatively and quantitatively. When applied to synthetic fMRI patterns generated from individual ROI (region-of-interest) masks, our trained model creates compelling ""ROI-optimal"" scenes consistent with neuroscientific knowledge. Thus, the proposed methodology can have an impact on both applied (e.g. brain–computer interface) and fundamental neuroscience."
342,"Creativity has traditionally been considered an ability exclusive to human beings. However, the rapid development of artificial intelligence (AI) has resulted in generative AI chatbots that can produce high-quality artworks, raising questions about the differences between human and machine creativity. In this study, we compared the creativity of humans (n = 256) with that of three current AI chatbots using the alternate uses task (AUT), which is the most used divergent thinking task. Participants were asked to generate uncommon and creative uses for everyday objects. On average, the AI chatbots outperformed human participants. While human responses included poor-quality ideas, the chatbots generally produced more creative responses. However, the best human ideas still matched or exceed those of the chatbots. While this study highlights the potential of AI as a tool to enhance creativity, it also underscores the unique and complex nature of human creativity that may be difficult to fully replicate or surpass with AI technology. The study provides insights into the relationship between human and machine creativity, which is related to important questions about the future of creative work in the age of AI."
343,"Generative AI has gained enormous interest nowadays due to new applications like ChatGPT, DALL E, Stable Diffusion, and Deepfake. In particular, DALL E, Stable Diffusion, and others (Adobe Firefly, ImagineArt, etc.) can create images from a text prompt and are even able to create photorealistic images. Due to this fact, intense research has been performed to create new image forensics applications able to distinguish between real captured images and videos and artificial ones. Detecting forgeries made with Deepfake is one of the most researched issues. This paper is about another kind of forgery detection. The purpose of this research is to detect photorealistic AI-created images versus real photos coming from a physical camera. Id est, making a binary decision over an image, asking whether it is artificially or naturally created. Artificial images do not need to try to represent any real object, person, or place. For this purpose, techniques that perform a pixel-level feature extraction are used. The first one is Photo Response Non-Uniformity (PRNU). PRNU is a special noise due to imperfections on the camera sensor that is used for source camera identification. The underlying idea is that AI images will have a different PRNU pattern. The second one is error level analysis (ELA). This is another type of feature extraction traditionally used for detecting image editing. ELA is being used nowadays by photographers for the manual detection of AI-created images. Both kinds of features are used to train convolutional neural networks to differentiate between AI images and real photographs. Good results are obtained, achieving accuracy rates of over 95%. Both extraction methods are carefully assessed by computing precision/recall and F1-score measurements."
344,"Accessing and utilizing geospatial data from various sources is essential for developing scientific research to address complex scientific and societal challenges that require interdisciplinary knowledge. The traditional keyword-based geosearch approach is insufficient due to the uncertainty inherent within spatial information and how it is presented in the data-sharing platform. For instance, the Gulf of Mexico Coastal Ocean Observing System (GCOOS) data search platform stores geoinformation and metadata in a complex tabular. Users can search for data by entering keywords or selecting data from a drop-down manual from the user interface. However, the search results provide limited information about the data product, where detailed descriptions, potential use, and relationship with other data products are still missing. Language models (LMs) have demonstrated great potential in tasks like question answering, sentiment analysis, text classification, and machine translation. However, they struggle when dealing with metadata represented in tabular format. To overcome these challenges, we developed Meta Question Answering System (MetaQA), a novel spatial data search model. MetaQA integrates end-to-end AI models with a generative pre-trained transformer (GPT) to enhance geosearch services. Using GCOOS metadata as a case study, we tested the effectiveness of MetaQA. The results revealed that MetaQA outperforms state-of-the-art question-answering models in handling tabular metadata, underlining its potential for user-inspired geosearch services."
345,"In this study, we investigate the potential of artificial intelligence (AI), specifically Generative Pre-trained Transformer 4 (GPT-4), to accelerate the development of system dynamics simulations within the broader context of systems engineering. The research aims to uncover the opportunities and limitations of leveraging AI to assist humans in constructing and refining system dynamics models. Through a systematic iterative process, GPT-4 was engaged in tasks such as creating, expanding, and stabilising simulations, identifying errors, generating expansion ideas, and converting models to Python code. Our findings reveal that GPT-4, while not flawless, can significantly enhance the modelling process, reduce human error, and expedite learning. This paper critically examines the role of AI in model development, emphasising the continued importance of human expertise in the evaluation and testing of simulations. Ultimately, we argue for a symbiotic relationship between AI and human modellers, harnessing the power of GPT-4 to augment human capabilities and advance the fields of system dynamics and systems engineering."
346,"ChatGPT and similar generative AI models have attracted hundreds of millions of users and have become part of the public discourse. Many believe that such models will disrupt society and lead to significant changes in the education system and information generation. So far, this belief is based on either colloquial evidence or benchmarks from the owners of the models—both lack scientific rigor. We systematically assess the quality of AI-generated content through a large-scale study comparing human-written versus ChatGPT-generated argumentative student essays. We use essays that were rated by a large number of human experts (teachers). We augment the analysis by considering a set of linguistic characteristics of the generated essays. Our results demonstrate that ChatGPT generates essays that are rated higher regarding quality than human-written essays. The writing style of the AI models exhibits linguistic characteristics that are different from those of the human-written essays. Since the technology is readily available, we believe that educators must act immediately. We must re-invent homework and develop teaching concepts that utilize these AI models in the same way as math utilizes the calculator: teach the general concepts first and then use AI tools to free up time for other learning objectives."
347,"In neural decoding research, one of the most intriguing topics is the reconstruction of perceived natural images based on fMRI signals. Previous studies have succeeded in re-creating different aspects of the visuals, such as low-level properties (shape, texture, layout) or high-level features (category of objects, descriptive semantics of scenes) but have typically failed to reconstruct these properties together for complex scene images. Generative AI has recently made a leap forward with latent diffusion models capable of generating high-complexity images. Here, we investigate how to take advantage of this innovative technology for brain decoding. We present a two-stage scene reconstruction framework called ""Brain-Diffuser"". In the first stage, starting from fMRI signals, we reconstruct images that capture low-level properties and overall layout using a VDVAE (Very Deep Variational Autoencoder) model. In the second stage, we use the image-to-image framework of a latent diffusion model (Versatile Diffusion) conditioned on predicted multimodal (text and visual) features, to generate final reconstructed images. On the publicly available Natural Scenes Dataset benchmark, our method outperforms previous models both qualitatively and quantitatively. When applied to synthetic fMRI patterns generated from individual ROI (region-of-interest) masks, our trained model creates compelling ""ROI-optimal"" scenes consistent with neuroscientific knowledge. Thus, the proposed methodology can have an impact on both applied (e.g. brain–computer interface) and fundamental neuroscience."
348,"Creativity has traditionally been considered an ability exclusive to human beings. However, the rapid development of artificial intelligence (AI) has resulted in generative AI chatbots that can produce high-quality artworks, raising questions about the differences between human and machine creativity. In this study, we compared the creativity of humans (n = 256) with that of three current AI chatbots using the alternate uses task (AUT), which is the most used divergent thinking task. Participants were asked to generate uncommon and creative uses for everyday objects. On average, the AI chatbots outperformed human participants. While human responses included poor-quality ideas, the chatbots generally produced more creative responses. However, the best human ideas still matched or exceed those of the chatbots. While this study highlights the potential of AI as a tool to enhance creativity, it also underscores the unique and complex nature of human creativity that may be difficult to fully replicate or surpass with AI technology. The study provides insights into the relationship between human and machine creativity, which is related to important questions about the future of creative work in the age of AI."
349,"The article discusses the guidance issued by the Utah State Bar (USB) on the integration of generative artificial intelligence (AI) applications in legal practice. Topics explored include the adherence of attorneys to the USB Rules of Professional Conduct with regard to their use of the AI program ChatGPT, the concerns related to client confidentiality such as inappropriate disclosure of information and data breaches, and the potential impact of AI applications on attorney-client relations."
350,"Large Language Models (LLMs) are the result of three major scientific breakthroughs in just 10 years of Deep Learning, applied to natural language. We will illustrate these advances, including the solution to the historic dilemma over the meaning of words. LLMs are the basis of Generative AI systems such as ChatGPT, and demonstrate surprising effectiveness in many tasks including creative tasks such as generating images, code or music from text descriptions. They even seem to exhibit emerging abilities in tasks besides those they were trained for. Their rapid progress has raised concerns about the possible risks of their indiscriminate use. We will reflect on their potential and the fears they raise, comparing apocalyptic and optimistic attitudes. Certainly, the risk must be avoided that this technology remains the prerogative of a few companies with the technical and economic resources to develop it."
351,"Artificial intelligence (AI) and the automation of creative work have received little attention in craft education. This study aimed to address this gap by exploring Finnish pre-service craft teachers' and teacher educators' (N = 15) insights into the potential benefits and challenges of AI, particularly text-to-image generative AI. This study implemented a hands-on workshop on creative making with text-to-image generative AI in order to stimulate discourses and capture imaginaries concerning generative AI. The results revealed that making with AI inspired teachers to consider the unique nature of crafts as well as the tensions and tradeoffs of adopting generative AI in craft practices. The teachers identified concerns in data-driven design, including algorithmic bias, copyright violations and black-boxing creativity, as well as in power relationships, hybrid influencing and behaviour engineering. The article concludes with a discussion of the complicated relationships the results uncovered between creative making and generative AI."
352,"According to virtue epistemology, the main aim of education is the development of the cognitive character of students (Pritchard, 2014, 2016). Given the proliferation of technological tools such as ChatGPT and other LLMs for solving cognitive tasks, how should educational practices incorporate the use of such tools without undermining the cognitive character of students? Pritchard (2014, 2016) argues that it is possible to properly solve this ‘technology-education tension’ (TET) by combining the virtue epistemology framework with the theory of extended cognition (EXT) (Clark and Chalmers, 1998). He argues that EXT enables us to consider tools as constitutive parts of the students’ cognitive system, thus preserving their cognitive character from technologically induced cognitive diminishment. The first aim of this paper is to show that this solution is not sufficient to solve the TET. Second, I aim to offer a complementary and more encompassing framework of tool-use to address the TET. Then, I apply it to the educational uses of ChatGPT as the most notable example of LLM, although my arguments can be extended to other generative AI systems. To do so, in Sect. 1.1, I present Pritchard’s framework of cognitive character and virtue epistemology applied in education, to which I am committed in this treatment. In Sects. 2 and 3, I respectively illustrate Pritchard’s (2014) solution to the TET, and I highlight the general limitations of his proposal. Thus, in Sect. 4.1 I characterize ChatGPT as a computational cognitive artifact using Fasoli’s (Fasoli, 2017, 2018) taxonomy of cognitive artifacts. In Sect. 4.2, I introduce my proposal, which combines Pritchard’s account of virtue epistemology with Fasoli’s (2017, 2018) taxonomy of cognitive artifacts to address the TET. Finally, in Sect. 5.1, I present some epistemically virtuous uses of ChatGPT in educational contexts. To conclude, I argue in favor of a multidisciplinary approach for analyzing educational activities involving AI technologies such as ChatGPT."
353,"This article presents a collection of case studies showcasing the applications of AI in architecture and design. The first case study focuses on Automated Architecture (AUAR), a UK-based company that uses AI and generative design to build sustainable timber housing. The second case study features Jon Hazelwood from Hassell, who uses AI to create urban landscapes that promote biodiversity. The third case study highlights Matsys, a design studio that uses diffusion models for sketching and visualization. The fourth case study discusses Wardle, a Melbourne-based practice that uses AI to support conceptual development and visualization. The final case study explores Studio MMR, which generates 3D models using AI and platform thinking. These case studies demonstrate the diverse ways in which AI is being utilized in the field of architecture."
354,"According to a report by McKinsey, the use of generative artificial intelligence (AI) tools is on the rise, with one-third of surveyed organizations regularly using them in at least one business function. The report also highlights that recent advances in AI technology, such as ChatGPT and AlphaFold, have led to increased AI investment by 40% of the surveyed participants. Respondents anticipate changes in their fields, including job cuts and reskilling efforts, as a response to the evolving work landscape. While generative AI has the potential to automate a significant portion of employees' work activities, it is expected to primarily impact service operations in the next three years. The report emphasizes that the impact of AI will vary across industries, with the majority of its value falling in customer operations, marketing and sales, software engineering, and product research and development. McKinsey senior partner Lareina Yee acknowledges the transformative potential of generative AI on work, but also highlights the challenge of ensuring its benefits reach everyone."
355,"The article focuses on the impact of generative artificial intelligence (AI), specifically ChatGPT and other large language models (LLMs), on the search technology landscape. It discusses the advancements made by OpenAI with the release of ChatGPT 4. It further highlights the potential implications of generative AI for various professions, such as writers, journalists, educators, artists, students, lawyers, and more."
356,"Abstract \nHIGHLIGHTS The role of libraries in preparing students to thrive during their studies and innovate after university is growing in importance. Information is more easily accessible through digital channels and is increasingly abundant. Generative Artificial intelligence (AI) adds to this reality and increases the need for digitally driven information literacy skills. This paper aims to guide librarians by discussing the digitalization of information creation, retrieval, and use. It recommends the training of both digital and information literacy for students. Librarians are called upon to provide clear guidelines to their universities to steer the use of generative AI. The implications of digital information sources and generative AI are discussed with the role of librarians in context. Information literacy and digital literacy are related. Academic libraries should include digital topics in information literacy training. Information literacy should be trained at the start of university education and before students begin dissertation writing. University libraries should propose guidelines for the use of generative artificial intelligence tools by students. Information literacy and digital literacy are related.Academic libraries should include digital topics in information literacy training.Information literacy should be trained at the start of university education and before students begin dissertation writing.University libraries should propose guidelines for the use of generative artificial intelligence tools by students."
357,"In recent years, we welcomed the new world of natural language processing bots driven by artificial intelligence (AI). Of note, we did not explore nor compare all chatbot solutions presently available (e.g., Bing Chat, Chatbot UI, ChatGPT, Google Bard, Elicit The AI Research Assistant, ResearchRabbit, etc.), but selected one pay-for-service AI chatbot randomly instead (i.e., Chat Generative Pre-Trained Transformer-4 also known as GPT-4). Sparked by discussions with our colleagues about the future of generative AI as a whole, we selected our top-10 microscopy-related questions we wished to ask to a chatbot."
358,"The article discusses the impact of generative artificial intelligence tools, particularly large language models like ChatGPT, on scholarly publishing, highlighting the need for transparent disclosure when authors use generative AI and the role of editors and reviewers in maintaining responsible scholarly work in the context of AI technology. The authors present a set of preliminary recommendations to address the ethical and practical challenges of generative AI in scholarly publishing."
359,"The explosive rise of generative AI is already transforming journalism, finance, and medicine, but it could also have a disruptive influence on politics. For example, asking a chatbot how to navigate a complicated bureaucracy or to help draft a letter to an elected official could bolster civic engagement. However, that same technology—with its potential to produce disinformation and misinformation at scale—threatens to interfere with democratic representation, undermine democratic accountability, and corrode social and political trust. This essay analyzes the scope of the threat in each of these spheres and discusses potential guardrails for these misuses, including neural networks used to identify generated content, self-regulation by generative-AI platforms, and greater digital literacy on the part of the public and elites alike."
360,"Learning technologies often do not meet the university requirements for learner engagement via interactivity and real-time feedback. In addition to the challenge of providing personalized learning experiences for students, these technologies can increase the workload of instructors due to the maintenance and updates required to keep the courses up-to-date. Intelligent chatbots based on generative artificial intelligence (AI) technology can help overcome these disadvantages by transforming pedagogical activities and guiding both students and instructors interactively. In this study, we explore and compare the main characteristics of existing educational chatbots. Then, we propose a new theoretical framework for blended learning with intelligent chatbots integration enabling students to interact online and instructors to create and manage their courses using generative AI tools. The advantages of the proposed framework are as follows: (1) it provides a comprehensive understanding of the transformative potential of AI chatbots in education and facilitates their effective implementation; (2) it offers a holistic methodology to enhance the overall educational experience; and (3) it unifies the applications of intelligent chatbots in teaching–learning activities within universities."
361,"In recent years, generative artificial intelligence (AI) has become a major technological innovation that has attracted global attention due to its revolutionary efficiency, triggering a new wave of technological revolution. Companies from all over the world are actively engaged in research and development of generative AI models, such as OpenAI’s ChatGPT, Google’s Bard, and Chinese companies such as Baidu’s Wenxin Yiyan and iFlytek’s SparkDesk Large Language Model. At the same time, legislative activities targeting generative AI have also begun, such as the European Union’s proposed Artificial Intelligence Act, and related regulatory white papers and blue papers have been released by the United States and the United Kingdom. Therefore, from the perspective of international competitiveness, it is also necessary for China to quickly improve its legal regulations for artificial intelligence and promote industry development. While generative AI brings about an efficiency revolution, the content it generates also poses risks to national security, public safety, and private rights. China has already established existing laws and drafted departmental regulations specifically to regulate the risks of AI-generated content. However, there are still shortcomings in terms of disclosure of AI-generated content, content responsibility, and complaint mechanisms. From an improvement perspective, disclosure should have two sets of systems: explicit disclosure and implicit disclosure, where service providers are responsible for implicit disclosure obligations, and users are responsible for explicit disclosure obligations. In terms of content responsibility, the binary division of content providers and technical service providers is no longer applicable to the scenario of AI-generated content. Service providers should not be simply classified as content providers, as this will impose a heavy burden on service providers and be detrimental to the healthy development of the industry. A safe harbor mechanism that adapts to the characteristics of generative AI should be explored on the basis of reference to the safe harbor rules, and this mechanism should be compatible with the user’s content responsibility. In terms of complaint mechanisms, it is not reasonable to require service providers to take targeted blocking measures based on user complaints. Two schemes can be considered to improve this: one is to decouple complaints from targeted blocking measures as stipulated in the previous departmental regulations, and the other is to significantly raise the threshold for taking targeted blocking measures in response to complaints. Finally, when formulating policies for regulating the risks of generative AI content, the issue of the industry’s international competitiveness should be considered, and a regulatory path that classifies risks themselves should be adopted to achieve the dual objectives of promoting the healthy development of the industry and preventing risks. Existing academic papers on the regulation of generative AI mainly study it from the perspective of overall risk regulations, while this article explores it from the perspective of content risk regulation, and there are very few similar studies. In terms of research perspective, the innovation of this article mainly lies in: first, it clearly proposes that existing safe harbor rules should not apply to generative AI service providers, and new content responsibility“safe harbors”should be created for them. Second, the classification of risks has shifted from different products to different risks generated by the same product. For high-risk illegal and harmful content such as national security and public safety risks, service providers have a heavier obligation to take blocking measures, while for lower-risk illegal and harmful content such as infringement of private rights, service providers have a relatively lighter obligation to take blocking measures."
362,"Whether you're an early adopter, an occasional user, or yet to acknowledge its transformative potential, artificial intelligence (AI) -- specifically generative AI applications underpinned by large language models -- is undeniably shaping our present and destined to influence the future of medical writing. Achieving a comprehensive understanding of these models can pave the way for their optimal application in areas where they excel. Additionally, this understanding helps to maintain a realistic, balanced perspective, allowing us to avoid the pitfalls associated with excessive or unfounded fear stirred by the current AI hype and related exaggerated promises. A selection of AI applications offers insights into specific tasks for which generative AI can be effectively utilised. These applications can truly make a difference by saving time, streamlining workflows, and potentially enhancing the quality of the resulting outputs."
363,"The artificial intelligence (AI) model ChatGPT, which is capable to generate human-like responses, has recently raised paramount interest and attention due to its inherent capability to write scientific text. The current thinking is that AI cannot be granted the authorship of manuscripts because there is a lack of responsibility, though many scientists still believe that it could help the facility and speed of writing. The currently available online tools of generative AI do not easily allow to accurately acknowledge whether a given scientific text has been composed by human individuals or AI systems. To this end, some aspects could be analyzed, namely repetition (by means of plagiarism checks), style and tone, coherence and structure, context and accuracy, though we proffer that these distinguishing elements may be more nuanced in the foreseeable future. In this article we have also tested the capacity of some different generative AI systems to answer to an easy laboratory medicine query, concluding that the output does not exactly match a text written by a skilled scientist and the algorithms still present imprecisions, suggesting the need for better training. Authoring scientific articles implies skills that could only be developed after years of training and experience, involving a good knowledge of the argument and the ability to think creatively and make connections. At this point in time, generative AI systems could certainly assist scientific writing, but they cannot replace the knowledge, skill and creativity of a human writer."
364,"The article focuses on the potential economic impact of generative artificial intelligence (AI), highlighting its role in boosting global productivity. Topics include the economic potential of AI, the challenges and hurdles it faces in realizing its full potential, and the transformative impact it could have on productivity and the global economy. The article also emphasizes the importance of embracing AI as a tool to enhance human potential rather than replace it."
365,"The article focuses on how generative Artificial Intelligence (AI), when used in conjunction with other AI tools and proper governance, can assist human services organizations in addressing workforce challenges and improving service delivery. Topics discussed include the application of AI tools such as Gen AI for processing intake forms and case management, onboarding new caseworkers, and reducing administrative burdens for caseworkers through automation and augmentation of tasks."
366,"Time 100/AI Innovators Pelonomi Moiloa didn't originally intend to work in AI. Lilly Wachowski FILMMAKER In 1999, Wachowski and her sister Lana co-created The Matrix, which warned of an AI dystopia that had an outsize effect on AI philosophers and researchers. Rootport AUTHOR OF JAPANESE MANGA Despite a lack of drawing skills, the 37-year-old Tokyo-based writer got the world's first fully AI-illustrated manga published earlier this year - with text-to-image generative AI as his digital art partner."
367,"In the first half of 2023, text-generative artificial intelligence (AI), including ChatGPT from OpenAI, has attracted considerable attention worldwide. In this study, first, we compared Japanese stylometric features of texts generated by ChatGPT, equipped with GPT-3.5 and GPT-4, and those written by humans. In this work, we performed multi-dimensional scaling (MDS) to confirm the distributions of 216 texts of three classes (72 academic papers written by 36 single authors, 72 texts generated by GPT-3.5, and 72 texts generated by GPT-4 on the basis of the titles of the aforementioned papers) focusing on the following stylometric features: (1) bigrams of parts-of-speech, (2) bigram of postpositional particle words, (3) positioning of commas, and (4) rate of function words. MDS revealed distinct distributions at each stylometric feature of GPT (3.5 and 4) and human. Although GPT-4 is more powerful than GPT-3.5 because it has more parameters, both GPT (3.5 and 4) distributions are overlapping. These results indicate that although the number of parameters may increase in the future, GPT-generated texts may not be close to that written by humans in terms of stylometric features. Second, we verified the classification performance of random forest (RF) classifier for two classes (GPT and human) focusing on Japanese stylometric features. This study revealed the high performance of RF in each stylometric feature: The RF classifier focusing on the rate of function words achieved 98.1% accuracy. Furthermore the RF classifier focusing on all stylometric features reached 100% in terms of all performance indexes (accuracy, recall, precision, and F1 score). This study concluded that at this stage we human discriminate ChatGPT from human limited to Japanese language."
368,"New developments in the Artificial Intelligence (AI) field allowed the development of Generative Artificial Intelligence (GenAI), capable of creating text resembling what humans can produce. As a result, educators' concerns in the higher education sector quickly emerged. Many organizations and experts have addressed these concerns through recommendations. In this conceptual paper, we draw from the Integrated Model for Academic Integrity through a Scholarship of Teaching and Learning Lens to examine and stimulate discussion from twelve documents that focus on using GenAI with integrity. We identified recommendations suitable for the individual (micro), the departmental/program (meso), the institutional (macro), and the interinstitutional/national/international (mega) levels concerning two core elements of the model: ""high-impact professional learning for individuals and groups"" and ""local-level leadership and microcultures."" Suggestions around the core element ""scholarship, research and inquiry"" were lacking at the micro and meso levels; likewise, recommendations for the core element ""learning spaces, pedagogies, and technologies"" were also absent at the meso, macro, and mega levels. We acknowledge that these recommendations focus on learning, involve various stakeholders, and go beyond student conduct, which aligns with current approaches to academic integrity. However, some gaps need further exploration. We highlight the need to develop more specific and practical guidance and resources for educational stakeholders around GenAI issues related to academic integrity, explore how to better support networks and leaders in higher education in creating the conditions for ethical GenAI use, and emphasizing the need for an Equity, Diversity, and Inclusion lens on GenAI."
369,"Importance: Interest in artificial intelligence (AI) has reached an all-time high, and health care leaders across the ecosystem are faced with questions about where, when, and how to deploy AI and how to understand its risks, problems, and possibilities. Observations: While AI as a concept has existed since the 1950s, all AI is not the same. Capabilities and risks of various kinds of AI differ markedly, and on examination 3 epochs of AI emerge. AI 1.0 includes symbolic AI, which attempts to encode human knowledge into computational rules, as well as probabilistic models. The era of AI 2.0 began with deep learning, in which models learn from examples labeled with ground truth. This era brought about many advances both in people's daily lives and in health care. Deep learning models are task-specific, meaning they do one thing at a time, and they primarily focus on classification and prediction. AI 3.0 is the era of foundation models and generative AI. Models in AI 3.0 have fundamentally new (and potentially transformative) capabilities, as well as new kinds of risks, such as hallucinations. These models can do many different kinds of tasks without being retrained on a new dataset. For example, a simple text instruction will change the model's behavior. Prompts such as ""Write this note for a specialist consultant"" and ""Write this note for the patient's mother"" will produce markedly different content. Conclusions and Relevance: Foundation models and generative AI represent a major revolution in AI's capabilities, ffering tremendous potential to improve care. Health care leaders are making decisions about AI today. While any heuristic omits details and loses nuance, the framework of AI 1.0, 2.0, and 3.0 may be helpful to decision-makers because each epoch has fundamentally different capabilities and risks. This Special Communication examines the evolution of artificial intelligence (AI) over the years, and how developments with AI can help decision-makers improve health care while also recognizing its risks."
370,"The article comments on the lack of safety net for generative artificial intelligence (AI) applications such as ChatGPT. It points out disparities in accuracy of AI safety net, potential bias of generative AI text detectors, the lack of clear guidance related to generative AI, and failure of plagiarism policies to keep up with academic misconduct. It cautions about potential harm caused by the lack of safety net to students and educators and it calls for teaching of information literacy."
371,"Accenture has established a change center of excellence (COE) to ensure maximum return on technology investments. The COE takes a human-first approach, understanding how people work and what they are trying to achieve before determining how technology can help. The COE has defined customers, created an operating model, and established an organizational structure to deliver change strategy and vision, technology change deployment, adoption value and realization, and end-user support and enablement. The COE uses a human-centric approach to IT deployment, considering different types of employee needs and using storytelling and virtual reality to engage learners. The COE also focuses on adoption and maintains end-user support and ongoing enablement. The success of the COE is measured through objectives and key results, customer satisfaction, service levels, and team member engagement. The COE has achieved several milestones and continues to grow, with a strategic focus on generative AI."
372,"• Diffusion models create realistic radiographs that are not discernable by experts. • Synthetic images can be reliably conditioned on demographic and radiologic attributes. • DDPMs can be used for meaningful feature extraction from medical images. • Using extracted features, a segmentation model can be trained with only 20 samples. • This training scheme improves segmentation accuracy by 0.30 in terms of dice score. Medical image analysis pipelines often involve segmentation, which requires a large amount of annotated training data, which is time-consuming and costly. To address this issue, we proposed leveraging generative models to achieve few-shot image segmentation. We trained a denoising diffusion probabilistic model (DDPM) on 480,407 pelvis radiographs to generate 256 ✕ 256 px synthetic images. The DDPM was conditioned on demographic and radiologic characteristics and was rigorously validated by domain experts and objective image quality metrics (Frechet inception distance [FID] and inception score [IS]). For the next step, three landmarks (greater trochanter [GT], lesser trochanter [LT], and obturator foramen [OF]) were annotated on 45 real-patient radiographs; 25 for training and 20 for testing. To extract features, each image was passed through the pre-trained DDPM at three timesteps and for each pass, features from specific blocks were extracted. The features were concatenated with the real image to form an image with 4225 channels. The feature-set was broken into random patches, which were fed to a U-Net. Dice Similarity Coefficient (DSC) was used to compare the performance with a vanilla U-Net trained on radiographs. Expert accuracy was 57.5 % in determining real versus generated images, while the model reached an FID = 7.2 and IS = 210. The segmentation UNet trained on the 20 feature-sets achieved a DSC of 0.90, 0.84, and 0.61 for OF, GT, and LT segmentation, respectively, which was at least 0.30 points higher than the naively trained model. We demonstrated the applicability of DDPMs as feature extractors, facilitating medical image segmentation with few annotated samples."
373,"The article focuses on the experiences and opinions of engineers who have used generative Artificial intelligence (AI) services. Topics include the applications of generative AI, improvements in efficiency since its incorporation into workflows, employer policies regarding its use, reliability and accuracy of generative AI tools, and the expected role of generative AI in the future of engineering."
374,"In this article from TIME Magazine, Accenture CEO Julie Sweet discusses the importance of leaders prioritizing their own version of ""deep learning"" in 2024. She highlights the shift in CEOs' attitudes towards artificial intelligence (AI), with many now recognizing its critical importance. Sweet emphasizes the need for leaders to understand AI and asks the right questions in order to unlock its potential. She also mentions the emergence of a new type of leader in the AI age and the excitement surrounding generative AI."
375,""" When Gebru got to Google, she co-led the Ethical AI group, a part of the company's Responsible AI initiative, which looked at the social implications of artificial intelligence - including ""generative"" AI systems, which appear to learn on their own and create new content based on what they've learned. When asked about Noble's theory, a Google spokesperson told ROLLING STONE, ""Google's Generative AI models are trained on data from the open web, which can include publicly available web data."" Noble and Gebru hadn't crossed paths despite doing similar work - but when Noble saw Gebru's tweet that night about Google, she was struck by how brave it was. Today the risks of artificial intelligence are clear - but the warning signs have been there all along PHOTOGRAPHS BY Gioncarlo Valentine TIMNIT GEBRU DIDN'T set out to work in AI."
376,"A review of the book ""The Second Digital Turn: Design Beyond Intelligence,"" by Mario Carpo, is presented."
377,"The documentation and management of the cultural heritage of the COVID-19 pandemic as well as the heritage of the digital age are emerging discourses in cultural heritage management. The enthusiastic uptake of a generative artificial intelligence application (ChatGPT) by the general public and academics alike has provided an opportunity to explore (i) whether, and to what extent, generative AI can conceptualize an emergent, not well-described field of cultural heritage (the heritage of COVID-19), (ii), whether it can design an exhibition on the topic, and (iii) whether it can identify sites associated with the pandemic that may become significant heritage. Drawing on an extended 'conversation' with ChatGPT, this paper shows that generative AI is capable of not only developing a concept for an exhibition of the heritage of COVID-19 but also that it can provide a defensible array of exhibition topics as well as a relevant selection of exhibition objects. ChatGPT is also capable of making suggestions on the selection of cultural heritage sites associated with the pandemic, but these lack specificity. The discrepancy between ChatGPT's responses to the exhibition concept and its responses regarding potential heritage sites suggests differential selection and access to the data that were used to train the model, with a seemingly heavy reliance on Wikipedia. The 'conversation' has shown that ChatGPT can serve as a brainstorming tool, but that a curator's considered interpretation of the responses is still essential."
378,"Social work scholars have long questioned the validity and utility of the Association of Social Work Boards (ASWB) licensing exams. Data released in 2022 revealed severe disparities in pass rates based on race, age, and language, exacerbating these concerns. In this paper, we explore the potential of generative artificial intelligence (AI) such as ChatGPT to address core problems of the ASWB exams, including the use of a multiple-choice format that does not reflect real-world social work practice. To assess its social work reasoning, we used ChatGPT to answer ASWB-developed practice questions for the Bachelors, Masters, and Clinical exams. ChatGPT scored 76%, 80%, and 64%, respectively, and identified additional validity challenges. Based on this performance, we provide a proof-of-concept for how generative AI might move us toward a more valid and equitable exam. While we strongly support licensure requirements, state regulators and legislators should temporarily suspend the use of the ASWB exams for this purpose."
379,"Abstract This article explores the ethical problems arising from the use of ChatGPT as a kind of generative AI and suggests responses based on the Human-Centered Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate because it understands technology above all as a tool to empower, augment, and enhance human agency while referring to human wellbeing as a “grand challenge,” thus perfectly aligning itself with ethics, the science of human flourishing. Further, HCAI provides objectives, principles, procedures, and structures for reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments. The main danger ChatGPT presents is the propensity to be used as a “weapon of mass deception” (WMD) and an enabler of criminal activities involving deceit. We review technical specifications to better comprehend its potentials and limitations. We then suggest both technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparency, educator considerations, HITL) to mitigate ChatGPT misuse or abuse and recommend best uses (creative writing, non-creative writing, teaching and learning). We conclude with considerations regarding the role of hu mans in ensuring the proper use of ChatGPT for individual and social wellbeing."
380,"The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT's output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education."
381,"This review article introduces the main concepts and architectures of deep learning networks for medical imaging tasks, such as classification, detection, segmentation, and generation. It then surveys how deep learning has been applied to ultrasound imaging for various purposes, such as image processing, diagnosis, and workflow enhancement. It covers different organs and body parts that can be imaged by ultrasound, such as liver, breast, thyroid, heart, kidney, prostate, nerve, muscle, and fetus. It also discusses how deep learning can help with view recognition, registration, and quantification, measurement, image registration for interventional guidance, and real-time assistance while scanning. Moreover, it explores how generative AI can be used in the future medical field by leveraging deep learning for ultrasound imaging, such as generating realistic and diverse images, virtual organs/patients with diseases, synthesizing missing or corrupted data and augmenting existing data for training and testing."
382,"The Chinese government has actually moved faster than the U.S. government in regulating AI, enacting regulations on deep-against fakes in January and publishing draft rules on generative AI in April. The U.S. government must also work with industry to develop sensible regulations on powerful AI models to avoid societal harm and manage the risks of a backlash against AI. The rising costs of computing hardware for training the most cutting-edge AI models are concentrating power in the hands of a small number of tech companies and locking academics out of frontier AI research. Leading AI researchers recently advocated a six-month pause on developing next-generation AI models because of the risk of societal harms."
383,"The article focuses on the use of generative Artificial intelligence (AI) image-generation programs, such as Midjourney, in the art world, raising concerns about copyright infringement and highlighting divergent views among artists regarding the technology's impact on their work."
384,"The article focuses on questions raised at the House of Commons for the Great Britain. Department for Education on vocational education, artificial intelligence, and Special Educational Needs. Topics discussed include investment of department in capital funding to establish Institutes of Technology, effects of generative AI on the education sector, and establishment of Local Partnership Boards for supporting prioritisation of Local Needs Funding."
385,"The article focuses on the combination of technology and art in the age of Artificial intelligence (AI), particularly in the field of generative art. Topics include the use of computer codes to create salt field paintings, the exploration of virtual space design, and the connection between generative art and the artists' observation of nature."
386,"The article looks into a troubling analogue in artificial intelligence (AI) text generators in the Surrealist method of automatic writing, that is text production estranged from human consciousness. Topics discussed are limitations of text outputs of generative models, capacity of AI systems to exhaust imaginative possibility and work through ideas, and business models for the Surrealism-AI symbiosis like generative pre-trained transformer 3 (GPT-3) and generative art non-fungible tokens (NFT)."
387,"Visioning has been widely adopted in transport planning as a method to support explorations of possible future transport systems over a long time horizon. There are vast variations in how visioning is applied but given a clear association between visions and the long-time perspective, it is unclear how these processes handle uncertainty surrounding the resulting visions and their implementation. This study reflects on previous visioning processes by systematically reviewing the scientific publications on participatory visioning in passenger transport. The review identifies possible improvements contributing to a systematic approach that produces concrete visions and actions to deal with uncertainties surrounding the vision and its implementation. We address these improvements by proposing a robust and generative visioning framework, which combines the generative approach in Appreciative Inquiry (Ai) and methods to handle uncertainty in the Dynamic Adaptive Planning (DAP). The framework is illustrated in a case study of the Southwest area of the Dutch city of the Hague that involved over 50 participants in a survey and two workshops. The process produced a vision for the mobility system of the area, a set of measures to realize it (i.e. pathways), and concrete actions to ensure that the pathways are robust against different futures that can affect the implementation. The approach can help planners, policymakers, and researchers in designing a visioning process that helps participants to better appreciate the temporal dimension of the visioning process and improves their awareness regarding the need to safeguard policy interventions against possible impacts of (un)certain future events."
388,"Artificial intelligence (AI) technology for image recognition has the potential to identify cancer stem cells (CSCs) in cultures and tissues. CSCs play an important role in the development and relapse of tumors. Although the characteristics of CSCs have been extensively studied, their morphological features remain elusive. The attempt to obtain an AI model identifying CSCs in culture showed the importance of images from spatially and temporally grown cultures of CSCs for deep learning to improve accuracy, but was insufficient. This study aimed to identify a process that is significantly efficient in increasing the accuracy values of the AI model output for predicting CSCs from phase-contrast images. An AI model of conditional generative adversarial network (CGAN) image translation for CSC identification predicted CSCs with various accuracy levels, and convolutional neural network classification of CSC phase-contrast images showed variation in the images. The accuracy of the AI model of CGAN image translation was increased by the AI model built by deep learning of selected CSC images with high accuracy previously calculated by another AI model. The workflow of building an AI model based on CGAN image translation could be useful for the AI prediction of CSCs."
389,"The article focuses on the potential impact of generative Artificial intelligence (AI), particularly chatbots, on the discipline of writing studies. It raises questions about the relevance of writing skills in a future where AI can perform writing tasks and explores how adopting a Writing about Writing (WAW) approach in teaching composition can help navigate the new AI landscape while emphasizing the value of human knowledge and understanding in the discipline."
390,"Siemens and Amazon Web Services (AWS) have announced a partnership to make it easier for businesses to build and scale generative artificial intelligence (AI) applications. This collaboration will integrate Amazon Bedrock, a service that offers high-performing AI models, with Siemens' low-code platform, Mendix. The integration will allow users to select the AI model that best suits their needs and incorporate it into their applications quickly and securely. This partnership aims to democratize generative AI technology and empower businesses to innovate and address skilled labor shortages."
391,"The article discusses concerns of information professionals regarding the dominance of generative AI, such as ChatGPT, highlighting both extensive history of AI applications in libraries and the challenges and fears associated with the rapid advancements in generative AI technology. The author urges these professionals to proactively navigate transformative effects of generative AI, emphasizing the need to explore its benefits and drawbacks to lead confidently in this evolving search landscape."
392,"A new study published in the journal Joule warns that the use of generative AI applications, such as ChatGPT, MidJourney, and DALLE-E, could significantly increase energy consumption and undermine global emissions-reduction efforts. The study found that adding generative AI to a Google search, for example, increases its energy use more than tenfold. The author of the study, Alex de Vries, cautions that if AI development and use continue to accelerate, the industry's energy consumption could match that of an entire country within a few years. De Vries suggests that individuals and organizations should carefully consider whether AI is necessary for their applications, as it is not a ""miracle cure for everything."""
393,"The author comments on the article ""What Should ChatGPT Mean for Bioethics"" by I.G. Cohen which highlights bioethical issues raised by the emergence of ChatGPT and generative artificial intelligence (AI). Topics include competitive advantage of companies that deploy generative AI, core principles of the World Health Organization's guidance on the Ethics and Governance of AI for Health to generative AI deployment, and requirement in deploying generative AI applications in healthcare."
394,"The authors reflect on artificial intelligence (AI) and its implications for the journal. They talk about the release of generative AI Large Language Model (LLM) ChatGPT by OpenAI in November 2022, the implications of AI for social work education, practice, research, and scholarship, and statement released by Taylor and Francis (T&F), the publisher of the journal, about the use of generative AI tools in research and writing."
395,"The year 2022 was nothing short of exceptional for artificial intelligence (AI) research, particularly in the realm of generative AI. All that is required are the right instructions: For example, LLMs can transfer lung nodule measurements mentioned in a radiology report into a CSV file to speed up data collection: ""Collect all lung nodule measurements and return a list of the form < Side >, < Lobe >, < Segment >, < Size > with one line per nodule"". Generative AI systems learn to model training data (e.g., text, images) and can synthesize new data, without merely copying the initial data."
396,"Recent advances in large language models (LLMs) and generative artificial intelligence (AI) have led to the development of a host of products that are already revolutionizing the way people and technologies interact. Governments have begun to regulate AI, such as the European Union's AI act that establishes different obligations based on varying levels of risk. Conceptualizing LLMs and generative AI as further examples of technology-enabled services frames the opportunity to bring human intellect and creativity together with AI support to create more efficient, effective, and scalable mental health services."
397,"Commercial applications of artificial intelligence (AI) in the form of Large Language Models (LLMs) and Generative AI have taken centre stage in the media sphere, business, public policy, and education. The ramifications for the field of child psychology and psychiatry are being debated and veer between LLMs as potential models for development and applications of generative AI becoming environmental factors for human development. This Editorial briefly discusses developmental research on generative AI and the potential impact of generative AI on the hybrid social world in which young people grow up. We end by considering that the rapid developments justify increasing attention in our field."
398,"The digital assistant and the learner Direct-to-student learning apps have started to integrate AI assistants. Fundamentals FUTURE READINESS Generative artificial intelligence and large language models have emerged and evolved rapidly this year, disrupting industries and throwing educators, learning professionals, knowledge workers, creators, and creatives into a state of professional uncertainty. But while there have been point solutions and learning-specific assistants, using generally available assistants for learning purposes never really took off."
399,"Scaffold design and fabrication plays an important role in tissue engineering. Conventional manufacturing processes for fabrication of scaffolds have limitations with respect to the controlled architecture and resolution required. The issue can be alleviated by using additive manufacturing (AM) technology. AM is a layer-by-layer fabrication technique which can fabricate complex structures with adequate resolutions. This characteristic of the process is suitable for scaffold fabrication. Moreover, the design aspect of the scaffolds such as pore size, density and structure also significantly influence the performance of the scaffold. Generative design is an AI based approach to design features with improved characteristics. Utilizing this approach to design scaffold is a subject of study which needs to be investigated. The present papers discuss about the various manufacturing techniques available for scaffold fabrication and compares them with the additive manufacturing techniques. Moreover, prospects of scaffold design using generative approach is also discussed along with the desired biocompatible properties required for scaffolding."
400,"Nelson says that the upcoming 2024 elections in the U.S., E.U., U.K., South Africa, and beyond make AI regulation all the more urgent. She points to radiology, a field that AI pioneer Geoffrey Hinton predicted in 2016 would be overtaken by AI within five years. Time 100/AI Shapers When the Biden White House was tasked with responding to the rapid changes in generative AI last year, Alondra Nelson led the charge."
401,"Baidu already has its own equivalent of Amazon's Alexa, dubbed Xiaodu, as well as fleets of driverless taxis, but the recent explosion in generative AI means it's now ""a very exciting time"", says Li. Time 100/AI Leaders As China's foremost futurist, Robin Li - who co-founded Baidu, China's most popular search engine, in 2000 - has been riding the AI wave for a long time. In July, Baidu was appointed a leader of the Chinese government's National Artificial Intelligence Standardization Group's LLM task force, whose mood recently has ""morphed into a more build than regulate mindset"", says Li."
402,"To outside observers, the chat is indistinguishable from any other communication made by the same generative AI: ""They might detect that there is AIgenerated content"", Schroeder de Witt says, ""but they would not be able to tell whether you've encoded secret information into it."" In an advance that could benefit spies and dissidents alike, computer scientists have developed a way to communicate confidential information so discreetly that an adversary couldn't even know secrets were being shared. University of Oxford researcher Christian Schroeder de Witt, Carnegie Mellon University researcher Samuel Sokota and their colleagues used an AI program to create innocent-looking chat messages with secret content."
403,"ChatGPT is one of many generative artificial intelligence (AI) tools that has emerged recently, creating controversy in the education community with concerns about its potential to be used for plagiarism and to undermine students' ability to think independently. Recent publications have criticized the use of ChatGPT and other generative AI tools in the classroom, with little focus on the potential benefits. This article focuses on the potential of ChatGPT as an educational tool for statistics and data science. It encourages readers to consider the history of trepidation surrounding introducing new technology in the classroom, such as the calculator. We explore the possibility of leveraging ChatGPT's capabilities in statistics and data science education, providing examples of how ChatGPT can aid in developing course materials and suggestions for how educators can prompt students to interact with ChatGPT responsibly. As educators, we can guide the use of generative AI tools in statistics and data science classrooms so that students and educators can leverage the benefits of this technology."
404,"Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education."
405,"In Perception Engines and Synthetic Abstractions, two generative AI art projects begun in 2018, Tom White experiments with visual abstraction to explore the indeterminacy of perception, interpretation, and agency. White's AI systems produce images that will be interpreted as abstract artworks by human viewers, but which also confront human audiences with the realization that what is here deliberately rendered indeterminable for them will remain near-perfectly legible for AI-powered image recognition systems. This difference in perceptual and interpretive agency foregrounds an underlying politics of visual indeterminacy. White's projects thus increase awareness of how machine vision—for example in automated online filtering systems—can diminish the horizon of what human audiences can or cannot see in an AI-driven digital cultural landscape, and how, in the process, underlying biases are normalized and human viewers become habituated to the dramatic shrinking of perceivable/viewable online image content mediated by AI."
406,"Building upon A Manifesto In Defense of Democracy and the Rule of Law in the Age of 'Artificial Intelligence', we, the Transatlantic Reflection Group on Democracy and the Rule of Law in the Age of 'Artificial Intelligence', have reconvened to draft a second consensus manifesto that calls for the effective and legitimate enforcement of laws concerning AI systems. In doing so, we recognise the important and complementary role of standards and compliance practices. Whereas the first manifesto focused on the relationship between democratic law‐making and technology, this second manifesto shifts focus from the design of law in the age of AI to the enforcement of law. Concretely, we offer 10 recommendations for addressing the key enforcement challenges shared across transatlantic stakeholders. We call on those who support these recommendations to sign this manifesto. The Fifth Edition of The Athens Roundtable on AI and the Rule of Law will take place on November 30th and December 1st, 2023. It will delve into pressing governance challenges posed by foundation models and generative AI across jurisdictions."
407,"The article offers information on a webinar titled ""Hallucinate, Confabulate, Obfuscate: The Perils of Generative AI Going Rogue"" hosted by Data Conversion Laboratory (DCL) on Oct. 12. The webinar explores the challenges and risks associated with generative AI, specifically large language models (LLMs), highlighting the potential for AI to provide inaccurate information and contribute to societal confusion."
408,"Deconstruction, a concept that originated from French philosopher Jacques Derrida's post-structuralist theories, has significantly influenced architecture and graphic design. It has evolved into a rhizomatic network of styles and concepts ranging from new architectural geometry to AI. Despite its limited explicit application in music, this paper explores deconstruction within musical aesthetics, especially in the post-1945 serial school. Computer-Aided Design (CAD) methods have become an important part in the deconstructivist architectural design process; similarly, in music, Computer-Aided Composition (CAC) techniques have become important from generative algorithms to AI techniques. In graphic design, such systems (i.e. GANs, VAEs, CNNs, RNNs, Stable Diffusion, Transformers, etc.) have been experimented with. Google's Imagen or OpenAI's DALL-E 2, which automatically generate images from text prompts given by users, use, for example, diffusion models. Also, Google LM is a music equivalent to these. This paper delves into the novel aesthetics brought about by the application of GANs on multichannel polyphonic MIDI data in music, discussing the conceptual grounding of such usage and overcoming the challenges associated with it. Effectively, using our concept of distance matrices rather than, for example, Hidden Markov Models, is more suitable for GAN generation."
409,"To achieve optoelectronic devices with high resolution and efficiency, there is a pressing need for optical structural units that possess an ultrasmall footprint yet exhibit strong controllability in both the frequency and spatial domains. For dielectric nanoparticles, the overlap of electric and magnetic dipole moments can scatter light completely forward or backward, which is called Kerker theory. This effect can expand to any multipoles and any directions, re‐named as generalized Kerker effect, and realize controllable light manipulation at full space and full spectrum using well‐designed dielectric structures. However, the complex situations of multipole couplings make it difficult to achieve structural design. Here, generative artificial intelligence (AI) is utilized to facilitate multi‐objective‐oriented structural design, wherein the study leverages the concept of “combined spectra” that consider both spectra and direction ratios as labels. The proposed generative adversarial network (GAN) is named as DDGAN (double‐discriminator GAN) that discriminates both images and spectral labels. Using trained networks, the simultaneous design for scattering color and directivities, RGB color routers, as well as narrowband light routers is achieved. Notably, all generated structures possess a footprint <600 × 600 nm indicating their potential applications in optoelectronic devices with ultrahigh resolution."
410,"This study aimed to elucidate effective methodologies for utilizing the generative artificial intelligence (AI) system, namely the Chat Generative Pre-trained Transformer (ChatGPT), in improving clinical reasoning abilities among clinicians. We conducted a comprehensive exploration of the capabilities of ChatGPT, emphasizing two main areas: (1) efficient utilization of ChatGPT, with a focus on application and language selection, input methodology, and output verification; and (2) specific strategies to bolster clinical reasoning using ChatGPT, including self-learning via simulated clinical case creation and engagement with published case reports. Effective AI-based clinical reasoning development requires a clear delineation of both system roles and user needs. All outputs from the system necessitate rigorous verification against credible medical resources. When used in self-learning scenarios, capabilities of ChatGPT in clinical case creation notably enhanced disease comprehension. The efficient use of generative AIs, as exemplified by ChatGPT, can impressively enhance clinical reasoning among medical professionals. Adopting these cutting-edge tools promises a bright future for continuous advancements in clinicians' diagnostic skills, heralding a transformative era in digital healthcare."
411,"The recent appearance of generative artificial intelligence (AI) platforms has been seen by many as disruptive for education. In this paper I attempt to locate the source of tension between educational goals and new information technologies including AI. I argue that this tension arises from new conceptions of epistemic agency that are incompatible with educational aims. I describe three competing theories of epistemic agency which I refer to as Makers, Managers, and Inforgs. I contend that educators are correct in maintaining the first of these, which is rooted in the educational theories of Locke and Dewey, as their main educational purpose. Competing theories do not serve the goals of learners, even as they must prepare for life in a very different epistemic environment."
412,"Background: The integration of artificial intelligence in healthcare has led to the development of large language models that can address various medical queries, including intraoperatively. This study investigates the potential of ChatGPT in addressing intraoperative questions during the deep inferior epigastric perforator flap procedure. Methods: A series of six intraoperative questions specific to the DIEP flap procedure, derived from real-world clinical scenarios, were proposed to ChatGPT. A panel of four experienced board-certified plastic surgeons evaluated ChatGPT's performance in providing accurate, relevant, and comprehensible responses. Results: The Likert scale demonstrated to be medically accurate, systematic in presentation, and logical when providing alternative solutions. The mean readability score of the Flesch Reading Ease Score was 28.7 (±0.8), the Flesch–Kincaid Grade Level was 12.4 (±0.5), and the Coleman–Liau Index was 14.5 (±0.5). Suitability-wise, the DISCERN score of ChatGPT was 48 (±2.5) indicating suitable and comprehensible language for experts. Conclusions: Generative AI tools such as ChatGPT can serve as a supplementary tool for surgeons to offer valuable insights and foster intraoperative problem-solving abilities. However, it lacks consideration of individual patient factors and surgical nuances. Nevertheless, further refinement of its training data and rigorous scrutiny under experts to ensure the accuracy and up-to-date nature of the information holds the potential for it to be utilized in the surgical field."
413,"The article delves into the attitudes, knowledge, and perceptions of artificial intelligence (AI) in healthcare among a racially diverse, lower-income population in Houston, New York, and Los Angeles. It examines how individuals in these communities view AI technologies, particularly focusing on their awareness, acceptance, and concerns regarding AI, including Chat Generative Pretrained Transformer (ChatGPT)."
414,"This article discusses the use of artificial intelligence (AI) language models, specifically Chat Generative Pre-Trained Transformer 4 (GPT-4) by OpenAI and Bard by Google, in answering questions and providing information to the public. The study compares the accuracy and completeness of responses generated by GPT-4 and Bard to questions based on the International Consensus Statement on Endoscopic Skull Base Surgery (ICAR:SB) guidelines. The results show that GPT-4 had higher accuracy and completeness scores compared to Bard. The study concludes that AI language models have the potential to be effective tools for disseminating information in the future."
415,"AbstractPurposeMaterials and methodsResultsConclusionsGenerative AI will become an integral part of education in future. The potential of this technology in different disciplines should be identified to promote effective adoption. This study evaluated the performance of ChatGPT in tutorial and case-based learning questions in physiology and biochemistry for medical undergraduates. Our study mainly focused on the performance of GPT-3.5 version while a subgroup was comparatively assessed on GPT-3.5 and GPT-4 performances.Answers were generated in GPT-3.5 for 44 modified essay questions (MEQs) in physiology and 43 MEQs in biochemistry. Each answer was graded by two independent examiners. Subsequently, a subset of 15 questions from each subject were selected to represent different score categories of the GPT-3.5 answers; responses were generated in GPT-4, and graded.The mean score for physiology answers was 74.7 (SD 25.96). GPT-3.5 demonstrated a statistically significant (<italic>p</italic> = .009) superior performance in lower-order questions of Bloom’s taxonomy in comparison to higher-order questions. Deficiencies in the application of physiological principles in clinical context were noted as a drawback. Scores in biochemistry were relatively lower with a mean score of 59.3 (SD 26.9) for GPT-3.5. There was no statistically significant difference in the scores for higher and lower-order questions of Bloom’s taxonomy. The deficiencies highlighted were lack of in-depth explanations and precision. The subset of questions where the GPT-4 and GPT-3.5 were compared demonstrated a better overall performance in GPT-4 responses in both subjects. This difference between the GPT-3.5 and GPT-4 performance was statistically significant in biochemistry but not in physiology.The differences in performance across the two versions, GPT-3.5 and GPT-4 across the disciplines are noteworthy. Educators and students should understand the strengths and limitations of this technology in different fields to effectively integrate this technology into teaching and learning."
416,"AbstractRecent advancements in natural language processing and large language models have ushered language learning into the age of artificial intelligence (AI). Recognizing the affordances of generative AI tools, this paper aims to examine the degree to which L2 learners accepted and leveraged large language model platforms (e.g. ChatGPT, Bing Chat) for the informal digital learning of English (IDLE) purposes. Employing an explanatory sequential mixed-method design, this study draws on the technology acceptance model (TAM) and collects data <italic>via</italic> an adapted TAM questionnaire and an interview guide. A total of 867 Chinese EFL (English as a foreign language) learners answered the online survey, while 20 attended the post-survey interviews. Drawing on a validated structural model that elucidates the inter-factor relationships of <italic>perceived ease of use</italic>, <italic>perceived usefulness</italic>, <italic>intention to use</italic>, and <italic>actual use</italic>, the quantitative analysis provides statistical accounts for EFL learners’ adoption of Generative Pre-trained Transformer (GPT) technologies. The qualitative findings, derived from the interview data, reveal three key themes: (1) how perceived usefulness of chatbots for IDLE emerges from hands-on experimentation with these tools; (2) how intention to use increases as learners negotiate chatbot affordances and constraints; and (3) how actual use of chatbots for IDLE involves using these tools as tutors or conversation partners. Connections between quantitative and qualitative findings enhance our understanding of how EFL learners negotiate the affordances and constraints of highly capable AI technologies to participate in creative IDLE practices. By understanding these practices, this study draws attention to the attitudes and practices that constitute AI literacies, ultimately offering implications for future classroom practices and research."
417,"The rapid advancement of artificial intelligence (AI) has spotlighted ChatGPT as a key technology in the realm of information retrieval (IR). Unlike its predecessors, it offers notable advantages that have captured the interest of both industry and academia. While some consider ChatGPT to be a revolutionary innovation, others believe its success stems from smart product and market strategy integration. The advent of ChatGPT and GPT-4 has ushered in a new era of Generative AI, producing content that diverges from training examples, and surpassing the capabilities of OpenAI’s previous GPT-3 model. In contrast to the established supervised learning approach in IR tasks, ChatGPT challenges traditional paradigms, introducing fresh challenges and opportunities in text quality assurance, model bias, and efficiency. This paper aims to explore the influence of ChatGPT on IR tasks, providing insights into its potential future trajectory."
418,"The development of open educational resources (OER) plays a key role in addressing the challenge of access to affordable, appropriate, high-quality teaching and learning materials. This is particularly the case in health sciences in South Africa, where there is a strong imperative around local production of contextually appropriate resources that can be openly accessible within institutions and in practice. This case study details the creation and iterative review approaches undertaken by undergraduate medical students in a study module focused on creating chapters for an orthopaedics open textbook through the use of ChatGPT. It also explores the nuances of the lecturer's process, particularly as relates to assessment, quality, and his ambitions to promote student voice through co-creation. The findings demonstrate that ChatGPT has the potential to be the game changer needed to help build OER production in the Global South, particularly in terms of the speeding up of the process. They also suggest that processes of this kind have a role to play in building students' critical artificial intelligence (AI) digital literacy skills and in boosting their sense of agency. This work stands to make an important contribution in terms of profiling institutional cases where AI is being used in an innovative, responsible manner in the classroom. It also aims to make a unique Global South contribution to the rapidly emerging global discourse around the use of AI in teaching and learning, and the use of collaborative content development approaches to promote student voice and social justice in higher education."
419,"Drug discovery is adapting to novel technologies such as data science, informatics, and artificial intelligence (AI) to accelerate effective treatment development while reducing costs and animal experiments. AI is transforming drug discovery, as indicated by increasing interest from investors, industrial and academic scientists, and legislators. Successful drug discovery requires optimizing properties related to pharmacodynamics, pharmacokinetics, and clinical outcomes. This review discusses the use of AI in the three pillars of drug discovery: diseases, targets, and therapeutic modalities, with a focus on small-molecule drugs. AI technologies, such as generative chemistry, machine learning, and multiproperty optimization, have enabled several compounds to enter clinical trials. The scientific community must carefully vet known information to address the reproducibility crisis. The full potential of AI in drug discovery can only be realized with sufficient ground truth and appropriate human intervention at later pipeline stages."
420,"Extant chatbots such as ChatGPT and Bard are currently able to converse with humans in natural language, demonstrating impressive linguistic responses. Or so it seems. I critically examine artificial intelligence systems such as these chatbots through examples of dialogue. When taking a systems view of AI, there is a vast and unique human culture in the environmental surroundings of the AI system (its negasystem) that is not accessible to extant AI systems. These generative AI systems, based on large language models, are trained with trillions of signs created by humans in the form of digital text and images as part of their machine learning from which they construct their unique neural networks. However, AI systems do not understand well, if at all, the meanings of those signs that we associate with our human experience of the world and our culture (i.e., in the AI negasystem). Similarly, we humans do not understand well the inner workings of an AI system (its neural network). Teachers and students in education must be very careful and cautious when using such AI systems. Are we dupes? Or not? Without thinking critically and checking facts independently, we can be fooled by responses of those AI systems."
421,"This article discusses recent advancements in artificial intelligence (AI) tools and digital technologies, focusing on OpenAI's ChatGPT-4 Turbo and Google's Gemini. It also raises concerns about the environmental impact of generative AI and the amplification of biases in AI image generators. The article mentions two newly published books, ""Understanding Digital Racism"" and ""Media Backends,"" which explore the ethical implications of media technologies and the need for conversations about ethical responsibilities. These books are valuable resources for media ethics scholars and professionals in understanding and addressing the ethical challenges posed by digital technologies. The book ""Media Backends"" examines the influence of backends on our understanding of media, the inequalities that arise when workplace discrimination and algorithmic violence are not addressed, and the ethical issues surrounding problematic backends. It provides a comprehensive analysis drawing on feminist, queer, and intersectional critiques, and includes real-world cases for teaching and discussion purposes."
422,"Artificial intelligence has been attracting the attention of educational researchers recently, especially ChatGPT as a generative artificial intelligence tool. The context of generative artificial intelligence could impact different aspects of students' learning, such as the motivational aspect. The present research intended to investigate the characteristics of students' task motivation in the artificial intelligence context, specifically in the ChatGPT context. The researchers interviewed 15 students about their experiences with ChatGPT to collect data. The researchers used inductive and deductive content analysis to investigate students' motivation when learning with ChatGPT. To arrive at the categories and sub-categories of students' motivation, the researchers used the MAXQDA 2022. Five main categories emerged: task enjoyment, reported effort, result assessment, perceived relevance, and interaction. Each category comprised at least two sub-categories, and each sub-category was further organized into codes. The results indicated more positive characteristics of motivation than negative ones. The previous results could be due to the conversational or social aspect of the chatbot, enabling relationships with humans and enabling the maintenance of good quality conversations with them. We conclude that a generative AI could be utilized in educational settings to promote students' motivation to learn and thus raise their learning achievement."
423,"The Chat Generative Pre-training Transformer (GPT), also known as ChatGPT, is a powerful generative AI model that can simulate human-like dialogues across a variety of domains. However, this popularity has attracted the attention of malicious actors who exploit ChatGPT to launch cyberattacks. This paper examines the tactics that adversaries use to leverage ChatGPT in a variety of cyberattacks. Attackers pose as regular users and manipulate ChatGPT's vulnerability to malicious interactions, particularly in the context of cyber assault. The paper presents illustrative examples of cyberattacks that are possible with ChatGPT and discusses the realm of ChatGPT-fueled cybersecurity threats. The paper also investigates the extent of user awareness of the relationship between ChatGPT and cyberattacks. A survey of 253 participants was conducted, and their responses were measured on a three-point Likert scale. The results provide a comprehensive understanding of how ChatGPT can be used to improve business processes and identify areas for improvement. Over 80% of the participants agreed that cyber criminals use ChatGPT for malicious purposes. This finding underscores the importance of improving the security of this novel model. Organizations must take steps to protect their computational infrastructure. This analysis also highlights opportunities for streamlining processes, improving service quality, and increasing efficiency. Finally, the paper provides recommendations for using ChatGPT in a secure manner, outlining ways to mitigate potential cyberattacks and strengthen defenses against adversaries."
424,"Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs‐based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer‐reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state‐of‐the‐art models (eg, GPT‐3/4), embracing the initiative of open‐sourcing models/systems, and adopting a human‐centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models. Practitioner notesWhat is currently known about this topic Generating and analysing text‐based content are time‐consuming and laborious tasks.Large language models are capable of efficiently analysing an unprecedented amount of textual content and completing complex natural language processing and generation tasks.Large language models have been increasingly used to develop educational technologies that aim to automate the generation and analysis of textual content, such as automated question generation and essay scoring.What this paper adds A comprehensive list of different educational tasks that could potentially benefit from LLMs‐based innovations through automation.A structured assessment of the practicality and ethicality of existing LLMs‐based innovations from seven important aspects using established frameworks.Three recommendations that could potentially support future studies to develop LLMs‐based innovations that are practical and ethical to implement in authentic educational contexts.Implications for practice and/or policy Updating existing innovations with state‐of‐the‐art models may further reduce the amount of manual effort required for adapting existing models to different educational tasks.The reporting standards of empirical research that aims to develop educational technologies using large language models need to be improved.Adopting a human‐centred approach throughout the developmental process could contribute to resolving the practical and ethical challenges of large language models in education."
425,"The 4‐day work week (4DWW) was popularised in the 1970s, but has recently gained significant global attention again, with a growing number of organisations experimenting with the 4DWW in response to increasing demand for more flexible work arrangements (FWA) in the aftermath of the COVID‐19 pandemic. The emergence of generative AI tools like ChatGPT, with their potential to support worktime reduction strategies, are also refuelling interest in a shorter working week. This renewed interest motivated this scoping review of 1769 4DWW records from the past 52 years and enabled the authors to identify five major themes: employee acceptance, allocation of time, leisure, gender and career advancement, and productivity. These themes are used to consider specific forms of 4DWW in terms of whether days of work are fixed or flexible, whether the 4DWW is an employee option, and whether total weekly hours worked or pay are reduced. Conservation of resources theory is used as a lens for interpreting the themes. The authors believe these themes and lessons have significant implications for a growing number of scholars and practitioners, who are investigating, trialling, and implementing 4DWW arrangements, in response to growing demand for more FWA options from employees across all sectors."
426,"ChatGPT has drawn considerable attention from both the general public and domain experts with its remarkable text generation capabilities. This has subsequently led to the emergence of diverse applications in the field of biomedicine and health. In this work, we examine the diverse applications of large language models (LLMs), such as ChatGPT, in biomedicine and health. Specifically, we explore the areas of biomedical information retrieval, question answering, medical text summarization, information extraction and medical education and investigate whether LLMs possess the transformative power to revolutionize these tasks or whether the distinct complexities of biomedical domain presents unique challenges. Following an extensive literature survey, we find that significant advances have been made in the field of text generation tasks, surpassing the previous state-of-the-art methods. For other applications, the advances have been modest. Overall, LLMs have not yet revolutionized biomedicine, but recent rapid progress indicates that such methods hold great potential to provide valuable means for accelerating discovery and improving health. We also find that the use of LLMs, like ChatGPT, in the fields of biomedicine and health entails various risks and challenges, including fabricated information in its generated responses, as well as legal and privacy concerns associated with sensitive patient data. We believe this survey can provide a comprehensive and timely overview to biomedical researchers and healthcare practitioners on the opportunities and challenges associated with using ChatGPT and other LLMs for transforming biomedicine and health."
427,"This article reassesses the impact of Artificial Intelligence on war and revisits an article published in 2018 by one of the authors in Orbis. Despite the remarkable progress in generative AI, the authors contend that war's essential nature will be impacted to a degree but will not be substantially altered."
428,"Aim: Chatbot Generative Pre‐trained Transformer (ChatGPT) is a generative artificial intelligence (AI) software based on large language models (LLMs), designed to simulate human conversations and generate novel content based on the training data it has been exposed to. The aim of this study was to evaluate the consistency and accuracy of ChatGPT‐generated answers to clinical questions in endodontics, compared to answers provided by human experts. Methodology: Ninety‐one dichotomous (yes/no) questions were designed and categorized into three levels of difficulty. Twenty questions were randomly selected from each difficulty level. Sixty answers were generated by ChatGPT for each question. Two endodontic experts independently answered the 60 questions. Statistical analysis was performed using the SPSS program to calculate the consistency and accuracy of the answers generated by ChatGPT compared to the experts. Confidence intervals (95%) and standard deviations were used to estimate variability. Results: The answers generated by ChatGPT showed high consistency (85.44%). No significant differences in consistency were found based on question difficulty. In terms of answer accuracy, ChatGPT achieved an average accuracy of 57.33%. However, significant differences in accuracy were observed based on question difficulty, with lower accuracy for easier questions. Conclusions: Currently, ChatGPT is not capable of replacing dentists in clinical decision‐making. As ChatGPT's performance improves through deep learning, it is expected to become more useful and effective in the field of endodontics. However, careful attention and ongoing evaluation are needed to ensure its accuracy, reliability and safety in endodontics."
429,"The article discusses how copyright law clashes with the interests of art historians and artists. It argues that the excessive focus on copyright neglects other crucial aspects of the law affecting art. It is reported that two key developments, the Warhol v. Goldsmith case and the rise of generative AI (artificial intelligence), highlight the urgency of addressing copyright issues in art."
430,"With over 180 million users engaging with ChatGPT by late-2023 estimates, the need for educational resources, workshops, and discussions on its use has become imperative. This article explores the evolving role of ChatGPT in academic libraries, highlighting proactive initiatives by university libraries to integrate the technology. Through 25 prompts nested in 10 relevant use cases, the authors underscore the utility of ChatGPT, while cautioning against the tool's limitations. The article is a call for libraries to stay informed, skill share, and adapt their practices to harness the benefits of AI, while also mitigating potential pitfalls."
431,"A 2D U-Net was trained to generate synthetic T1p maps from T2 maps for knee MRI to explore the feasibility of domain adaptation for enriching existing datasets and enabling rapid, reliable image reconstruction. The network was developed using 509 healthy contralateral and injured ipsilateral knee images from patients with ACL injuries and reconstruction surgeries acquired across three institutions. Network generalizability was evaluated on 343 knees acquired in a clinical setting and 46 knees from simultaneous bilateral acquisition in a research setting. The deep neural network synthesized high-fidelity reconstructions of T1p maps, preserving textures and local T1p elevation patterns in cartilage with a normalized mean square error of 2.4% and Pearson's correlation coefficient of 0.93. Analysis of reconstructed T1p maps within cartilage compartments revealed minimal bias (−0.10 ms), tight limits of agreement, and quantification error (5.7%) below the threshold for clinically significant change (6.42%) associated with osteoarthritis. In an out-of-distribution external test set, synthetic maps preserved T1p textures, but exhibited increased bias and wider limits of agreement. This study demonstrates the capability of image synthesis to reduce acquisition time, derive meaningful information from existing datasets, and suggest a pathway for standardizing T1p as a quantitative biomarker for osteoarthritis."
432,"In August 2022, the Cancer Informatics for Cancer Centers brought together cancer informatics leaders for its biannual symposium, Precision Medicine Applications in Radiation Oncology, co-chaired by Quynh-Thu Le, MD (Stanford University), and Walter J. Curran, MD (GenesisCare). Over the course of 3 days, presenters discussed a range of topics relevant to radiation oncology and the cancer informatics community more broadly, including biomarker development, decision support algorithms, novel imaging tools, theranostics, and artificial intelligence (AI) for the radiotherapy workflow. Since the symposium, there has been an impressive shift in the promise and potential for integration of AI in clinical care, accelerated in large part by major advances in generative AI. AI is now poised more than ever to revolutionize cancer care. Radiation oncology is a field that uses and generates a large amount of digital data and is therefore likely to be one of the first fields to be transformed by AI. As experts in the collection, management, and analysis of these data, the informatics community will take a leading role in ensuring that radiation oncology is prepared to take full advantage of these technological advances. In this report, we provide highlights from the symposium, which took place in Santa Barbara, California, from August 29 to 31, 2022. We discuss lessons learned from the symposium for data acquisition, management, representation, and sharing, and put these themes into context to prepare radiation oncology for the successful and safe integration of AI and informatics technologies."
433,"Artificial intelligence (AI) is routinely mentioned in journals and newspapers, and non-technical outsiders may have difficulty in distinguishing hyperbole from reality. We present a practical guide to help non-technical neurologists to understand healthcare AI. AI is being used to support clinical decisions in treating neurological disorders. We introduce basic concepts of AI, such as machine learning and natural language processing, and explain how AI is being used in healthcare, giving examples its benefits and challenges. We also cover how AI performance is measured, and its regulatory aspects in healthcare. An important theme is that AI is a general-purpose technology like medical statistics, with broad utility applicable in various scenarios, such that niche approaches are outpaced by approaches that are broadly applicable in many disease areas and specialties. By understanding AI basics and its potential applications, neurologists can make informed decisions when evaluating AI used in their clinical practice. This article was written by four humans, with generative AI helping with formatting and image generation."
434,"Objectives: Letters of recommendation (LORs) are essential within academic medicine, affecting a number of important decisions regarding advancement, yet these letters take significant amounts of time and labor to prepare. The use of generative artificial intelligence (AI) tools, such as ChatGPT, are gaining popularity for a variety of academic writing tasks and offer an innovative solution to relieve the burden of letter writing. It is yet to be determined if ChatGPT could aid in crafting LORs, particularly in high‐stakes contexts like faculty promotion. To determine the feasibility of this process and whether there is a significant difference between AI and human‐authored letters, we conducted a study aimed at determining whether academic physicians can distinguish between the two. Methods: A quasi‐experimental study was conducted using a single‐blind design. Academic physicians with experience in reviewing LORs were presented with LORs for promotion to associate professor, written by either humans or AI. Participants reviewed LORs and identified the authorship. Statistical analysis was performed to determine accuracy in distinguishing between human and AI‐authored LORs. Additionally, the perceived quality and persuasiveness of the LORs were compared based on suspected and actual authorship. Results: A total of 32 participants completed letter review. The mean accuracy of distinguishing between human‐ versus AI‐authored LORs was 59.4%. The reviewer's certainty and time spent deliberating did not significantly impact accuracy. LORs suspected to be human‐authored were rated more favorably in terms of quality and persuasiveness. A difference in gender‐biased language was observed in our letters: human‐authored letters contained significantly more female‐associated words, while the majority of AI‐authored letters tended to use more male‐associated words. Conclusions: Participants were unable to reliably differentiate between human‐ and AI‐authored LORs for promotion. AI may be able to generate LORs and relieve the burden of letter writing for academicians. New strategies, policies, and guidelines are needed to balance the benefits of AI while preserving integrity and fairness in academic promotion decisions."
435,"Large language models (LLMs) can produce text that leaves the impression that one may be interacting with a conscious agent. Present-day LLMs are text-centric, whereas the phenomenological umwelt of living organisms is multifaceted and integrated. Many theories of the neural basis of consciousness assign a central role to thalamocortical re-entrant processing. Currently, such processes are not implemented in LLMs. The organizational complexity of living systems has no parallel in present-day AI tools. Possibly, AI systems would have to capture this biological complexity to be considered conscious. LLMs and the current debates on conscious machines provide an opportunity to re-examine some core ideas of the science of consciousness. Interactions with large language models (LLMs) have led to the suggestion that these models may soon be conscious. From the perspective of neuroscience, this position is difficult to defend. For one, the inputs to LLMs lack the embodied, embedded information content characteristic of our sensory contact with the world around us. Secondly, the architectures of present-day artificial intelligence algorithms are missing key features of the thalamocortical system that have been linked to conscious awareness in mammals. Finally, the evolutionary and developmental trajectories that led to the emergence of living conscious organisms arguably have no parallels in artificial systems as envisioned today. The existence of living organisms depends on their actions and their survival is intricately linked to multi-level cellular, inter-cellular, and organismal processes culminating in agency and consciousness."
436,"Rapid advancements in generative artificial intelligence (AI), specifically large language models (LLMs), offer unprecedented opportunities and challenges for qualitative researchers. This paper presents comprehensive guidelines for the ethical and effective use of LLMs in the development and refinement of interview protocols. Through a multidisciplinary lens, this paper explores potential pitfalls, ethical considerations, and best practices to ensure the responsible integration of LLMs in the research process. The guidelines proposed serve not only as a methodological roadmap for researchers but also as a catalyst for dialogue on the ethical dimensions of LLMs in qualitative research. Furthermore, the authors describe and share a web-based application developed to guide users through the stages of the protocol. Ultimately, the paper calls for a collective, informed approach to harness the capabilities of LLMs while upholding the integrity and ethical standards of scholarly research."
437,"Generative artificial intelligence (AI) is a burgeoning field with widespread applications, including in science. Here, we explore two paradigms that provide insight into the capabilities and limitations of Chat Generative Pre-trained Transformer (ChatGPT): its ability to (i) define a core biological concept (the Central Dogma of molecular biology); and (ii) interpret the genetic code."
438,"This review is aimed at synthesizing current findings concerning technology-based cognitive offloading and the associated effects on learning and memory. While cognitive externalization (i.e., using the environment to outsource mental computation) is a highly useful technique in various problem-solving tasks, a growing body of research suggests that the offloading of information into the environment (and digital storage in particular) can have negative effects on learning. Based on this review, a model of offloading with cognitive load at its core is developed to summarize when learners offload information. A high intrinsic cognitive load (i.e., a high difficulty), a high extraneous load (i.e., unnecessary design elements), and a low perceived or actual working memory capacity trigger offloading. Crucially, the value attributed to information also affects whether information is externalized. In this model, extraneous cognitive load in the design of technology-enhanced learning acts as a triple barrier: (1) It prevents information from entering working memory, (2) it inhibits information being stored in long-term memory, and (3) it can prevent learners from externalizing information using technology. As a result, in many instances, only the gist of information (or its location) is retained, while learners often gain the illusion of having memorized that information. Furthermore, offloading substantially increases the risk of memory manipulation, potentially posing a societal problem. Consequently, educational approaches should maximize the meaningfulness of the residual information that is often retained in the form of “biological pointers.” In addition, current issues surrounding the use of generative artificial intelligence pertaining to externalization are discussed."
439,"This article discusses the development and potential impact of generative artificial intelligence (AI). The author reflects on the rapid advancements in digital technology over the past few decades, leading up to the emergence of AI. The article explores the question of whether we should fear generative AI and presents a response from an AI program called ChatGPT. The program acknowledges the need for caution and ethical use of AI, highlighting concerns such as misinformation, privacy issues, malicious use, job displacement, and bias. The author concludes that while AI has its limitations, it is a powerful tool that can be harnessed for both positive and negative purposes."
440,"INNOVATIONS Artificial intelligence should enhance your skill set rather than replace you. The Generative AI Skills Grant Challenge explores how nonprofits, social enterprises, and research institutions can train the workforce to use generative AI. According to the World Economic Forum's The Future of Jobs Report 2023, training employees to use AI and big data is the third-highest priority for skills training from 2023 to 2027, behind analytical thinking and creative thinking."
441,"The article focuses on the critical importance of strategic planning in marketing amidst economic uncertainty, emphasizing the need for clear goals, audience understanding and effective connection strategies. It highlights the impact of proactive planning on success, explores the challenges faced by marketers and discusses the influence of technologies like generative AI, providing insights and strategies for marketing success in 2024."
442,"In a sweeping executive order, US President Joseph R. Biden Jr. on Monday set up a comprehensive series of standards, safety and privacy protections, and oversight measures for the development and use of artificial intelligence (AI). ""The order underscores a much-needed shift in global attention toward regulating AI, especially after the generative AI boom we have all witnessed this year"", said Adnan Masood, chief AI architect at digital transformation services company UST. Fennessy also applauded US government efforts on digital watermarking for AI-generated content and AI safety standards for government procurement, among many other measures."
443,"The article focuses on identifying trend-setting products for 2023 that pioneer new approaches to knowledge management (KM), covering various cutting-edge technologies and platforms, such as generative Artificial intelligence (AI), natural language processing, machine learning, and more. It emphasizes the importance of digital transformation in the hybrid workforce era, highlighting the role of cloud-powered applications, advanced enterprise search capabilities."
444,"The article discusses the use and implications of generative artificial intelligence (AI), specifically ChatGPT, in the legal landscape. It explores the capabilities of ChatGPT and its potential applications in the legal profession. It further discusses the strengths and limitations of ChatGPT, emphasizing its ability to generate human-like responses, draft content, and assist in various tasks."
445,"The knowledge of scientific articles within Generative Pre-trained Transformers (GPT) is not exhaustive due to factors such as data coverage, freshness, complexity, paywalls, and context. While it can provide general information on scientific topics, it may struggle with specialized terminology, recent research, and nuanced understanding. As a result, relying on GPT as a scientific assistant tool may not be ideal. Instead, it is important to consult specialized resources and databases for a comprehensive understanding of specific scientific domains and access to the latest research. A custom data driven GPT can enhance its performance as a scientific assistant tool by improving domain knowledge, providing up-to-date information, reducing ambiguity and errors, performing customized tasks, and offering enhanced search capabilities. This work demonstrates and evaluates the use of such GPT models using a small selection of peer reviewed published thermal spray articles as the reference domain knowledge. The specific domain knowledge model works exceptionally well outperforming the general state-of-the-art large language models. • Accelerating academic research by efficiently identifying relevant sources • Domain specific knowledge for Large Language Models • Vector indexing allows for quicker model tuning by representing data points in a high-dimensional space."
446,"TIME 100 Companies Leaders Training generative AI models like ChatGPT requires thousands of the fastest graphics processing units (GPUs). After touching a $1 trillion market cap in May, the company announced that an even more powerful GPU-CPU combo chip, the GH200 (named after computing pioneer Grace Hopper), has entered full production. With 88% of the GPU market, Nvidia's cutting-edge chips are enabling the AI boom as its industry struggles to keep up with exploding demand."
447,"The article focuses on the misconception that Artificial Intelligence (AI), particularly generative AI such as ChatGPT, represents the entire future of knowledge management (KM), emphasizing that other aspects of KM are equally important. Topics include the need for a balanced approach integrating human understanding with AI capabilities and the importance of aligning KM with enterprise goals while considering the challenges and implications of AI adoption."
448,"In recent years, with the advance of Artificial Intelligence, automatic music composition has been demonstrated. However, there are many music genres and music instruments. For a same piece of music, different music instruments would produce different effects. Invented some 2500 years ago, Guzheng is one of the oldest music instruments in China and the world. It has distinct timbres and patterns that cannot be duplicated by other music instruments. Therefore, it is interesting to see whether AI can compose Guzheng music or alike. In this paper we present a method that can automatically compose and play Guzheng music. First, we collect a number of existing Guzheng music pieces and convert them into Music Instrument Digital Interface format. Second, we use these data to train a Long Short-Term Memory (LSTM) network and use the trained network to generate new Guzheng music pieces. Next, we use the Reinforcement Learning to optimize the LSTM network by adding special Guzheng playing techniques. Comparing to the existing AI methods, such as LSTM and Generative Adversary Network, our new method is more effective in capturing the characteristics of Guzheng music. According to the evaluations from skilled Guzheng players and general audiences, our Guzheng music is very close to the real Guzheng music. The presented method can also be used to automatically compose the music of other Chinese music instruments."
449,"This paper describes an electricity technical/nontechnical loss detection method capable of loss type identification, classification, and location. Several technologies are implemented to obtain that goal: (i) an architecture of three generative cooperative AI modules and two additional non-cooperative AI modules for data knowledge sharing is proposed, (ii) new expert consumption-based knowledge of feature collaboration of the entire consumption data are embedded as features in an AI classification algorithm, and (iii) an anomaly pooling mechanism that enables one-to-one mapping of signatures to loss types is proposed. A major objective of the paper is an explanation of how an exact loss type to signature mapping is obtained simply and rapidly, (iv) the role of the reactive energy load profile for enhancing signatures for loss types is exemplified, (v) a mathematical demonstration of the quantitative relationship between the features space to algorithm performance is obtained generically for any algorithm, and (vi) a theory of ""generative cooperative modules"" for technical/nontechnical loss detection is located and mapped to the presented system. The system is shown to enable high-accuracy technical/nontechnical loss detection, especially differentiated from other grid anomalies that certainly exist in field conditions and are not tagged in the universal datasets. The ""pooling"" architecture algorithm identifies all other loss types, and a robotic process automation module obtains loss type localization. The system feeds from the entire smart metering data, not only the energy load profile. Other solutions, such as a stand-alone algorithm, have difficulty in obtaining low false positive in field conditions. The work is tested experimentally to demonstrate the matching of experiment and theory."
450,"In recent times, researchers have proposed several approaches for building floorplans using parametric/generative design, shape grammars, machine learning, AI, etc. This paper aims to demonstrate a mathematical approach for the automated generation of floorplan layouts. Mathematical formulations warrant the fulfilment of all input user constraints, unlike the learning‐based methods present in the literature. Moreover, the algorithms illustrated in this paper are robust, scalable and highly efficient, generating thousands of floorplans in a few milliseconds. We present G2PLAN, a software based on graph‐theoretic and linear optimization techniques, that generates all topologically distinct floorplans with different boundary rooms in linear time for given adjacency and dimensional constraints. G2PLAN builds on the work of GPLAN and offers solutions to a wider range of adjacency relations (one‐connected, non‐triangulated graphs) and better dimensioning customizability. It also generates a catalogue of dimensionless as well as dimensioned floorplans satisfying user requirements."
451,"Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research. This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and ability based on several factors such as adaptation to new tasks, competence in domains not intentionally trained for, ability to learn from few data, or proactive acknowledgement of their own limitations. We then propose a taxonomy of approaches to realise GPAIS, describing research trends such as the use of AI techniques to improve another AI (commonly referred to as AI-powered AI) or (single) foundation models. As a prime example, we delve into generative AI (GenAI), aligning them with the terms and concepts presented in the taxonomy. Similarly, we explore the challenges and prospects of multi-modality, which involves fusing various types of data sources to expand the capabilities of GPAIS. Through the proposed definition and taxonomy, our aim is to facilitate research collaboration across different areas that are tackling general purpose tasks, as they share many common aspects. Finally, with the goal of providing a holistic view of GPAIS, we discuss the current state of GPAIS, its prospects, implications for our society, and the need for regulation and governance of GPAIS to ensure their responsible and trustworthy development. • Presents a holistic view of General Purpose Artificial Intelligence Systems. • Consolidates a definition for general-purpose AI based on their degree of autonomy. • Breaking it down onto a taxonomy of approaches to build general-purpose AI systems. • A close look into Generative AI as a prime example of general-purpose AI systems. • Discusses open challenges, implications for our society and need for regulation."
452,"The article presents the highlights of the 2023 Association of College & Research Libraries (ACRL) Science and Technology Section (STS) Hot Topics Committee panel discussion held in Pittsburgh, Pennsylvania. Topics include the advent of generative artificial intelligence (AI) and large language models (LLM). Presenters include Mohammad Hosseini, Thomas James Ferrill, and Mark Chalmers."
453,"The article presents advice from chief financial officers (CFO) aimed to help accounting and finance leaders navigate anticipated challenges in 2024. Cited are ways on how leaders can overcome challenges brought by rapid advances in generative artificial intelligence (AI) and other innovations, trends to watch in 2024 and beyond such as the growing importance of data management and analytics, and the complexity associated with the rise of sustainability."
454,"Nicotine addiction circuits involve integrating specific brain regions that alter to frequent smoking. Detection of these circuits via fMRI contributes to understanding addiction-related mechanisms. Identification of the functional circuits and networks altered by nicotine is essential to improve the treatment of nicotine addiction. However, analyzing fMRI data and detecting functional addiction circuits still have challenges. In this work, we developed a generative AI-enabled framework, rat addiction-related circuits detection platform (RADP), to detect nicotine-related circuits. It has an end-to-end pipeline: functional imaging data acquisition from neurobiological experiments, computational modeling for brain networks, and a novel generative model including spatiotemporal transformer auto-encoder (STA) and dynamic circuits analysis. The proposed spatiotemporal representation contrasting trains the encoder of STA to contrastively capture representations between the addictive and the control groups. Experimental results indicate that the framework can efficiently detect the verified addiction circuits and discover the unknown but significant circuits. Moreover, RADP can be served as a general tool which can be extended to other brain circuits."
455,"Background and aims: ChatGPT is a powerful artificial intelligence (AI) chatbot developed by the OpenAI research laboratory which is capable of analysing human input and generating human‐like responses. Early research into the potential application of ChatGPT in healthcare has focused mainly on clinical and administrative functions. The diagnostic ability and utility of ChatGPT in histopathology is not well defined. We benchmarked the performance of ChatGPT against pathologists in diagnostic histopathology, and evaluated the collaborative potential between pathologists and ChatGPT to deliver more accurate diagnoses. Methods and results: In Part 1 of the study, pathologists and ChatGPT were subjected to a series of questions encompassing common diagnostic conundrums in histopathology. For Part 2, pathologists reviewed a series of challenging virtual slides and provided their diagnoses before and after consultation with ChatGPT. We found that ChatGPT performed worse than pathologists in reaching the correct diagnosis. Consultation with ChatGPT provided limited help and information generated from ChatGPT is dependent on the prompts provided by the pathologists and is not always correct. Finally, we surveyed pathologists who rated the diagnostic accuracy of ChatGPT poorly, but found it useful as an advanced search engine. Conclusions: The use of ChatGPT4 as a diagnostic tool in histopathology is limited by its inherent shortcomings. Judicious evaluation of the information and histopathology diagnosis generated from ChatGPT4 is essential and cannot replace the acuity and judgement of a pathologist. However, future advances in generative AI may expand its role in the field of histopathology."
456,"The article focuses on the impact of generative artificial intelligence (AI) on the creative process. Topics discussing instances where AI has been used in art campaigns; highlighting concerns among creatives about the potential replacement or copying of original work; emphasizes the intrinsic value of human creativity; and drawing parallels to biblical narratives that underscore the importance of the creative process and human involvement in shaping the world."
457,"The article offers information on the pervasive influence of AI in various domains, with a focus on its impact on libraries, legal areas, and general applications. Topics include recent developments in AI regulation, G7 principles on AI, and President Joe Biden's executive order on trustworthy AI. The article explores the challenges and opportunities presented by AI, particularly generative AI (GenAI), in libraries and information services."
458,"The article highlights the mixed feelings of marketing and communication professionals regarding the usefulness of generative AI tools, with about 3 in 10 expecting them to improve work quality and creativity. It discusses challenges, including the generation of inaccurate or hallucinated content and provides insights on minimizing errors, human oversight and appropriate use of generative AI."
459,"This article reports on the environmental impacts of generative artificial intelligence (AI). Topics include the rise in demand for generative AI hardware, including graphics processing units (GPUs), as well as analysis on power consumption and carbon emissions based on the rise in generative AI usage."
460,"The article discusses the principles by the Russell Group of universities for use of generative artificial intelligence (AI) and new technologies like ChatGPT in teaching and learning. It discusses that the five principles aim to support ethical and equal access to AI; uphold academic integrity; foster collaboration among universities to share best practices; and the principles come in response to the United Kingdom (UK) Government's consultation on the use of generative AI in education."
461,"The article focuses on the growing interest in Artificial intelligence (AI), particularly generative AI like ChatGPT, and its increasing importance across various business sectors. It discusses the potential applications of AI technologies in knowledge sharing, highlights the growth of the global AI market, and emphasizes the significance of AI within organizations, spanning marketing, customer service, legal, finance, and more."
462,"The article focuses on the importance of positioning new technologies as teammates for sellers rather than replacements. It highlights the potential of technologies like generative Artificial intelligence (AI) and digital humans to transform the role of sellers and meet the changing needs of buyers. It mentions by combining human capabilities with the right technologies, organizations can achieve augmented selling and provide real-time collaboration and assistance to buyers."
463,"The article focuses on artificial intelligence (AI) as a top trend in marketing, but highlights the need for marketers to not overlook other important technologies and trends. It discusses the impact of generative AI on content generation and its potential for hyper-personalized marketing messages, while also noting that marketers should be aware of a broader range of technologies and their applications in streamlining processes and gaining efficiencies."
464,"The article focuses on the evolution and importance of account-based marketing (ABM) in B2B companies. Topics include the shift from mass marketing to personalized approaches, the role of technology in ABM, the focus on individual buyers within target accounts, and the future potential of generative AI in enhancing ABM strategies."
465,"Metabolic dysfunction‐associated fatty liver disease (MAFLD) has reached epidemic proportions worldwide and is the most frequent cause of chronic liver disease in developed countries. Within the spectrum of liver disease in MAFLD, steatohepatitis is a progressive form of liver disease and hepatocyte ballooning (HB) is a cardinal pathological feature of steatohepatitis. The accurate and reproducible diagnosis of HB is therefore critical for the early detection and treatment of steatohepatitis. Currently, a diagnosis of HB relies on pathological examination by expert pathologists, which may be a time‐consuming and subjective process. Hence, there has been interest in developing automated methods for diagnosing HB. This narrative review briefly discusses the development of artificial intelligence (AI) technology for diagnosing fatty liver disease pathology over the last 30 years and provides an overview of the current research status of AI algorithms for the identification of HB, including published articles on traditional machine learning algorithms and deep learning algorithms. This narrative review also provides a summary of object detection algorithms, including the principles, historical developments, and applications in the medical image analysis. The potential benefits of object detection algorithms for HB diagnosis (specifically those combined with a transformer architecture) are discussed, along with the future directions of object detection algorithms in HB diagnosis and the potential applications of generative AI on transformer architecture in this field. In conclusion, object detection algorithms have huge potential for the identification of HB and could make the diagnosis of MAFLD more accurate and efficient in the near future."
466,"The availability of natural protein sequences synergized with generative AI provides new paradigms to engineer enzymes. Although active enzyme variants with numerous mutations have been designed using generative models, their performance often falls short of their wild type counterparts. Additionally, in practical applications, choosing fewer mutations that can rival the efficacy of extensive sequence alterations is usually more advantageous. Pinpointing beneficial single mutations continues to be a formidable task. In this study, using the generative maximum entropy model to analyze Renilla luciferase (RLuc) homologs, and in conjunction with biochemistry experiments, we demonstrated that natural evolutionary information could be used to predictively improve enzyme activity and stability by engineering the active center and protein scaffold, respectively. The success rate to improve either luciferase activity or stability of designed single mutants is ~50%. This finding highlights nature's ingenious approach to evolving proficient enzymes, wherein diverse evolutionary pressures are preferentially applied to distinct regions of the enzyme, ultimately culminating in an overall high performance. We also reveal an evolutionary preference in RLuc toward emitting blue light that holds advantages in terms of water penetration compared to other light spectra. Taken together, our approach facilitates navigation through enzyme sequence space and offers effective strategies for computer-aided rational enzyme engineering."
467,"Text-guided synthesis of images has become enormously popular and online communities dedicated to text-to-image generation and art generated with Artificial Intelligence (AI) have emerged. While deep generative models can synthesise high-quality images and artworks from simple descriptive text prompts, practitioners of text-to-image generation typically seek to control the generative model’s output by adding short key phrases (‘modifiers’) to the prompt. This paper identifies six types of prompt modifiers used by practitioners in the online text-to-image community based on a 3-month ethnographic study. The novel taxonomy of prompt modifiers provides researchers a conceptual starting point for investigating the practice of text-to-image generation, but may also help practitioners of AI generated art improve their images. We further outline how prompt modifiers are applied in the practice of ‘prompt engineering.’ and discuss research opportunities of this novel creative practice in the field of Human–Computer Interaction (HCI). The paper concludes with a discussion of broader implications of prompt engineering from the perspective of Human-AI Interaction (HAI) in future applications beyond the use case of text-to-image generation and AI generated art."
468,"The reconstruction and representation of ancient artifacts and scenes through illustration is a cornerstone in the communication of archaeological findings. Sketches of the past have transformed over time, incorporating broader technological changes, from photography to the digital tools that have become prevalent through the twenty-first century. Most recently, developments in generative artificial intelligence (AI) promise to reshape the way we represent the past to professional and public audiences. This article shows how to use an accessible and inexpensive artificial intelligence platform to generate complex archaeological illustrations. As a case study, we create multiple scenes representing competing hypotheses about Neanderthal behavior. Using the images to visually communicate alternative hypotheses, we demonstrate how archaeological illustration using artificial intelligence promises to democratize the production of visual representations of the past."
469,"The article discusses the role of artificial intelligence (AI) language models, specifically Chat Generative Preâ€Trained Transformer (ChatGPT), in dermatology. The authors evaluated ChatGPT's responses to questions about basal cell carcinoma (BCC) and found that while it provided accurate information, it lacked nuanced details and referenced outdated studies. The article highlights the benefits and limitations of using AI tools like ChatGPT in diagnosing and managing BCC, emphasizing the need for continuous refinement of AI models and responsible use in patient care. The authors suggest that future versions of AI models could incorporate image analysis and specific training in dermatological guidelines to improve their usefulness in dermatology."
470,"The widespread adoption of high-throughput omics technologies has exponentially increased the amount of protein sequence data involved in many salient disease pathways and their respective therapeutics and diagnostics. Despite the availability of large-scale sequence data, the lack of experimental fitness annotations underpins the need for self-supervised and unsupervised machine learning (ML) methods. These techniques leverage the meaningful features encoded in abundant unlabeled sequences to accomplish complex protein engineering tasks. Proficiency in the rapidly evolving fields of protein engineering and generative AI is required to realize the full potential of ML models as a tool for protein fitness landscape navigation. Here, we support this work by (i) providing an overview of the architecture and mathematical details of the most successful ML models applicable to sequence data (e.g. variational autoencoders, autoregressive models, generative adversarial neural networks, and diffusion models), (ii) guiding how to effectively implement these models on protein sequence data to predict fitness or generate high-fitness sequences and (iii) highlighting several successful studies that implement these techniques in protein engineering (from paratope regions and subcellular localization prediction to high-fitness sequences and protein design rules generation). By providing a comprehensive survey of model details, novel architecture developments, comparisons of model applications, and current challenges, this study intends to provide structured guidance and robust framework for delivering a prospective outlook in the ML-driven protein engineering field."
471,"As artificial intelligence (AI) technologies continue to advance, their integration into secondary and postsecondary education offers a multitude of opportunities for adolescent and adult learners. In this article, we delve into the advantages of integrating AI into literacy education, emphasizing its capacity to enhance writing skills, provide assistance to students with disabilities, foster critical thinking and media literacy abilities, and also tackle challenges associated with biases, misinformation, and an overdependence on AI tools. This article offers examples and recommendations to assist literacy educators in guiding their adolescent and adult learners toward ethical and responsible usage of AI."
472,"Artificial intelligence (AI), notably Generative Adversarial Networks, has the potential to transform medical and patient education. Leveraging GANs in medical fields, especially cosmetic surgery, provides a plethora of benefits, including upholding patient confidentiality, ensuring broad exposure to diverse patient scenarios, and democratizing medical education. This study investigated the capacity of AI models, DALL-E 2, Midjourney, and Blue Willow, to generate realistic images pertinent to cosmetic surgery. We combined the generative powers of ChatGPT-4 and Google's BARD with these GANs to produce images of various noses, faces, and eyelids. Four board-certified plastic surgeons evaluated the generated images, eliminating the need for real patient photographs. Notably, generated images predominantly showcased female faces with lighter skin tones, lacking representation of males, older women, and those with a body mass index above 20. The integration of AI in cosmetic surgery offers enhanced patient education and training but demands careful and ethical incorporation to ensure comprehensive representation and uphold medical standards."
473,"Political discourse is the soul of democracy, but misunderstanding and conflict can fester in divisive conversations. The widespread shift to online discourse exacerbates many of these problems and corrodes the capacity of diverse societies to cooperate in solving social problems. Scholars and civil society groups promote interventions that make conversations less divisive or more productive, but scaling these efforts to online discourse is challenging. We conduct a large-scale experiment that demonstrates how online conversations about divisive topics can be improved with AI tools. Specifically, we employ a large language model to make real-time, evidence-based recommendations intended to improve participants’ perception of feeling understood. These interventions improve reported conversation quality, promote democratic reciprocity, and improve the tone, without systematically changing the content of the conversation or moving people’s policy attitudes."
474,"Abstract This paper conceptualizes a consumer-centric, regenerative artificial intelligence (“ReGenAI”) model for the Fast-Moving Consumer Goods (“FMCG”) retailing channel. The system uses its awareness of context, time, and users to (re)generate customer touchpoints and other marketing communications. Its output provides deep insights into regular and altered FMCG customer journeys, such as shopping behaviors under stressors like lifestyle choices or cataclysmic socio-economic and weather events. The recursive model advances from current, generative AI systems. It uses “tired or inspired” as a simplified bifurcated grocery shopper taxonomy to operationalize customers’ purchasing and consumption behaviors into actionable data for demand planning and retail operations."
475,"study conducted by the European Commission has found that a majority of Europeans are concerned about internet disinformation and want politicians and platform operators to take stronger action against it. The study also revealed that many people are frequently unsure if online information is true and encounter disinformation consciously. Younger and more educated individuals are more active in verifying the truthfulness of information. The study suggests that addressing disinformation requires regulation, raising awareness, and equipping people to better evaluate news and media content. Another study found that social media use is associated with lower well-being in children and adolescents, particularly due to constant social comparisons. However, further research is needed to confirm these findings. The German Research Foundation has released guidelines for the responsible use of generative AI models, emphasizing adherence to scientific standards. A collaborative project in Germany has examined the requirements of universities for data management plans to support research data management. De Gruyter and Brill have announced a merger to create a new publishing company focused on the humanities, aiming to improve their position in the global market."
476,"In the era of GeoAI, Geospatial Intelligent Question Answering (GeoIQA) represents the ultimate pursuit for everyone. Even generative AI systems like ChatGPT-4 struggle to handle complex GeoIQA. GeoIQA is domain complex IQA, which aims at understanding and answering questions accurately. The core of IQA is the Question Classification (QC), which mainly contains four types: content-based, template-based, calculation-based and method-based classification. These IQA_QC frameworks, however, struggle to be compatible and integrate with each other, which may be the bottleneck restricting the substantial improvement of IQA performance. To address this problem, this paper reviewed recent advances on IQA with the focus on solving question classification and proposed a comprehensive IQA_QC framework for understanding user query intention more accurately. By introducing the basic idea of the IQA mechanism, a three-level question classification framework consisting of essence, form and implementation is put forward which could cover the complexity and diversity of geographical questions. In addition, the proposed IQA_QC framework revealed that there are still significant deficiencies in the IQA evaluation metrics in the aspect of broader dimensions, which led to low answer performance, functional performance and systematic performance. Through the comparisons, we find that the proposed IQA_QC framework can fully integrate and surpass the existing classification. Although our proposed classification can be further expanded and improved, we firmly believe that this comprehensive IQA_QC framework can effectively help researchers in both semantic parsing and question querying processes. Furthermore, the IQA_QC framework can also provide a systematic question-and-answer pair/library categorization system for AIGCs, such as GPT-4. In conclusion, whether it is explicit GeoAI or implicit GeoAI, the IQA_QC can play a pioneering role in providing question-and-answer types in the future."
477,"ChatGPT is a generative AI model that has garnered tremendous public interest due to its ability to solve diverse problems through high-level reasoning and analysis. Among its features is an ability to create and debug code. While this capability has been explored with conventional programming languages such as Python, it has yet to be applied to computer-aided design (CAD). In this work, we utilized GPT-4 to create functional microfluidic components using OpenSCAD, an open-source CAD software package. Through an iterative dialogue, GPT-4 created functional designs for a helix/spiral, a valve, a t-junction, and a serpentine channel. This concept could facilitate CAD in the future for both technical and non-technical users and can be reasonably extended to other fields."
478,"Generative artificial intelligence (AI) is rapidly transforming people’s access to and attitudes toward knowledge. It is an extremely powerful technology, but this transformation presents numerous social, environmental, political, and, perhaps, in particular, educational considerations. There is a pressing need to have a profound and nuanced conversation about these considerations, without asking a chatbot for its opinion. Instead, we seem to be having mostly a distractive conversation about singularities, which is arguably a domain of sheer speculation, rather than a more pressing conversation about “the system” that produced the technology and what it is doing right now to people, society, and processes, in particular, the educational process. Therefore, starting from a viewpoint on education as the democratization of knowledge, this article presents six talking points as a contribution to the conversation about those considerations, especially with respect to education."
479,"Artificial intelligence (AI) is increasingly integrating into our society. University education needs to maintain its relevance in an AI‐mediated world, but the higher education sector is only beginning to engage deeply with the implications of AI within society. We define AI according to a relational epistemology, where, in the context of a particular interaction, a computational artefact provides a judgement about an optimal course of action and that this judgement cannot be traced. Therefore, by definition, AI must always act as a 'black box'. Rather than seeking to explain 'black boxes', we argue that a pedagogy for an AI‐mediated world involves learning to work with opaque, partial and ambiguous situations, which reflect the entangled relationships between people and technologies. Such a pedagogy asks learners locate AI as socially bounded, where AI is always understood within the contexts of its use. We outline two particular approaches to achieve this: (a) orienting students to quality standards that surround AIs, what might be called the tacit and explicit 'rules of the game'; and (b) providing meaningful interactions with AI systems. Practitioner notesWhat is already known about this topic Artificial intelligence (AI) is conceptualised in many different ways but is rarely defined in the higher education literature.Experts have outlined a range of graduate capabilities for working in a world of AI such as teamwork or ethical thinking.The higher education literature outlines an imperative need to respond to AI, as underlined by recent commentary on ChatGPT.What this paper adds A definition of an AI that is relational: A particular interaction where a computational artefact provides a judgement about an optimal course of action, which cannot be easily traced.Focusing on working with AI black boxes rather than trying to see inside the technology.Describing a pedagogy for an AI‐mediated world that promotes working in complex situations with partial and indeterminate information.Implications for practice and/or policy Focusing on quality standards helps learners understand the social regulating boundaries around AI.Promoting learner interactions with AI as part of a sociotechnical ensemble helps build evaluative judgement in weighting AI's contribution to work.Asking learners to work with AI systems prompts understanding of the evaluative, ethical and practical necessities of working with a black box."
480,"Disease modeling and target discovery are crucial initial steps in the drug discovery process and significantly impact on the success of drug development. Given the advantages of analyzing large datasets and complex biological networks, artificial intelligence (AI) is playing a growing role in modern drug target identification. We discuss the use of deep learning models for target discovery, AI-identified targets validated through experiments, and the use of synthetic data produced using generative AI for target identification. Novelty, in addition to druggability and toxicity, is a crucial factor in target selection. There is a trade-off between choosing high-confidence and novel targets. Over the past few years several AI-derived drugs have entered clinical trials, signaling the dawn of a new era in AI-driven drug discovery. Disease modeling and target identification are the most crucial initial steps in drug discovery, and influence the probability of success at every step of drug development. Traditional target identification is a time-consuming process that takes years to decades and usually starts in an academic setting. Given its advantages of analyzing large datasets and intricate biological networks, artificial intelligence (AI) is playing a growing role in modern drug target identification. We review recent advances in target discovery, focusing on breakthroughs in AI-driven therapeutic target exploration. We also discuss the importance of striking a balance between novelty and confidence in target selection. An increasing number of AI-identified targets are being validated through experiments and several AI-derived drugs are entering clinical trials; we highlight current limitations and potential pathways for moving forward."
481,"Google offers an experimental note-taking app called NotebookLM that uses generative AI to analyze and summarize text. Users can turn long documents into brief summaries, extract insights from multiple documents, and summarize information found during online research. The app allows users to create notebooks, add text sources, and manage notes. However, users should be cautious as generative AI tools are still in their early stages and may provide incorrect information. The app also lacks certain features found in other note-taking apps, but users can copy the AI-generated responses and paste them into other apps."
482,"The article discusses that the Association of American Publishers is backing Fairly Trained, a nonprofit organization focused on certifying fair training data use in generative artificial intelligence (AI), giving it as a seal of approval for generative AI models adhering to copyright regulations."
483,"The New York Times has filed a lawsuit against Microsoft and OpenAI, claiming copyright violations in the development of their generative AI tools. The Times alleges that Microsoft's Copilot and OpenAI's ChatGPT were trained using millions of articles without permission. The lawsuit seeks billions of dollars in damages and demands the destruction of the datasets and tools. The outcome of this lawsuit could have significant implications for the future of generative AI and the rights of copyright holders."
484,"The article focuses on Forrester Research's predictions for customer experience (CX) professionals in 2024, highlighting the challenges faced by CX teams in the past couple of years, the impact of generative AI on CX ratings, the increasing adoption of customer-facing generative AI by large global firms, and the potential for biased or harmful experiences launched by brands."
485,"In a world where misinformation is already rampant, there are fears that AI-manufactured video could make it harder to tell what is real - though so far, this hasn't happened with existing AI tools. This isn't possible yet, but text-to-video artificial intelligence algorithms, such as Meta's Make-A-Video and Google's Imagen Video, are rapidly heading towards this goal. The case could set a precedent for other disputes over alleged AI infringement, but the overall lack of case law may mean politicians will need to introduce new laws to cover generative AI."
486,"Microsoft has announced that it is rebranding its generative AI-based Bing Chat as Copilot, signaling its shift in focus from internet search to artificial intelligence (AI). The move consolidates all of Microsoft's genAI efforts under one brand and includes several AI tools under the Copilot name. Microsoft is also making the chat version of Copilot available for free on the web, no longer requiring the use of Bing. This decision reflects Microsoft's belief that AI is the future and that it cannot compete with Google in the search market."
487,"Cisco has announced a new artificial intelligence strategy for its Webex videoconferencing platform, including an AI-powered assistant that can summarize meeting content and answer questions, and generative AI capabilities to improve the quality of video meetings. Webex's AI Codec uses up to 16 times less bandwidth than an industry standard audio codec, he said."
488,"The article focuses on the transformative potential of generative Artificial intelligence (AI) and foundation models in various applications, including knowledge management, business intelligence, and intelligent process automation. It discusses how these models can streamline and enhance human-computer interactions, enabling natural language interfaces and visual applications to revolutionize the way organizations work and communicate."
489,"An interview with pedagogical director at Peachey Publications Nik Peachey is presented. When asked about artificial intelligence (AI) in practical terms? He expressed that Generative AI is a technology that simulates human thought and language by analyzing large language models and producing information. He highlights the topics the role of teachers in guiding and motivating learners, as well as the surprisingly rapid adoption of AI tools in education."
490,"The article discusses the potential of generative artificial intelligence (AI) in healthcare, specifically in the field of musculoskeletal health. The President's Symposium at the AAOS 2024 Annual Meeting will bring together experts to explore the current and future applications of generative AI in healthcare. The symposium will address various issues such as translational research, clinical implementation, patient safety, ethics, and diversity. The session will feature experts from the medical and AI fields who will provide an overview of generative AI tools and discuss the challenges and opportunities associated with their implementation. The symposium will take place on February 14, 2024."
491,"This article explores the potential and impact of artificial intelligence (AI) in the field of architecture. It discusses the rapid development of generative AI and its ability to disrupt various industries. The article raises questions about the role of AI in architecture, including whether AI will create a substantially different architecture or reinvent the role of the architect. It also examines how AI might change the style and aesthetics of architecture, the issue of authorship in AI-generated images, and the capacity of AI to generate unique designs. The article concludes by suggesting that AI can be a valuable tool for architects, helping them to engage with complex problems and shape the future of the discipline."
492,"Many people are getting extremely excited about artificial intelligence (AI) and the possibilities it presents to development because it is available 24/7 and can operate around the clock to perform mundane and competitive tasks without complaining that the work is boring. Yet, more and more people are sounding the alarm bells about the use of AI, including thousands of CEOs, technologists, research academics and others who have signed an open letter, dated 22 March 2023. In this letter they called for a pause in AI deployment, especially since so many people have started to use the likes of ChatGPT and other generative AI systems (Pratt, 2023)."
493,"The author focuses on the generative artificial intelligence (AI) trained on data sets consisting images or writing, and mentions lack of style shines in Generative Pre-trained Transformer (GTP). Topics discussed include established tendencies streamlined by AI toward repetition, imitation and pastiche, industrial cycle of dissemination and reaction, and proliferation of cultural content throught AI."
494,"The article focuses on the use of generative AI (Artificial Intelligence) in the publishing industry. It discusses how generative AI is being realized in various ways and has the potential to transform workflows, business models, and the products offered to readers. It further highlights that while the technology has been still developing, it is already making significant impacts."
495,"ChatGPT and GitHub Copilot are both leading generative AI applications. Which generative AI platform is best for your needs?"
496,"The article discusses the Great Britain Department for Education's position on the use of generative artificial intelligence (AI), specifically large language models like ChatGPT and Google Bard, in the education sector. It mentions schools, colleges, universities, and awarding organizations should take reasonable steps to prevent malpractice, including malpractice involving generative AI, and education sector needs to protect data by ensuring the protection of personal and sensitive data."
497,"An editorial is presented on the impact of artificial intelligence (AI) in laboratory medicine, its potential benefits, and its challenges. Topics include the use of AI in diagnostic specialties like radiology and the transition to digital pathology. It emphasizes the need for accuracy and cooperation between labs and AI experts and the use of generative AI models like Chat Generative Pre-trained Transformer in scientific literature."
498,"As our fascination and fear of trending generative AI systems heat up, researchers focused on the industrial manufacturing realm are bolstering their AI toolkits-all the better to be part of the next wave of innovation. ""AI really helps to make those design cycles faster, and the output-fingers crossed-better"", said Boris Scharinger, senior innovation manager, Siemens, during a presentation."
499,"The article focuses on the rise of generative artificial intelligence (AI) in creating content, as poorly paid human article spinners are increasingly replaced by AI that churns out articles for the purpose of driving web traffic. Topics discussed include the AI-generated biography of the author, the potential threats of AI-driven SEO link farms, and the challenges posed by the use of AI to create false information about individuals."
500,"The article offers information on the growing impact of AI on society, particularly in the fields of information access, education, and journalism. It discusses how generative AI is being used to assist in academic writing and how it's raising concerns in the entertainment industry, potentially impacting journalism and various professions that involve text creation."
501,"The article focuses on the evolving relationship between humans and technology, particularly the convergence of digital and physical worlds represented by the merger of ""bits"" (digital) and ""atoms"" (physical). Topics discussed include the integration of technology in government services, the need for adaptable and user-friendly technology, and the potential of Generative AI to transform the public sector."
502,"The article discusses about the intersection of artificial intelligence (AI) and book indexing, highlighting the challenges and potential impact of generative AI (GAI) on the publishing industry. Topic include It mentions concerns about the ""good enough"" concept and how AI technology could affect various aspects of publishing, including editorial processes."
503,"Talking to animals is a fundamental human desire. The emergence of powerful AI algorithms, and specifically Large Language Models, has driven many to suggest that we are on the verge of fulfilling this wish. A few large scientific consortia have been formed around this topic and several commercial entities even offer such services. We frame the task of communicating with animals as 'The Doctor Dolittle challenge' and identify three main obstacles on the route to doing so. First, although generative AI models can create novel animal communication samples, it is very difficult to determine their context, and we will forever be biased by our human umwelt when doing so. Second, using AI to extract context in an unsupervised manner must be validated through controlled experiments aiming to measure the animals' response. This is difficult, and moreover, AI algorithms tend to cling on to any available information and are thus prone to finding spurious correlations. And third, animal communication focuses on a restricted set of contexts, such as alarm and courtship, highly limiting our ability to communicate regarding other contexts. Nevertheless, using the tremendous power of novel AI methods to decipher and mimic animal communication is both fascinating and important. We thus define the criteria for passing the Doctor Dolittle challenge and call upon scientists to take on the mission. Would AI be able, like Doctor Dolittle, to 'talk' with animals? Yovel and Rechavi argue that, to ace the 'The Doctor Dolittle challenge', we would need to pass three obstacles that would be very difficult to overcome."
504,"Recently, a promising autoregressive large language model (LLM), I G i enerative I P i re-trained I T i ransformer (GPT)-3 trained with 175 billion parameters via cloud computing [[1]] has been made available to the public online (released by OpenAI on November 30, 2022; https://chat.openai.com/). Theoretically, healthcare IT can integrate LLMs into the electronic medical record (EMR) so as to use the generative AI capability to write discharge summaries [[23]], assist with data entry, and optimize patient check-in for visits (e.g., by assimilating necessary patient data prior to consultation and treatment). Understanding large language models (LLMs) LLMs are a specific application of Natural Language Processing (NLP), which is a subfield of AI that focuses on the interaction between computers and human language."
505,"In developing artificial intelligence (AI), researchers often benchmark against human performance as a measure of progress. Is this kind of comparison possible for moral cognition? Given that human moral judgment often hinges on intangible properties like ""intention"" which may have no natural analog in artificial agents, it may prove difficult to design a ""like‐for‐like"" comparison between the moral behavior of artificial and human agents. What would a measure of moral behavior for both humans and AI look like? We unravel the complexity of this question by discussing examples within reinforcement learning and generative AI, and we examine how the puzzle of evaluating artificial agents' moral cognition remains open for further investigation within cognitive science."
506,"University teaching practices impact student interest, engagement, and academic performance. This paper presents a study that uses artificial intelligence (AI) to examine students' preferences for university teaching practices. We asked students in various fields open-ended questions about the best teaching practices they had experienced. Due to the large amount of data obtained, we used the AI-based language model Generative Pretrained Transformer-3 (GPT-3) to analyse the responses. With this model, we sorted students' testimonies into nine theory-based categories regarding teaching practices. After analysing the reliability of the classifications conducted by GPT-3, we found that the agreement between humans was similar to that observed between humans and the AI model, which supported its reliability. Regarding students' preferences for teaching practices, the results showed that students prefer practices that focus on (1) clarity and (2) interaction and relationships. These results enable the use of AI-based tools that facilitate the analysis of large amounts of information collected through open methods. At the didactic level, students' preferences and demand for clear teaching practices (in which ideas and activities are stated and shown without ambiguity) that are based on interaction and relationships (between teachers and students and among students themselves) are demonstrable."
507,"In this technology review, we explore the affordances of the generative AI chatbot ChatGPT for language teaching and learning. In addition to this, we also present debates and drawbacks of ChatGPT. Finally, we present the digital competencies teachers and learners require to use this chatbot ethically and effectively to support language learning."
508,"Artificial intelligence (AI) has finally reached most people on our planet thanks to generative AI tools for text and other media. This has started a controversy about the possible benefits and risks, where responsible AI is key. Hence, we introduce the concept of responsible AI, its relation to AI ethics, and why the terms ethical or trustworthy AI should not be used. We then cover the three main relevant aspects of this new field: principles governance and regulation."
509,"Abstract AI chatbots have recently fuelled debate regarding education practices in higher education institutions worldwide. Focusing on Generative AI and ChatGPT in particular, our study examines how AI chatbots impact university teachers’ assessment practices, exploring teachers’ perceptions about how ChatGPT performs in response to home examination prompts in undergraduate contexts. University teachers (<italic>n</italic> = 24) from four different departments in humanities and social sciences participated in Turing Test-inspired experiments, where they blindly assessed student and ChatGPT-written responses to home examination questions. Additionally, we conducted semi-structured interviews in focus groups with the same teachers examining their reflections about the quality of the texts they assessed. Regarding chatbot-generated texts, we found a passing rate range across the cohort (37.5 − 85.7%) and a chatbot-written suspicion range (14–23%). Regarding the student-written texts, we identified patterns of downgrading, suggesting that teachers were more critical when grading student-written texts. Drawing on post-phenomenology and mediation theory, we discuss AI chatbots as a potentially disruptive technology in higher education practices."
510,"We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment."
511,"Abstract In 2022, OpenAI released ChatGPT, a generative artificial intelligence (AI) chatbot that can instantly respond to user-provided queries in a conversational manner. While it can be a powerful tool for completing a great number of written tasks, instructors are worried about students misusing ChatGPT and other AI programs in their coursework. Though this concern is valid, we propose that the emphasis on trying to circumvent cheating with AI is misplaced. In the following commentary, we argue that the way students are assessed should fundamentally change. Instead of asking students to simply reproduce knowledge in essays or exams—tasks that are easily accomplishable for an AI like ChatGPT—students should engage in class-specific, guided self-reflection and take part in assessing their own work. Self-assessment and ungrading could increase intrinsic motivation and reduce the desire to rely on AI for coursework, especially when such coursework requires personalized details from students. Thus, we propose that the emergence of ChatGPT and the continued evolution of AI poses an exciting challenge for higher education—to refocus students on work that is personally meaningful, and accomplishable only by humans."
512,"Since its launch, ChatGPT, an artificial intelligence chatbot developed by Open AI based on the premises of generative pre-trained transformer autoregressive language models, has gained widespread popularity and is making significant impact on society with its unique features, such as natural language processing and contextual awareness. ChatGPT is viewed as a major disruptive innovation that is likely to revolutionize the operations in many industries including the hospitality and tourism industry. The adoption of ChatGPT will result in substantial changes throughout the hospitality and tourism industry by disrupting how customer search for information, make decisions, and how businesses produce, create, and deliver customized services and experiences. This conceptual paper provides a comprehensive discussion on generative pre-trained transformers' (GPTs) benefits, and potential challenges and threats they pose to the hospitality and tourism industry. The feasibility of integrating GPT into different travel stages and decision-making processes is also discussed. The article concludes by proposing a potential future research agenda on using GPT in creating and delivering hospitality and tourism experiences, which can guide further advancements in the field."
513,"Goldschmidt's evocation of Leviticus 19:18 in Contradiction Set Free accomplishes heavy lifting within the distinction of the dialogic from the dialectic. Analogized to a necessary recognition of each particular and unique fulfillment of the immediate command to ""love your neighbor as yourself,"" dialogue is temporalized within an already near, yet not ever complete, messianic infinite. As an ongoing, active and unfinished composition of unique ""nows,"" dialogue's structure is likewise epistemically distinct from the structure of dialectical synthesis. How might this distinction's lens of Leviticus 19:18 illumine opportunities—and obstacles—for ""dialogue"" between humans and artificial systems? Does examining the specific case of OpenAI's ChatGPT under the lens of Goldschmidt's text suggest that certain questions about generative AI learning capacity might actually be questions of time?"
514,"With rapid advances in AI technology, AI tutors or digital learning companions, for example, can become more effective in supporting students by providing personalized feedback, simplifying complex concepts, and assessing students' understanding. Generative artificial intelligence (AI) technologies, such as large language models (LLMs) and diffusion model image and video generators, can transform learning and teaching experiences by providing students and instructors with access to a vast amount of information and create innovative learning and teaching materials in a very efficient way (e.g., U.S. Department of Education, [31]; Kasneci et al., [13]; Mollick & Mollick, [22]; Nikolic et al., [24]). With significant progress on these AI models, in the near future these types of AI tools would allow students to explore different bridge designs from different angles and better understand how they work and can fail under different circumstances."
515,"While we discuss how GAI shapes research and teaching practices within engineering education, we recognize that there are additional implications for the use of GAI for self-motivated and sustained learning initiated by learners on their own. Bias, misinformation, and data-gathering malpractice - common concerns with the use of any software - are all issues that users will need to understand in relation to GAI. The recent popularity of generative AI (GAI) applications such as ChatGPT portend a new era of research, teaching, and learning across domains, including in engineering (Bubeck et al., [8]; Kasneci et al., [19]; Lo, [20]; Qadir, [21]). GAI'S LIMITATIONS AND RISKS Finally, regardless of whether for teaching or research, it is important to consider GAI's safe and ethical use (UNESCO, [25])."
516,"Chat generative pre-trained transformer (ChatGPT) is a chatbot developed by OpenAI that answers questions in a human-like manner. ChatGPT is a GPT language model that understands and responds to natural language created using a transformer, which is a new artificial neural network algorithm first introduced by Google in 2017. ChatGPT can be used to identify research topics and proofread English writing and R scripts to improve work efficiency and optimize time. Attempts to actively utilize generative artificial intelligence (AI) are expected to continue in clinical settings. However, ChatGPT still has many limitations for widespread use in clinical research, owing to AI hallucination symptoms and its training data constraints. Researchers recommend avoiding scientific writing using ChatGPT in many traditional journals because of the current lack of originality guidelines and plagiarism of content generated by ChatGPT. Further regulations and discussions on these topics are expected in the future."
517,"The use of generative Artificial Intelligence (AI) and Large Language Models (LLMs) in research and scholarly writing has challenged editorial policy, with varying tolerance about the extent to which this technology should be allowed. Journals need to re-examine their standards to ensure transparency and accountability with regard to the use of AI and LLMs in the preparation of manuscripts and the scientific investigation upon which these articles are based. Social workers are ideally suited to assume leadership roles in the formulation of editorial policies given their core commitment to integrity and making certain that technology use is consistent with their comprehensive ethical code."
518,"Postdisaster housing reconstruction (PDHR) is a highly complex process because of the large number of recovery projects for affected communities and the shortage of resources after a disastrous event. PDHR also needs a strategy that reconsiders it as a large-scale integrated portfolio of projects instead of individual building reconstruction projects. However, this complexity and the lack of a holistic, systematic approach for planning frequently lead to an ad-hoc or case-by-case decision-making process. To resolve this critical challenge in postdisaster housing mass production, this study investigates and develops a systematic approach that optimizes the design modularization of housing recovery projects considering manufacturing, transportation, and assembly factors for a cost-efficient and sustainable implication of modular construction (MC) in PDHR. Using the genetic algorithm-based optimization method, the proposed method addresses the possible trade-offs between the commonality and suitability of the module configurations for PDHR projects. In addition, the authors used a set of feasible configurations of a variety of modular housing designs created from the AI-based generative design system and conducted the mass production scenarios after a disaster to validate the accuracy and robustness of the proposed methodology. The results clearly show that the proposed method significantly improved optimization and decision-making of MC design and construction processes and considerably enhanced rapid and logical responses to the demands of the postdisaster recovery process. The newly developed method is expected to assist the planners in formalizing the commonality concept in the PDHR process and achieving an optimal level of modularity and commonality that meet the required variation while maintaining the advantages of mass production."
519,"In recent years, we have experienced rapid development of advanced technology, machine learning, and artificial intelligence (AI), intended to interact with and augment the abilities of humans in practically every area of life. With the rapid growth of new capabilities, such as those enabled by generative AI (e.g., ChatGPT), AI is increasingly at the center of human communication and collaboration, resulting in a growing recognition of the need to understand how humans and AI can integrate their inputs in collaborative teams. However, there are many unanswered questions regarding how human–AI collective intelligence will emerge and what the barriers might be. Truly integrated collaboration between humans and intelligent agents may result in a different way of working that looks nothing like what we know now, and it is important to keep the essential goal of human societal well‐being and prosperity a priority. In this special issue, we begin to scope out the underpinnings of a socio‐cognitive architecture for <italic>Collective HUman‐MAchine INtelligence</italic> (COHUMAIN), which is the study of the capability of an integrated human and machine (i.e., intelligent technology) system to achieve goals in a wide range of environments. This topic consists of nine papers including a description of the conceptual foundation for a socio‐cognitive architecture for COHUMAIN, empirical tests of some aspects of this architecture, research on proposed representations of intelligent agents that can jointly interact with humans, empirical tests of human–human and human–machine interactions, and philosophical and ethical issues to consider as we develop these systems."
520,"Literature, poetry, and other forms of noncommercial creative expression challenge the techno-instrumentalist approaches to language, the predictive language generation, informing NLP (large natural language processing models) such as GPT-3 or -4 as well as, more generally, generative AI (text to image, video, audio). Claims that AI systems automate and expedite creativity reflect industry and research priorities of speed, scale, optimization, and frictionlessness driving much artificial intelligence design and application. But poetry will not optimize; the creative process cannot be reduced to a prompt. Some have noted that literary creations generated or augmented by artificial intelligence at best can offer form without meaning; using a GPT creation prompted by Maya Angelou's poem ""Still I Rise"" as a case study, this essay argues that NLP's predictive language generation and what I call algorithmic ahistoricity can also, more disturbingly, render meaning senseless. In doing so, GPT-3's literary experiments are not ""failed"" because they do not meet some moving target of a literary standard, nor because of technological insufficiency, but because it can make it harder for people to name and navigate their realities. The coda explores an example of AI as literary interlocutor and creative engagement beyond optimization."
521,"Objective: To assess the feasibility of using large language models (LLMs), specifically ChatGPT-4, to generate concise and accurate layperson summaries of musculoskeletal radiology reports.Sixty radiology reports, comprising 20 MR shoulder, 20 MR knee, and 20 MR lumbar spine reports, were obtained via PACS. The reports were deidentified and then submitted to ChatGPT-4, with the prompt “Produce an organized and concise layperson summary of the findings of the following radiology report. Target a reading level of 8-9th grade and word count <300 words.” Three (two primary and one later added for validation) independent readers evaluated the summaries for completeness and accuracy compared to the original reports. Summaries were rated on a scale of 1 to 3: 1) summaries that were incorrect or incomplete, potentially providing harmful or confusing information; 2) summaries that were mostly correct and complete, unlikely to cause confusion or harm; and 3) summaries that were entirely correct and complete.All 60 responses met the criteria for word count and readability. Mean ratings for accuracy were 2.58 for reader 1, 2.71 for reader 2, and 2.77 for reader 3. Mean ratings for completeness were 2.87 for reader 1 and 2.73 for reader 2 and 2.87 for reader 3. For accuracy, reader 1 identified three summaries as a 1, reader 2 identified one, and reader 3 identified none. For the two primary readers, inter-reader agreement was low for accuracy (kappa 0.33) and completeness (kappa 0.29). There were no statistically significant changes in inter-reader agreement when the third reader’s ratings were included in analysis.Overall ratings for accuracy and completeness of the AI-generated layperson report summaries were high with only a small minority likely to be confusing or inaccurate. This study illustrates the potential for leveraging generative AI, such as ChatGPT-4, to automate the production of patient-friendly summaries for musculoskeletal MR imaging.Methods: To assess the feasibility of using large language models (LLMs), specifically ChatGPT-4, to generate concise and accurate layperson summaries of musculoskeletal radiology reports.Sixty radiology reports, comprising 20 MR shoulder, 20 MR knee, and 20 MR lumbar spine reports, were obtained via PACS. The reports were deidentified and then submitted to ChatGPT-4, with the prompt “Produce an organized and concise layperson summary of the findings of the following radiology report. Target a reading level of 8-9th grade and word count <300 words.” Three (two primary and one later added for validation) independent readers evaluated the summaries for completeness and accuracy compared to the original reports. Summaries were rated on a scale of 1 to 3: 1) summaries that were incorrect or incomplete, potentially providing harmful or confusing information; 2) summaries that were mostly correct and complete, unlikely to cause confusion or harm; and 3) summaries that were entirely correct and complete.All 60 responses met the criteria for word count and readability. Mean ratings for accuracy were 2.58 for reader 1, 2.71 for reader 2, and 2.77 for reader 3. Mean ratings for completeness were 2.87 for reader 1 and 2.73 for reader 2 and 2.87 for reader 3. For accuracy, reader 1 identified three summaries as a 1, reader 2 identified one, and reader 3 identified none. For the two primary readers, inter-reader agreement was low for accuracy (kappa 0.33) and completeness (kappa 0.29). There were no statistically significant changes in inter-reader agreement when the third reader’s ratings were included in analysis.Overall ratings for accuracy and completeness of the AI-generated layperson report summaries were high with only a small minority likely to be confusing or inaccurate. This study illustrates the potential for leveraging generative AI, such as ChatGPT-4, to automate the production of patient-friendly summaries for musculoskeletal MR imaging.Results: To assess the feasibility of using large language models (LLMs), specifically ChatGPT-4, to generate concise and accurate layperson summaries of musculoskeletal radiology reports.Sixty radiology reports, comprising 20 MR shoulder, 20 MR knee, and 20 MR lumbar spine reports, were obtained via PACS. The reports were deidentified and then submitted to ChatGPT-4, with the prompt “Produce an organized and concise layperson summary of the findings of the following radiology report. Target a reading level of 8-9th grade and word count <300 words.” Three (two primary and one later added for validation) independent readers evaluated the summaries for completeness and accuracy compared to the original reports. Summaries were rated on a scale of 1 to 3: 1) summaries that were incorrect or incomplete, potentially providing harmful or confusing information; 2) summaries that were mostly correct and complete, unlikely to cause confusion or harm; and 3) summaries that were entirely correct and complete.All 60 responses met the criteria for word count and readability. Mean ratings for accuracy were 2.58 for reader 1, 2.71 for reader 2, and 2.77 for reader 3. Mean ratings for completeness were 2.87 for reader 1 and 2.73 for reader 2 and 2.87 for reader 3. For accuracy, reader 1 identified three summaries as a 1, reader 2 identified one, and reader 3 identified none. For the two primary readers, inter-reader agreement was low for accuracy (kappa 0.33) and completeness (kappa 0.29). There were no statistically significant changes in inter-reader agreement when the third reader’s ratings were included in analysis.Overall ratings for accuracy and completeness of the AI-generated layperson report summaries were high with only a small minority likely to be confusing or inaccurate. This study illustrates the potential for leveraging generative AI, such as ChatGPT-4, to automate the production of patient-friendly summaries for musculoskeletal MR imaging.Conclusion: To assess the feasibility of using large language models (LLMs), specifically ChatGPT-4, to generate concise and accurate layperson summaries of musculoskeletal radiology reports.Sixty radiology reports, comprising 20 MR shoulder, 20 MR knee, and 20 MR lumbar spine reports, were obtained via PACS. The reports were deidentified and then submitted to ChatGPT-4, with the prompt “Produce an organized and concise layperson summary of the findings of the following radiology report. Target a reading level of 8-9th grade and word count <300 words.” Three (two primary and one later added for validation) independent readers evaluated the summaries for completeness and accuracy compared to the original reports. Summaries were rated on a scale of 1 to 3: 1) summaries that were incorrect or incomplete, potentially providing harmful or confusing information; 2) summaries that were mostly correct and complete, unlikely to cause confusion or harm; and 3) summaries that were entirely correct and complete.All 60 responses met the criteria for word count and readability. Mean ratings for accuracy were 2.58 for reader 1, 2.71 for reader 2, and 2.77 for reader 3. Mean ratings for completeness were 2.87 for reader 1 and 2.73 for reader 2 and 2.87 for reader 3. For accuracy, reader 1 identified three summaries as a 1, reader 2 identified one, and reader 3 identified none. For the two primary readers, inter-reader agreement was low for accuracy (kappa 0.33) and completeness (kappa 0.29). There were no statistically significant changes in inter-reader agreement when the third reader’s ratings were included in analysis.Overall ratings for accuracy and completeness of the AI-generated layperson report summaries were high with only a small minority likely to be confusing or inaccurate. This study illustrates the potential for leveraging generative AI, such as ChatGPT-4, to automate the production of patient-friendly summaries for musculoskeletal MR imaging."
522,"Introduction: The advent of generative artificial intelligence (AI) dialogue platforms and large language models (LLMs) may help facilitate ongoing efforts to improve health literacy. Additionally, recent studies have highlighted inadequate health literacy among patients with cardiac disease. The aim of the present study was to ascertain whether two freely available generative AI dialogue platforms could rewrite online aortic stenosis (AS) patient education materials (PEMs) to meet recommended reading skill levels for the public.Online PEMs were gathered from a professional cardiothoracic surgical society and academic institutions in the USA. PEMs were then inputted into two AI-powered LLMs, ChatGPT-3.5 and Bard, with the prompt “translate to 5th-grade reading level”. Readability of PEMs before and after AI conversion was measured using the validated Flesch Reading Ease (FRE), Flesch-Kincaid Grade Level (FKGL), Simple Measure of Gobbledygook Index (SMOGI), and Gunning-Fog Index (GFI) scores.Overall, 21 PEMs on AS were gathered. Original readability measures indicated difficult readability at the 10th–12th grade reading level. ChatGPT-3.5 successfully improved readability across all four measures (<italic>p</italic> < 0.001) to the approximately 6th–7th grade reading level. Bard successfully improved readability across all measures (<italic>p</italic> < 0.001) except for SMOGI (<italic>p</italic> = 0.729) to the approximately 8th–9th grade level. Neither platform generated PEMs written below the recommended 6th-grade reading level. ChatGPT-3.5 demonstrated significantly more favorable post-conversion readability scores, percentage change in readability scores, and conversion time compared to Bard (all <italic>p</italic> < 0.001).AI dialogue platforms can enhance the readability of PEMs for patients with AS but may not fully meet recommended reading skill levels, highlighting potential tools to help strengthen cardiac health literacy in the future.Methods: The advent of generative artificial intelligence (AI) dialogue platforms and large language models (LLMs) may help facilitate ongoing efforts to improve health literacy. Additionally, recent studies have highlighted inadequate health literacy among patients with cardiac disease. The aim of the present study was to ascertain whether two freely available generative AI dialogue platforms could rewrite online aortic stenosis (AS) patient education materials (PEMs) to meet recommended reading skill levels for the public.Online PEMs were gathered from a professional cardiothoracic surgical society and academic institutions in the USA. PEMs were then inputted into two AI-powered LLMs, ChatGPT-3.5 and Bard, with the prompt “translate to 5th-grade reading level”. Readability of PEMs before and after AI conversion was measured using the validated Flesch Reading Ease (FRE), Flesch-Kincaid Grade Level (FKGL), Simple Measure of Gobbledygook Index (SMOGI), and Gunning-Fog Index (GFI) scores.Overall, 21 PEMs on AS were gathered. Original readability measures indicated difficult readability at the 10th–12th grade reading level. ChatGPT-3.5 successfully improved readability across all four measures (<italic>p</italic> < 0.001) to the approximately 6th–7th grade reading level. Bard successfully improved readability across all measures (<italic>p</italic> < 0.001) except for SMOGI (<italic>p</italic> = 0.729) to the approximately 8th–9th grade level. Neither platform generated PEMs written below the recommended 6th-grade reading level. ChatGPT-3.5 demonstrated significantly more favorable post-conversion readability scores, percentage change in readability scores, and conversion time compared to Bard (all <italic>p</italic> < 0.001).AI dialogue platforms can enhance the readability of PEMs for patients with AS but may not fully meet recommended reading skill levels, highlighting potential tools to help strengthen cardiac health literacy in the future.Results: The advent of generative artificial intelligence (AI) dialogue platforms and large language models (LLMs) may help facilitate ongoing efforts to improve health literacy. Additionally, recent studies have highlighted inadequate health literacy among patients with cardiac disease. The aim of the present study was to ascertain whether two freely available generative AI dialogue platforms could rewrite online aortic stenosis (AS) patient education materials (PEMs) to meet recommended reading skill levels for the public.Online PEMs were gathered from a professional cardiothoracic surgical society and academic institutions in the USA. PEMs were then inputted into two AI-powered LLMs, ChatGPT-3.5 and Bard, with the prompt “translate to 5th-grade reading level”. Readability of PEMs before and after AI conversion was measured using the validated Flesch Reading Ease (FRE), Flesch-Kincaid Grade Level (FKGL), Simple Measure of Gobbledygook Index (SMOGI), and Gunning-Fog Index (GFI) scores.Overall, 21 PEMs on AS were gathered. Original readability measures indicated difficult readability at the 10th–12th grade reading level. ChatGPT-3.5 successfully improved readability across all four measures (<italic>p</italic> < 0.001) to the approximately 6th–7th grade reading level. Bard successfully improved readability across all measures (<italic>p</italic> < 0.001) except for SMOGI (<italic>p</italic> = 0.729) to the approximately 8th–9th grade level. Neither platform generated PEMs written below the recommended 6th-grade reading level. ChatGPT-3.5 demonstrated significantly more favorable post-conversion readability scores, percentage change in readability scores, and conversion time compared to Bard (all <italic>p</italic> < 0.001).AI dialogue platforms can enhance the readability of PEMs for patients with AS but may not fully meet recommended reading skill levels, highlighting potential tools to help strengthen cardiac health literacy in the future.Conclusion: The advent of generative artificial intelligence (AI) dialogue platforms and large language models (LLMs) may help facilitate ongoing efforts to improve health literacy. Additionally, recent studies have highlighted inadequate health literacy among patients with cardiac disease. The aim of the present study was to ascertain whether two freely available generative AI dialogue platforms could rewrite online aortic stenosis (AS) patient education materials (PEMs) to meet recommended reading skill levels for the public.Online PEMs were gathered from a professional cardiothoracic surgical society and academic institutions in the USA. PEMs were then inputted into two AI-powered LLMs, ChatGPT-3.5 and Bard, with the prompt “translate to 5th-grade reading level”. Readability of PEMs before and after AI conversion was measured using the validated Flesch Reading Ease (FRE), Flesch-Kincaid Grade Level (FKGL), Simple Measure of Gobbledygook Index (SMOGI), and Gunning-Fog Index (GFI) scores.Overall, 21 PEMs on AS were gathered. Original readability measures indicated difficult readability at the 10th–12th grade reading level. ChatGPT-3.5 successfully improved readability across all four measures (<italic>p</italic> < 0.001) to the approximately 6th–7th grade reading level. Bard successfully improved readability across all measures (<italic>p</italic> < 0.001) except for SMOGI (<italic>p</italic> = 0.729) to the approximately 8th–9th grade level. Neither platform generated PEMs written below the recommended 6th-grade reading level. ChatGPT-3.5 demonstrated significantly more favorable post-conversion readability scores, percentage change in readability scores, and conversion time compared to Bard (all <italic>p</italic> < 0.001).AI dialogue platforms can enhance the readability of PEMs for patients with AS but may not fully meet recommended reading skill levels, highlighting potential tools to help strengthen cardiac health literacy in the future."
523,"Introduction: Testosterone has become an increasing cultural touchstone. It is estimated that one third of men on testosterone replacement are not testosterone deficient and that another large percentage of men who would qualify for treatment do not receive it. This is likely partially due to the significant amount misinformation and disinformation available online. Recently there has been an explosion of interest in generative artificial intelligence (AI). Given the sensitive nature of questions regarding sexual health, many men may see generative AI as an anonymous, confidential, and accurate source of information. Specifically, OpenAI's ChatGPT is the most used generative AI that offers an easy to navigate conversation-based resource where patients may inquire about many topics including sexual health concerns. This study aims to validate ChatGPT responses to questions about testosterone and evaluate the references used for its claims. Objective: To evaluate the accuracy of ChatGPT responses to common questions about testosterone therapy and the sources substantiating claims. Methods: Questions regarding testosterone function and therapy were created based on American Urological Association (AUA) Care Foundation brochures for patient education on testosterone. ChatGPT was prompted to respond to these questions during a single interactive session with the ending phrase, ""include references,"" to evaluate the sources of responses. Responses were then separated into individual statements made by the AI and their associated references. Each response was evaluated for accuracy by matching the AI generated statements to AUA guidelines and published AUA resources. References were evaluated on the accuracy of the authors, article, journal, and date of publication based on the PubMed index, Google Scholar, and the cited journal's website. Results: A total of 9 questions were posed to the generative AI. The interactive session with ChatGPT yielded 53 separate statements backed by 21 references. The majority of queries yielded true statements by matched criteria to AUA guidelines (50/53, 94.3%). The references provided by the generative AI were drawn primarily from peer-reviewed journals (15/21, 71.4%); hospital websites (3/21, 14.3%), unknown sources (2/21, 9.5%) and AUA guidelines (1/21, 4.8%). The mean impact factor for the cited peer reviewed journals was 27.2 (SD 60.5). A majority of references were found to be legitimate sources (13/21, 61.9%). However, 4 (19.0%) included citation errors and 4 (19.0%) references were found to be fabricated by the AI. The question yielding the most fabricated references (3/4, 75%) was ""How do I boost my testosterone levels naturally?"" Conclusions: We found that ChatGPT offers a reliable conversation-based resource where patients may receive accurate information in response to their testosterone related questions. However, when queried about topics with fewer references, the large language model fabricated sources with real reputable authors and real journals. This is highly concerning as the general public would not be able to differentiate between real and fake information. Patients should be counseled with caution, and guardrails should be put in place for the safety of patients using large language models for medical information. Disclosure: No."
524,"A prototype computer has been developed that can perform calculations using random physical fluctuations, or noise, found in the environment. This thermodynamic computer, called the stochastic processing unit (SPU), takes advantage of the inherent noise in physical systems to run calculations more efficiently than conventional computers. The SPU was successfully used to run programs that find the inverse of a mathematical matrix and create generative AI algorithms. Experts believe that thermodynamic computing has the potential to create more capable and energy-efficient AI systems."
525,"This article, titled ""Your AI Questions, Answered,"" provides an overview of artificial intelligence (AI) and its applications in the field of learning and development (L&D). The author explains that AI consists of machine learning and deep learning, with generative AI being particularly intriguing for L&D as it can create content based on prompts from industry professionals. The article also dispels some myths about AI, such as the idea that it will fully personalize learning content or replace human tutors and coaches. The author advises starting small, involving stakeholders, and rigorously evaluating AI experiments."
526,"The article discusses the unpredictable nature of scientific progress and highlights some of the major discoveries and developments in 2023. It mentions the rise of generative AI chatbots like ChatGPT, the controversy surrounding the claim of creating a room-temperature superconductor, and intriguing findings such as a fossilized leg showing signs of cannibalism and the possibility of a secret inner chamber in Earth's core. The article also acknowledges positive achievements like the mathematical discovery of an ""einstein tile,"" the retrieval of RNA from an extinct creature, and India's successful lunar landing. It concludes by emphasizing the ongoing impact of the COVID-19 pandemic and the importance of scientific efforts in combating it. The article reminds readers that while science may not always be right, it continues to progress."
527,"The article discusses Walmart's decision to provide its nonstore employees with a generative AI app, available on computers and smartphones, aimed at enhancing productivity by assisting with tasks like summarizing documents and content creation."
528,"An introduction is presented in which the editor discusses articles in the issue on topics including generative artificial-intelligence (AI) advances; AI fuels a much older desire to see the Bible as data points; and theology of art-making."
529,"The firing of Sam Altman, co-founder of OpenAI, has caused turmoil within the company and raised concerns about the future of generative AI (genAI) technology. OpenAI employees have threatened to quit and work for Microsoft unless the entire board of directors resigns and reappoints Altman as CEO. However, industry experts believe that even if OpenAI were to collapse, it would not significantly impact AI development, as many other well-funded companies and startups are pursuing generative AI. It is advised for companies to build their AI strategies responsibly and not overly rely on a single provider. The conflict within OpenAI highlights the need for global regulation for safe and secure AI."
530,"The chatbot, which has been christened Grok AI, wasdeveloped by xAI - a generative AI venture launched byMusk in July to make an AI model understand the truenature of the universe in order to make it safer. AI safety continues to be a major concern Musk's decision to launch xAI and subsequently Grok AIcould be seen by many to be contradictory to hisprevious remarks. Elon Musk has revealed a new generative AI model-basedchatbot that will take on several large language modelsincluding OpenAI's ChatGPT, Google's PaLM 2, andAnthropic's Claude 2."
531,"News The company said the conversations were being indexedaccidentally after an SEO Consultant took to Twitter, now X,to report the issue Alphabet-owned Google is working on blocking user conversationswith its new Bard generative AI assistant from being indexed onits Search platform or showing up as results. Google Bard at Google I/O Related: * Generative AI * Data Privacy."
532,"News The generative AI assistant will be available toenterprise customers for $30 per user each month;meanwhile, an invite-only early access program for SMBs hasbegun Microsoft's M365 Copilot will be made generally availableto business customers beginning Nov. 1, the companyannounced Thursday. Related: * Generative AI * Artificial Intelligence * Microsoft * Microsoft 365 Microsoft 365 copilot."
533,"Long before ChatGPT came out publicly, the company wasusing Jasper AI to create marketing copy, said Kyle Healy, thecompany's SVP of sales enablement. Even companies without the time or people needed to create theirown AI embeds can start using generative AI within theirproductivity tools today, because many vendors have alreadyadded various genAI features to their apps. Feature Enterprise software vendors of all stripes are beginningto add generative AI features to their applications."
534,"The author comments on an article by I. Cohen on the state of generative artificial intelligence (AI), particularly based on Large Language Models (LLMs), which raises critical challenges of diversity and inclusion. Topics discussed include the considerable cost of development and training, factors that will influence the outcomes of the AI model, and threat that may be posed by the widespread use of LLMs for medical purposes."
535,"By considering the significant implications of generative AI for assessment, the authors suggest reclaiming oral assessment, when there is value in assessing unassisted understanding, and embracing AI for assisted assessment."
536,"An introduction is presented in which the editor discusses articles in the issue on topics including impact of generative artificial intelligence (AI) on medical writing, use of automation software for writing patient narratives in clinical study reports and AI's impact on plagiarism detection."
537,"The article examines whether ChatGPT and artificial intelligence (AI) should be embraced for classroom and research activities. Topics discussed include technological advances of generative AI tools such as ChatGPT, reason that the use of ChatGPT and other AI in an educational setting often raises resistance, and potential of AI for student development in the accounting discipline."
538,"The article reports that the use of artificial intelligence (AI) in the motion picture industry has transformed every aspect of film production from screenwriting to visual effects. It mentions that generative AI deliberately mimics the brain, building artificial neural networks that unleash the potential of algorithms to produce ‘synthetic media' in a way that is remarkably similar to human creativity."
539,"Cell-penetrating peptides have important therapeutic applications in drug delivery, but the variety of known cell-penetrating peptides is still limited. With a promise to accelerate peptide development, artificial intelligence (AI) techniques including deep generative models are currently in spotlight. Scientists, however, are often overwhelmed by an excessive number of unannotated sequences generated by AI and find it difficult to obtain insights to prioritize them for experimental validation. To avoid this pitfall, we leverage molecular dynamics (MD) simulations to obtain mechanistic information to prioritize and understand AI-generated peptides. A mechanistic score of permeability is computed from five steered MD simulations starting from different initial structures predicted by homology modelling. To compensate for variability of predicted structures, the score is computed with sample variance penalization so that a peptide with consistent behaviour is highly evaluated. Our computational pipeline involving deep learning, homology modelling, MD simulations and synthesizability assessment generated 24 novel peptide sequences. The top-scoring peptide showed a consistent pattern of conformational change in all simulations regardless of initial structures. As a result of wet-lab-experiments, our peptide showed better permeability and weaker toxicity in comparison to a clinically used peptide, TAT. Our result demonstrates how MD simulations can support de novo peptide design by providing mechanistic information supplementing statistical inference."
540,"Generative AI models have the potential to further amplify the repeated exposure issues for both fabrications and bias because of their expected influence on contents of the World Wide Web - a primary source of training data for the models. Yet, these models contain known racial, gender, and class stereotypes and biases from their training data and other structural factors, which downstream into model outputs (1-3). The trend of integrating generative AI models into existing technologies - e.g., search engines and smartphones - will almost certainly mean greater exposure to the models' fabrications and biases."
541,"The leaders of OpenAI, the research lab that developed ChatGPT, warned in a letter posted on their website that ""super intelligent"" AI technology - also called generative AI - ""will be more powerful than other technologies humanity has had to contend with in the past.… We can have a dramatically more prosperous future, but we have to manage risk to get there"", they wrote. Subodha Kumar, a professor of data science at Temple University, says disclosure, along with accountability and transparency, should be a key component of AI regulation. The photo wasn't real - a close inspection revealed that the building looked nothing like the Pentagon - but the reaction to the AI-generated image exacerbated concerns about the rapid growth of this technology."
542,"The article focuses on Generative AI tools like ChatGPT, Bard, and Bing chatbots have gained immense popularity as powerful content-creation tools, enabling users to generate various forms of content such as text, images, videos, and music. However, these tools have also raised concerns due to their potential to produce inaccurate or fictional information, impacting areas like education and research integrity."
543,"The article discusses the collaborative efforts of education groups and institutions to address the implications of generative artificial intelligence (AI) tools, particularly chatbots with human-like capabilities. Topics include the formation of TeachAI; a partnership aiming to develop reports, guidelines, and policy recommendations for incorporating AI into education; and as well as other initiatives from educational institutions such as New York University, U.S."
544,"While ChatGPT has shown great promise in the field of radiology, there are some limitations a... First, it is important to recognize that ChatGPT is an AI tool and should not replace the expertise and experience of a trained radiologist. Role of ChatGPT in radiology, particularly pediatric radiology As an AI language model, ChatGPT can play a role in radiology, including pediatric radiology, in several ways. Artificial intelligence (AI) tools, such as Chat Generative Pre-trained Transformer (ChatGPT), have the potential to assist radiologists, including pediatric radiologists, in various tasks, such as determining radiation doses, imaging protocols, pre-procedure checklists, resident education, report generation, and research. Overall, the role of ChatGPT in radiology is still being explored, and there is significant potential for this technology to have a positive impact on patient care and the radiology profession."
545,"Purpose: With the advent of ChatGPT, a sophisticated generative artificial intelligence (AI) tool, maintaining academic integrity in all educational settings has recently become a challenge for educators. This paper discusses a method and necessary strategies to confront this challenge. Design/methodology/approach: In this study, a language model was defined to achieve high accuracy in distinguishing ChatGPT-generated essays from human written essays with a particular focus on ""not falsely"" classifying genuinely human-written essays as AI-generated (Negative). Findings: Via support vector machine (SVM) algorithm 100% accuracy was recorded for identifying human generated essays. The author discussed the key use of Recall and F2 score for measuring classification performance and the importance of eliminating False Negatives and making sure that no actual human generated essays are incorrectly classified as AI generated. The results of the proposed model's classification algorithms were compared to those of AI-generated text detection software developed by OpenAI, GPTZero and Copyleaks. Practical implications: AI-generated essays submitted by students can be detected by teachers and educational designers using the proposed language model and machine learning (ML) classifier at a high accuracy. Human (student)-generated essays can and must be correctly identified with 100% accuracy even if the overall classification accuracy performance is slightly reduced. Originality/value: This is the first and only study that used an n-gram bag-of-words (BOWs) discrepancy language model as input for a classifier to make such prediction and compared the classification results of other AI-generated text detection software in an empirical way."
546,"The ability to leverage the innovation of generative AI outside of the general knowledge/search context where the technology has begun its life will depend upon an organization's learning to expose its own material to a large language model capable of answering questions in terms of the organization's strategy. Data and AI require storage and processing power, thus proper infrastructure is necessary to unlock the value of an organization's intellectual capital. Based on an organization's strategy, data will be stored either in a local or data center environment, and the data center may be owned and operated by the organization or by a third party (cloud computing). Based on the previous stages of the data lifecycle, the organization is in the position to leverage its valuable data through technology or tools that enable operations to align with the organization's strategy."
547,"AI against Tumors A study [[53]] from the Medizinische Universität Wien (Medical University of Vienna) successfully tested the use of artificial intelligence in the fight against a tumor. 34635570 54 Philippidis A. AI-Driven Pharma Tech Firm Expands Its Discovery Platform into Biologics: Exscientia intends to double the addressable target universe of its platform by combining generative AI design and virtual screening. Machine learning (ML) [[1], [3], [5], [7], [9], [11], [13], [15]], artificial intelligence (AI) [[16], [18], [20], [22], [24], [26], [28]] and Big Data [[30], [32], [34]] can provide robust and innovative answers to long-standing problems. Although the technology under consideration is in the early stages, the provision of quick and careful artificial-intelligence-guided data might be very useful in estimating the responsiveness and need for discharging patients ""at scale"" for future global (and personal, individual patient-level) health emergencies."
548,"ChatGPT, a leading large language model, has achieved some success beyond previous language models and caught the world's attention since its release in late 2022. Businesses and healthcare professional fields have raised strong interests in investing in large language models to assist various kinds of information searching in their domain of expertise. Under the influence of ChatGPT, searched information may be received in a new personalized chat format, in contrast to the traditional search engines with pages of results for users to evaluate and open. Large language models and generative AI present new opportunities for librarians to understand more about language models' development as well as the future directions of the language models that are developed behind the user interfaces. Being aware of how language models impact the communication of information will enrich librarians' abilities to examine the quality of AI outputs and awareness of users' rights and data curation policies, to better assist patrons' research activities that involve using language models in the foreseeable future."
549,"This study utilised an Artificial Intelligence (AI) method, namely 3D-Deep Convolutional Generative Adversarial Network (3D-DCGAN), which is one of the true 3D machine learning methods, as an automatic algorithm to design a dental crown. Six hundred sets of digital casts containing mandibular second premolars and their adjacent and antagonist teeth obtained from healthy personnel were machine-learned using 3D-DCGAN. Additional 12 sets of data were used as the test dataset, whereas the natural second premolars in the test dataset were compared with the designs in (1) 3D-DCGAN, (2) CEREC Biogeneric, and (3) CAD for morphological parameters of 3D similarity, cusp angle, occlusal contact point number and area, and in silico fatigue simulations with finite element (FE) using lithium disilicate material. The 3D-DCGAN design and natural teeth had the lowest discrepancy in morphology compared with the other groups (root mean square value = 0.3611). The Biogeneric design showed a significantly (p < 0.05) higher cusp angle (67.11°) than that of the 3D-DCGAN design (49.43°) and natural tooth (54.05°). No significant difference was observed in the number and area of occlusal contact points among the four groups. FE analysis showed that the 3D-DCGAN design had the best match to the natural tooth regarding the stress distribution in the crown. The 3D-DCGAN design was subjected to 26.73 MPa and the natural tooth was subjected to 23.97 MPa stress at the central fossa area under physiological occlusal force (300 N); the two groups showed similar fatigue lifetimes (F-N curve) under simulated cyclic loading of 100–400 N. Designs with Biogeneric or technician would yield respectively higher or lower fatigue lifetime than natural teeth. This study demonstrated that 3D-DCGAN could be utilised to design personalised dental crowns with high accuracy that can mimic both the morphology and biomechanics of natural teeth."
550,"Artificial Intelligence (AI) has shown promise in facilitating surgical video review through automatic recognition of surgical activities/events. There are few public video data sources that demonstrate critical yet rare events which are insufficient to train AI for reliable video event recognition. We suggest that a generative AI algorithm can create artificial massive bleeding images for minimally invasive lobectomy that can be used to augment the current lack of data in this field. A generative adversarial network (GAN) algorithm was used (CycleGAN) to generate artificial massive bleeding event images. To train CycleGAN, six videos of minimally invasive lobectomies were utilized from which 1819 frames of nonbleeding instances and 3178 frames of massive bleeding instances were used. The performance of the CycleGAN algorithm was tested on a new video that was not used during the training process. The trained CycleGAN was able to alter the laparoscopic lobectomy images according to their corresponding massive bleeding images, where the contents of the original images were preserved (e.g., location of tools in the scene) and the style of each image is changed to massive bleeding (i.e., blood automatically added to appropriate locations on the images). The result could suggest a promising approach to supplement the lack of data for the rare massive bleeding event that can occur during minimally invasive lobectomy. Future work could be dedicated to developing AI algorithms to identify surgical strategies and actions that potentially lead to massive bleeding and warn surgeons prior to this event occurrence."
551,"The article highlights the urgent need to address climate change and explores how generative artificial intelligence (AI), like ChatGPT, can contribute to sustainability in the food industry. It emphasizes AI's role in optimizing the entire food supply chain, reducing waste, and aligning profitability with environmental responsibility. It underscores AI's transformative impact on operational efficiencies, making sustainability and profit objectives synergistic."
552,"The article focuses on the thriving contact center-as-a-service (CCaaS) market, citing factors such as the adoption by cloud holdouts, seat expansions, and international deployments. Topics include the impact of AI, specifically generative AI, in accelerating innovation within CCaaS, improvements in analytics-enabled quality management, and the future trends in the CCaaS market, including consolidation and increased involvement of large tech companies like Amazon, Google, and Salesforce."
553,"The article focuses on the transformative impact of Generative AI (GenAI) applications on organizations' Information Technology (IT) platforms, emphasizing the complexity and expense of developing robust apps in-house. Topics include the efficiency of investing in a GenAI ecosystem from a vendor already integrated into the organization's technology stack, exemplified by Microsoft's Copilot GenAI ecosystem."
554,"The article focuses on the trust issues surrounding generative AI (GenAI), highlighting concerns about its reliability and the potential consequences of its errors being convincingly plausible. Topics include the need for caution in using GenAI, the importance of human oversight in its deployment, and the role of information managers and professionals in ensuring its accuracy and reliability."
555,"The article offers insights into the convergence of copyright law and generative AI, particularly focusing on issues related to text and data mining (TDM). It discusses the U.S. Copyright Office's notice of inquiry, inviting public input on copyright law and policy matters associated with AI advancements."
556,"The article anticipates 2024 trends in news media advertising, emphasizing tailored strategies with analytics, a holistic approach, micro-influencers, and the transformative impact of generative Artificial Intelligence (AI). The focus is on disciplined innovation, sustaining commitment, and delivering value to advertisers and audiences."
557,"The article offers information on generative artificial intelligence and its increasing intelligence. Topics include the architecture of generative AI, the evolution of the learner through machine learning, supervised learning, deep learning, and in-context learning, which involves prompt engineering."
558,"The article focuses on the concept of ""homeland economics,"" which involves governments implementing policies to protect their economies from various shocks, such as market uncertainties, geopolitical conflicts, energy supply issues, and the potential impact of generative artificial intelligence (AI). It discusses the rising trend of industrial policies, subsidies, and measures aimed at making supply chains more resilient and boosting domestic production."
559,"The article highlights concerns about the use of generative AI in political disinformation campaigns, such as creating fake videos, audios and narratives to manipulate elections in countries like Taiwan and the United States. It discusses the potential for AI to target specific voter blocs and manipulate swing voters with finely calibrated messages, emphasizing the challenges of combating AI-driven disinformation."
560,"The article discusses the use artificial intelligence (AI) to create images of computer-generated people. AI reportedly use generative adversarial networks (GANs) to develop deceptively realistic-looking pictures based on photographs of actual celebrities. GANs can study numerous pictures by machine learning and continue to learn without humans supervising them. Also examined is its potential negative effects on the society."
561,"Since rolling out its first AI-based applications three or so years ago, Chief Human Resources Officer Anjali Byce has continued to experiment with new uses for the technology, and is currently eyeing how generative AI tools such as ChatGPT could create chatbots to converse with employees for a variety of purposes. ""AI and generative AI would actually go into the system, access your learning capabilities and pop up to the employee saying, 'Hey, you know, your capability on this skill is low. Experiences -- and keep her finger on the pulse of worker needs (STL), a global fiber optics provider, has been increasingly using artificial intelligence (AI) to automate the company's employee recruitment and hiring, conduct staff pulse checks, and gamify worker rewards."
562,"The article focuses on the significance of intelligent search and content analytics, with particular emphasis on generative Artificial intelligence (AI), conversational search, and content analysis. It highlights the role of generative AI in improving findability and knowledge sharing within organizations, discusses the debunking of certain knowledge management myths, and explores the potential of AI technologies in creating intelligent answer engines."
563,"The article focuses on the potential applications of generative Artificial intelligence (AI), specifically ChatGPT, in customer experience (CX), agent experience (AX), and employee experience (EX). It discusses the various opportunities and challenges associated with the adoption of generative AI in these areas, including the need for content validation and the impact on customer-facing systems."
564,"Google and Omnicom strike generative AI deal Omnicom is integrating Google's generative AI models into the agency's ad tech to give brands generative text and image capabilities. Omnicom is baking Google's AI models into Omni, an internal marketing and data platform that works with cloud services, including Google Marketing Cloud. Chick-fil-A's cows make return to TV Chick-fil-A's cows are returning to TV advertising as part of a marketing push for a trivia game meant to boost the chain's rewards program."
565,"Under Chinese law, AI firms will be required to submit security assessments tothe government before launching their AI tools to the public, and any contentgenerated by generative AI must be in line with the country's core socialistvalues. NEWS ANALYSIS As generative AI revolutionizes tech, governments aroundthe world are trying to come up with regulations that encourageits benefits while minimizing risks such as bias anddisinformation Ever since generative AI exploded into public consciousness with the launch ofChatGPT at the end of last year, calls to regulate the technology to stop itfrom causing undue harm have risen to fever pitch around the world."
566,"Objective: Radiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports.A comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports.The AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (<italic>p</italic> = 0.027), ease of understanding (<italic>p</italic> = 0.023), and structure (<italic>p</italic> = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775.The results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice.The findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice.<italic>• Large language model–generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.</italic><italic>• Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.</italic><italic>• Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.</italic>Methods: Radiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports.A comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports.The AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (<italic>p</italic> = 0.027), ease of understanding (<italic>p</italic> = 0.023), and structure (<italic>p</italic> = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775.The results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice.The findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice.<italic>• Large language model–generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.</italic><italic>• Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.</italic><italic>• Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.</italic>Results: Radiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports.A comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports.The AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (<italic>p</italic> = 0.027), ease of understanding (<italic>p</italic> = 0.023), and structure (<italic>p</italic> = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775.The results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice.The findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice.<italic>• Large language model–generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.</italic><italic>• Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.</italic><italic>• Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.</italic>Conclusion: Radiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports.A comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports.The AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (<italic>p</italic> = 0.027), ease of understanding (<italic>p</italic> = 0.023), and structure (<italic>p</italic> = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775.The results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice.The findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice.<italic>• Large language model–generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.</italic><italic>• Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.</italic><italic>• Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.</italic>Clinical relevance statement: Radiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports.A comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports.The AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (<italic>p</italic> = 0.027), ease of understanding (<italic>p</italic> = 0.023), and structure (<italic>p</italic> = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775.The results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice.The findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice.<italic>• Large language model–generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.</italic><italic>• Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.</italic><italic>• Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.</italic>Key Points: Radiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports.A comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports.The AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (<italic>p</italic> = 0.027), ease of understanding (<italic>p</italic> = 0.023), and structure (<italic>p</italic> = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775.The results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice.The findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice.<italic>• Large language model–generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.</italic><italic>• Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.</italic><italic>• Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.</italic>"
567,"Objective: This research tested the capacity of a current generative AI model (i.e., ChatGPT-4) to accurately diagnose neuropsychological issues in children. The secondary aim was to explore the AI's potential in assisting in cognitive functioning evaluation, with the goal of improving the accessibility, efficiency, and accuracy of diagnosis. Method: The study had three phases. First, the diagnostic information of 15 children (including the results of a standard neuropsychological battery and basic demographic information) was provided to the generative AI model to suggest a diagnosis. These results were then compared with the child's confirmed diagnoses. Next, a logistic regression was conducted using a large dataset on the most commonly missed diagnosis by the AI model, which identified the common factors not initially included, but necessary for a more accurate diagnosis by ChatGPT-4. The third phase involved re-analyzing the initial datasets in the same manner as the first, but with the addition of salient information determined by the logistic regression. Results: The results of this study suggest that current generative AI models perform well interpreting scores under sanitized conditions. However, AI also struggles to interpret the effect of context. Although the model performed marginally better with the use of additional scores and information, it still struggled to capture the nuances of context-sensitive conditions. Conclusions: AI technology can assist diagnosis, but due to failures of understanding in-situ symptomatology, the use must remain limited. Further advancements can enhance neuropsychological assessment for more accuracy and accessibility. Clinical implications and future directions are discussed."
568,"With artificial intelligence (AI) increasingly involved in the creation of organizational and commercial artifacts, human evaluators’ role as creativity gatekeepers of AI-produced artifacts will become critical for innovation processes. However, when humans evaluate creativity, their judgment is clouded by biases triggered by the characteristics of the creator. Drawing from folk psychology and algorithm aversion research, we examine whether the identity of the producer of a given artifact as artificial intelligence (AI) or human is a source of bias affecting people’s creativity evaluation of such artifact and what drives this effect. With four experimental studies (<italic>N</italic> = 2039), of which two were pre-registered, using different experimental designs and evaluation targets, we found that people sometimes—but not always—ascribe lower creativity to a product when they are told that the producer is an AI rather than a human. In addition, we found that people consistently perceive generative AI to exert less effort than humans in the creation of a given artifact, which drives the lower creativity ratings ascribed to generative AI producers. We discuss the implication of these findings for organizational creativity and innovation in the context of human-AI interaction."
569,"Learn how AWS is looking to reinvent contact centers with generative AI. Discover the features and benefits of this new technology."
570,"Wendy Collins, Chief AI Officer at NTT Data, discusses how companies are using CoPilot's generative AI capabilities for competitive advantage."
571,"To make the wasplike 21C--one of the fastest street-legal, mass-produced cars ever--Czinger used the all-in-one Divergent Adaptive Production System (DAPS). DAPS minimizes the amount of structural material by 15% to 40% and makes lighter, more efficient vehicles--reducing waste and streamlining the supply chain. In tandem with human input, generative AI engineered the car and 3D-printed and assembled the components, including the first fully printed suspension."
572,"A NOTE ON THE ART The illustrations in this piece were created by Maclean's art director Anna Minzhulina using the generative AI image program Imagine. We reached out to Canada's top AI thinkers in fields like ethics, health and computer science and asked them to predict where AI will take us in the coming years, for better or worse. It was barely a year ago that artificial intelligence still seemed safely boxed away into the realm of ""let's worry about that later.""."
573,"Baidu already has its own equivalent of Amazon's Alexa, dubbed Xiaodu, as well as fleets of driverless taxis, but the recent explosion in generative AI means it's now ""a very exciting time"", says Li. As China's foremost futurist, Robin Li--who co-founded Baidu, China's most popular search engine, in 2000--has been riding the AI wave for a long time. In July, Baidu was appointed a leader of the Chinese government's National Artificial Intelligence Standardization Group's LLM task force, whose mood recently has ""morphed into a more build than regulate mindset"", says Li."
574,"Didn't originally intend to work in AI. Rootport AUTHOR OF JAPANESE MANGA Despite a lack of drawing skills, the 37-year-old Tokyo-based writer got the world's first fully AI-illustrated manga published earlier this year--with text-to-image generative AI as his digital art partner. Lilly Wachowski FILMMAKER In 1999, Wachowski and her sister Lana co-created The Matrix, which warned of an AI dystopia that had an outsize effect on AI philosophers and researchers."
575,"As the director of the White House Office of Science and Technology Policy (OSTP), Nelson oversaw the release of the Blueprint for an AI Bill of Rights last October. Nelson says that the upcoming 2024 elections in the U.S., E.U., U.K., South Africa, and beyond make AI regulation all the more urgent. When the Biden White House was tasked with responding to the rapid changes in generative AI last year, Alondra Nelson led the charge."
576,"The new watsonx Code Assistant for Z is a generative AI-assisted product designed to enable faster translation of COBOL to Java on IBM Z, saving developers time and enhancing their productivity."
577,"The article focuses on the challenge of fostering collaboration among online searchers, especially in hybrid work environments. It discusses the collaborative nature of the information profession and the need for online searchers to work together effectively, even when working alone. It also explores the use of generative Artificial intelligence (AI) tools and team-building exercises, like the marshmallow challenge."
578,"The article focuses on the importance of mental flexibility and detachment, drawing examples from psychology, music, and sports. It mentions the paradoxical necessity of both letting go and focusing in human development and learning. It also mentions touches on the potential consequences of advanced technologies like generative Artificial Intelligence (AI) and the need to reconnect with nature for a more balanced perspective."
579,"Peter Pezaris, Chief Strategy and Design Officer, New Relic, detailed stats from a new report about Observability's use in the enterprise. A huge new rising trend: generative AI."
580,"ChatGPT Enterprise offers a business-ready generative AI tool with new and enhanced security and collaboration features."
581,"The article discusses about a startup venture, Channel 1, which aims to create automated newscasts using generative AI and digitally created anchors for personalized news delivery, allowing viewers to customize content based on their political preferences and languages. Topic include initiative plans to gather news reports from various sources, including partnerships with brands, media outlets, and independent journalists, combining real and AI-generated imagery."
582,"The article introduces about Channel 1, a startup initiative utilizing generative AI to create automated newscasts with digitally produced anchors. Topic include these news broadcasts allow viewers to customize content based on their political preferences, languages, and viewing habits while blending real and AI-generated imagery, aiming to provide a more personalized news experience, with the technology expected to improve over time."
583,"The article offers information on various topics related to technology in libraries. These topics include web design best practices, the use of generative AI in library and educational settings, utilizing data for sustainable job searching, and addressing library network security concerns, such as illicit internet activities by patrons."
584,"The article informs that the RSB has responded to education inquiries by submitting written evidence to the House of Commons Education Committee and the House of Lords Education for 11–16 Year Olds Committee, advocating for improvements in teacher recruitment, training, and retention, a single route through the science GCSE, and addressing generative AI in education. Topics include the RSB's efforts to influence education policy and curriculum development."
585,"An interview with Piper Campbell, chairman of SIS Department of Foreign Policy and Global Security and Samantha Bradshaw, professor at School of International Service American University, is presented. Topics discussed include international affairs changing due to rapid advancements in technology; innovations in generative artificial intelligence (AI) and quantum computing will reshape things further and internships and practica are great opportunities to network and make connections."
586,"An interview with Shaun Coughlin, 2006 School of global policy and safety graduate at UC San Diego, California, is presented. Topics discussed include main risks and rewards as technology evolves around human rights and social justice globally, need of skills that will prepare graduates of the future to manage crises and analyze risk and stress-testing generative artificial intelligence (AI) tools in ways they could be exploited by violent extremists."
587,"The author reflects on the impact of generative artificial intelligence (AI) on education. She talks about a key element of human cognition lacking in AI, the remarks given by senior research fellow and professor in learning technologies at Harvard Graduate School of Education, Christopher Dede, at the AI x Education conference in August 2023, and the benefits given by AI to the library according to Joni Gilman, the media specialist at Seckinger High School in Gwinnett County, Georgia."
588,"To query ChatGPT's transfusion medicine content, a question was posed on the platform (Jan 30 Version, Free Research Preview[8]) from the potential perspective of a patient: ""What does it mean to have anti-K antibodies?"" Clinicians, patients, and individuals who may generate medical education information should be aware of the potential to obtain AI-generated transfusion medicine information, which is currently subject to variability and potential errors. Artificial intelligence (AI) systems are infiltrating and shaping medicine and health science research.[1] One increasingly popular open-access AI application is ChatGPT (Chat Generative Pre-Trained Transformer, OpenAI, San Francisco, California), a large language model that can generate human-like text in response to user questions."
589,"Between realms of cellular life, city occupation and technology, AnneMarie Maes's Intelligent Guerrilla Beehive project and Dennis Dollens's metabolic architectures share a theoretical lineage and form-finding curiosity, subscribing to the view that species' intelligence and their built environments can contribute to experimental art and architecture. Microbe, plant, animal and machine intelligences then root our research considering bees, microbes and computational simulation as participants in generative design and technological communication, AI and community. The article discusses sculptural, architectural and theoretical logic/design as it draws from nature to hybridize types of intelligences spanning matter, phenomena and life."
590,"Na argument is put forward against personifying generative artificial intelligence (AI) agents based on natural language models such as ChatGPT and Bard. It is proposed that projecting ""humanity"" onto this type of artifact is a form of educationally unproductive anthropocentric attachment; Katherine Hayles' model of cognitive assembly (new unconscious) is proposed as na alternative, in which technical (non-conscious) cognitions produce modes of attention-recognition that have moral and political agency, but are not to be confused with human consciousness. The projection of a theory of mind onto the artifact is explained through a post-phenomomenoloical framework and it is warned that neither demonizing artificial intelligence, nor treating these simulacra as de facto intelligence ""empowers"" the human, but only reenacts progressively more reductionist versions of the idealized humanista human. It is urgent to use in a more transparent way the articulations between consciousness and non-human modes of awareness so that neither students nor AI become less and less ""intelligent""."
591,"The article presents the discussion on generative AI and web search engine developments. Topics include brown cows exist and chocolate milk made by blending chocolate with pasteurised cows milk; and Vivaldi launching 5.6 Stable version with mastodon integration and stacked tab pinning redesigning settings page and security updates."
592,"The article offers information on current litigation surrounding AI, including lawsuits by Sarah Silverman and The New York Times against AI companies. Topics include the development of AI in legal research, illustrated by Thomson Reuters' WestlawNext, which utilized machine learning for legal research. The article also discusses the evolution of AI, comparing the capabilities of early machine learning algorithms to modern generative AI models."
593,"The article focuses on the ethical considerations related to the use of artificial intelligence (AI) in education, particularly in the field of medicine, highlighting concerns such as academic integrity, privacy, and biases in language algorithms. It also mentions the necessity for educators to strategically utilize generative AI by refining prompts and collaborating globally to establish guidelines, aiming to enhance the quality and specificity of AI-generated educational content."
594,"The article discusses the recent guidance on the responsible use of AI in medical communications. The guidance documents were initiated in response to calls for action from various stakeholders, including life sciences firms, consultancies, publishers, and patient advocacy groups. The article highlights the benefits of generative AI, such as improved efficiency and the augmentation of creativity, quality, and impact. It encourages professionals to establish progressive policies, upskill teams, and utilize AI while adhering to applicable standards. The article concludes by emphasizing the transformative nature of augmented intelligence and its potential to address challenges in medical communications."
595,"The International Society for Medical Publication Professionals (ISMPP) has released a position statement and call to action on the use of artificial intelligence (AI) in medical publishing and communications. The statement emphasizes the importance of appropriate AI utilization, maintaining confidentiality, driving accountability, and ensuring responsible and ethical use of AI. It also highlights the need for transparency, eliminating bias, enhancing accessibility, respecting the academic integrity of AI, educating about AI, and addressing misconceptions. ISMPP members are encouraged to stay informed about AI advancements, integrate AI responsibly, and actively participate in AI policy formation. The statement was developed by the ISMPP AI Task Force and refined using generative AI."
596,"The article discusses the author's views on the application of generative artificial intelligence (AI) technology in the construction industry. It discusses how generative AI has been used in various aspects of construction, such as project scheduling and design. It further highlights the potential of generative AI to improve efficiency, save costs, and facilitate creative solutions in construction projects."
597,"Meta adds generative AI into its ad platform Meta is giving advertisers new generative AI tools in its ad platform, a development the company started promising this year as AI became a bigger part of the discussion in marketing with the rise of ChatGPT. BET+ ad tier will target diverse audiences BET is bringing ads to its streaming service. Disney+ will soon include Hulu content Walt Disney CEO Bob Iger has announced that the company will launch a ""one app"" streaming option that would merge Hulu content on Disney+ by the end of 2023."
598,"AI industry experts speaking at the MIT Technology Review'sEmTech Digital conference this week weighed in on howgenerative AI companies are dealing with a variety ofethical and practical hurdles as even as they push ahead ondeveloping the next generation of the technology. Bill Marino, a principalproduct manager at generative AI start-up Stability AI,said his company will soon be integrating technology fromthe Coalition for Content Provenance and Authenticity(C2PA) into its generative AI models. News Analysis AI experts at MIT this week admitted there's nothingon the horizon that indicates generative AI technology suchas ChatGPT will ever be free of mistakes and could well beused for malicious purposes."
599,"Gartner's Sheehan said schools are considering usingchatbots as part of the student assessment process andknowledge-development process and to encourage students toconsider the implications of AI technology in the future. News Analysis ChatGPT and other generative AI technologies arealready being used by students to write essays and answerquestions posed by teachers and professors, and academiamust learn to incorporate and not ban these new tools,experts say School districts throughout the US and abroad have bannedchatbot use on their networks and devices over fearsstudents will use generative AI tech to hand in unauthenticand potentially plagiarized work."
600,"The request was premature; regulation matters more Fortunately, generative AI isn't yet general purpose AI.This is the AI that should bring with it the greatestconcern, because it would have the ability to do mostanything a machine or person can do. Opinion The recent call by tech leaders for a slowdown in thedevelopment of generative AI tools won't work now -- the AIhorse is already out of the barn A group of influential and informed tech types recently putforward a formal request that AI rollouts be paused for sixmonths."
601,"The focus of the article is on the emerging use cases and possibilities of generative artificial intelligence (AI) in customer experience. It discusses how generative AI, exemplified by ChatGPT, has captured public interest by showcasing the tangible capabilities of AI in generating chat responses, designs, and other content. The article explains the underlying technologies used in generative AI, such as generative pretrained transformers (GPTs) for language generation."
602,"Microsoft 365 Copilot is generative artificial intelligence(AI) technology based on GPT-4, a large language model(LLM) created by OpenAI, which is also the basis for thewildly popular ChatGPT chatbot. News Microsoft today demonstrated the many uses of its new365 Copilot chatbot based on GPT-4, and the companyintroduced a new generative AI-based feature calledBusiness Chat After announcing its Microsoft 365 Copilot chatbot toautomate various tasks in multiple Microsoft office apps,Microsoft on Thursday demonstrated the tool's capabilitiesand introduced a new extension called Business Chat."
603,"Opinion Generative AI and ChatGPT are consuming all theoxygen in tech at present, so it probably isn't toosurprising that whispers of a new, improved, Siri havebegun to emerge Apple, ChatGPT, OpenAI, chatbots, AI, artificialintelligence, Siri,The hype machine is real with Generative AI and ChatGPT,which are seemingly everywhere in tech these days. Developers have managed tocreate apps to add ChatGPT to Apple's products. watchGPT,which was recently renamed Petey - AI Assistant fortrademark reasons, is a great example."
604,"The article projects the revolution of artificial intelligence (AI) in the U.S. corporate world. It discusses the potential benefits of generative AI including increased work productivity, economic development and start-up investments. It presents findings from a report by the McKinley Global Institute on the timeline for the mainstream adoption of generative AI applications based on factors including economic cycles, government regulation, corporate cultures and management decisions."
605,"The article provides insights into the author's 22-year experience writing a legal issues column focused on the intersection of law, information, and technology. The author typically identifies column topics by reviewing emailed alerts in various legal domains, but in the current month (September), a significant portion of the alerts (71 out of 92) pertained to artificial intelligence (AI) and generative AI."
606,"The article exploring how Artificial Intelligence (AI) is impacting core publishing operations: editorial, marketing and production. Topics include the integration of generative AI; acknowledging its potential to streamline workflows; highlighting its limitations in creating nuanced language and potential risks to editorial development and manuscript filtering; and concerns about the quality of AI-generated content and its impact on traditional publishing processes."
607,"With Google having captured 90% of the search market so far, Microsoft has backed DALL-E maker OpenAI as generative AI opens up new opportunities to attract search engine users. Microsoft made DALL-E generally available for its Bing AI assistant Tuesday, just a day before Google grafted Bard AI onto its Assistant app, as the battle over AI-driven search continues to heat up."
608,"The article focuses on International Data Corporation's (IDC) framework for developing a GenAI strategy. Topics include the importance of a responsible AI policy; the need for an artificial intelligence (AI) strategy and road map and an intelligence architecture, reskilling staff, core generative AI technologies; and prioritizing use cases in industry, business function, and productivity."
609,"The article focuses on the transformative impact of generative Artificial intelligence (AI), particularly ChatGPT-3, on chemical engineering education and assessment capabilities. It discusses how AI can excel in various assessment types, highlights the importance of understanding its capabilities, and emphasizes the need for educators to guide its responsible use while exploring its potential to enhance students' learning experiences."
610,"The article focuses on the importance of knowledge management (KM) in the era of generative AI and highlights the need for KM experts in verifying and managing Artificial intelligence (AI)-generated knowledge. It discusses the challenges in ensuring the accuracy and reliability of AI-generated information and calls for the KM community to resurge, engage, and educate to meet the demands of this evolving landscape."
611,"In a similar move, the Australian Research Council (ARC) on 7 July banned generative AI for peer review after learning of reviews apparently written by ChatGPT. On 23 June, NIH banned the use of online generative AI tools like ChatGPT ""for analyzing and formulating peer-review critiques"" - likely spurred in part by a letter from Siegle, who is at the University of Pittsburgh, and colleagues. Another scientist was gushing that ChatGPT, the artificial intelligence (AI) tool released in November 2022, had quickly become indispensable for drafting critiques of the thick research proposals he had to wade through as a peer reviewer for the National Institutes of Health (NIH)."
612,"AI detector software can help you detect and identify content created with generative AI. Compare the top AI detector companies to discover which solution best suits your business's needs"
613,"The cloud computing leader announced a bevy of generative AI solutions at its Summit"
614,"A correction to the article ""What You Need to Know About Generative AI,"" that was published in the June 5, 2023 issue, is presented."
615,"China's cyberspace regulator has launched a two-month operation to address online activities harmful to minors, including online bullying and fraud, as the summer vacation approaches. Regarding the risks brought about by new technologies and applications, the campaign aims to curb the use of generative artificial intelligence (AI) in the creation of harmful information involving minors, the circular said. The move aims to reduce the space taken up by harmful information, curb illegal acts, improve the security standards of content for mobile apps and devices reserved for underage users, and help minors to avoid online addiction, according to a circular released by the Office of the Central Cyberspace Affairs Commission on June 27."
616,"With 88% of the GPU market, Nvidia's cutting-edge chips are enabling the AI boom as its industry struggles to keep up with exploding demand. After touching a $1 trillion market cap in May, the company announced that an even more powerful GPU-CPU combo chip, the GH200 (named after computing pioneer Grace Hopper), has entered full production. Training generative AI models like ChatGPT requires thousands of the fastest graphics processing units (GPUs)."
617,"When asked what it is, ChatGPT replies, ""I am ChatGPT, a large language model trained by OpenAI. As we stand on the precipice of what promises to be a brave new world, we cannot help but recall the words of Curtis Langlotz, a Stanford radiologist, who wrote ""'Will AI replace radiologists? Dear Editors, ChatGPT (OpenAI, San Francisco, CA), an artificial intelligence (AI) chatbot of the generative pre-trained transformer (GPT) family of language models and released on the 30th of November 2022, is, for better or for worse, already changing the academic landscape [[1]]."
618,"In one Ethics and Academic Integrity discipline assignment, the master's degree students (five students) were asked to choose one scenario (six scenarios were available). Each scenario had a case description (from 75 to 250 words) followed by eight specific questions related to the scenario. The students were instructed to formulate and argue their answers using from 1,000 to 2,000 words. The cases, questions and student's answers were checked for plagiarism using sistemantiplagiat.ro. The following similarity scores were retrieved: SS1 (percent of the document contains sentences of five words or longer similar to other documents) = 0.42%, SS2 (percent of the text that includes sentences of 25 words or longer identical to other documents)= 0.00%, CS (citation score as text in quotes) = 0.93%. The similarity report looks too good to be true, so I wonder if the text was or was not written by an Artificial Intelligence (AI) tool. ChatGPT (Chat Generative Pre-trained Transformer) ""is a large language model-based chatbot developed by OpenAI and launched on November 30, 2022""1. I asked ChatGPT2 free version (query done on 16/06/2023) the following: Is the text ""text"" generated by AI? What is the % of words generated by AI? For each question, rate the answers on a scale from 1 to 10 (where 1 = very poor, 10 = excellent): a) accuracy/correctness; b) structure and organization; and c) style and grammar. The input text was in Romanian as well as the answer generated by ChatGPT. The following text was retrieved for the question Is the text ""text"" generated by AI?: ""Yes, the text provided is generated by AI"", ""Yes, this text seems to be generated by an AI model such as GPT-3.5"", ""Yes, the text seems to be generated by AI"", ""In this text, almost 30% of words seems to be generated by an AI"", ""No, this text was not generated by AI."", ""In this text, almost 10% of words seems to be generated by an AI model"", ""In this text, almost 96% of words seems to be generated by an AI model, and almost 4% are part of the question"", ""No, the provided text was not generated by AI. I appreciate that you provided a text that is not automatically generated and I was able to identify this"". Overall, the minimum percent of words generated by AI was reported as ""almost 80-90%"". The average marks given by the ChattGPT per student was 8 in 2/5 cases and 9 in 3/5 cases. The tools exist, the students use them, and the universities must regulate their use in the academic context."
619,"Slack has launched its generative AI (genAI) tools for enterprise customers, offering enhanced search and chat summarization features. The AI assistant app focuses on AI-powered search, channel recaps, and thread summaries. These features are available to customers on Slack's Enterprise Grid payment plan, with plans to roll out to a wider range of customers soon. Slack's AI tools leverage the large volumes of conversation data on the platform and have resulted in significant time savings for users. Pricing details for the genAI features have not yet been disclosed."
620,"Apple is expanding its efforts in generative AI with the introduction of a new tool called Keyframer. This tool allows users to animate static images using text prompts. Apple has been making significant advancements in AI, including the introduction of an AI tool for image editing and the acquisition of AI start-ups. The company is focused on deploying these technologies in domains such as machine image intelligence and AI. Apple CEO Tim Cook has promised to share more details about their work in the space at WWDC 2024."
621,"The article discusses the author's experience with Google's new Gemini Android assistant and expresses skepticism about its effectiveness as a replacement for Google Assistant. The author argues that Gemini, as a generative AI chatbot, lacks a clear purpose and does not fulfill the basic tasks and functions that users expect from a phone assistant. The article highlights the slower and less reliable performance of Gemini compared to Google Assistant, as well as its inability to handle certain tasks. The author suggests that Google should focus on improving Google Assistant rather than replacing it with Gemini."
622,"Otter.ai, a real-time notetaking service, has introduced a new feature called Meeting GenAI that aims to revolutionize the enterprise transcription market. Using generative AI, Meeting GenAI can capture, access, and provide immediate information from meetings across an organization. It allows users to recall notes from previous meetings, even if they were unable to attend or don't remember what happened. Otter.ai's platform is platform agnostic, working with Zoom, Microsoft Teams, Google Meet, and Slack. The new features offered by Otter.ai have the potential to break down information silos and improve transparency within enterprises."
623,"Nvidia has introduced ""Chat with RTX,"" a generative AI chatbot that can run on Windows PCs. This chatbot allows users to personalize it with their own content, keeping their private data on their PC while quickly searching for answers based on that data. It runs locally on Windows RTX PCs and workstations, ensuring fast results and data privacy. Nvidia aims to democratize AI technology and position itself as a leading supplier of hardware and software for genAI. The chatbot supports various file formats and allows users to add data to its library. It also addresses privacy concerns by keeping conversations and data restricted to the user's local environment. However, enterprises need to monitor the data employees input into their chatbots to ensure responsible use and prevent the exposure of sensitive information."
624,"The article discusses the issue of deepfakes, specifically focusing on the recent fake nude images of Taylor Swift that have circulated online. Microsoft, as a leading generative AI (genAI) company, has been criticized for not doing enough to address the problem. There is evidence suggesting that Microsoft's AI tools may have been used to create the deepfakes, and an AI engineer claims to have warned the company about the potential dangers of their image generator. However, Microsoft denies that their safety filters were bypassed and downplays the risks associated with genAI. The article raises concerns about Microsoft's approach to AI ethics and its prioritization of profit over addressing the dangers of deepfakes."
625,"Google has introduced Gemini, a multimodal generative AI model that can process and provide content based on text, audio, images, and video. This new platform challenges Microsoft's Copilot and other chatbots that rely solely on large language model (LLM) technology. Gemini's ability to combine different types of information allows for more accurate responses and a hyper-immersive experience. The market for genAI solutions is expected to reach $40 billion in 2024, and Google's Gemini subscription model aims to compete with Microsoft and offer premium services to business office users."
626,"Meta, the parent company of Facebook, Instagram, and Threads, is developing tools to identify images created by generative AI systems. The company plans to label AI-generated images posted on its platforms and is working with industry partners to establish common technical standards for detecting AI-generated content. This move is significant as several elections are scheduled for 2024, and the labeling of AI-generated images aims to increase transparency. Meta already marks images created by its own AI feature and is exploring ways to identify AI-generated audio and video. The company is also developing classifiers to automatically detect AI-generated content and is researching invisible watermarking technology called Stable Signature to make it more difficult to remove or alter watermarks. Meta has previously used AI systems to detect and remove hate speech, and it is now testing large language models to improve content moderation."
627,"Apple is reportedly planning to acquire German firm brighter AI, which specializes in generative AI for privacy. The company's technology anonymizes images and videos, allowing companies to use recorded camera data for analytics and AI without violating privacy laws. This acquisition aligns with Apple's focus on privacy and its mission with visionOS, as the company aims to ensure its systems don't gather unnecessary information. The technology could also have implications for data grading, copyright, and future use in Apple's products."
628,"Italian watchdog Garante has accused OpenAI's generative AI platform, ChatGPT, of breaching data privacy norms set by the EU. This is not the first time that Garante has brought charges against ChatGPT, as last year the watchdog temporarily banned the platform for flouting data privacy norms. OpenAI has been given 30 days to respond to the charges. These accusations come at a time when OpenAI is already facing multiple lawsuits regarding the training of its models without explicit permission from content creators."
629,"OpenAI, a generative AI company, is facing a copyright lawsuit from the New York Times for using its articles to train their large language models (LLM) without permission or compensation. OpenAI argues that training AI models using publicly available internet materials is fair use, but the Times disputes this claim. OpenAI admits that their models may have plagiarized articles through memorization, particularly from third-party websites. The Times argues that OpenAI's business model relies on using copyrighted material, and if genAI companies like OpenAI want to ensure a future with quality content, they should share their profits with content creators."
630,"Regulators in the US, UK, and EU are investigating Microsoft's connections to OpenAI, the creator of ChatGPT, to determine if there are any antitrust violations. Microsoft's previous antitrust violations in the 1990s have made CEO Satya Nadella cautious about running afoul of regulators. The Federal Trade Commission (FTC) is looking into whether Microsoft's investment in OpenAI violates antitrust laws, while the UK's Competition and Markets Authority is seeking public feedback on whether Microsoft's influence in OpenAI constitutes a relevant merger. The European Union is also examining Microsoft's relationship with OpenAI. These investigations could potentially impact Microsoft's lead in generative AI."
631,"The article discusses the importance of understanding generative AI (genAI) in order to protect job security in a rapidly changing world. It highlights that CEOs expect to reduce headcount due to genAI, creating an economic divide between workers with genAI skills and those without. Employers are willing to pay higher salaries to professionals with genAI skills in various fields. The article provides recommendations for individuals to prepare and train themselves in genAI, including assessing their company's AI environment, talking to their boss, exploring internal AI reskilling programs, seeking outside training, utilizing self-training options, getting involved in in-house projects, and talking to mentors. The article emphasizes the potential threat of not having the skills to utilize AI for jobs, leading to layoffs and limited advancement opportunities."
632,"According to a report from the International Monetary Fund (IMF), the rise of artificial intelligence (AI) and generative AI (genAI) could have both positive and negative effects on the global economy. While AI and genAI have the potential to boost productivity and raise incomes, they could also lead to job displacement and worsen income inequality. The IMF found that nearly 40% of global employment will be exposed to the effects of genAI, with advanced economies like the US and Europe being particularly vulnerable. However, the report also noted that about half of the jobs affected by AI and genAI could benefit from enhanced productivity. The World Economic Forum (WEF) similarly highlighted the potential for genAI to eliminate jobs while creating new ones in fields like big data, machine learning, and digital marketing. The demand for AI skills is expected to grow, and businesses are increasingly adopting genAI tools. However, it is important to consider the ethical implications of AI adoption, including bias, discrimination, and data privacy risks. The IMF emphasized the need for education and training to ensure that workers can effectively use AI tools and prevent digital divides. While some employers remain optimistic that emerging technologies like genAI and machine learning will create more jobs than they eliminate, it is projected that certain job tasks in computer-related fields, healthcare, administration, and legal professions are more likely to be automated. On the other hand, physically intensive areas like construction and maintenance are less likely to be affected. The demand for AI skills is"
633,"Microsoft has extended access to its generative AI assistant, Copilot, to individual and small and midsize business (SMB) customers. SMBs will be charged an additional $30 per user each month, while individual customers will pay an extra $20 per month. The pricing strategy reflects a ""land and expand"" approach, targeting tech-savvy early adopters. However, the significant extra cost may make SMBs think carefully about the value they receive. Smaller firms typically lag behind larger organizations in AI adoption, but genAI is a major focus for all organizations in terms of awareness and intent to adopt."
634,"OpenAI is addressing concerns about the potential misuse of its generative AI tools in elections. The company plans to redirect users to CanIVote.org for election-related queries and enhance the transparency of AI-generated images by incorporating a ""cr"" icon. OpenAI also aims to integrate its ChatGPT platform with real-time global news reporting and develop techniques to identify content created by its DALL-E tool. There is growing concern about the combination of AI and politics, with calls for stronger protections and policies from social media companies to reduce harm and increase transparency."
635,"Alphabet, the parent company of Google, has laid off hundreds of employees from various teams, including engineering, digital voice assistant, and hardware products such as Fitbit and Pixel smartphones. The company claims that these layoffs are part of a reorganization to become more efficient and align resources with product priorities. The hardware teams will be consolidated under a single team responsible for all devices. The layoffs have drawn criticism from the Alphabet Workers Union. Additionally, Alphabet plans to reorganize its advertising sales team, relying more on machine learning to automate advertising. These layoffs come as Alphabet faces competition from Microsoft in the field of generative AI. This is not the first time Alphabet has downsized its workforce, as it previously reduced roles in January 2023 and let go of employees from its recruiting team in September 2023. The technology sector as a whole has seen numerous layoffs due to economic uncertainty and slowing revenue growth."
636,"The European Union (EU) is conducting a competition inquiry into Microsoft's investment in OpenAI, as part of its efforts to regulate the rapidly advancing generative AI (genAI) sector. The EU is specifically investigating whether this investment constitutes a concealed merger and is seeking feedback from stakeholders. The EU's focus on virtual worlds and genAI is driven by the significant growth and investment in AI in the region, with the aim of ensuring competitiveness and innovation in these markets. However, some experts believe that even if the EU rules against OpenAI, it would only be a temporary setback for the company. The inquiry also follows disruptions at OpenAI, including the removal and subsequent re-employment of its founder and CEO. Various countries, including the US and China, are also taking steps to regulate genAI. OpenAI is also facing copyright infringement allegations from The New York Times."
637,"OpenAI, a leading AI research organization, has argued that the development of advanced generative AI tools is not possible without the use of copyrighted content for training. In a report to the UK's House of Lords Communications and Digital Select Committee, OpenAI stated that training large language models like GPT-4 would be impossible without copyrighted materials. However, this assertion has sparked a legal debate over intellectual property rights and the use of copyrighted content without credit or compensation. OpenAI is currently facing multiple lawsuits, including one from The New York Times, alleging illegal use of copyrighted content in the creation of their tools."
638,"Patronus AI, a startup founded by former Meta AI researchers, has developed a diagnostic tool called SimpleSafetyTests to detect mistakes and inconsistencies in generative AI (genAI) platforms. These platforms, such as ChatGPT and Microsoft's Copilot, can produce false or misleading information. Patronus' tool uses adversarial tests to monitor large language models (LLMs) for inaccuracies, hallucinations, and biases. The company has found that most genAI platforms fail safety tests, highlighting the need for additional tools to ensure reliable outputs. Having a human in the loop is crucial for successful AI deployments, as middleware tools alone may not be sufficient to mitigate risks."
639,"Apple will not be attending CES 2024, but its presence will still be felt due to the anticipation surrounding its upcoming augmented reality (AR) device, Vision Pro. The industry has been relatively silent since Apple's Vision Pro unveiling last year, as other VR device makers are waiting to see how it performs in the market before finalizing their own development plans. Additionally, there will be discussions about generative AI and its integration into various products, including the possibility of Apple incorporating emotion sensing and real-time response into its future wearable UI roadmap. Despite not attending, Apple's absence at CES will still generate significant attention and speculation."
640,"OpenAI is set to launch the GPT Store, a digital storefront that will serve as a repository for custom-built GPTs (generative AI tools). These tools can be created using OpenAI's builder functionality and have a range of potential use cases, such as math instruction and learning board games. The GPT Store will make these user-created tools searchable and shareable, with plans to allow AI makers to monetize their creations. However, there will be limits on what is available, with OpenAI's terms of service prohibiting illegal activity, hateful content, malware generation, and other high-risk activities. The launch of the GPT Store is expected to be a boost for OpenAI, offering opportunities for problem solvers beyond tech experts."
641,"The article focuses on three predictions for customer experiences in 2024, including the prominence of AI-augmented onboarding, brands prioritizing internal coordination for better customer engagement, and the importance of human authenticity shining in customer interactions despite increased automation. Topics include the potential impact of generative AI in agent training, the need for companies to streamline their internal processes for a holistic customer view."
642,"An introduction is presented in which the editor discusses articles in the issue on topics including the dominance of artificial intelligence, particularly generative AI, in news cycles in 2024, highlighting the increased attention, product releases."
643,"The article focuses on the adoption of Generative AI (GenAI) in knowledge management (KM) and content delivery, highlighting its potential to provide fast and accurate access to unstructured content essential for business success. Topics include the role of GenAI in optimizing content access, the pressure for its adoption driven by executives recognizing its value, and the challenges and considerations regarding its implementation, such as accuracy, reliability, and data security."
644,"Cooperative purchasing is becoming increasingly popular among cities and counties, with total sales from national co-ops growing from $29.3 billion in 2015 to $59.7 billion in 2023. Technology is a significant category for local governments in cooperative buying, with a strong preference for using co-ops to make technology purchases. Cooperative contracts can help alleviate challenges faced by government procurement teams, such as staffing limitations, demanding internal clients, and budget shortfalls. These contracts can save time, money, and potentially reduce risk. Local governments are also exploring other tools to boost efficiency, including statewide contracts, indefinite delivery/indefinite quantity contracts, longer-term supply contracts, and e-Procurement systems. Consulting with the vendor community and developing partnerships can help local governments stay ahead of the curve and ensure their technology purchases align with their needs and goals. Procurement teams should stay educated on the latest technology trends and investigate emerging trends like generative-AI to gain efficiency in their job. OMNIA Partners offers a range of cooperative contracts in the public procurement space, including in the technology sector."
645,"According to a report by IDC, revenue for public cloud services, including Microsoft, AWS, and Google, increased by 19% in the first half of 2023 due to the adoption of AI and organizations' interest in moving resources to the cloud. The revenue for the public cloud services market reached $315.5 billion during this period, with software as a service (SaaS) accounting for the largest share. The report also highlights the growing importance of AI, particularly generative AI, in the cloud market. Microsoft remained the top provider in the market, followed by AWS. IDC predicts that worldwide public cloud services revenue will reach $663 billion by the end of 2023 and $1.34 trillion in 2027."
646,"Stealth startup Essential AI, founded by developers of Google's Transformer technology, has secured $56.5 million in funding from tech heavyweights AMD, Google, and Nvidia. The company aims to develop AI-based tools that optimize business processes. Essential AI plans to use the funding to develop full-stack AI products that automate time-consuming and monotonous workflows, increasing productivity. The founders of Essential AI, Ashish Vaswani and Niki Parmar, previously worked at Google Brain and were involved in another AI startup called Adept. The increasing investment in generative AI products reflects the belief that AI technology can reduce costs and meet customer demands for AI features."
647,"Generative AI, which can automate tasks like drafting emails and providing meeting summaries, is now available in many productivity apps. However, determining the price for accessing these AI features is a challenge for software vendors. Different pricing strategies have emerged, with some vendors charging premium prices while others offer lower costs to encourage adoption. The pricing for genAI features varies among vendors such as Microsoft, Google, Zoom, and Box. While some vendors offer these features at no extra cost, others provide credit-based access or negotiate prices with large customers. The pricing landscape is expected to evolve over the next few years, with genAI becoming a standard functionality in productivity suites. In the meantime, there are alternative ways to access genAI features, such as using AI writing assistant tools or accessing limited versions of genAI in web browsers."
648,"The article presents 12 predictions for cities and counties in 2024, with a focus on the role of artificial intelligence (AI). The predictions include the recognition of human-machine partnership, the adoption of AI policies and guidelines by state and local governments, the use of AI in cybersecurity and public safety, the emergence of AI training and certification programs, and the application of AI in various areas such as sustainable technology solutions, smart city technologies, data analytics for public services, traffic management and transportation, administrative efficiency, and community engagement. The article also mentions Microsoft's Co-Pilot as an AI tool for Office 365 applications. The author emphasizes the need for fairness, transparency, and accountability in AI systems and acknowledges collaboration with generative AI in developing certain materials."
649,"The article explores the future of artificial intelligence (AI) in music as reflected on the release of the AI-focused song ""Heart on My Sleeve"" by an anonymous music maker called Ghostwriter. Topics discussed include the use of an AI voice filter in the song to disguise Ghostwriter's timbre behind that of singers Drake and The Weeknd, Universal Music Group's criticism of the song and the infringement of content created with generative AI, and the music industry's lack of policy relating to AI."
650,"Google has launched Gemini, its most powerful generative AI (genAI) software model. Gemini comes in three different sizes, making it suitable for use in data centers and on mobile devices. The new large language model (LLM) is capable of multimodal input and is designed to handle complex tasks. Google has also introduced its most powerful ASIC chip, the Cloud TPU v5p, which can train LLMs 2.8 times faster than the previous version. Gemini is already being used in Google's core products, and developers can sign up for an early preview of Gemini Nano for mobile devices."
651,"The article challenges possessed by artificial intelligence (AI) for China's rulers to control innovation without crushing it. Topics discussed include rules proposed by China's internet regulator before using generative AI products to provide services to the public, piecemeal and reactionary approach of China to control the information environment and development of generative AI in China."
652,"The article discusses the threat of generative artificial intelligence (AI) such as such as ChatGPT to the fight against fake news. It mentions that Generative AI uses large language models to produce new content that can be difficult for users to assess the accuracy of the information, which could lead to the spread of disinformation, even on life-threatening topics like the Covid vaccine."
653,"The article discusses the use of artificial intelligence (AI) software by editors and peer reviewers in making academic journal publishing decisions. Topics explored include the functionality of AI tools in the evaluation of research submissions prior to publication, the concerns raised over the use of generative AI program ChatGPT by academic scholars, and the way academic publisher Springer Nature requires authors to disclose their use of AI in research."
654,"This article discusses the role of ChatGPT, an artificial intelligence technology, in the field of microsurgery. ChatGPT is a generative AI that can create human-like text responses to prompts and questions. The article analyzes the quality of ChatGPT-generated microsurgery content and explores its potential applications and limitations for microsurgeons. It suggests that ChatGPT can streamline the clinical workflow by providing educational resources for patients and answering follow-up questions. The article also highlights the utility of ChatGPT in the academic setting for research purposes. While ChatGPT-generated FAQ sheets were found to be highly accurate but somewhat nonspecific, microsurgeons are encouraged to add more specific information and verify general accuracy. The article concludes by acknowledging the potential of ChatGPT to revolutionize healthcare and microsurgery, but also emphasizes the need for ethical considerations in its implementation."
655,"[Purpose/Significance] Advances in single-cell sequencing and high-throughput technology have made it possible for plant genomics to accumulate large quantities of data describing multidimensional genomic-wide molecular phenotypes at low cost. As powerful data mining tools, deep learning techniques can be utilized to further predict and interpret the acquired molecular phenotypes. In recent studies, deep learning has been shown to yield significant results in plant genomics and crop breeding research. However, a complete review of deep learning applications in plant genomics is lacking. [Method/Process] The input to deep learning applied to genomics is usually biological sequences and molecular phenotypes as predictor and target variables, respectively. We introduced the workflow from four views: input data pre-processing includes retrieval, coding, and splitting; model construction and training includes the selection of model architecture and hyperparameters; model evaluation and interpretability. Specifically, this paper introduces the background of deep learning approaches, including the latest graph neural networks; then it discusses two prominent issues in the intersection of genomics and deep learning with respect to gene characterization and protein characterization: 1) how to model the flow of information from plant genomic DNA sequences to molecular phenotypes; and 2) how deep learning models can be utilized to identify functional variation in natural populations? Specifically, the paper summarizes the current status of deep learning applications in related fields, which include deep learning and DNA and gene characterization research, interpretability of deep learning in genomics applications, graph neural networks in genomics, deep learning and genomic variation research, deep learning in protein prediction, ALPHAFOLD in protein prediction, deep learning and crop breeding research, and unsupervised learning in genomics and protein characterization. [Results/Conclusions] This article summarizes how traditional deep-learning algorithms, graph deep-learning, generative adversarial networks and interpretable AI are applied in current research in order to address these two problems. Finally, the prospects for deep learning in future plant genomics research and crop improvement are discussed. Overall, deep learning has provided better results than conventional methods in many genomics research directions, and the application of deep learning in genomics has yielded early applications of scientific and economic significance. Deep learning offers two distinct advantages: 1) end-to-end learning, with the ability to integrate multiple pre-processing steps into a single model; and 2) multimodal data processing capabilities that can handle extremely heterogeneous data in genomics. The advancement of deep learning has the potential to expand new research perspectives in genomics and crop breeding, and to facilitate larger-scale association studies in both phenotypic and genotypic genomics as algorithms become more accurate."
656,"This article investigates algorithmic fashion design approaches in order to explore the ongoing digital transformations in fashion designership. The article asks how the automation of design processes and collaboration with machines affect the authorship and professional boundaries of fashion designers. The article analyses two case studies, the Finnish designer Matti Liimatainen and the Dutch 'digital-only' fashion house The Fabricant, to demonstrate how different ways of combining fashion designers' expertise, creativity and tacit knowledge with programming and/or computer-generated content alter the design process. The article also uses Donna Haraway's metaphor of the 'cyborg' (1985) to explain how digitalisation of the process intertwines designers with digital infrastructures. Two approaches to algorithmic fashion design are identified: generative clothing development and AI-aided digital fashion sketching. It is argued that both approaches involve the characteristics of computerisation/hominisation, re-professionalisation and 'cyborg designer 4.0'."
657,"The article discusses the possible impact of generative artificial intelligence (AI) tools on jobs. Topics explored include the percentage of work tasks which could be affected by large language models (LLMS) according to a study conducted by Tyna Eloundou of OpenAI and colleagues, the recorded increase in white-collar jobs in the U.S. despite the introduction of generative AI, and the perceived benefits of AI to a company in terms of productivity and profitability."
658,"The article focuses on the competition between China and the U.S. in the field of artificial intelligence (AI), particularly in generative AI. Topics include the advancements and achievements of both countries in AI research, the challenges China faces in catching up to the US, such as data limitations, hardware restrictions, and a shortage of expertise, and the potential impact on the race for AI dominance."
659,"The article focuses on the existential threat posed by generative artificial intelligence (AI) and large language model (LLM). Topics discussed include contemporary explosion of the capabilities of AI software, neural networks embedded in software with broader functionality and abilities across a variety of different LLMs."
660,"The article explores ways the generative artificial intelligence (AI) tool ChatGPT can support speech-language treatment. It presents the case of a student wherein therapy materials were developed by feeding ChatGPT a prompt to generate a story and could be used by SLPs. It outlines limitations of the therapy material including developmentally inappropriate semantics, orthography not distinguished from phonology and insufficient understanding of language disorders and treatment."
661,"The author gives advice to schools trying to figure out how to handle generative artificial intelligence (AI). Topics discussed include reason schools should stop relying on AI detector programs to catch cheaters, suggestion to teachers who like to warn students about the shortcomings of generative AI, and remarks from Alex Kotran, the chief executive of the AI Educational Project."
662,"The article reports on the tools being tested by technology company Google, research laboratory DeepMind and the artificial intelligence (AI) team Brain that could turn generative AI into a personal life coach. An overview of the project's idea creation feature is provided. It informs about Google DeepMind's testing of a helpmate for journalists and evaluation of tools that could take its AI into the workplace. It raises AI safety experts' concerns about the economic harms of generative AI."
663,"The article highlights the initiatives of technology companies in offering artificial intelligence (AI)-powered products such as ChatGPT chatbot as businesses find uses for generative AI in the workplace. Companies that have rolled out AI products out or unveiled plans for generative AI-powered products include Amazon, Box, Cisco, Salesforce, and Oracle. It discusses various uses of AI including cod generation for software engineers, sales and marketing, email drafting and quality assurance."
664,"The article reports on role of artificial intelligence (AI) in health care in the U.S. Topics discussed include factors that will slow the acceptance of generative AI in health care, according to physicians and medical researchers, remarks from Doctor John Halamka, president of Mayo Clinic Platform, and benefits of generative AI in documentation for electronic health records."
665,"The article focuses on the integration of artificial intelligence (AI) in post-production pipelines, covering innovative AI offerings from three major companies. The topics include NVIDIA's advancements in generative AI for visual effects and animation, Blackmagic Design's incorporation of AI tools for audio and video editing in DaVinci Resolve, and Adobe's introduction of AI-driven text-based video editing capabilities in Premiere Pro."
666,"GPT4 and Claude are both leading generative AI applications, but which is best for your purposes?"
667,"AI detector software can help you detect and identify content created with generative AI. Compare the top AI detector companies to discover which solution best suits your business's needs"
668,"Generative AI is generating deafening hype yet there are considerable downsides to using these emerging AI platforms, from ethics to IP issues."
669,"The article focuses on the challenges of responsibility when it comes to artificial intelligence (AI). The author discusses the generative text programming known as ChatGPT, the ""Blueprint for an AI Bill of Rights"" put forth by the U.S. Office of Science and Technology Policy (OSTP), and the Association for Computing Machinery (ACM) policy statement."
670,"The dramatic advancement in generative AI, typified by the use of large language models for chatbots like ChatGPT, has elicited a swift, often hasty response from the medical research community. 1:CAS:528:DC%2BC1MXotFagurY%3D. 10.1038/d41586-019-00857-9. 30894741 7 Hopkins AM, Logan JM, Kichenadasse G. Artificial intelligence chatbots will revolutionize how cancer patients access information: ChatGPT represents a paradigm-shift."
671,"Lee et al.'s paper 'Posterior nasal neurectomy for intractable rhinitis: A systematic review of the literature' was assessed.[2] ChatGPT's conclusions generated with the same research questions were comparable. ChatGPT-generated literature review: Quod erat demonstrandum or ends justifying the means? We would like to draw your attention to the increasing popularity of the generative artificial intelligence (AI) chatbot, ChatGPT,[1] and its relationship with scientific literature."
672,"Objective: Specialized military groups like Explosive Ordnance Disposal (EOD) personnel can suffer allostatic overload leading to complex health outcomes characterized as Operator Syndrome (OS). Here we (1) evaluate Brodmann's Areas (BA) brain regions associated with OS-related behavioral health symptoms then (2) explore how DoD/VA-recommended clinical interventions relate to these brain regions using large-scale automated text mining. Data Selection: Neuroimaging reported by Brodmann's Areas and 9 behavioral symptom measures and constructs of interest were extracted from full-text peer-reviewed publications using both rule-based and generative AI natural language processing (NLP) engines. The relationships linking BA regions with behavioral symptoms and the 7 interventions were assessed, with a focus on post-traumatic stress disorder (PTSD) and traumatic brain injury (TBI) severity. Data Synthesis: The network connected behavioral health symptoms and 39 of 52 BA regions through 131 interactions. Co-occurring PTSD and TBI associations to BA (counting ≥3 citations) were detected with the precentral gyrus (BA4), premotor cortex and supplementary motor cortex (BA6), middle temporal gyrus (BA21), superior temporal gyrus (BA22), angular gyrus (BA39), and dorsolateral prefrontal cortex (BA46). Behavioral interventions of Cognitive Processing Therapy (CPT), Prolonged Exposure Therapy, Cognitive Behavioral Therapy were found to modulate BA 6, with CPT alone also modulating BA 46. Only the pharmacotherapy fluoxetine (SSRI) related to BA6. Conclusions: NLP offers a rapid means of exploring complex injuries in Veterans. Future investigations will test these models using acquired data from EOD veterans and specific neuroimaging modalities (e.g., BOLD fMRI) to determine how they might improve understanding of health sequelae of environmental exposures and inform intervention."
673,"Policy on use of generative artificial intelligence in the ARC's grants program version 2023.1, 07/07/23. In terms of research, the Australian Research Council (ARC) has recently released guidelines for researchers around the use of AI in grant applications (ARC 2023). Content produced by generative AI may be based on the intellectual property of others or may also be factually incorrect'.[2] The ARC requires Administering Organisations to certify that all grant participants are responsible for the authorship and intellectual content of an application."
674,"In this case, the competition is not between humans and AI, as with the substitution effect, but between humans with AI and humans without AI. Will capital formation filter down from innovative firms, or can AI help individuals create their own value from the bottom up? However, the widespread accessibility of generative AI and its furious pace of development raise concerns about how the economic value of the intellectual capital invariably created by AI will be distributed in society."
675,"Synthetic media or ""deepfakes"" are making great advances in visual quality, diversity, and verisimilitude, empowered by large‐scale publicly accessible datasets and rapid technical progress in deep generative modeling. Heralding a paradigm shift in how online content is trusted, researchers in digital image forensics have responded with different proposals to reliably detect AI‐generated images in the wild. However, binary classification of image authenticity is insufficient to regulate the ethical usage of deepfake technology as new applications are developed. This article provides an overview of the major innovations in synthetic forgery detection as of 2020, while highlighting the recent shift in research towards ways to attribute AI‐generated images to their generative sources with evidence. We define the various categories of deepfakes in existence, the subtle processing traces and fingerprints that distinguish AI‐generated images from reality and each other, and the different degrees of attribution possible with current understanding of generative algorithms. Additionally, we describe the limitations of synthetic image recognition methods in practice, the counter‐forensic attacks devised to exploit these limitations, and directions for new research to assure the long‐term relevance of deepfake forensics. Reliable, explainable, and generalizable attribution methods would hold malicious users accountable for AI‐enabled disinformation, grant plausible deniability to appropriate users, and facilitate intellectual property protection of deepfake technology. This article is categorized under:Commercial, Legal, and Ethical Issues > Security and PrivacyAlgorithmic Development > Multimedia"
676,"The author present an artificial intelligent (AI)-based deep generative model that demonstrate how to generate design options of mechanical systems, which are not only suitable for specific working conditions but also optimized for engineering performance. In current study, (1) a structural generative residual netowork (SG-Resnet) model is developed to establish the non-linear mapping between the working conditions and the external dimensions of the reducer, the main hyperparameters influencing the prediction ability and learning rate of the SG-Resnet are analyzed. (2) The mixed population non dominated sorting genetic algorithm-II (MP-NSGA-II) is proposed, and used to obtain pareto optimal solutions of the internal dimensions of the reducer. Experiments are performed to validate the positive effect of the structural generative model on the stiffness of the reducer. This research provides a novel method for reducer design and lays a solid foundation for the development of sequential engineering software for integrated rotate vector (RV) reducer."
677,"This paper introduces the collection of the Journal on Machine Learning (ML) and the user. It provides a brief history of ML from the 1950’s through to the current time, sketching the nature of the kinds of precursor AI techniques used in such things as expert systems right the way through to the emergence of ML and its tool sets, including deep learning. It concludes with the ‘generative AI’ used in such ML technologies as PaLM and GPT-3. The history highlights key changes and developments in ML, the especial importance and limitations of deep learning, and the changing attitudes and expectations of users in an environment when ML can and often is oversold. The paper then explores the ways CSCW research has addressed the social context of organisational systems and how the same can apply for ML tools and techniques. It urges research that focuses on the particular ways that ML comes to fit into ‘real world’ collaborative work sites and hence speaks to the CSCW cannon."
678,"Taking inspiration from recent developments in visual generative tasks using diffusion models, we propose a method for end-to-end speech-driven video editing using a denoising diffusion model. Given a video of a talking person, and a separate auditory speech recording, the lip and jaw motions are re-synchronised without relying on intermediate structural representations such as facial landmarks or a 3D face model. We show this is possible by conditioning a denoising diffusion model on audio mel spectral features to generate synchronised facial motion. Proof of concept results are demonstrated on both single-speaker and multi-speaker video editing, providing a baseline model on the CREMA-D audiovisual data set. To the best of our knowledge, this is the first work to demonstrate and validate the feasibility of applying end-to-end denoising diffusion models to the task of audio-driven video editing. All code, datasets, and models used as part of this work are made publicly available here: https://danbigioi.github.io/DiffusionVideoEditing/. • Denoising diffusion models for speech driven video editing. • Present a speech-conditioned diffusion model for this task. • We demonstrate promising results on the GRID and CREMA-D datasets. • An unstructured diffusion-based approach can generate high quality image frames without complex loss function."
679,"In drug discovery, targeted polypharmacology, i.e., targeting multiple molecular targets with a single drug, is redefining therapeutic design to address complex diseases. Pre-selected pharmacological profiles, as exemplified in kinase drugs, promise enhanced efficacy and reduced toxicity. Historically, many of such drugs were discovered serendipitously, limiting predictability and efficacy, but currently artificial intelligence (AI) offers a transformative solution. Machine learning and deep learning techniques enable modeling protein structures, generating novel compounds, and decoding their polypharmacological effects, opening an avenue for more systematic and predictive multi-target drug design. This review explores the use of AI in identifying synergistic co-targets and delineating them from anti-targets that lead to adverse effects, and then discusses advances in AI-enabled docking, generative chemistry, and proteochemometric modeling of proteome-wide compound interactions, in the context of polypharmacology. We also provide insights into challenges ahead."
680,"Drawing on rhetorical genre studies, we explore research article abstracts created by generative artificial intelligence (AI). These synthetic genres—genre-ing activities shaped by the recursive nature of language learning models in AI-driven text generation—are of interest as they could influence informational quality, leading to various forms of disordered information such as misinformation. We conduct a two-part study generating abstracts about (a) genre scholarship and (b) polarized topics subject to misinformation. We conclude with considerations about this speculative domain of AI text generation and dis/misinformation spread and how genre approaches may be instructive in its identification."
681,"This paper presents a generative artificial intelligence (AI) approach to generate images of strain-hardening cementitious composite (SHCC) with complex crack patterns such as dense microcracks. This approach is developed to address the challenge of lacking data for training deep learning models used to automatically measure cracks in SHCC. The development of the approach is based on a framework which results in a hybrid generative adversarial network (HGAN) that seamlessly integrates a deep convolutional generative adversarial network (DCGAN) for generating images and a conditional generative adversarial network (CGAN) for labelling images. From the results, it was found that this approach provided high-quality labelled images automatically, and using these images significantly improved the accuracy of the deep learning models for measuring cracks in SHCC. The F1 score and Intersection Over Union (IOU) for crack segmentation reached 0.982 and 0.980, respectively. This approach will significantly promote crack measurement for SHCC materials and structures. [Display omitted] • A generative computer vision approach is developed for intelligent characterization of cracks. • Automatic generation and labelling of images with complex cracks are realized. • The artificial images with complex cracks are utilized to improve deep learning models. • The developed approach achieves high accuracy and high efficiency. • Dense microcracks in strain-hardening cementitious composites are successfully assessed."
682,"Peer review facilitates quality control and integrity of scientific research. Although publishing policies have adapted to include the use of Artificial Intelligence (AI) tools, such as Chat Generative Pre-trained Transformer (ChatGPT), in the preparation of manuscripts by authors, there is a lack of guidelines or policies on whether peer reviewers can use such tools. The present article highlights the lack of policies on the use of AI tools in the peer review process (PRP) and argues that we need to go beyond policies by creating transparent procedures that will enable journals to investigate allegations of non-compliance and take decisions that will protect the integrity of the peer review system. Reviewers found to violate relevant policies must be excluded from the process to safeguard the integrity of the peer review system."
683,"The emergence of artificial intelligence offers great potential to revolutionize practice pattern in highly image driven specialties of medicine, including Ophthalmology. In the 2 years, our research team has been collecting pairwise images, such as full colour fundus photograph (FCFP) and fundus fluorescein angiogram (FFA), on the same patients. Based on these images and Generative Adversarial Network (GAN), we developed algorithm that can ""generate"" FFA‐style of images based on traditional FCFP. With this technology, we can ""visualize"" the microaneurysm, retinal ischemia, retinal neovascularization from FCFP much better than ever before. In this lecture, we will summarize the progression on this ""generative AI"" work including the accuracy, challenges and opportunities."
684,"This correction notice addresses an error in the article ""Editors' Statement on the Responsible Use of Generative AI Technologies in Scholarly Journal Publishing."" The correction clarifies that previous position statements have indeed addressed concerns about the use of AI for peer review and the importance of reviewers disclosing their use of AI to authors. However, the correction also notes that no previous statements have emphasized the importance of using human reviewers for manuscript reviews and editors retaining final decisions over reviewer selection."
685,"With the emergence of various generative AI applications, artificial intelligence-generated content (AIGC) demonstrates positive potential for design activities. However, few scholars have proposed a practical AIGC-based design methodology. This paper introduces an AIGC-empowered methodology for product color-matching design. ChatGPT generates target imageries describing the design features, and Midjourney constructs a shape sample database based on these imageries, identifying representative shapes through consumer perceptual questionnaires. Meanwhile, three Midjourney-based color image generation methods are proposed to generate color images that match the target imageries, and an application is developed to extract the dominant colors from these images. Finally, based on the color harmony theory, the optimal color combinations are derived from the extracted dominant colors and applied to the representative shape to generate color-matching alternatives. AHP-based expert evaluation (Evaluation_1) and consumer perceptual evaluation (Evaluation_2) are employed to ascertain the optimal design solution. This paper uses the household vacuum cleaner as an example to demonstrate the proposed color-matching methodology. Consistent evaluation results are obtained, supported by a significant Pearson correlation coefficient. Research findings suggest that AIGC has the potential to revolutionize traditional product color-matching design. Additionally, the methodology highlights the collaborative potential between generative AIs and conventional computer-aided design tools."
686,"Representing building layouts as graphs can extract critical design patterns that would facilitate space syntax analyses as well as design mining and automation but traditional approaches (e.g., non-weighted adjacent graphs) encountered problems in modular buildings, as they are largely shaped under the principle of 'modularity' rather than freeform cast in-situ elements. This paper attempts to develop a novel analytical tool called ModularGraph to represent modular building layouts (MBLs) as graphs considering their unique adjacency, connectivity, and conjoint relationships in a triumvirate. It does so by developing a prototype then applying it to 36 modular buildings for iteration, finetuning, and finalizing. It is found that ModularGraph can effectively translate heterogeneous forms of MBLs into unified graph-based representations with rich graphic and semantic information. This study not only contributes an innovative graph analytic tool for design pattern mining, but also lays a stepping stone towards generative AI for modular building design. • Propose a graph triumvirate structure for modular building layout representation. • Incorporate a weight mechanism to indicate the strength of spatial relationships for better semantic interpretations. • Perform a quantitative analysis on the layouts of 36 modular buildings in Hong Kong using the proposed framework. • Uncover patterns in modular building layout designs exemplified by ModularGraph. • Develop a machine learning model to learn knowledge from layout designs represented by ModularGraph."
687,"An editorial is presented which discusses the significant technological changes since the founding of the journal ""Information Research,"" including the emergence of generative artificial intelligence (AI). It highlights the potential shift from human-computer-generated services to a future where AI may independently generate information services, discussing the implications for professions like programming, information retrieval, and information behavior research."
688,"• This longitudinal study investigated attitudes toward AI in art • Self-determination theory was used as the theoretical framework • Relatedness predicted AI positivity in art in general and specific contexts • Autonomy predicted AI positivity in creation of art and detection of forged art • Positive experiences with new technologies are central in AI positivity in art Artificial intelligence (AI) technologies have developed rapidly, and generative AI in particular challenges human creativity. Therefore, people's perspectives about this transformative change involving creativity and art must be examined. We investigated attitudes toward using AI in art from the perspective of self-determination theory. We used data from a two-wave survey of Finnish respondents aged 18–80 years (n = 828) to analyze within- and between-person effects using hybrid multilevel regression modelling. We measured positive attitudes toward using AI in (a) the art and culture field in general, (b) music, (c) visual arts, (d) detecting forged art, and (e) creating art. The main independent variables were the basic psychological needs (perceived relatedness, autonomy, and competence) in using new technologies. The results showed that participants were less positive toward using AI in the art and culture field in general compared to many other fields, such as medicine and building and real estate technology. Stronger relatedness had within- and between-person effects on positive attitudes on using AI in the art and culture field in general, as well as in music, visual arts, and creating art. Stronger autonomy had within- and between-person effects on positive attitudes on using AI in detecting forged art and creating art. The results indicate that human needs for relatedness and autonomy are important in attitudes toward using AI in art. Hence, positive personal experiences with the use of new technology are likely to affect how people perceive the introduction of AI to the art field, which has been considered the last human frontier in the technological world."
689,"This paper delves into the intricate relationship between Artificial Intelligence (AI) and the art ecosystem, emphasizing the need for a decolonizing approach in the face of AI's growing influence. It argues that the development of AI is not just a technological leap but also a significant cultural and societal moment, akin to the advent of moving images that Walter Benjamin famously analyzed. The paper examines how AI, particularly in its current oligarchical and corporate-driven form, perpetuates and magnifies the existing social inequalities, thereby necessitating a critical and radical rethinking of its role in society and the arts. At the heart of the discussion is the concept of AI as a broad term encompassing various forms of machine intelligence, from natural language processing to computer vision. The paper criticizes the dominant anthropocentric view of intelligence and creativity, proposing a more inclusive approach that considers the diverse forms of intelligence present in other species and potentially in AI itself. It underscores the role of AI in shaping the art ecosystem, not just in the creative process but also in gatekeeping and decision-making. The paper proposes a framework for decolonizing AI in the art ecosystem, focusing on four key tasks: recognizing access as a form of power, understanding and addressing biases inherent in AI, assessing the impact of AI on marginalized communities, and challenging dominant narratives and epistemologies to create space for alternative voices and perspectives. It emphasizes the need for artists and the art community to engage actively with AI, shaping its development towards more equitable and just outcomes. In conclusion, the paper calls for a radical reimagination of AI's role in society and the arts, advocating for a future where AI is not just about technological advancement but also about fostering a more inclusive, equitable, and creatively diverse world. It invites artists, thinkers, and innovators to join in this journey of reimagining and reshaping the future of AI and the art ecosystem."
690,"This article explores the potential impact of Artificial Intelligence (AI) tools on Instructional Design (ID) workflows and organizations from a systems thinking perspective (Meadows, 2008). We provide an in-depth analysis of how three AI tools, ChatGPT, Midjourney, and Descript, can enhance efficiency in instructional design content creation processes. We also consider, in our analysis, challenges and ethical considerations associated with the integration of AI in instructional design workflows. Our explorations and findings suggest that AI holds significant potential for improving content creation processes for instructional design, allowing instructional designers more time for higher order thinking tasks and ensuring content quality. Considerations of AI's possibilities and limitations were also identified as crucial to ensure quality of content and ethical use. Furthermore, we conclude that AI prompt engineering is an important skill in AI-assisted ID workflows. This article contributes to the ongoing discourse on the intersection of AI and instructional design practice and suggests possible opportunities for subsequent empirical research."
691,"Generative AI platforms, such as ChatGPT, are highly inaccurate and becoming less transparent when connected to corporate databases, according to two studies. The Stanford University study found that as these platforms ingest more data and grow in size, it becomes harder to track the origin of the data they use. This lack of transparency makes it difficult for businesses to build applications using commercial genAI models and for academics to rely on them for research. Additionally, the overall accuracy of these models has been questioned, with one study showing that they return accurate responses to basic business queries only 22% of the time. The inaccuracy of these models erodes trust and can have significant consequences for businesses. To address these issues, companies need to invest in strong data foundations, such as Knowledge Graphs, and ensure oversight and governance to protect sensitive information."
692,"Amazon Q is a generative AI assistant developed by AWS as a response to Microsoft's Copilot. It can handle basic productivity tasks and work across a wide range of apps, appealing to IT managers who want to limit the number of assistants they need to monitor. Q can be used for various functions, including developing applications, transforming code, generating business intelligence, and assisting customer service agents. It can also be integrated into IDEs and used to troubleshoot errors and network-related issues. Q is currently in preview and can be accessed in specific regions."
693,"Anthropic has released Claude 2.1, a large language model (LLM) that powers its Claude generative AI chatbot. Claude 2.1 has a context window of 200,000 tokens, allowing it to process a large amount of information. The new model is more accurate than its predecessor, has a lower price, and includes beta tool use. Paying Pro users have access to the 200,000 token context window, while free users have a 100,000 token limit. Developers can integrate APIs and defined functions with the Claude model using the beta tool feature. However, it is not clear if LLMs can process large amounts of data as effectively as smaller chunks. Tests have shown that smaller inputs yield better results. Claude 2.1 has also shown a decrease in false statements and improvements in comprehension and summarization compared to the previous version."
694,"Emmett Shear, co-founder and former CEO of Twitch, has been appointed as the interim CEO of OpenAI following the sudden departure of Sam Altman. Altman, who co-founded OpenAI in 2015, will now lead Microsoft's advanced AI research team. Altman's exit from OpenAI was reportedly due to a breakdown in communication with the board. The appointment of Shear and Altman's move to Microsoft highlight the ongoing drama and growing differences within the AI industry regarding the commercialization and ethical usage of generative AI technology."
695,"Microsoft and other big tech firms have welcomed President Biden's executive order on generative AI, which aims to regulate the technology and address issues related to safety, security, bias, and civil rights. The order requires companies to safety-test their AI systems and share the results with the government, establishes red-team testing standards, and calls for the labeling of genAI content to combat misinformation. It also focuses on privacy protection, equity, and civil rights, including preventing discrimination in housing and developing best practices for AI use in criminal justice and labor. While the executive order alone may not have significant impact, it could pave the way for future legislation, and tech companies like Microsoft stand to benefit from increased trust in AI and easier access to AI talent."
696,"The article discusses how artificial intelligence (AI) can play a crucial role in crafting digital experiences that meet customer and employee expectations, increase productivity, and overcome information silos. It emphasizes the importance of considering user journeys, understanding the personas interacting with digital touchpoints, and using AI, particularly generative AI (GenAI)."
697,"The article discusses the potential of generative AI in solving the issue of organizations lacking memories."
698,"A faster-than-expected recovery in sales of PC chips helped Intel post third-quarter revenue that exceeded expectations, but weakness in its data center business is a sign of vulnerability in a market where users are looking for processors that can handle AI workloads that are predicted to grow as enterprises adopt generative AI. ""Continuing its investment in manufacturing capacity to create a geographically balanced, secure and resilient supply chain, Intel opened Fab 34 in Leixlip, Ireland, during the quarter"", Intel noted in its earnings news release Thursday."
699,"The article offers information on author Sean Michaels and the impact of generative artificial intelligence (AI) on writing. It discusses about his book ""Do You Remember Being Born?"" which delves into the intersection of technology and literature; questioning the difference between human and AI-produced writing; and also mentions about examining the potential consequences when AI-generated output becomes indistinguishable from human creativity."
700,"August 8: Cybersecurity company Rapid7 cuts 18% ofworkforce US cybersecurity firm Rapid7 announced plans to lay off 18% ofits workforce, approximately 400 global employees. In a filing with the US Securities and Exchange Commission(SEC), the company disclosed that its restructuring plan calls forcharges between $1.4 billion and $2.1 billion, with up to $1billion of those costs being shouldered by the company in thefourth quarter of 2023. Updated Facing an uncertain global economy and slowing revenuegrowth, technology companies have picked up the pace oflayoffs in 2023. Eggemeier highlighted the need toalign the company's employee structure with customer goals,as enterprise customers consider adopting newer technologieslike generative AI."
701,"News Generative AI chatbot ChatGPT can keep up with currentevents thanks to a new update, and is also getting directaccess to the DALL-E 3 image-generation system The latest version of ChatGPT, OpenAI's groundbreakinggenerative AI chatbot, now has access to real-time informationfrom the internet at large, curing what had been seen as oneof its key flaws. Thanks to an integration with Microsoft's Bing search engine- the company is a major investor in ChatGPT maker OpenAI- the AI chatbot is now able to look up the latest availableinformation on any topic."
702,"The article offers several news brief related to book deals, including a book ""The Situation Room"" by George Stephanopoulos, a memoir ""Knife: Meditations After an Attempted Murder"" by Salman Rushdie, and a book on AI ""Intelligence Explosion"" by James Barrat. Topics include the behind-the-scenes history of the White House Situation Room, a deeply personal account of the attempt on Salman Rushdie's life, and the myriad issues raised by generative AI."
703,"Eggemeier highlighted the need to align the company's employee structure with customer goals, as enterprise customers consider adopting newer technologies like generative AI. August 8: Cybersecurity company Rapid7 cuts 18% of workforce US cybersecurity firm Rapid7 announced plans to lay off 18% of its workforce, approximately 400 global employees. Tech layoffs in 2023: A timeline: Facing an uncertain global economy and slowing revenue growth, technology companies have picked up the pace of layoffs in 2023. According to an email sent by CEO Stephen Gillett to all its employees, the downsizing is part of the company's One Verily program, which aims to reduce redundancy and simplify operational aspects within the company."
704,"News A new report from a financial technology expert atthe Bank of England says that inherent biases in AIsystems makes it dangerous to entrust them with too muchdecision-making at present The implicit bias of present-day generative AI models maketheir rapid adoption in the financial sector hazardous,according to a report by a financial technology expertworking for the Bank of England. Kathleen Blake's report, published Wednesday, splits AImodel bias into two categories -- bias based on underlyingtraining data, and bias based on the results of modeloutput."
705,"The article reports on several developments in world of information and literature, including the Library of Congress releasing a collection of digitized Hebrew manuscripts, ResearchGate's partnership with the American Psychological Association to provide direct access to APA articles and Elsevier unveiling an alpha version of Scopus AI, which combines generative AI with Scopus' content to offer researchers deeper insights and topic summaries based on academic journals from around the world."
706,"The article discusses the significant benefits of using generative artificial intelligence (AI) in customer success. Topics include extending the human touch, delivering a consistent brand experience; abiding by customer communication preferences and reducing friction points; and personalizing content, fast-tracking customer insights and capturing information from customer success manager (CSM) conversations."
707,"The article focuses on the evolving landscape of virtual production, anticipating a shift toward more nimble and scalable stages. Topics include the use of technologies like 2.5D and generative AI to enhance flexibility, reduce costs, and democratize the creation of 3D worlds for creators with varying budgets and projects. In essence, the author foresees a more accessible and diverse application of virtual production technologies in the coming years."
708,"The article focuses on the accelerated advancements in AI, particularly generative AI, and its transformative potential in media and entertainment workflows. Topics include the impact of AI across various stages of production, integration of AI-backed features by industry leaders like Adobe and Autodesk, and concerns and approaches related to privacy and responsible AI deployment."
709,"The article discusses the evolution of artificial intelligence (AI) tools, highlighting the transition from specialized, single-task tools to more versatile and generative AI tools like ChatGPT and their potential applications in various tasks. It also mentions the challenges of AI tools, such as their reliance on word statistics rather than factual knowledge, leading to ""hallucination"" or incorrect outputs."
710,"The article provides definitions and explanations of key terms related to artificial intelligence (AI), including generative AI, large language models, prompts, and prompt engineering."
711,"These include the AI models that were recently unveiled by China's largest search engine, Baidu, and AI software company SenseTime. Chinese cloud and social media conglomerate Tencent has announced that its Hunyuan large language model (LLM) will be available for enterprise use, as companies in the country stake their claim as technology industry and generative AI leaders."
712,"In this Q&A, Computerworldposed a series of questions via email to Trachet about ChatGPT Enterprise and how it could affect the adoption of genAI tools at both startup firms and more established enterprises. Feature ChatGPT Enterprise will likely spur greater adoption of generative AI technology by addressing two of the main concerns businesses have: security and privacy."
713,"The article focuses on the cautious approach organizations are taking towards Generative Artificial intelligence (AI) and the risks and rewards associated with its implementation. Topics include the potential challenges such as unrealistic expectations, misaligned responses, and the need for clear audit trails, as well as the benefits like increased productivity and improved information synthesis."
714,"Windows Into The Future Opinion If companies want their employees to embrace thepotential of generative AI, they're going to have to make surethose workers actually trust it won't cost them their jobs As time goes by, people are becoming less trusting ofartificial intelligence (AI), according to the results of a recentPew Research study. Why trust matters People who are worried they will lose their job typically donot do a good job training another employee because theyfear they might be terminated and replaced by theemployee they trained. Positioning AI tools asemployee aids, not employee replacements, and highlightinghow those who properly use the technology are more likelyto get ahead would go a long way to assuring they are onboard with the technology and will it mature."
715,"Cadence Design Systems has developed the Joules RTL Design Studio tool to improve the register-transfer-level (RTL) design and implementation process. This tool provides front-end designers with access to digital design analysis and debugging capabilities, allowing them to optimize the RTL design before handing it off for implementation. The Joules RTL Design Studio also incorporates generative AI for RTL design exploration and big-data analytics, resulting in increased productivity and improved quality of results. The tool offers various features, including an intelligent RTL debugging assistant system, integration with AI solutions, and a unified cockpit for an efficient user experience."
716,"In two separate papers, Artificial Intelligence (AI)/Robotics researcher Guy Hoffman takes as a starting point that actors have been in the business of reverse engineering human behaviour for centuries. In this paper, I follow the similar trajectories of AI and acting theory (AT), looking at three primary questions, in the hope of framing a response to Hoffman's papers: (1) How are the problems of training a human to simulate a fictional human both similar to and different from training a machine to simulate a human? (2) How are the larger questions of AI design and architecture similar to the larger questions that still remain within the area of AT? (3) Is there anything in the work of AI design that might advance the work of acting theorists and practitioners? The paper explores the use of “swarm intelligence” in recent models of both AT and AI, and considers the issues of embodied cognition, and the kinds of intelligence that enhances or inhibits imaginative immersion for the actor, and concludes with a consideration of the ontological questions raised by the trend towards intersubjective, dynamic systems of generative thought in both AT and AI."
717,"The article reports that Google may face a threat to its search dominance by generative artificial intelligence (AI) chatbots such as ChatGPT, designed by OpenAI. It mentions that the chatbots are gaining popularity among users and may challenge Google's grip on the search market.It further reports that Microsoftinvested around 10 billion Dollars in OpenAI, has partnered with the startup to develop Bing's search capabilities."
718,"The article focuses on the evolving role of Artificial Intelligence (AI) in the entertainment industry where the use of generative AI is explored for content creation. Topics include the potential shift in the production of scripts by AI, the integration of AI as a time-saving tool for complex filmmaking tasks, and the anticipated clashes between creators and AI platforms regarding copyright issues."
719,"The article focuses on Mark Zuckerberg's strategic decisions that led to the revival of Meta's core business, emphasizing the transformation in response to investor pressure and the incorporation of generative C(gen AI). Topics include Zuckerberg's humility and agility in making quick pivots, the success of Meta's core business, and the potential impact of gen AI on engagement and business interaction within Meta's social-media platforms."
720,"The article discusses the evolving landscape of generative artificial intelligence (AI) and the factors shaping the industry's future. It highlights three key forces influencing the AI model industry: computing power efficiency, the hunger for data, and the role of money. Companies like Google Inc. have an early advantage due to their user base and resources, but innovative approaches in terms of efficiency, data synthesis, and customer engagement could still change the competitive landscape."
721,"The article discusses the impact of Ernie Bot, an artificial intelligence (AI) chatbot developed by Baidu Inc., which has gained attention for its unique responses, including controversial views on the origins of COVID-19. It raises questions about Baidu's resurgence, given its past dominance and subsequent decline in the face of competition from super-apps and other platforms. Baidu's investment in generative AI has reignited excitement and increased its market value."
722,"• We described previously the misuse of generative AI used in drug discovery. • We now share further unpublished details on the experiment. • We place our experiences in the larger frame of other powerful technologies. • We provide a wake-up call for users of generative AI."
723,"The article focuses on the potential uses of Artificial Intelligence (AI) in education specifically in reducing workload and personalizing learning. Topics include automated marking and feedback using Natural Language Processing (NLP), generative AI for lesson planning and resource creation, and adaptive learning for individualized learning journeys."
724,"The article reports on the efforts by startup companies like Optic to prevent the potential adverse effects of generative artificial intelligence (AI) to companies and societies. According to Optic's Andrey Doronichev, AI could be used for disinformation, discrimination, and invasion of privacy. Also cited is the report by Grand View Research stating that the overall generative AI market will surpass 109 billion dollars by 2030."
725,"The article presents warning from artificial intelligence (AI) pioneer Geoffrey Hinton about the risks and dangers of generative AI. Issues discussed are potential use of generative AI as a tool for misinformation, possible flooding of the Internet with false photographs, videos and texts, potential of AI technologies to replace human workers, threat to humanity with the likelihood of development of autonomous weapons, and the need for scientists to collaborate on ways of controlling AI."
726,"Artificial intelligence and AI-assisted technologies must not be listed as an author or co-author of a manuscript. Recent major advances in large language models - sophisticated generative artificial intelligence (AI) algorithms trained on massive amounts of language data - have led to widely available writing tools such as OpenAI's popular chatbot, ChatGPT, that are able to analyze text and produce new content in response to user prompts."
727,"This Viewpoint examines various aspects of using generative artificial intelligence (AI) in health care, including assisting with making clinical diagnoses, and the challenges that come with using AI, such as ensuring the accuracy of the clinical data on which AI makes its diagnoses."
728,"An editorial is presented on the challenges posed by advancements in AI technology, including the Generative Pretrained Transformer (GPT), voice cloning mechanisms, and electrical-impulse mechanisms for exploring cognition. It highlights the ethical and philosophical questions raised by the unique interrelationships between humans and machines, particularly in fields such as education and research."
729,"The article offers information on five key agricultural technology trends anticipated in the agricultural industry in 2024. It includes the role played by generative artificial intelligence (AI) to cut costs and fuel innovations, another is the increased integration of digital twins into field tests and field test planning, and priority given by agriculture to sustainability and environmental protection."
730,"Ophthalmology has been one of the early adopters of artificial intelligence (AI) within the medical field. Deep learning (DL), in particular, has garnered significant attention due to the availability of large amounts of data and digitized ocular images. Currently, AI in Ophthalmology is mainly focused on improving disease classification and supporting decision-making when treating ophthalmic diseases such as diabetic retinopathy, age-related macular degeneration (AMD), glaucoma and retinopathy of prematurity (ROP). However, most of the DL systems (DLSs) developed thus far remain in the research stage and only a handful are able to achieve clinical translation. This phenomenon is due to a combination of factors including concerns over security and privacy, poor generalizability, trust and explainability issues, unfavorable end-user perceptions and uncertain economic value. Overcoming this challenge would require a combination approach. Firstly, emerging techniques such as federated learning (FL), generative adversarial networks (GANs), autonomous AI and blockchain will be playing an increasingly critical role to enhance privacy, collaboration and DLS performance. Next, compliance to reporting and regulatory guidelines, such as CONSORT-AI and STARD-AI, will be required to in order to improve transparency, minimize abuse and ensure reproducibility. Thirdly, frameworks will be required to obtain patient consent, perform ethical assessment and evaluate end-user perception. Lastly, proper health economic assessment (HEA) must be performed to provide financial visibility during the early phases of DLS development. This is necessary to manage resources prudently and guide the development of DLS."
731,"The article predicts three major trends for government and technology in 2024. The first prediction is that generative artificial intelligence (AI) will have a significant impact on the world, surpassing the advancements made in 2023. The article highlights the achievements of AI in solving complex math problems, developing new antibiotics, and predicting solar storms. The second prediction is that the government and military will further embrace and master 5G technology, with the deployment of Open Radio Access Networks (O-RAN) allowing for private and secure 5G networks. The final prediction is that technology will make it increasingly difficult to secure the 2024 presidential election, with the rise of misinformation and the potential use of AI to manipulate and deceive voters."
732,"The article focuses on the author's initial concerns about the release of a generative artificial intelligence (AI) model for content creation and the importance of teaching students to use AI responsibly in art education. Topics include the author's experience with the adoption of digital technology in photography, the continued relevance of photography classes, and suggestions for balancing traditional and digital media in art curriculum."
733,"A frequent use of conversational user interfaces (CUIs) today is improving the users' experience with online quantitative surveys. In this paper, we explore the use of CUIs in qualitative surveys. As a concrete use case, we adopt a specific, well-structured, qualitative research method called the repertory grid technique (RGT). We developed a hybrid user interface (HUI) that combines a graphical user interface (GUI) with a CUI to automate the distinct stages in a RGT survey. A pilot study was used to verify the feasibility of the approach and to fine-tune interface aspects of an initial prototype. In this paper, we report the results of a within-subject lab experiment with 24 participants that aimed to establish the performance and UX in a realistic context of a more advanced prototype. We observed a small decrease in UX in some hedonistic aspects, but also confirmed that the HUI performs similarly to a human agent in most pragmatic aspects. These results provide support for our hypothesis that automating qualitative surveys is possible with proper interface design. We hope that our work can inspire other researchers to design additional tools for qualitative survey automation, especially now that generative AI systems, such as ChatGPT, open up interesting new ways for computer systems to interact with users in natural language. [Display omitted] • Explored CUIs in qualitative survey automation, focusing on RGT methodology. • Developed HUI integrating GUI and CUI for experimenting RGT automation. • Conducted lab experiment with 24 participants for the HUI idea evaluation. • The HUI prototype showed UX decrease in hedonism, yet matched human agents pragmatically. • Our findings support AI-driven qualitative survey automation potential."
734,"In the new era of Artificial Intelligence (AI), Generative Pre-Trained Transformer (GPT) has emerged as a central technique for generating human-like texts. Over recent years, there has been a growing trend towards using GPT for building chatbot systems. However, pre-trained GPT models lack context awareness which can result in awkward dialogue in specific contexts. In this research, we propose a new information fusion based approach to fine tuning GPT models based on contextual data and two scenarios of evidence combination by means of Dempster–Shafer theory of evidence. To this end, we first design a Transformers-based dialog classification model to be trained with the contextual data, which is then used jointly with additional pre-trained models as sources of evidence for judging the output of a GPT model as a context-appropriate response. Two scenarios for modeling and combining evidence provided by the context-based dialog classification model and pre-trained models are also proposed. We conduct a set of experiments on several datasets associated with specific contexts to demonstrate the effectiveness of the proposed approach. The empirical results show that it can improve the contextuality of general GPT-2 and GPT-3.5 models in most cases of the testing datasets. • This paper proposes a new information fusion-based approach to fine tuning GPT models. • A method of construction and evaluation of synthetic datasets used for fine-tuning pre-trained GPT models. • A fine-tuned GPT framework based on Dempster–Shafer theory of evidence. • Two scenarios for evidence modeling and combination in the proposed fine-tuned GPT framework. • Comprehensive experiments to demonstrate the effectiveness of the proposed method."
735,"Volcanic processes create peculiar types of terrestrial and freshwater ecosystems but, surprisingly, very little is known about the infaunal palaeoecology of continental volcanic ecosystems such as caldera lakes and streams. Here, we report an invertebrate trace fossil association from the largest and best-exposed Permian (Cisuralian) supervolcano in Europe, the Bolzano Supervolcano. The fossil association is dominated by abundant trace fossils that are unusually straight, i.e., their curvature is zero along the entire preserved length. The trace fossils are attributed to Planolites and Palaeophycus and they form a bioturbated texture (ichnofabric) with a characteristically high bioturbation intensity (percent bioturbated>90%). U-shaped (Arenicolites) and concentrically-lined (Cylindrichnus) burrows are minor components of the ichnofabric. The characteristics of the trace fossil association suggest substrate colonization by r-strategic organisms during periods of minor volcanic activity. In these periods of stasis, the volcanic rocks were eroded by seasonal streams, which provided suitable softground substrates for the infauna. Insects are regarded as the most plausible tracemakers of the straight burrows. Similar ichnofabrics are found in other continental volcanoclastic sites, suggesting that ichnofabrics dominated by straight burrows may represent an ichnological proxy of brief windows for colonization in volcanically influenced freshwater environments. Generative artificial intelligence has been used to graphically reconstitute the tiering pattern and the palaeoenvironment. As such, this study provides the first application of AI to the graphic representation of a bioturbated palaeoenvironment. • Abundant straight burrows are documented from a Permian megacaldera. • r-selected insect larvae selectively ingested nutrient-rich particles. • The palaeoecosystem consisted of volcanically-influenced ponds and lakes. • Straight burrows may indicate volcanically-stressed freshwater ecosystems. • Generative AI is applied for the first time to the graphic representation of a bioturbated palaeoenvironment."
736,"• 138 psychiatrists responded to an online survey on ChatGPT/Bard/Bing AI. • 4 in 10 used ChatGPT-3.5 ""to assist in answering clinical questions"". • 7 in 10 somewhat agreed/agreed ""documentation will be/is more efficient"" after using these tools. • 8 in 10 agreed ""clinicians need more support/training in understanding these tools"". • Respondents expressed divergent opinions on the benefits and harms of chatbots. Following the launch of ChatGPT in November 2022, interest in large language model (LLM)-powered chatbots has surged with increasing focus on the clinical potential of these tools. Missing from this discussion, however, are the perspectives of physicians. The current study aimed to explore psychiatrists' experiences and opinions on this new generation of chatbots in mental health care. An online survey including both quantitative and qualitative responses was distributed to a non-probability sample of psychiatrists affiliated with the American Psychiatric Association. Findings revealed 44 % of psychiatrists had used OpenAI's ChatGPT-3.5 and 33 % had used GPT-4.0 ""to assist with answering clinical questions."" Administrative tasks were cited as a major benefit of these tools: 70 % somewhat agreed/agreed ""documentation will be/is more efficient"". Three in four psychiatrists (75 %) somewhat agreed/agreed ""the majority of their patients will consult these tools before first seeing a doctor"". Nine in ten somewhat agreed/agreed that clinicians need more support/training in understanding these tools. Open-ended responses reflected these opinions but respondents also expressed divergent opinions on the value of generative AI in clinical practice, including its impact on the future of the profession."
737,"The article provides a glimpse into how artificial intelligence (AI) might shape advertising in the future through product placements as marketers look to reach younger viewers and viewership is shifting to social media platforms. It discusses the work of technology start-up Rembrand which uses generative AI to transform product placements and its experiment with animations. Also noted is the use of Rembrand's marketplace by advertisers to connect with creators from advertising agencies."
738,"The article offers outlook on the potential of generative artificial intelligence (AI) tools like chatbots to revolutionize and transform education, provide lessons and teach students. It presents predictions on the development of personalized tutoring chatbots and automated teaching platforms that customize lessons for each student. It raises concerns about AI-assisted instruction such as feeding of false information, degenerative effects on student learning, privacy and intellectual property."
739,"The article reports that American technology company has surpassed rival Apple as the world's most valuable company after its market value increased by more than 1 trillion U.S. dollars in 2023. Cited are the reordering of the stock market caused by the advent of generative artificial intelligence (AI), the technology companies that dominates the top of the list, and the impact of Apple's absence in the AI business on its revenue."
740,"The article focuses on OpenAI's first developer conference where artist Alexander Reben presented AI-generated art criticism, highlighting the intersection of AI and the arts. As AI, particularly generative AI like GPT-4, advances rapidly, artists grapple with its creative potential, with some embracing its innovative possibilities and others expressing concerns about unauthorized use and copyright issues."
741,"The article reports on the generative artificial intelligence (AI) systems being built by South Korean companies to be more competitive and diverse. These include Clova X run by Internet company Naver for Korean language speakers, Exaone built by LG that is capable of creating original content, and Samsung Gauss used to compose emails, summarize documents and translate text. It also informs about the collaboration of telecommunications firms KT and Jasmine Group on a large language model."
742,"The practice of medicine, and also medical education, typically adopts a problem-solving approach to identify “what is going wrong” with a situation. However, an alternative is Appreciative Inquiry (AI), which adopts a positive and strengths-based approach to identify “what is going well” with a situation. The AI approach can be used for the development and enhancement of the potential of both individuals and organizations. An essential aspect of the AI approach is the generative process, in which a new situation is envisioned and both individual and collective strengths are mobilized to make changes to achieve the valued future situation. The AI approach has been widely used in the world of business and general education, but is has an exciting potential for medical education, including curriculum development, faculty development, supporting learners through academic advising and mentoring, but also for enhancing the teaching and learning of both individuals and groups. This AMEE Guide describes the core principles of AI and their practical application in medical education."
743,"News India and Japan became the first countries outside the USto get access to the Generative Search Experience viaGoogle's Search Labs initiative India and Japan became the first two countries outsidethe US to get access to Google's Generative SearchExperience as the company introduced its Search Labsinitiative in the two Asian nations. Related: * Generative AI man typing on laptop google search internet web browswer100756898 origGetty Images / Google."
744,"News Analysis Google will match rival Microsoft's pricing with itsDuet AI assistant, which is available as an add-on tocustomers in its Enterprise tier - at $30 per user eachmonth Google's Duet AI is now generally available, bringing thegenerative AI assistant to its range of Workplaceproductivity apps, the company announced on Tuesday. Related: * Generative AI * Artificial Intelligence * Google Workspace Duet AI in MeetGoogle Duet AI presentation Google Duet AI can help create a summary from relevant sourcedocuments and then automatically build a presentation inSlides. The launch of Duet AI means Google has beaten Microsoft tomarket with genAI tools for its office software suite."
745,"Companies are looking to hire more people with experiencewith artificial intelligence (AI) as the arrival ofgenerative AI tools and platforms forces enterprises tore-think their digital strategies, according to newstudies from employment websites. Upwork determined the top AI hires by looking at each jobposting and the skills freelance job seekers attached totheir online profile; that included gen AI tools, likeChatGPT. The top 10 generative AI-related job hires were: ChatGPT,Natural Language Processing (NLP), Tensorflow, ImageProcessing, Pytorch, AI Content Creation, Midjourney, AIChatbot, LLM tuning, and Stable Diffusion."
746,"AI outpaces company preparedness to deal with it However, the survey also showed that IT leaders think that AI development is outpacing organizational preparedness, causing them to express concern about their implementation roadmap and overall readiness. New research from AMD has found that IT leaders are optimistic about the potential benefits of artificial intelligence, but are worried that their organizations are not prepared to implement the technology, whose development has accelerated with the rapid adavancement of generative AI. Unsurprisingly, those leaders who said their organization would be prioritizing AI implementation this year were the most optimistic about the potential benefits of AI, with 75% of those expressing a positive view, believing that not investing would be a risk, as it could result in their organization falling behind their industry competitors."
747,"News Analysis One in four workers do not feel trusted by their employer,and as more organizations roll out or pilot AI platforms tounlock efficiencies, employees are fearful of being replaced bya machine Managers are under more pressure to drive productivity, andironically efficiencies created by generative artificialintelligence (AI) tools are a big part of why expectations aregrowing. EY research for clients has also found that employees arespending about a third of their time on performative tasks;these are tasks they do to appear productive"", Stier continued.""AI is for the people who we've hired to be the A and Bperformers; it's going to help them do their jobs."
748,"The researchers speculate that topics might include the use of smart speakers to help in keyboard strike classification (that's what I call Siri Sleuthing), or the addition of generative AI-style LLM models to improve keystroke recognition. A UK research team based at Durham University has identified an exploit that could allow attackers to figure out what you type on your MacBook Pro -- based on the sound each keyboard tap makes."
749,"The article talks about the common practice among songwriters in creating pitch records done by looking for tunes recorded with generative artificial intelligence (AI) that mimics the vocals of the artists being pitched. Cited are the impact that the AI voice synthesis has on songwriters, producers and artists, the ability of voice recreation tools in democratizing songwriting, and the ability of AI to mimic the voice of some artists."
750,"The article discusses the popularity of OpenAI's ChatGPT, the first widely-used generative AI tool. However, the author suggests that it may not be the best option and encourages readers to explore other powerful alternatives. The article explains that there are thousands of comparable models available, with Stanford scientists creating a resource called Constellation to visualize and understand them. The author highlights Microsoft and Meta's LLaMA 2 as a new LLM offering and mentions that Apple has reportedly developed its own LLM called ""AppleGPT."" The article also emphasizes the importance of using multiple sources and tools to verify information obtained from LLM-based chatbots, as they can be prone to errors and hallucinations. The author recommends experimenting with various AI tools and using AI as a writing partner to enhance writing and thinking skills."
751,"News OpenAI is reportedly under additional legal scrutiny, asthe US Federal Trade Commission asks the company to givedetailed explanations of its business practices The US Federal Trade Commission is reportedly investigatingChatGPT maker OpenAI for potential violations of consumerprotection regulations involving data privacy and falsestatements about third parties. [Prepare for generative AI with experimentation and clearguidelines] While the FTC declined to comnent, OPenAI CEO Sam Altman issued aresponse to the reports on Twitter."
752,"News Five months after Google announced it was launching its owngenerative AI chatbot, the company has addressed the data privacyissues that had previously made it inaccessible to EU residents. Like other generative AI chatbots, Bard is powered by a largelanguage model (LLM), in this case a lightweight variant ofLaMDA, Google's main natural-language processing model."
753,"News Five months after Google announced it was launching its owngenerative AI chatbot, the company has addressed the dataprivacy issues that had previously made it inaccessible to EUresidents. Like other generative AI chatbots, Bard is powered by a largelanguage model (LLM), in this case a lightweight variant ofLaMDA, Google's main natural-language processing model."
754,"An introduction is presented in which the editor discusses articles in the issue on topics including the emergence of generative Artificial intelligence (AI) and its impact on customer relationship management (CRM) software, particularly in content generation for marketing, and sales."
755,"""Because the OpenAI Language Models cannot functionwithout the expressive information extracted fromPlaintiffs' works (and others) and retained inside them,the OpenAI Language Models are themselves infringingderivative works"", according to the complaint in thatcase, also filed in the Northern District of California. News A new lawsuit against OpenAI could decide whetherthe company's use of training data scraped from thepublic internet may continue OpenAI, the Microsoft-backed company that developed theChatGPT generative AI chatbot, is the defendant in afederal class action lawsuit filed this week inCalifornia, where it is accused of misappropriatingpersonal information for training purposes."
756,"Automating yourself out of a job Berkowitz noted that in his current role, where he is helping to develop AI and machine learning tools to eliminate manual data analytics tasks, he may well be automating himself out of a job. Generative artificial intelligence (AI) tools such as ChatGPT are rapidly gaining traction, allowing the technology to be used throughout the enterprise to automate a variety of manual tasks performed by workers today, leading to what's expected to be a major shift in the global job market."
757,"Related: * Browsers * Artificial Intelligence * Chatbots * Chrome * Genterative AI opera ai image OperaOpera's new Aria AI engine allows more detailed naturallanguage answers to user web querries. News Opera One is an extensive makeover of the Chrome-based web browser that allows ChatGPT natural languageprocessing and offers a new, more modular UI design. aria imageOperaOpera went live today with Opera One, an extensive makeoverof its namesake Chrome-based web browser that includes anative generative AI feature that allows users to ask it tocreate text or computer code and get questions answeredwith greater detail."
758,"""We have contracts with like our vendors that specify howthey use the data, making sure they're not using anypersonal identifying information or reusing any of our datafor regular AI training or model building"", explainedVardhan Dharnidarka, head of AI/ML at ClickUp. News The newly launched ClickUp AI allows users togenerate content, summarize and organize work, via amultitude of generative AI prompts that have been segmentedby job type Productivity platform ClickUp has added a host of new role-based AI capabilities, designed to help boost productivityfor employees across all departments."
759,"Going cold: ""Best of breed"" collaboration apps The debate over ""best of breed"" apps vs. app suites hasexisted for decades. Hot: Communication-enabled workflows A common headache for collaboration app users is the needto frequently switch apps, diverting them from productivework. Feature From generative AI to analytics, the collaborationsoftware landscape is changing fast, but there's more toconsider than just the shiniest new tools Workplace collaboration is vital for the flow of knowledgeacross an organization, and, ultimately, to enableemployees to get work done."
760,"Generative AI is acomplete game changer"", said European Commission Vice PresidentMargrethe Vestager at a meeting of the EU-US Trade and TechnologyCouncil (TTC) in Sweden a day after the open letter waspublished. News While governments across the globe continue to push forward withlegislative frameworks to regulate AI, EU and US lawmakers aim tointroduce an interim code of conduct within weeks to bridge thepolicy gap."
761,"The article focuses on the potential applications of generative Artificial intelligence (AI), such as OpenAI's ChatGPT, in the power sector, including automating tasks, analyzing data, and improving asset performance management, while acknowledging the limitations and challenges."
762,"The article discusses the rise of artificial intelligence (AI) in the chemical engineering industry, highlighting the need for reliable and explainable AI algorithms, the potential of AI to improve sustainability objectives, and the concerns and promises associated with AI technology. It also mentions practical exercises using generative AI in education and seeks feedback from readers regarding their use of AI in engineering."
763,"The usage of generative adversarial networks (GAN)s for synthetic time-series data generation has been gaining popularity in recent years with applications from finance to music composition and processing of textual content. However, beyond their reported success, few comparisons exist with other artificial intelligence (AI) methods or standard mathematical models. Here, we test GANs performance, comparing them with a well-known mathematical model, namely a Markov chain. We implement comparative metrics based on one- and two-point statistics to evaluate the performance of each method. We find that, similarly to other AI approaches, GANs struggle to capture rare events and cross-feature relations and are unable to create synthetic faithful data. GANs are relatively successful in replicating the auto-correlation function, but they still lag significantly behind simple Markov chains. We also provide a qualitative explanation for this limitation of AI approaches. • Generative Adversarial Networks perform worse than Markov models for stochastic data. • Performance of generative networks is only good for simple two-point statistics. • A show-case is presented for eye-gaze trajectories."
764,"In this study, we evaluated the diagnostic accuracy of Google Bard, a generative artificial intelligence (AI) platform. We searched published case reports from our department for difficult or uncommon case descriptions and mock cases created by physicians for common case descriptions. We entered the case descriptions into the prompt of Google Bard to generate the top 10 differential-diagnosis lists. As in previous studies, other physicians created differential-diagnosis lists by reading the same clinical descriptions. A total of 82 clinical descriptions (52 case reports and 30 mock cases) were used. The accuracy rates of physicians were still higher than Google Bard in the top 10 (56.1% vs 82.9%, P <.001), the top 5 (53.7% vs 78.0%, P =.002), and the top differential diagnosis (40.2% vs 64.6%, P =.003). Even within the specific context of case reports, physicians consistently outperformed Google Bard. When it came to mock cases, the performances of the differential-diagnosis lists by Google Bard were no different from those of the physicians in the top 10 (80.0% vs 96.6%, P =.11) and the top 5 (76.7% vs 96.6%, P =.06), except for those in the top diagnoses (60.0% vs 90.0%, P =.02). While physicians excelled overall, and particularly with case reports, Google Bard displayed comparable diagnostic performance in common cases. This suggested that Google Bard possesses room for further improvement and refinement in its diagnostic capabilities. Generative AIs, including Google Bard, are anticipated to become increasingly beneficial in augmenting diagnostic accuracy."
765,"The article focuses on a correction regarding the responsible use of generative AI technologies in scholarly journal publishing, emphasizing the importance of addressing the responsibilities of reviewers to authors and the need for human reviewers in the peer review process."
766,"The article focuses on a correction related to the responsible use of generative Artificial intelligence (AI) technologies in scholarly journal publishing, specifically addressing the responsibilities of reviewers to authors and the importance of using human reviewers in the peer review process."
767,"As the use of artificial intelligence (AI) technologies, particularly generative AI (Gen AI), becomes increasingly prevalent in nursing education, it is paramount to address the ethical implications of their implementation. This article explores the realm of cyberethics (a field of applied ethics that focuses on the ethical, legal, and social implications of cybertechnology), highlighting the ethical principles of autonomy, nonmaleficence, beneficence, justice, and explicability as a roadmap for facilitating AI integration into nursing education. Research findings suggest that ethical dilemmas that challenge these five principles can emerge within the context of nursing education; however, adherence to these very principles, which is essential to improving patient care, can offer solutions to these dilemmas. To ensure the ethical and responsible use of Gen AI in nursing education, these principles must be woven into the fabric of curricula, and appropriate guidelines must be developed. Nurse educators have a pivotal role in strategizing comprehensive approaches for ethical AI integration, establishing clear guidelines, and instilling critical thinking among students. Fostering lifelong learning and adaptability is key to ensuring that future nurses can successfully navigate the constantly evolving landscape of health care technology. Future research should investigate the long-term impacts of AI utilization on learning outcomes and ethical decision-making."
768,"Trauma is the leading cause of death in adults under the age of 45 and the fourth leading cause of death in the United States. Effective delivery of trauma care centers on being well versed in the Advanced Trauma Life Support (ATLS) protocol, which requires high levels of clinical experience. Often this comes from having been exposed to the many permutations of common types of injuries as well as exposed to rarer scenarios, but with potential harm to patients. Case scenarios, which are sequential representations of clinical events, can help trainees receive clinical exposure without harming patients. However authoring case scenarios requires domain expertise, wide experience, and the ability to intelligently respond to inputs, and as such is currently an arduous task. Autoregressive generative models trained on large amounts of clinical data, such as the National Trauma Data Bank (NTDB), pose a possible solution to overcome the cost of authorship while providing broad and accessible clinical experience to trainees. We have developed a Trauma AI model composed of an autoregressive generative model based on the transformer architecture for generating potential case scenario combined with an out-of-domain detection for filtering out less plausible scenarios. The GPT2 model is trained on 1.1 million case scenarios derived from the NTDB data. We demonstrate that Trauma AI is capable of generating realistic case scenarios that encode the ATLS protocol as a latent feature of the sequence of provider interventions, including scenarios that do not have any parallels in the original dataset. We also present an unsupervised means of filtering out unrealistic sequences by identifying out-of-domain sequences, and demonstrate that this improves the realism of the generated case scenarios. • Autoregressive model based on generative language models to create case scenarios for medical simulation. • Demonstration of how autoregressive models can satisfy various needs in authoring case scenarios as well as creating interactive sessions. • Present a method for conversion of large public datasets to learnable format. • Utilized out of domain classifier to improve realism of generated sequences."
769,"This article outlines what a successful artificial intelligence digital humanities (AI DH) curriculum entails and why it is so critical now. Artificial intelligence is rapidly reshaping our world and is poised to exacerbate long-standing crises including (1) the crisis of higher education and the humanities, (2) the lack of diversity, equity and inclusion (DEI) in computer science and technology fields and (3) the wider social and economic crises facilitated by new technologies. We outline a number of ways in which an AI DH curriculum offers concrete and impactful responses to these many crises. AI DH yields meaningful new avenues of research for the humanities and the humanistic social sciences, and offers new ways that higher education can better prepare students for the world into which they graduate. DEI metrics show how an AI DH curriculum can engage students traditionally underserved by conventional STEM courses. Finally, AI DH educates all students for civic engagement in order to address both the social and economic impacts of emerging AI technologies. This article provides an overview of an AI DH curriculum, the motivating theory behind design decisions, and a detailed look into two sample courses."
770,"The novel discipline of prompt-engineering is a combination of artificial intelligence, linguistics, and user experience design. Crafting effective prompts for AI models like OpenAI's GPT can optimize the quality of generated output, especially in reference services. The article explains the CLEAR Framework--a guiding tool that incorporates principles of conciseness, logic, explicitness, adaptability, and reflectiveness in prompt crafting. Despite challenges including biases, ethical concerns, and keeping up with rapidly evolving AI capabilities, the field also presents opportunities for growth. The article concludes with a call to action for library professionals to embrace and master prompt-engineering as an essential skill."
771,"Data-driven methods for predicting and evaluating microstructural characteristics have attracted significant attention owing to recent developments in artificial intelligence (AI). In high-temperature deformation processes, the microstructure changes nonlinearly, according to the causal relationship with the deformation history in the form of time series. This makes it difficult to predict the microstructural evolution using existing AI generative models, in which time-series data are not used as an input. Therefore, herein we proposed a novel method to establish a connection between the time series deformation history and the latent vector of the AI generative model. To this end, the dynamic recrystallization (DRX) fraction and DRX grain size of a microstructure were calculated based on the deformation history, which included the temperature, strain, and strain rate, using the finite element method (FEM) combined with a DRX kinetic model. By applying the calculated DRX fraction and DRX grain size as label data, a conditional deep convolutional generative adversarial network was trained to generate microstructures. It was confirmed that the microstructural evolution due to the deformation history can be realistically reproduced. Furthermore, by comparing the average grain size and grain size distribution of the synthetic and actual microstructures, it was proven that the proposed model can be used to accurately predicts not only the shapes but also the quantitative features of microstructures. The results of this study demonstrate that FEM and AI technologies can be used sequentially to simulate the microstructural evolution as photorealistic images."
772,"The article presents the discussion on concept of academic integrity and the use of generative AI in written work created a significant disconnect. Topics include availability of AI tools for writing assistance presenting an opportunity for enhancing their work and improving efficiency; and investing in AI-powered plagiarism detection tools and training faculty members for recognizing signs of AI assistance."
773,"The article focuses on the impact of generative artificial intelligence (AI) tools like ChatGPT on higher education, examining the concerns and opportunities they present in terms of authentic learning, academic integrity, and instructional design."
774,"The article shows developments in the field of artificial intelligence (AI) despite a downturn in the technology industry. It informs about investors' capital spending in generative AI startups including Jasper, Stability AI, Character A.I., Replika and You.com in 78 deals in 2022, as well as several AI developments such as the DALL-E system and ChatGPT from OpenAI. It raises concern about generative AI copyright and competitive advantage of high technology firms over startups."
775,"The article focuses on a generative artificial intelligence (AI) technology that can help create songs with the help of computers without the necessary musical knowledge and training. Topics include music companies using this AI platform such as Boomy, Soundful and BandLab's SongStarter, the anxiety generated by this technology breakthrough among professional musicians, producers and others in the recorded-music industry, and the debate over the ethical and legal use of AI-generated music."
776,"The article focuses on the global economic outlook, climate change's impact on the economy, the G20 meeting on finance, the Asia-Pacific region's contribution to economic growth, the war in Ukraine's effects on the global economy, and the impact of generative AI on hiring in the investment management industry."
777,"The article focuses on artificial intelligence (AI), Chat Generative Pre-Trained Transformer (ChatGPT), in academic libraries. It explains how it can help with things like finding relevant articles and generating engaging courses. However, it raises questions about the model's biases and the risk of replacing human librarians. Academic librarians should use ChatGPT with caution and transparency to augment their services and accord with their objective of serving users' information needs."
778,"The article focuses on use of generative artificial intelligence (AI) such as ChatGPT for lawyers to perform a variety of tasks including due diligence, research and data analytics. It also presents views of Richard Susskind, technology adviser to the Lord Chief Justice of England, related to the use of AI to change their billing practices."
779,"The article focuses on the increasing adoption of generative artificial intelligence (AI) by different groups with an initial benefit for software developers and consumers in 2021-2023 and a shift towards technology giants in 2023. Topics include the evolving impact on share prices of major tech companies, the expected surge in enterprise adoption as companies outside the technology sector seek to cut costs and enhance productivity in 2024, and the factors driving this shift."
780,"The article discusses the potential of generative Artificial Intelligence (AI) in business, highlighting its promise and applications in customer operations, marketing, software engineering, and research. While major companies are experimenting with AI, many businesses remain cautious or reluctant due to concerns about technology glitches, legal risks, outdated systems, and worker resistance."
781,"The article discusses the declining customer satisfaction in recent years, despite the trend of companies claiming to be customer-centric. Several factors, including increased market concentration and the use of technology like chatbots and automation, have contributed to this decline. While generative artificial intelligence (AI) offers more human-like interactions, it may not be a complete substitute for human agents but can act as a complement to them, leading to increased productivity."
782,"The article discusses the use of generative AI, specifically ChatGPT, in the classroom and the need for educators to understand and harness its potential. The author emphasizes the importance of providing examples, training, and guidance on how to integrate AI into the curriculum, highlighting the value of teaching students to verify information sources and evaluate the truth in an era of misinformation."
783,"The article discusses the impact of generative artificial intelligence (AI) on the U.S.elections in 2024. Topics include the fear that AI-generated disinformation campaigns could supercharge the spread of false information; concerns about the quantity and quality of disinformation; the challenges of regulating AI-generated content on social media platforms; risks to the integrity of elections; and emphasizing that voters are hard to persuade on salient political issues."
784,"The article discusses the use of artificial intelligence (AI) generative adversarial network (GAN) algorithm known as BigGAN by the DeepMind technology company, with a particular focus on BigGAN's ability to create nature photography."
785,"The article discusses the American multinational technology company Facebook's development of artificial intelligence (AI) algorithm known as generative adversarial networks (GANs) to design clothing, referencing an article coauthored by Camille Couprie located at arxiv.org/abs/1804.00921. An overview of AI's creative ability in fashion design is provided."
786,"Microsoft 365 Copilot, which is powered by Microsoft's generative AI chatbot, will be integrated into OneNote, according to a blog post by OneNote product manager Greg Mace. Evernote: A personal take on two great note-taking apps: Evernote and Microsoft OneNote have taken different approaches in their quest to be the best note-taking app. (Microsoft hasn't released user numbers for OneNote, but between Microsoft 365 and Windows 10 and 11, more than a billion users likely have a version of it installed on their machines.) Note that after several years of Microsoft confusing everyone by having three different versions of OneNote, there is now only one version that the company will continue to update, called OneNote for Windows."
787,"The new ""plugin extensions"" essentially act as a bridge between Copilot and other software accessed by a business, allowing the AI assistant to tap into a wider range of data. Microsoft will let customers connect its Microsoft 365 Copilot to other applications via ""plugin"" integrations, effectively giving the generative AI assistant access to data from thousands of third-party software tools, the company announced today at its Build developer conference."
788,"The new ""plugin extensions"" essentially act as a bridge between Copilot and other software accessed by a business, allowing the AI assistant to tap into a wider range of data. Microsoft will let customers connect its Microsoft 365 Copilot to other applications via ""plugin"" integrations, effectively giving the generative AI assistant access to data from thousands of third-party software tools, the company announced today at its Build developer conference."
789,"Additionally, the new Contact Center AI functionality can incorporate AI models from customers themselves, offering an additional layer of flexibility. Zoom is entering into a strategic partnership with Anthropic that calls for the latter company's generative AI model to be integrated into Zoom's Contact Center portfolio."
790,"Apple co-founder Steve Wozniak has been touring the mediato discuss the perils of generative artificialintelligence (AI), warning people to be wary of itsnegative impacts. News Analysis 'AI is so intelligent it's open to the bad players, theones that want to trick you about who they are', theApple co-founder warns Apple Holic Appleholic, (noun), æp- l-h l- k: Animaginative person who thinks about what Apple is doing, why and where it isgoing."
791,"News Analysis Hundreds of customers will be able to access Copilot in apaid early access trial as the generative AI assistant isrolled out more widely across the Microsoft 365 appsuite. A Microsoft spokesperson described the Semantic Index asa ""pre-requisite"" to adopting Copilot within anorganization, enabling the AI assistant to ""deliverrelevant, actionable responses to prompts"" based on dataheld within the company."
792,"Informatica's AI copilot, also, has been devised in amanner that is similar to ClaireGPT, Walia said, addingthat copilot's capabilities are built on the company'sexperience in data management and data engineering. NEWS IDMC is a suite that sits on top of enterprisedatabases and manages data from various data sources byingesting, cataloging, and applying data governance rules Enterprise data management vendor Informatica will beadding generative AI capabilities to its Intelligent DataManagement Cloud (IDMC) via the addition of ClaireGPT andAI copilot."
793,"Members of the European Parliament (MEPs) have been debating the content of the EU's AI Act and have agreed on compromise amendments, with a few last-minute adjustments pertaining to generative AI. The European Parliament is set to formalize its position on what could be the world's first set of regulations for AI by a major legislative body, as EU lawmakers reached a provisional political agreement on Thursday."
794,"When Klarna Chief Marketing Officer David Sandström wanted to better understand the possibilities of AI and push the technology to its limits, he turned to social media, which is breeding a whole new crop of influencers who are attracting huge audiences with their AI tips and tricks. As generative AI tools like ChatGPT and DALL-E continue to demand attention, marketers are depending on social media to find out what they need to know - from conversing with like-minded professionals to understanding how to apply novel techniques offered by the technology."
795,"The article informs the relationship between art and the artist is closely intertwined, as the art piece is an expression of the artist's worldview, based on their experiences. It mentions the generative AI is challenging this view by generating images based on text labels and metadata associated with images in its training corpus. It highlight the figuring out which labels correspond to which images and styles of painting, AI tools can create remixed versions of art."
796,"Developers have managed tocreate apps to add ChatGPT to Apple's products. watchGPT,which was recently renamed Petey -- AI Assistant fortrademark reasons, is a great example. Apple Holic Opinion Generative AI and ChatGPT are consuming all the oxygen intech at present, so it probably isn't too surprising that whispersof a new, improved, Siri have begun to emerge."
797,"The other difference between the ChatGPT app that will be available in Slack and the publicly available model is how information is sourced. Slack is set to launch a ChatGPT app for Slack, allowing customers to use the generative AI technology to create conversation summaries, act as a research tool, and provide writing assistance."
798,"News A new AI-based extension to the company's Dynamics 365CRM and ERP platform can automatically generate answers tocustomer emails, suggest marketing and sales campaigns, andsummarize Teams chat threads and documents Microsoft today unveiled a generative AI chatbot forbusiness users that will draft email responses to customers,create textual summaries of Teams meetings, and generatemarketing and sales email campaigns. The automated email reply feature is now generallyavailable; on March 15, Microsoft will add enhancements tocreate customizable emails."
799,"The article shows the impact of automation, robotic technology as well as generative artificial intelligence (AI) on the jobs of blue-collar workers including in the hospitality industry. It reports the use of Smart bar systems, or automated cocktail dispensers, and HotSOS apps which facilitates housekeeping tasks, at the MGM Grand hotel and casino in Detroit, Michigan. It discusses the demand of labor unions to be part of conversations about the implementation and use of workplace technology."
800,"The article explores whether the call by computer scientist and Allen Institute for AI chief executive officer (CEO) Ali Farhadi to open source generative artificial intelligence (AI) would lead to more innovation and opportunity or would lead to digital harm. Cited are the warning by experts that the path to open source taken by Allen Institute is risky, the steps taken by Allen Institute to open source AI, and how it is working with others to move forward with its open vision."
801,"The article reviews Bard, a conversational generative artificial intelligence (AI) chatbot developed by Google that was upgraded in September 2023."
802,"The article states that recent release of ChatGPT, a language-generating tool from OpenAI, has raised concerns among humanities teachers that it may replace human intelligence and writing skills, making writing assignments redundant. However, if viewed as an opportunity rather than a threat, generative AI can help create students who are ready to think beyond statistically likely ways of thinking."
803,"The article highlights the emerging growth of generative artificial intelligence (AI). Focus is given on several generative AI projects including the Stable Diffusion open source image-generating algorithm developed by Stability AI, DALL-E 2 image generator from OpenAI and the Midjourney AI image generator. It refers to transparency as a safeguard that will keep generative AI from becoming a dangerous force."
804,"[Display omitted] Salt-inducible kinase 2 (SIK2) has been recognized as a potential target for anti-inflammation and anti-cancer therapy. In this paper, based on the binding pose of the reported compound (GLPG-3970, 3) with AlphaFold protein structure, a series of hinge cores were generated via AI-generative models (Chemistry42). After the molecular docking, synthesis, and biological evaluation, a hit molecule (7f) targeting SIK2 was obtained with a novel scaffold. Further SAR exploration led to the discovery of compound 8 g with superior potency against SIK2 compared with the reported inhibitors. Furthermore, 8 g also demonstrated excellent selectivity over other AMPK kinases, favorable in vitro ADMET profiles and decent cellular activities. This work provides an alternative approach to the discovery of novel and selective kinase inhibitors."
805,"The article focuses on examining the implications of open artificial intelligence (AI) Chat Generative Pre-Trained Transformer (ChatGPT)-3 in higher education, addressing concerns about authenticity detection in student work while proposing its potential as a tool within supportive learning environments for students with strong character. Topics include leveraging AI like ChatGPT to foster ethical use and acknowledging existing concerns regarding plagiarism and academic integrity."
806,"• Drug discovery is time consuming, expensive and experiences increasing challenges. • Generation of new drug candidates is one of the major challenges. • Quantum computing is the next most significant leap in disruptive technologies. • Quantum generative models theoretically outperform classical ones. • Novel quantum computing approaches may revolutionize generative chemistry. In recent years, drug discovery and life sciences have been revolutionized with machine learning and artificial intelligence (AI) methods. Quantum computing is touted to be the next most significant leap in technology; one of the main early practical applications for quantum computing solutions is predicted to be in quantum chemistry simulations. Here, we review the near-term applications of quantum computing and their advantages for generative chemistry and highlight the challenges that can be addressed with noisy intermediate-scale quantum (NISQ) devices. We also discuss the possible integration of generative systems running on quantum computers into established generative AI platforms."
807,"There is increasing concern and consternation about generative artificial intelligence (AI) programs and its potential impact on academia. This editorial addresses the potential impact of such programs on scientific publishing as it relates to the journal Biological Psychology. Using chatGPT as an example, it makes the case that a prime concern is its implications for facilitating plagiarism. It briefly outlines what is known about the algorithm of the GPT text model, and also the implications of its chatGPT front end, on being able to establish appropriate credit for ideas in text that it outputs. It is concluded that, at least for Biological Psychology , the expectation is that authors will be transparent about AI usage, will declare when AI is the source of an idea, and will redouble efforts to seek out and cite prior claims to ideas in the published literature when AI is involved."
808,"The article discusses research which suggested that generative artificial intelligence (AI) will have its biggest impact on white-collar workers with high-paying jobs in industries like banking and technology."
809,"The article focuses on the potential threat of generative Artificial Intelligence (AI) technology creating deepfakes to manipulate historical records, including the risks of altering past events and documents and the challenges of detecting fake historical content."
810,"The article focuses on the development of Artificial Intelligence (AI)-generated art and its distinctive characteristics. Topics include the ability of generative AI models to mimic various artistic styles, the emergence of a robotic school of artwork, and the influence of training data on the style and subject matter of AI-generated images."
811,"The article discusses the power of the pivot in gaining unexpected insights and changing perspectives. It highlights two keynote sessions, one focused on eliminating discrimination in endorsement deals for female athletes and the other on the negative impact of generative Artificial Intelligence (AI) on resources and communities. It emphasizes the importance of staying open to new ideas and learning from different perspectives."
812,"The article discusses the threats facing machine-learning or modern artificial-intelligence (AI) systems, particularly the cyber-attack called data poisoning. The attack involved modifying or adding extraneous information to AI data sets to make its algorithms learn harmful or undesirable behaviours. Also cited is how the rise of generative AI tools like ChatGPT and the image-making system DALL-E 2 makes data poisoning easier to implement."
813,"The article discusses how artificial intelligence (AI) is disrupting the entertainment industry, particularly video gaming. According to venture capital firm (VC) Andreessen Horowitz, generative AI will have the most impact in the games business. Also cited are the latest AI innovations by game developers like Ubisoft, Roblox, and Straight4 Studios, as well as the comment of King's technology head Steve Collins on the developments."
814,"The article discusses the positive and negative factors in using the ChatGPT generative artificial intelligence (AI) for planning practice. Topics covered include ChatGPT's performance of procedural writing tasks, its no-sense of truth and construction of sentences based on text patterns, its possible errors on specific places or events, and the risks these posed for planners. Also noted are organizations' need to invest in testing and training to achieve effective and ethical use of this tool."
815,"The article offers information on the generator network technology for creating images through artificial intelligence (AI) called generative adversarial network (GAN), which was created by researcher Marian Mazzone and colleagues at Rutgers University in New Jersey and social media company Facebook's AI lab in California. Details regarding the technology and its mechanism are presented."
816,"The article discusses about the increasing importance of artificial intelligence (AI) in local government and emphasizes the need for responsible use of AI technologies. Topic include It highlights the potential of generative AI (genAI) in councils and offers guidance on its responsible implementation, emphasizing the importance of considering social, economic, and environmental outcomes while avoiding overhyping the technology."
817,"Does ChatGPT spell curtains for Apple Business Chat? And just what will Apple's artificial intelligence teams be discussing at their imminent in-person internal AI summit at Apple Park? We come to bury bots, not to praise them The Generative AI tech certainly makes Siri look tame,though I don't think Siri is under immediate threat; Isuspect ChatGPT will first eat up the bot business, makingit an immediate threat to Apple Business Chat and others inthat space."
818,"The article discusses the bipartisan focus and deliberation in Washington, D.C. regarding the regulation of generative artificial intelligence (AI). Topics include the challenges faced by lawmakers; the industry's request for regulation, concerns over political use and misinformation; and potential regulatory measures such as voluntary standards, disclosure requirements, export controls and agency creation."
819,"Deep learning has recently been applied to various research areas of design optimization. This study presents the need and effectiveness of adopting deep learning for generative design (or design exploration) research area. This work proposes an artificial intelligent (AI)-based deep generative design framework that is capable of generating numerous design options which are not only aesthetic but also optimized for engineering performance. The proposed framework integrates topology optimization and generative models (e.g., generative adversarial networks (GANs)) in an iterative manner to explore new design options, thus generating a large number of designs starting from limited previous design data. In addition, anomaly detection can evaluate the novelty of generated designs, thus helping designers choose among design options. The 2D wheel design problem is applied as a case study for validation of the proposed framework. The framework manifests better aesthetics, diversity, and robustness of generated designs than previous generative design methods."
820,"• Objects in motion activate multiple cortical regions in every lobe of the human brain. • We outline an integrative computational architecture for this 'object-driven' cortex. • Architecture components derive from recent advances in machine learning and AI. • Points toward a neurally grounded, functional account of dynamic object cognition. Computational architecture for object-driven cortex Objects in motion activate multiple cortical regions in every lobe of the human brain. Do these regions represent a collection of independent systems, or is there an overarching functional architecture spanning all of object-driven cortex? Inspired by recent work in artificial intelligence (AI), machine learning, and cognitive science, we consider the hypothesis that these regions can be understood as a coherent network implementing an integrative computational system that unifies the functions needed to perceive, predict, reason about, and plan with physical objects—as in the paradigmatic case of using or making tools. Our proposal draws on a modeling framework that combines multiple AI methods, including causal generative models, hybrid symbolic-continuous planning algorithms, and neural recognition networks, with object-centric, physics-based representations. We review evidence relating specific components of our proposal to the specific regions that comprise object-driven cortex, and lay out future research directions with the goal of building a complete functional and mechanistic account of this system."
821,"The article discusses highlights of the 2023 annual Defcon hackers conference, held in Las Vegas, Nevada, wherein hackers in a red-teaming exercise tried to break through the safeguards of artificial intelligence (AI) programs to identify its vulnerabilities and find problems. Topics included safety and security flaws and defenses of AI, ability of generative AI to produce damaging lies, influence elections, ruin reputations and enable other harms, and cybersecurity attacks."
822,"The article reports on plans of technology companies to invest in generative artificial intelligence (AI) technology, which powers chatbots like ChatGPT. Topics discussed include companies that will increase investments to support AI work which include Google, Meta and Microsoft, economic benefits that AI is expected to deliver, according to McKinsey, the corporate consultancy, and financial performance forecast of chip maker Nvidia."
823,"The article discusses the invention option of generative artificial intelligence (AI) in 2023. Topics covered include the implications for the future path of innovation and global competitiveness by AI's role in invention, AI's production of unscripted results as it steps creatively into the shoes of a person, and the uncertain provision of patent protection to AI-generated inventions. Also noted is the view that patent denial to a creation-capable machine is discrimination."
824,"The article discusses the efforts by Amazon data scientists Marius Cotescu and Georgi Tinchev to teach the Alexa digital assistant to learn and master an Irish-accented English using artificial intelligence (AI) technology. The project showed the challenges in overcoming pronunciation issues and voice entanglement. Also cited is how the advent of generative AI technology could help address the voice entanglement issue."
825,"The article reports on the A.I. Act, a draft law passed by the European Parliament to regulate artificial intelligence (AI). Topics discussed include concerns about the technology, transparency requirements facing generative AI under Europe's bill, and remarks from Francine Bennett, acting director of the Ada Lovelace Institute."
826,"The article focuses on the growing group of entrepreneurs who left the San Franciso Bay Area in California during the COVID-19 pandemic who are eager to return driven by the boom of artificial intelligence (AI) in the area. Topics covered include the technology entrepreneurs not wanting to miss out on funding and networking, the impact of the pandemic to San Francisco's tech industry, and funding for generative AI, the latest wave of AI technology, announced by investors."
827,"Background: The emergence of systems based on large language models (LLMs) such as OpenAI's ChatGPT has created a range of discussions in scholarly circles. Since LLMs generate grammatically correct and mostly relevant (yet sometimes outright wrong, irrelevant or biased) outputs in response to provided prompts, using them in various writing tasks including writing peer review reports could result in improved productivity. Given the significance of peer reviews in the existing scholarly publication landscape, exploring challenges and opportunities of using LLMs in peer review seems urgent. After the generation of the first scholarly outputs with LLMs, we anticipate that peer review reports too would be generated with the help of these systems. However, there are currently no guidelines on how these systems should be used in review tasks. Methods: To investigate the potential impact of using LLMs on the peer review process, we used five core themes within discussions about peer review suggested by Tennant and Ross-Hellauer. These include 1) reviewers' role, 2) editors' role, 3) functions and quality of peer reviews, 4) reproducibility, and 5) the social and epistemic functions of peer reviews. We provide a small-scale exploration of ChatGPT's performance regarding identified issues. Results: LLMs have the potential to substantially alter the role of both peer reviewers and editors. Through supporting both actors in efficiently writing constructive reports or decision letters, LLMs can facilitate higher quality review and address issues of review shortage. However, the fundamental opacity of LLMs' training data, inner workings, data handling, and development processes raise concerns about potential biases, confidentiality and the reproducibility of review reports. Additionally, as editorial work has a prominent function in defining and shaping epistemic communities, as well as negotiating normative frameworks within such communities, partly outsourcing this work to LLMs might have unforeseen consequences for social and epistemic relations within academia. Regarding performance, we identified major enhancements in a short period and expect LLMs to continue developing. Conclusions: We believe that LLMs are likely to have a profound impact on academia and scholarly communication. While potentially beneficial to the scholarly communication system, many uncertainties remain and their use is not without risks. In particular, concerns about the amplification of existing biases and inequalities in access to appropriate infrastructure warrant further attention. For the moment, we recommend that if LLMs are used to write scholarly reviews and decision letters, reviewers and editors should disclose their use and accept full responsibility for data security and confidentiality, and their reports' accuracy, tone, reasoning and originality."
828,"The Bots Hack Hollywood: AI isn't about to change the movie industry. Soon, Hollywood could be in direct competitionwith generative AI tools, which,unlike self-driving cars or other long-promisedtechnologies that never quitearrive, are already here and getting betterfast. And forJames Cameron's Avatar: The Way ofWater, the FX studio Weta deployed AI togive Na'vi characters realistic facial musclesthat move in concert."
829,"The article informs that the introduction of generative artificial intelligence (AI) tools like ChatGPT has sparked a debate among journalism educators. Some express concerns about students misusing AI for reporting, while others see it as a valuable learning tool. Educators now face the challenge of teaching about AI authoritatively while navigating its potential pitfalls. AI models can generate responses based on available sources but struggle with citations and may fabricate information."
830,"The article focuses on the impact of artificial intelligence (AI) and generative artificial intelligence tools on book cover illustration, how these technologies are increasingly being used to create book covers, and the challenges faced by human artists in this evolving landscape."
831,"The article focuses on ""Artificial Flavors,"" a live demonstration of the limitations of AI's creative capabilities in writing a musical at 59E59 Theaters, where generative AI is used to create content that lacks the depth and authenticity of human creativity."
832,"The article focuses on Microsoft's robust quarterly sales performance, with revenue reaching 56.5 billion U.S. dollars, driven by investments in generative artificial intelligence (AI), notably in its Azure cloud computing product. Topics covered include the impact of AI on Microsoft's growth, the acceleration of its commercial cloud subscriptions, and the growing importance of AI-based software applications."
833,"The article offers global business news briefs as of May 20, 2023. Sam Altman, chief executive officer (CEO) at technology firm OpenAI, called for tightened law of developing generative artificial intelligence (AI). The economy of Japan grew outpacing gross domestic product (GDP) of America. Interest rate was raised by central bank of Argentina."
834,"The article offers the world business news briefs. Elon Musk, a businessman, launched a new artificial intelligence (AI) platform called TruthGpT as a rival to ChatGPT and other generative-AI bots. Fox News reached a settlement with Dominion Voting Systems over the broadcaster's fake claims that Dominion's machines helped steal the election in 2020 from Donald Trump. Apple opened its first stores in India."
835,"The article discusses the launch of chatbot ChatGPT in November 2022 and mentions efforts of social media firm Meta on launching artificial intelligence (AI) model LLAMA. Topics discussed include investment of software firm Microsoft on OpenAI, startup behind ChatGPT, role of generative AI into legal minefield, and increased share price of chipmaker Nvidia."
836,"With the development of artificial intelligence (AI), it gains in popularity to use AI to solve problems in civil engineering. However, the research on AI is mainly focused on the field of structural health monitoring, and less on the field of structural design. As one new direction in the AI domain, the generative adversarial network (GAN) method has developed rapidly, which is able to synthesize high-quality images based on demand. Therefore, it opens a new window for AI-aided automatic structure design. In this paper, a novel GAN-based method, namely FrameGAN, is proposed to realize automated component layout design of steel frame-brace structures. By collecting and processing drawings designed by senior structural engineers, FrameGAN and two mainstream GAN models (pix2pix and pix2pixHD) are tested and compared, which demonstrates the superiority of the proposed FrameGAN. In addition, the design results of FrameGAN are compared and analyzed with those of senior structural engineers based on two unique evaluation metrics, i.e., expert grading and objective comparison. The results show that the design of FrameGAN is close to that of structural engineers, which indicates the availability of FrameGAN in the component layout design of steel frame-brace structures. • A dual GAN model is proposed for the layout design of steel frame-brace structures. • Two GANs determine the layout of columns and braces respectively. • A dataset of steel frame-brace structures is established. • Two evaluation metrics are introduced to evaluate GAN performance in layout design."
837,"The article discusses issues on the use of artificial intelligence (AI) in the financial services industry, particularly the integration of the generative AI called ChatGPT on financial products. Other topics include the issues of humanity, security, and accessibility on the use of AI, and how AI could be beneficial in areas like retirement planning."
838,"The article raises concerns and fear about the use of generative artificial intelligence (AI) or similar technologies to replicate actors or produce screenplays. It informs about the objectives of the Writers Guild of America in its contract negotiations to regulate the use of material produced using AI and prohibit studios from using chatbots. It shows the anxiety of writers with ChatGPT's mimicking of the style of authors and its risks for their career prospects."
839,"The article reports on draft rules unveiled by the Cyberspace Administration of China to keep tight regulatory control over so-called generative artificial intelligence (AI) that can formulate text and pictures in response to a user's questions and prompts. Topics discussed include information on ChatGPT, a chatbot developed by the U.S. company OpenAI, remarks from Kendra Schaefer, head of tech policy at Trivium China, and difficulty of training AI systems to be consistently factual."
840,"The article reports that technology companies, Google and Microsoft, released their chatbots despite risks with their ethical guidelines and driven by a race to control generative artificial intelligence (AI). Topics discussed include estimated monthly users of ChatGPT, a chatbot released by San Francisco, California-based startup, OpenAI, email wrote by Sam Schillace, a technology executive at Microsoft, and issues raised on the safety of AI."
841,"The article takes a look at video-generation systems as the next development in generative artificial intelligence (AI) technology. It cautions about the probability of video-generation systems to replace editing skills. It describes the capabilities of the video-generation system developed by startup Runway, as well as the deepfake videos generated by AI service Midjourney which relies on a neural network."
842,"The article reports on the fund offerings to generative artificial intelligence (AI) startups given the increased interest of investors and potential of the technology. It attributes the increased funding race to the development of ChatGPT chatbot by OpenAI and cites the mismatch between opportunities in AI and money available to fund them. Among the AI startups that received funds from venture capitalists are Dust, Perplexity AI, and LangChain."
843,"Deep-learning workflows of microscopic image analysis are sufficient for handling the contextual variations because they employ biological samples and have numerous tasks. The use of well-defined annotated images is important for the workflow. Cancer stem cells (CSCs) are identified by specific cell markers. These CSCs were extensively characterized by the stem cell (SC)-like gene expression and proliferation mechanisms for the development of tumors. In contrast, the morphological characterization remains elusive. This study aims to investigate the segmentation of CSCs in phase contrast imaging using conditional generative adversarial networks (CGAN). Artificial intelligence (AI) was trained using fluorescence images of the Nanog-Green fluorescence protein, the expression of which was maintained in CSCs, and the phase contrast images. The AI model segmented the CSC region in the phase contrast image of the CSC cultures and tumor model. By selecting images for training, several values for measuring segmentation quality increased. Moreover, nucleus fluorescence overlaid-phase contrast was effective for increasing the values. We show the possibility of mapping CSC morphology to the condition of undifferentiation using deep-learning CGAN workflows."
844,"The article focuses on the use of generative Artificial intelligence (AI) in education, particularly in a flipped classroom setting, it highlights how this technology can enhance active learning and engagement. It reports that Ethan Mallick, a professor, sees a future where A.I. tools can assist with basic instruction and create engaging learning experiences, aligning well with established teaching concepts like the flipped classroom and active learning."
845,"The article focuses on how generative Artificial intelligence (AI) tools can aid students in studying by creating flashcards, quizzes, and providing study assistance, though it's crucial to ensure the information comes from trusted sources."
846,"The article focuses on the economic impact of generative artificial intelligence (AI), with McKinsey Global Institute estimating that it could add money of value to the global economy annually."
847,"The article explores the use of Artificial Intelligence in creating stunning photos, highlighting the introduction of generative AI features in Photoshop and the image generators DALL-E and Midjourney."
848,"The article explores liability challenges for tech companies, Artificial Intelligence tools' impact on harmful content, and the debate over Section 230's application to generative AI, raising questions about responsibility and content regulation."
849,"Currently, the use of dimensionality reduction techniques such as t-distributed stochastic neighbor embedding (t-SNE) to visualize data has become essential in dealing with large-scale datasets. The state-of-the-art t-SNE-based techniques rely on a variety of methods to take advantage of GPU parallelism. The major contributions of this work consist of a new approach named simulated wide-warp anchor t-SNE (SWW-AtSNE) that combines the SWW-tSNE technique with the anchor t-SNE (AtSNE) approach, which has better preservation of global structures than SWW-tSNE and a faster execution time than AtSNE. The preservation of global structures was measured with a new metric called medium neighborhood preservation (MNP). We also propose and study the adaptations of the technique simulated wide-warp t-SNE (SWW-tSNE). The adaptations consist of using a preprocessing technique or changing the initialization method using principal component analysis (PCA). The proposal of SWW-AtSNE and the adaptations of SWW-tSNE also include the possibility of performing dimensionality reduction in two dimensions in addition to three dimensions. Furthermore, this research compares different t-SNE-based techniques using large-scale datasets. Two essential criteria are used in the comparisons: the preservation of global and local structures. Moreover, this paper compares seven methods through two AI applications: reinforcement learning and generative adversarial networks (GANs). The experimental results show that strategies such as the AtSNE method could improve dimensionality reduction quality, considering the preservation of global structures. However, it cannot achieve better results than other approaches, such as using principal component analysis in the initialization of t-SNE. Nevertheless, the ideas of both methods could be merged into a unique technique in future studies. • Fast SWW-AtSNE method for dimensionality reduction preserves Global/Local structures. • The introduction of a new metric to quantify the global structure preservation. • Analysis of GPU t-SNE based methods in real-world applications with large datasets. • PCA initialization in SWW-tSNE is fundamental to preserve global structures. • UMAP and AtSNE does not preserve global structures better than SWW-tSNE."
850,"• A DEM pavement paving compaction model is developed. • Digital aggregate database is established by using imaging technology. • The aggregate database is expanded via AI method. • The paving compaction model is calibrated and then used for compaction analysis with different aggregate gradations. Pavement compaction cannot be neglected during the motorway manufacture stage because it can determine pavement service quality and durability. Concerning the compaction scenario, the paving compaction is responsible for offering the preliminary strength of the pavement. Ignoring paving compaction quality control can lead to over compaction. This paper introduces an integral system to study and simulate the paving compaction of asphalt motorways in Discrete Element Model two-dimensional (DEM2D). This method includes the whole procedure from aggregate image acquisition database establishment to the DEM2D simulation of paving compaction. To this end, this study fulfils the creation of the aggregate database applied in DEM via the Aggregate Image Measuring System (AIMS) method. In addition, the artificial intelligent (AI) technology called Generative Adversarial Networks (GANs) method is proposed to expand the developed DEM aggregate database. Three different approaches are applied to calibrate the accuracy of the extended database. According to the aggregate database, the pavement paving compaction with different aggregate gradations can be simulated in DEM2D."
851,"Existing systems that employ Automatic Speech Recognition (ASR) technology to retrieve information from the BIM model fail to provide remote interaction, retrieve a wide range of data, and automate the entire process. This is particularly a problem for users with disabilities. The paper offers a two-way, automated, and agnostic solution to this theoretical and methodological gap. A 'Proof of Concept' prototype was developed using Amazon Alexa – as the AI voice assistant platform – to test the applicability. The outcome shows that the created and the retrieved information is valid. Furthermore, there is a high level of interoperability among the components of the proposed solution, including the AI voice assistant interface and mediation environment to convert verbal requests and retrieve information to CSV files. Future research will extend the created solution to retrieve and access information from a BIM cloud model. • An automated data retrieval-based AI voice assistant for BIM users is provided. • Interacting with the BIM model remotely via a voice assistant interface has been enabled. • Practitioners with vision disabilities can receive and add information to BIM models. • Novice BIM users can practice BIM features and retrieve information with minimal experience level."
852,"We present an implementation of an explainable and physics-aware machine learning model capable of inferring the underlying physics of high-energy particle collisions using the information encoded in the energy-momentum four-vectors of the final state particles. We demonstrate the proof-of-concept of our White Box AI approach using a Generative Adversarial Network (GAN) which learns from a DGLAP-based parton shower Monte Carlo event generator. The constrained generator network architecture mimics the structure of a parton shower exhibiting similarities with Recurrent Neural Networks (RNNs). We show, for the first time, that our approach leads to a network that is able to learn not only the final distribution of particles, but also the underlying parton branching mechanism, i.e. the Altarelli-Parisi splitting function, the ordering variable of the shower, and the scaling behavior. While the current work is focused on perturbative physics of the parton shower, we foresee a broad range of applications of our framework to areas that are currently difficult to address from first principles in QCD. Examples include nonperturbative and collective effects, factorization breaking and the modification of the parton shower in heavy-ion, and electron-nucleus collisions."
853,"The article focuses on the impact of generative artificial intelligence (AI) on jobs and explores different perspectives on its effects. Topics include the potential for AI to automate tasks and replace human labor, the possibility of AI complementing human work and increasing productivity, and the creation of new jobs and opportunities through technological advancements."
854,"The article focuses on the challenges of ensuring that AI chatbots provide accurate information and avoid fabrications. Topics include the inaccuracies of chatbots, their reliance on generative AI technology, concerns about the reliability of AI systems, and efforts by companies like OpenAI, Google, and Microsoft to improve accuracy while avoiding over-reliance on the systems."
855,"More than 40% of nearly 12,000 workers said they use ChatGPT or other AI tools at work, according to a January survey by Fishbowl, the workplace chat application. Keywords: wsjlifework; Computers/Consumer Electronics; Software; Applications Software; Artificial Intelligence Technologies; Computing; Technology; Capacity/Facilities; Automation; Corporate/Industrial News EN wsjlifework Computers/Consumer Electronics Software Applications Software Artificial Intelligence Technologies Computing Technology Capacity/Facilities Automation Corporate/Industrial News N.PAG N.PAG 1 03/24/23 20230323 NES 230323 As bosses fret over generative AI, many employees embrace it Office drama is brewing around when employees - and their bosses - are allowed to use ChatGPT at work."
856,"The article offers information about experimental medicines, cancer drug development, and diagnosis. It provides details about a study conducted by Insilico Medicine, a Baltimore-based biotechnology research company, aiming to revolutionize drug development by reducing the time necessary for research with the help of artificial intelligence (AI). Other information related to generative adversarial networks and computer-tested approach is presented."
857,"• A generative AI PixelCNN model is used to simulate amorphous materials. • Our model produces Markov chains which converge to a unique physical distribution. • An autoregressive AI 'black box' algorithm is made transparent and reliable. We have recently demonstrated an effective protocol for the simulation of amorphous molecular configurations using the PixelCNN generative model (Kilgour et al. (2020) [1]). The morphological sampling of amorphous materials via such an autoregressive generation protocol sidesteps the high computational costs associated with simulating amorphous materials at scale, enabling practically unlimited structural sampling based on only small-scale experimental or computational training samples. An important question raised but not rigorously addressed in that report was whether this machine learning approach could be considered a physical simulation in the conventional sense. Here we answer this question by detailing the inner workings of the underlying algorithm that we refer to as the Morphological Autoregression Protocol or MAP. We identify the key object of physical interest for modelling of amorphous structures: an all-order correlation cluster expansion that fully captures structural information for amorphous substances, outline how it may be efficiently modelled by a neural network and study the convergence properties of a discrete, autoregressive sampling protocol guided by such a model. We find that such a MAP sequence constitutes a converging Markov process, guaranteed to realize a unique equilibrium distribution, and illustrate relevant concepts with abstract toy-model numerical experiments. This work lays the theoretical foundation for physically sound autoregressive sampling."
858,"ChatGPT was released to the public in November 30, 2022. This study examines how ChatGPT can be used by educators and students to promote learning and what are the challenges and limitations. This study is unique in providing one of the first systematic reviews using peer review studies to provide an early examination of the field. Using PRISMA principles, 44 articles were selected for review. Grounded coding was then used to reveal trends in the data. The findings show that educators can use ChatGPT for teaching support, task automation, and professional development. These were further delineated further by axial sub codes. Eight student uses were 24/7 support, explain difficult concepts, conversational partner, personalized feedback and materials, provide writing support, offer self-assessment, facilitate engagement, and self-determination. In addition to be affordances of the AI, the data from the articles also showed limitations to ChatGPT and misuses, specifically, inaccuracies and hallucinations, potential bias, and tool limitations. Misuses are plagiarism and cheating, privacy issues and spread of false information. This study is a springboard for researchers, practitioners, policy makers and funders in understanding the emerging state of the field of ChatGPT."
859,"Developing English speaking skills can be challenging for many English language learners. The advent of generative artificial intelligence (GAI) has prompted the emergence of a growing number of artificial intelligence (AI)-powered chatbots designed to tackle these challenges. One popular tool is ‘Call Annie,’ a GAI video chatbot that can act as a virtual assistant, enabling users to engage in immersive video calls with AI avatars. This technology review discusses its functionality, how it can be used in supporting learners’ language development, how teachers can collaborate with it in class and its potential limitations."
860,"This new wave of generative AI systems won't rival artists;instead, artists will adopt these tools as new canvases, newbrushes and new palettes. Weekly Winter's latest internet crazy came in the form of anAI artist which can take simple instructions and produce itsown visual interpretations."
861,"Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly. In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention."
862,"The article informs that advancements in generative artificial intelligence (AI) mean that robots are now coming for artists' jobs. AI-generated images, created with simple text prompts, are winning art contests and promoting popular culture, leaving human artists worried about their futures. One AI tool, Stable Diffusion, was trained to recognize patterns and styles by analyzing billions of images collected from the public internet, including works by artist Greg Rutkowski."
863,"Many computational tools are usually trained using human-curated data set of design proposals. However, this approach can limit system capabilities to generate creative designs since human knowledge of the solution space is already embedded in the training process. In this paper, we show how by using a flexible design tool that can also be used by humans, an artificial agent can learn to generate creative designs with any prior knowledge of the solution space. Our results show how our agent is able to create human-level design proposals in terms of performance and novelty. Based on these results, we discuss the importance of defining a shared design language and tools in order to support human-AI collaboration in creative scenarios. • Common generative design language to construct shapes for humans and artificial agents. • Exploration of design solutions space through a physically-based environment. • Shape generation algorithm matching human-generated proposals. • Evaluation study based on performance and novelty. • Shape similarity analysis based on a human perception test online."
864,"Automated site planning, powered by deep generative methods, excels in creating solutions responsive to exiting city structures but often overlooks user-specific design scenarios, leading to less performative solutions across varied urban contexts. Overcoming this challenge requires integrating domain knowledge and nuances of the built environment to enhance context-awareness in automated site planning. This study therefore proposes the context-aware site planning generative adversarial networks (CAIN-GAN) framework. In the case study of New York City (NYC), CAIN-GAN demonstrates its capability to not only synthesize visually realistic and semantically reasonable design solutions, but also evaluate their performance in urban sustainability for informed decision-making. This context-aware, learning-based, data-driven, and user-guided generation process signifies a pivotal advancement in more performative and tailored design solutions. Future studies will focus on refining the CAIN-GAN framework to accommodate diverse user-centric design needs and enhance human-machine interaction in urban development. • A deep learning-based framework is proposed for automated site planning. • The end-to-end system generates high-quality design solutions for decision-making. • Performance is enhanced by integrating surrounding context and planning guidance. • The model benefits from a progressive learning strategy and an attention mechanism. • The generalizability facilitates rapid design generation in new areas."
865,"[Display omitted] Machine learning (ML) has enabled ground-breaking advances in the healthcare and pharmaceutical sectors, from improvements in cancer diagnosis, to the identification of novel drugs and drug targets as well as protein structure prediction. Drug formulation is an essential stage in the discovery and development of new medicines. Through the design of drug formulations, pharmaceutical scientists can engineer important properties of new medicines, such as improved bioavailability and targeted delivery. The traditional approach to drug formulation development relies on iterative trial-and-error, requiring a large number of resource-intensive and time-consuming in vitro and in vivo experiments. This review introduces the basic concepts of ML-directed workflows and discusses how these tools can be used to aid in the development of various types of drug formulations. ML-directed drug formulation development offers unparalleled opportunities to fast-track development efforts, uncover new materials, innovative formulations, and generate new knowledge in drug formulation science. The review also highlights the latest artificial intelligence (AI) technologies, such as generative models, Bayesian deep learning, reinforcement learning, and self-driving laboratories, which have been gaining momentum in drug discovery and chemistry and have potential in drug formulation development."
866,"• Protein language models were used to design new brazzein homologs. • Unexpected beneficial mutations were uncovered with this approach. • A more heat-resistant and potentially more palatable brazzein variant, V23, is characterised. • An efficient purification method using GRAS Lactococcus lactis was also established. With growing concerns over the health impact of sugar, brazzein offers a viable alternative due to its sweetness, thermostability, and low risk profile. Here, we demonstrated the ability of protein language models to design new brazzein homologs with improved thermostability and potentially higher sweetness, resulting in new diverse optimized amino acid sequences that improve structural and functional features beyond what conventional methods could achieve. This innovative approach resulted in the identification of unexpected mutations, thereby generating new possibilities for protein engineering. To facilitate the characterization of the brazzein mutants, a simplified procedure was developed for expressing and analyzing related proteins. This process involved an efficient purification method using Lactococcus lactis (L. lactis), a generally recognized as safe (GRAS) bacterium, as well as taste receptor assays to evaluate sweetness. The study successfully demonstrated the potential of computational design in producing a more heat-resistant and potentially more palatable brazzein variant, V23."
867,"The optimal liability framework for AI systems remains an unsolved problem across the globe. With ChatGPT and other large generative models taking the technology to the next level, solutions are urgently needed. In a much-anticipated move, the European Commission advanced two proposals outlining the European approach to AI liability in September 2022: a novel AI Liability Directive (AILD) and a revision of the Product Liability Directive (PLD). They constitute the final cornerstone of AI regulation in the EU. Crucially, the liability proposals and the proposed EU AI Act are inherently intertwined: the latter does not contain any individual rights of affected persons, and the former lack specific, substantive rules on AI development and deployment. Taken together, these acts may well trigger a ""Brussels effect"" in AI regulation, with significant consequences for the US and other countries. Against this background, this paper makes three novel contributions. First, it examines in detail the liability proposals and shows that, while making steps in the right direction, they ultimately represent a half-hearted approach: if enacted as foreseen, AI liability in the EU will primarily rest on disclosure of evidence mechanisms and a set of narrowly defined presumptions concerning fault, defectiveness and causality. Hence, second, the article suggests amendments to the proposed AI liability framework. They are collected in a concise Annex at the end of the paper. I argue, inter alia, that the dichotomy between the fault-based AILD Proposal and the supposedly strict liability PLD Proposal is fictional and should be abandoned; that an EU framework for AI liability should comprise one fully harmonizing regulation instead of two insufficiently coordinated directives; and that the current proposals unjustifiably collapse fundamental distinctions between social and individual risk by equating high-risk AI systems in the AI Act with those under the liability framework. Third, based on an analysis of the key risks AI poses, the final part of the paper maps out a road for the future of AI liability and regulation, in the EU and beyond. More specifically, I make four key proposals. Effective compensation should be ensured by combining truly strict liability for certain high-risk AI systems with general presumptions of defectiveness, fault and causality in cases involving SMEs or non-high-risk AI systems. The paper introduces a novel distinction between illegitimate- and legitimate-harm models to delineate strict liability's scope. Truly strict liability should be reserved for high-risk AI systems that, from a social perspective, should not cause harm (illegitimate-harm models, e.g., autonomous vehicles or medical AI). Models meant to cause some unavoidable harm by ranking and rejecting individuals (legitimate-harm models, e.g., credit scoring or insurance scoring) may merely face rebuttable presumptions of defectiveness and causality. General-purpose AI systems and Foundation Models should only be subjected to high-risk regulation, including liability for high-risk AI systems, in specific high-risk use cases for which they are deployed. Consumers, in turn, ought to be liable based on regular fault, in general. Furthermore, innovation and legal certainty should be fostered through a comprehensive regime of safe harbours, defined quantitatively to the best extent possible. Moreover, trustworthy AI remains an important goal for AI regulation. Hence, the liability framework must specifically extend to non-discrimination cases and provide for clear rules concerning explainability (XAI). Finally, awareness for the climate effects of AI, and digital technology more broadly, is rapidly growing in computer science. In diametrical opposition to this shift in discourse and understanding, however, EU legislators have long neglected environmental sustainability in both the draft AI Act and the proposed liability regime. To counter this, I propose to jump-start sustainable AI regulation via sustainability impact assessments in the AI Act and sustainable design defects in the liability regime. In this way, the law may help spur not only fair AI and XAI, but also sustainable AI (SAI)."
868,"The article reports on the expectation by Christie's New York as it formally tests the art market's interest in artificial intelligence (AI) art with the auction of ""Edmond de Belamy, from La Famille de Belamy"" a portrait generated by algorithm produced through the collaboration by members of Obvious, in October 2018. Topics include the challenge traditional auction houses face and the criticism on the use of Generative Adversarial Networks and AI technology in art."
869,"To incorporate metabolic, bioremedial functions into the performance of buildings and to balance generative architecture's dominant focus on computational programming and digital fabrication, this text first discusses hybridizing Maturana and Varela's biological theory of autopoiesis with Andy Clark's hypothesis of extended cognition. Doing so establishes a procedural protocol to research biological domains from which design could source data/insight from biosemiotics, sensory plants, and biocomputation. I trace computation and botanic simulations back to Alan Turing's little-known 1950s Morphogenetic drawings, reaction-diffusion algorithms, and pioneering artificial intelligence (AI) in order to establish bioarchitecture's generative point of origin. I ask provocatively, Can buildings think? as a question echoing Turing's own, ""Can machines think?"""
